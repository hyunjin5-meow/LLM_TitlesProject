title,abstract,rule_score,zs_playful_prob,playful_zs_flag,rule_norm,ensemble_score,playful_flag
Deterministic and Discriminative Imitation (D2-Imitation): Revisiting Adversarial Imitation for Sample Efficiency,"Sample efficiency is crucial for imitation learning methods to be applicable in real-world applications. Many studies improve sample efficiency by extending adversarial imitation to be off-policy regardless of the fact that these off-policy extensions could either change the original objective or involve complicated optimization. We revisit the foundation of adversarial imitation and propose an off-policy sample efficient approach that requires no adversarial training or min-max optimization. Our formulation capitalizes on two key insights: (1) the similarity between the Bellman equation and the stationary state-action distribution equation allows us to derive a novel temporal difference (TD) learning approach; and (2) the use of a deterministic policy simplifies the TD learning. Combined, these insights yield a practical algorithm, Deterministic and Discriminative Imitation (D2-Imitation), which oper- ates by first partitioning samples into two replay buffers and then learning a deterministic policy via off-policy reinforcement learning. Our empirical results show that D2-Imitation is effective in achieving good sample efficiency, outperforming several off-policy extension approaches of adversarial imitation on many control tasks.",0.8,0.7775285243988037,True,0.3318122278318339,0.5546703761153188,True
Automated Negotiating Agents Competition (ANAC),"
 
 The annual International Automated Negotiating Agents Competition (ANAC) is used by the automated negotiation research community to benchmark and evaluate its work andto challenge itself. The benchmark problems and evaluation results and the protocols and strategies developed are available to the wider research community.
 
",0.8,0.8293817043304443,True,0.3318122278318339,0.5805969660811391,True
Personalized Robot Tutoring Using the Assistive Tutor POMDP (AT-POMDP),"Selecting appropriate tutoring help actions that account for both a student’s content mastery and engagement level is essential for effective human tutors, indicating the critical need for these skills in autonomous tutors. In this work, we formulate the robot-student tutoring help action selection problem as the Assistive Tutor partially observable Markov decision process (AT-POMDP). We designed the AT-POMDP and derived its parameters based on data from a prior robot-student tutoring study. The policy that results from solving the AT-POMDP allows a robot tutor to decide upon the optimal tutoring help action to give a student, while maintaining a belief of the student’s mastery of the material and engagement with the task. This approach is validated through a between-subjects field study, which involved 4th grade students (n=28) interacting with a social robot solving long division problems over five sessions. Students who received help from a robot using the AT-POMDP policy demonstrated significantly greater learning gains than students who received help from a robot with a fixed help action selection policy. Our results demonstrate that this robust computational framework can be used effectively to deliver diverse and personalized tutoring support over time for students.",0.8,0.8154509663581848,True,0.3318122278318339,0.5736315970950093,True
Visual Pivoting for (Unsupervised) Entity Alignment,"This work studies the use of visual semantic representations to align entities in heterogeneous knowledge graphs (KGs). Images are natural components of many existing KGs. By combining visual knowledge with other auxiliary information, we show that the proposed new approach, EVA, creates a holistic entity representation that provides strong signals for cross-graph entity alignment. Besides, previous entity alignment methods require human labelled seed alignment, restricting availability. EVA provides a completely unsupervised solution by leveraging the visual similarity of entities to create an initial seed dictionary (visual pivots). Experiments on benchmark data sets DBP15k and DWY15k show that EVA offers state-of-the-art performance on both monolingual and cross-lingual entity alignment tasks. Furthermore, we discover that images are particularly useful to align long-tail KG entities, which inherently lack the structural contexts necessary for capturing the correspondences. Code release: https://github.com/cambridgeltl/eva; project page: http://cogcomp.org/page/publication view/927.",0.8,0.7788591980934143,True,0.3318122278318339,0.5553357129626241,True
Interleave Variational Optimization with Monte Carlo Sampling: A Tale of Two Approximate Inference Paradigms,"Computing the partition function of a graphical model is a fundamental task in probabilistic inference. Variational bounds and Monte Carlo methods, two important approximate paradigms for this task, each has its respective strengths for solving different types of problems, but it is often nontrivial to decide which one to apply to a particular problem instance without significant prior knowledge and a high level of expertise. In this paper, we propose a general framework that interleaves optimization of variational bounds (via message passing) with Monte Carlo sampling. Our adaptive interleaving policy can automatically balance the computational effort between these two schemes in an instance-dependent way, which provides our framework with the strengths of both schemes, leads to tighter anytime bounds and an unbiased estimate of the partition function, and allows flexible tradeoffs between memory, time, and solution quality. We verify our approach empirically on real-world problems taken from recent UAI inference competitions.",0.8,0.8714087009429932,True,0.3318122278318339,0.6016104643874135,True
The Psychology of Semantic Spaces: Experiments with Positive Emotion (Student Abstract),"Psychological concepts can help computational linguists to better model the latent semantic spaces of emotions, and understand the underlying states motivating the sharing or suppressing of emotions. This abstract applies the understanding of agency and social interaction in the happiness semantic space to its role in positive emotion. First, BERT-based fine-tuning yields an expanded seed set to understand the vocabulary of the latent space. Next, results benchmarked against many emotion datasets suggest that the approach is valid, robust, offers an improvement over direct prediction, and is useful for downstream predictive tasks related to psychological states.",0.8,0.7693610787391663,True,0.3318122278318339,0.5505866532855,True
What about Inputting Policy in Value Function: Policy Representation and Policy-Extended Value Function Approximator,"We study Policy-extended Value Function Approximator (PeVFA) in Reinforcement Learning (RL), which extends conventional value function approximator (VFA) to take as input not only the state (and action) but also an explicit policy representation. Such an extension enables PeVFA to preserve values of multiple policies at the same time and brings an appealing characteristic, i.e., value generalization among policies. We formally analyze the value generalization under Generalized Policy Iteration (GPI). From theoretical and empirical lens, we show that generalized value estimates offered by PeVFA may have lower initial approximation error to true values of successive policies, which is expected to improve consecutive value approximation during GPI. Based on above clues, we introduce a new form of GPI with PeVFA which leverages the value generalization along policy improvement path. Moreover, we propose a representation learning framework for RL policy, providing several approaches to learn effective policy embeddings from policy network parameters or state-action pairs. In our experiments, we evaluate the efficacy of value generalization offered by PeVFA and policy representation learning in several OpenAI Gym continuous control tasks. For a representative instance of algorithm implementation, Proximal Policy Optimization (PPO) re-implemented under the paradigm of GPI with PeVFA achieves about 40% performance improvement on its vanilla counterpart in most environments.",1.0,0.7967410087585449,True,0.3775406687981454,0.5871408387783452,True
Moving-Landmark Assisted Distributed Learning Based Decentralized Cooperative Localization (DL-DCL) with Fault Tolerance,"This paper considers the problem of cooperative localization of multiple robots under uncertainty, communicating over a partially connected, dynamic communication network and assisted by an agile landmark. Each robot owns an IMU and a relative pose sensing suite, which can get faulty due to system or environmental uncertainty, and therefore exhibit large bias in their estimation output. For the robots to localize accurately under sensor failure and system or environmental uncertainty, a novel Distributed Learning based Decentralized Cooperative Localization (DL-DCL) algorithm is proposed that involves real-time learning of an information fusion strategy by each robot for combining pose estimates from its own sensors as well as from those of its neighboring robots, and utilizing the moving landmark's pose information as a feedback to the learning process. Convergence analysis shows that the learning process converges exponentially under certain reasonable assumptions. Simulations involving sensor failures inducing around 40-60 times increase in the nominal bias show DL-DCL's estimation performance to be approximately 40% better than the well-known covariance-based estimate fusion methods. For the evaluation of DL-DCL's implementability and fault-tolerance capability in practice, a high-fidelity simulation is carried out in Gazebo with ROS2.",0.8,0.8062965273857117,True,0.3318122278318339,0.5690543776087728,True
High-Confidence Off-Policy (or Counterfactual) Variance Estimation,"Many sequential decision-making systems leverage data collected using prior policies to propose a new policy. For critical applications, it is important that high-confidence guarantees on the new policy’s behavior are provided before deployment, to ensure that the policy will behave as desired. Prior works have studied high-confidence off-policy estimation of the expected return, however, high-confidence off-policy estimation of the variance of returns can be equally critical for high-risk applications. In this paper we tackle the previously open problem of estimating and bounding, with high confidence, the variance of returns from off-policy data.",0.8,0.8194615244865417,True,0.3318122278318339,0.5756368761591878,True
Is Each Layer Non-trivial in CNN? (Student Abstract),"Convolutional neural network (CNN) models have achieved
great success in many fields. With the advent of ResNet, networks
used in practice are getting deeper and wider. However,
is each layer non-trivial in networks? To answer this
question, we trained a network on the training set, then we
replace the network convolution kernels with zeros and test
the result models on the test set. We compared experimental
results with baseline and showed that we can reach similar or
even the same performances. Although convolution kernels
are the cores of networks, we demonstrate that some of them
are trivial and regular in ResNet.",1.1,0.7431848645210266,True,0.401312339887548,0.5722486022042873,True
Fuzzy C-means: Differences on Clustering Behavior between High Dimensional and Functional Data (Student Abstract),"Fuzzy c-means (FCM) is a generalization of the classical k-means clustering algorithm to the case where an observation can belong to several clusters at the same time.
The algorithm was previously observed to have initialization problems when the number of desired clusters or the number of dimensions of the data are high.
We have tested FCM against clustering problems with functional data, generated from stationary Gaussian processes, and thus in principle infinite-dimensional.
We observed that when the data is more functional in nature, which can be obtained by tuning the length-scale parameter of the Gaussian process, the aforementioned problems do not appear.
This not only indicates that FCM is suitable as a clustering method for functional data, but also illustrates how functional data differs from traditional multivariate data.
In addition this seems to suggest a qualitative way to measure the latent dimensionality of the functional distribution itself.",1.8,0.9464176297187805,True,0.574442516811659,0.7604300732652198,True
"Dude, Where's My Robot?: A Localization Challenge for Undergraduate Robotics","
 
 I present a robotics localization challenge based on the inexpensive Neato XV robotic vacuum cleaner platform. The challenge teaches skills such as computational modeling, probabilistic inference, efficiency vs. accuracy tradeoffs, debugging, parameter tuning, and benchmarking of algorithmic performance. Rather than allowing students to pursue any localization algorithm of their choosing, here, I propose a challenge structured around the particle filter family of algorithms. This additional scaffolding allows students at all levels to successfully implement one approach to the challenge, while providing enough flexibility and richness to enable students to pursue their own creative ideas. Additionally, I provide infrastructure for automatic evaluation of systems through the collection of ground truth robot location data via ceiling-mounted location tags that are automatically scanned using an upward facing camera attached to the robot. The robot and supporting hardware can be purchased for under $400 dollars, and the challenge can even be run without any robots at all using a set of recorded sensor traces.
 
",1.1,0.957172691822052,True,0.401312339887548,0.6792425158548,True
Exploiting Time-Series Image-to-Image Translation to Expand the Range of Wildlife Habitat Analysis,"Characterizing wildlife habitat is one of the main topics in animal ecology. Locational data obtained from radio tracking and field observation are widely used in habitat analysis. However, such sampling methods are costly and laborious, and insufficient relocations often prevent scientists from conducting large-range and long-term research. In this paper, we innovatively exploit the image-to-image translation technology to expand the range of wildlife habitat analysis. We proposed a novel approach for implementing time-series imageto-image translation via metric embedding. A siamese neural network is used to learn the Euclidean temporal embedding from the image space. This embedding produces temporal vectors which bring time information into the adversarial network. The well-trained framework could effectively map the probabilistic habitat models from remote sensing imagery, helping scientists get rid of the persistent dependence on animal relocations. We illustrate our approach in a real-world application for mapping the habitats of Bar-headed Geese at Qinghai Lake breeding ground. We compare our model against several baselines and achieve promising results.",1.0,0.8372801542282104,True,0.3775406687981454,0.607410411513178,True
Planning with Pixels in (Almost) Real Time,"
 
 Recently, width-based planning methods have been shown to yield state-of-the-art results in the Atari 2600 video games. For this, the states were associated with the (RAM) memory states of the simulator. In this work, we consider the same planning problem but using the screen instead. By using the same visual inputs, the planning results can be compared with those of humans and learning methods. We show that the planning approach, out of the box and without training, results in scores that compare well with those obtained by humans and learning methods, and moreover, by developing an episodic, rollout version of the IW(k) algorithm, we show that such scores can be obtained in almost real time.
 
",0.8,0.868636429309845,True,0.3318122278318339,0.6002243285708394,True
Generate (non-software) Bugs to Fool Classifiers,"In adversarial attacks intended to confound deep learning models, most studies have focused on limiting the magnitude of the modification so that humans do not notice the attack. On the other hand, during an attack against autonomous cars, for example, most drivers would not find it strange if a small insect image were placed on a stop sign, or they may overlook it. In this paper, we present a systematic approach to generate natural adversarial examples against classification models by employing such natural-appearing perturbations that imitate a certain object or signal. We first show the feasibility of this approach in an attack against an image classifier by employing generative adversarial networks that produce image patches that have the appearance of a natural object to fool the target model. We also introduce an algorithm to optimize placement of the perturbation in accordance with the input image, which makes the generation of adversarial examples fast and likely to succeed. Moreover, we experimentally show that the proposed approach can be extended to the audio domain, for example, to generate perturbations that sound like the chirping of birds to fool a speech classifier.",0.8,0.9662318229675293,True,0.3318122278318339,0.6490220253996816,True
XDC: Adversarial Adaptive Cross Domain Face Clustering (Student Abstract),"In this work we propose a scheme, called XDC, that uses adversarial learning to train an adaptive cross domain clustering model. XDC trains a classifier on a labeled dataset and assigns labels to an unlabeled dataset. We benefit from adversarial learning such that the target dataset takes part in the training. We also use an existing image classifiers in a plug-and-play fashion (i.e, it can be replaced with any other image classifier). Unlike existing works we update the parameters of the encoder and expose the target dataset to the model during training. We apply our model on two face dataset and one non-face dataset and obtain comparable results with state-of-the-art face clustering models.",0.8,0.7972522974014282,True,0.3318122278318339,0.564532262616631,True
Adaptive Safe Behavior Generation for Heterogeneous Autonomous Vehicles Using Parametric-Control Barrier Functions (Student Abstract),"Control Barrier Functions have been extensively studied to ensure guaranteed safety during inter-robot interactions. In this paper, we introduce the Parametric-Control Barrier Function (Parametric-CBF), a novel variant of the traditional Control Barrier Function to extend its expressivity in describing different safe behaviors among heterogeneous robots. A parametric-CBF based framework is presented to enable the ego robot to model the neighboring robots behavior and further improve the coordination efficiency during interaction while enjoying formally provable safety guarantees. We demonstrate the usage of Parametric-CBF in behavior prediction and adaptive safe control in the ramp merging scenario.",1.8,0.6042963266372681,True,0.574442516811659,0.5893694217244636,True
ErfAct and PSerf: Non-monotonic smooth trainable Activation Functions,"An activation function is a crucial component of a neural network that introduces non-linearity in the network. The state-of-the-art performance of a neural network depends also on the perfect choice of an activation function. We propose two novel non-monotonic smooth trainable activation functions, called ErfAct and Pserf. Experiments suggest that the proposed functions improve the network performance significantly compared to the widely used activations like ReLU, Swish, and Mish. Replacing ReLU by ErfAct and Pserf, we have 5.68% and 5.42% improvement for top-1 accuracy on Shufflenet V2 (2.0x) network in CIFAR100 dataset, 2.11% and 1.96% improvement for top-1 accuracy on Shufflenet V2 (2.0x) network in CIFAR10 dataset, 1.0%, and 1.0% improvement on mean average precision (mAP) on SSD300 model in Pascal VOC dataset.",1.0,0.7225621342658997,True,0.3775406687981454,0.5500514015320226,True
Context-aware Health Event Prediction via Transition Functions on Dynamic Disease Graphs,"With the wide application of electronic health records (EHR) in healthcare facilities, health event prediction with deep learning has gained more and more attention. A common feature of EHR data used for deep-learning-based predictions is historical diagnoses. Existing work mainly regards a diagnosis as an independent disease and does not consider clinical relations among diseases in a visit. Many machine learning approaches assume disease representations are static in different visits of a patient. However, in real practice, multiple diseases that are frequently diagnosed at the same time reflect hidden patterns that are conducive to prognosis. Moreover, the development of a disease is not static since some diseases can emerge or disappear and show various symptoms in different visits of a patient. To effectively utilize this combinational disease information and explore the dynamics of diseases, we propose a novel context-aware learning framework using transition functions on dynamic disease graphs. Specifically, we construct a global disease co-occurrence graph with multiple node properties for disease combinations. We design dynamic subgraphs for each patient's visit to leverage global and local contexts. We further define three diagnosis roles in each visit based on the variation of node properties to model disease transition processes. Experimental results on two real-world EHR datasets show that the proposed model outperforms state of the art in predicting health events.",1.0,0.7236697673797607,True,0.3775406687981454,0.5506052180889531,True
Adversarial Training and Provable Robustness: A Tale of Two Objectives,"We propose a principled framework that combines adversarial training and provable robustness verification for training certifiably robust neural networks. We formulate the training problem as a joint optimization problem with both empirical and provable robustness objectives and develop a novel gradient-descent technique that can eliminate bias in stochastic multi-gradients. We perform both theoretical analysis on the convergence of the proposed technique and experimental comparison with state-of-the-arts. Results on MNIST and CIFAR-10 show that our method can consistently match or outperform prior approaches for provable l∞ robustness. Notably, we achieve 6.60% verified test error on MNIST at ε = 0.3, and 66.57% on CIFAR-10 with ε = 8/255.",0.8,0.9045865535736084,True,0.3318122278318339,0.6181993907027211,True
MAGIC: Multimodal relAtional Graph adversarIal inferenCe for Diverse and Unpaired Text-based Image Captioning,"Text-based image captioning (TextCap) requires simultaneous comprehension of visual content and reading the text of images to generate a natural language description. Although a task can teach machines to understand the complex human environment further given that text is omnipresent in our daily surroundings, it poses additional challenges in normal captioning. A text-based image intuitively contains abundant and complex multimodal relational content, that is, image details can be described diversely from multiview rather than a single caption. Certainly, we can introduce additional paired training data to show the diversity of images' descriptions, this process is labor-intensive and time-consuming for TextCap pair annotations with extra texts. Based on the insight mentioned above, we investigate how to generate diverse captions that focus on different image parts using an unpaired training paradigm. We propose the Multimodal relAtional Graph adversarIal InferenCe (MAGIC) framework for diverse and unpaired TextCap. This framework can adaptively construct multiple multimodal relational graphs of images and model complex relationships among graphs to represent descriptive diversity. Moreover, a cascaded generative adversarial network is developed from modeled graphs to infer the unpaired caption generation in image–sentence feature alignment and linguistic coherence levels. We validate the effectiveness of MAGIC in generating diverse captions from different relational information items of an image. Experimental results show that MAGIC can generate very promising outcomes without using any image–caption training pairs.",1.0,0.8653043508529663,True,0.3775406687981454,0.6214225098255559,True
Visual Sound Localization in the Wild by Cross-Modal Interference Erasing,"The task of audiovisual sound source localization has been well studied under constrained scenes, where the audio recordings are clean. However, in real world scenarios, audios are usually contaminated by off screen sound and background noise. They will interfere with the procedure of identifying desired sources and building visual sound connections, making previous studies nonapplicable. In this work, we propose the Interference Eraser (IEr) framework, which tackles the problem of audiovisual sound source localization in the wild. The key idea is to eliminate the interference by redefining and carving discriminative audio representations. Specifically, we observe that the previous practice of learning only a single audio representation is insufficient due to the additive nature of audio signals. We thus extend the audio representation with our Audio Instance Identifier module, which clearly distinguishes sounding instances when audio signals of different volumes are unevenly mixed. Then we erase the influence of the audible but off screen sounds and the silent but visible objects by a Cross modal Referrer module with cross modality distillation. Quantitative and qualitative evaluations demonstrate that our framework achieves superior results on sound localization tasks, especially under real world scenarios.",1.0,0.8363281488418579,True,0.3775406687981454,0.6069344088200017,True
HaPPy: Harnessing the Wisdom from Multi-Perspective Graphs for Protein-Ligand Binding Affinity Prediction (Student Abstract),"Gathering information from multi-perspective graphs is an essential issue for many applications especially for proteinligand binding affinity prediction. Most of traditional approaches obtained such information individually with low interpretability. In this paper, we harness the rich information from multi-perspective graphs with a general model, which abstractly represents protein-ligand complexes with better interpretability while achieving excellent predictive performance. In addition, we specially analyze the protein-ligand binding affinity problem, taking into account the heterogeneity of proteins and ligands. Experimental evaluations demonstrate the effectiveness of our data representation strategy on public datasets by fusing information from different perspectives.",0.8,0.9613958597183228,True,0.3318122278318339,0.6466040437750783,True
A Multi-Factor Classification Framework for Completing Users' Fuzzy Queries (Student Abstract),"Intent identification is the key technology in dialogue system. However, not all online queries are clear or complete. To identify users' intents from those fuzzy queries accurately, this paper proposes a multi-factor classification framework on the query level. Experimental results on our online serving system JIMI demonstrate the effectiveness of our proposed framework.",0.8,0.7876562476158142,True,0.3318122278318339,0.559734237723824,True
Joint Demosaicking and Denoising in the Wild: The Case of Training Under Ground Truth Uncertainty,"Image demosaicking and denoising are the two key fundamental steps in digital camera pipelines, aiming to reconstruct clean color images from noisy luminance readings. In this paper, we propose and study Wild-JDD, a novel learning framework for joint demosaicking and denoising in the wild. In contrast to previous works which generally assume the ground truth of training data is a perfect reflection of the reality, we consider here the more common imperfect case of ground truth uncertainty in the wild. We first illustrate its manifestation as various kinds of artifacts including zipper effect, color moire and residual noise. Then we formulate a two-stage data degradation process to capture such ground truth uncertainty, where a conjugate prior distribution is imposed upon a base distribution. After that, we derive an evidence lower bound (ELBO) loss to train a neural network that approximates the parameters of the conjugate prior distribution conditioned on the degraded input. Finally, to further enhance the performance for out-of-distribution input, we design a simple but effective fine-tuning strategy by taking the input as a weakly informative prior. Taking into account ground truth uncertainty, Wild-JDD enjoys good interpretability during optimization. Extensive experiments validate that it outperforms state-of-the-art schemes on joint demosaicking and denoising tasks on both synthetic and realistic raw datasets.",1.0,0.9567704200744629,True,0.3775406687981454,0.6671555444363042,True
Explaining (Sarcastic) Utterances to Enhance Affect Understanding in Multimodal Dialogues,"Conversations emerge as the primary media for exchanging ideas and conceptions. From the listener’s perspective, identifying various affective qualities, such as sarcasm, humour, and emotions, is paramount for comprehending the true connotation of the emitted utterance. However, one of the major hurdles faced in learning these affect dimensions is the presence of figurative language, viz. irony, metaphor, or sarcasm. We hypothesize that any detection system constituting the exhaustive and explicit presentation of the emitted utterance would improve the overall comprehension of the dialogue. To this end, we explore the task of Sarcasm Explanation in Dialogues, which aims to unfold the hidden irony behind sarcastic utterances. We propose MOSES, a deep neural network which takes a multimodal (sarcastic) dialogue instance as an input and generates a natural language sentence as its explanation. Subsequently, we leverage the generated explanation for various natural language understanding tasks in a conversational dialogue setup, such as sarcasm detection, humour identification, and emotion recognition. Our evaluation shows that MOSES outperforms the state-of-the-art system for SED by an average of ∼2% on different evaluation metrics, such as ROUGE, BLEU, and METEOR. Further, we observe that leveraging the generated explanation advances three downstream tasks for affect classification – an average improvement of ~14% F1-score in the sarcasm detection task and ∼2% in the humour identification and emotion recognition task. We also perform extensive analyses to assess the quality of the results.",0.8,0.9840868711471558,True,0.3318122278318339,0.6579495494894948,True
Exploring Artificial Intelligence in English Language Arts with StoryQ,"Exploring Artificial Intelligence (AI) in English Language Arts (ELA) with StoryQ is a 10-hour curriculum module designed for high school ELA classes. The module introduces students to fundamental AI concepts and essential machine learning workflow using StoryQ, a web-based GUI environment for Grades 6-12 learners. In this module, students work with unstructured text data and learn to train, test, and improve text classification models such as intent recognition, clickbait filter, and sentiment analysis. As they interact with machine-learning language models deeply, students also gain a nuanced understanding of language and how to wield it, not just as a data structure, but as a tool in our human-human encounters as well. The current version contains eight lessons, all delivered through a full-featured online learning and teaching platform. Computers and Internet access are required to implement the module. The module was piloted in an ELA class in the Spring of 2022, and the student learning outcomes were positive. The module is currently undergoing revision and will be further tested and improved in Fall 2022.",1.0,0.8004166483879089,True,0.3775406687981454,0.5889786585930272,True
Learnable Blur Kernel for Single-Image Defocus Deblurring in the Wild,"Recent research showed that the dual-pixel sensor has made great progress in defocus map estimation and image defocus deblurring.
However, extracting real-time dual-pixel views is troublesome and complex in algorithm deployment.
Moreover, the deblurred image generated by the defocus deblurring network lacks high-frequency details, which is unsatisfactory in human perception. To overcome this issue, we propose a novel defocus deblurring method that uses the guidance of the defocus map to implement image deblurring.
The proposed method consists of a learnable blur kernel to estimate the defocus map, which is an unsupervised method, and a single-image defocus deblurring generative adversarial network (DefocusGAN) for the first time.
The proposed network can learn the deblurring of different regions and recover realistic details. We propose a defocus adversarial loss to guide this training process.
Competitive experimental results confirm that with a learnable blur kernel, the generated defocus map can achieve results comparable to supervised methods.
In the single-image defocus deblurring task, the proposed method achieves state-of-the-art results, especially significant improvements in perceptual quality, where PSNR reaches 25.56 dB and LPIPS reaches 0.111.",1.0,0.803105890750885,True,0.3775406687981454,0.5903232797745153,True
Intensity-Aware Loss for Dynamic Facial Expression Recognition in the Wild,"Compared with the image-based static facial expression recognition (SFER) task, the dynamic facial expression recognition (DFER) task based on video sequences is closer to the natural expression recognition scene. However, DFER is often more challenging. One of the main reasons is that video sequences often contain frames with different expression intensities, especially for the facial expressions in the real-world scenarios, while the images in SFER frequently present uniform and high expression intensities. Nevertheless, if the expressions with different intensities are treated equally, the features learned by the networks will have large intra-class and small inter-class differences, which are harmful to DFER. To tackle this problem, we propose the global convolution-attention block (GCA) to rescale the channels of the feature maps. In addition, we introduce the intensity-aware loss (IAL) in the training process to help the network distinguish the samples with relatively low expression intensities. Experiments on two in-the-wild dynamic facial expression datasets (i.e., DFEW and FERV39k) indicate that our method outperforms the state-of-the-art DFER approaches. The source code will be available at https://github.com/muse1998/IAL-for-Facial-Expression-Recognition.",1.0,0.7315891981124878,True,0.3775406687981454,0.5545649334553167,True
Opening the Black Box: Automatically Characterizing Software for Algorithm Selection (Student Abstract),"Meta-algorithmics, the field of leveraging machine learning to use algorithms more efficiently, has achieved impressive performance improvements in many areas of AI. It treats the algorithms to improve on as black boxes – nothing is known about their inner workings. This allows meta-algorithmic techniques to be deployed in many applications, but leaves potential performance improvements untapped by ignoring information that the algorithms could provide. In this paper, we open the black box without sacrificing the universal applicability of meta-algorithmic techniques by automatically analyzing the source code of the algorithms under consideration and show how to use it to improve algorithm selection performance. We demonstrate improvements of up to 82% on the standard ASlib benchmark library.",0.8,0.912587583065033,True,0.3318122278318339,0.6221999054484334,True
f-Aware Conflict Prioritization & Improved Heuristics For Conflict-Based Search,"Conflict-Based Search (CBS) is a leading two-level algorithm for optimal Multi-Agent Path Finding (MAPF). The main step of CBS is to expand nodes by resolving conflicts (where two agents collide). Choosing the ‘right’ conflict to resolve can greatly speed up the search. CBS first resolves conflicts where the costs (g-values) of the resulting child nodes are larger than the cost of the node to be split. However, the recent addition of high-level heuristics to CBS and expanding nodes according to f=g+h reduces the relevance of this conflict prioritization method. Therefore, we introduce an expanded categorization of conflicts, which first resolves conflicts where the f-values of the child nodes are larger than the f-value of the node to be split, and present a method for identifying such conflicts. We also enhance all known heuristics for CBS by using information about the cost of resolving certain conflicts, and with only a small computational overhead. Finally, we experimentally demonstrate that both the expanded categorization of conflicts and the improved heuristics contribute to making CBS even more efficient.",0.8,0.8445465564727783,True,0.3318122278318339,0.5881793921523061,True
Mask-Net: Learning Context Aware Invariant Features Using Adversarial Forgetting (Student Abstract),"Training a robust system, e.g., Speech to Text (STT), requires large datasets. Variability present in the dataset, such as unwanted nuances and biases, is the reason for the need for large datasets to learn general representations. In this work, we propose a novel approach to induce invariance using adversarial forgetting (AF). Our initial experiments on learning invariant features such as accent on the STT task achieve better generalizations in terms of word error rate (WER) compared to traditional models. We observe an absolute improvement of 2.2% and 1.3% on out-of-distribution and in-distribution test sets, respectively.",0.8,0.8067474365234375,True,0.3318122278318339,0.5692798321776357,True
Polynomially Bounded Logic Programs with Function Symbols: A New Decidable,"
 
 A logic program with function symbols is called finitely ground if there is a finite propositional logic program whose stable models are exactly the same as the stable models of this program. Finite groundability is an important property for logic programs with function symbols because it makes feasible to compute such program’s stable models using traditional ASP solvers. In this paper, we introduce a new decidable class of finitely ground programs called POLY-bounded programs, which, to the best of our knowledge, strictly contains all decidable classes of finitely ground programs discovered so far in the literature. We also study the related complexity property for this class of programs. We prove that deciding whether a program is POLY-bounded is EXPTIMEcomplete.
 
",1.0,0.723067581653595,True,0.3775406687981454,0.5503041252258702,True
Stage Conscious Attention Network (SCAN) : A Demonstration-Conditioned Policy for Few-Shot Imitation,"In few-shot imitation learning (FSIL), using behavioral cloning (BC) to solve unseen tasks with few expert demonstrations becomes a popular research direction. The following capabilities are essential in robotics applications: (1) Behaving in compound tasks that contain multiple stages. (2) Retrieving knowledge from few length-variant and misalignment demonstrations. (3) Learning from an expert different from the agent. No previous work can achieve these abilities at the same time. In this work, we conduct FSIL problem under the union of above settings and introduce a novel stage conscious attention network (SCAN) to retrieve knowledge from few demonstrations simultaneously. SCAN uses an attention module to identify each stage in length-variant demonstrations. Moreover, it is designed under demonstration-conditioned policy that learns the relationship between experts and agents. Experiment results show that SCAN can perform in complicated compound tasks without fine-tuning and provide the explainable visualization. Project page is at https://sites.google.com/view/scan-aaai2022.",0.8,0.7960236668586731,True,0.3318122278318339,0.5639179473452535,True
Transformer-Based Multi-Hop Question Generation (Student Abstract),"Question generation is the parallel task of question answering, where given an input context and, optionally, an answer, the goal is to generate a relevant and fluent natural language question. Although recent works on question generation have experienced success by utilizing sequence-to-sequence models, there is a need for question generation models to handle increasingly complex input contexts to produce increasingly detailed questions. Multi-hop question generation is a more challenging task that aims to generate questions by connecting multiple facts from multiple input contexts. In this work, we apply a transformer model to the task of multi-hop question generation without utilizing any sentence-level supporting fact information. We utilize concepts that have proven effective in single-hop question generation, including a copy mechanism and placeholder tokens. We evaluate our model’s performance on the HotpotQA dataset using automated evaluation metrics, including BLEU, ROUGE and METEOR and show an improvement over the previous work.",0.8,0.9243366122245789,True,0.3318122278318339,0.6280744200282063,True
Combining Machine Learning & Reasoning for Biodiversity Data Intelligence,"The current crisis in global natural resource management makes it imperative that we better leverage the vast data sources associated with taxonomic entities (such as recognized species of plants and animals), which are known collectively as biodiversity data. However, these data pose considerable challenges for artificial intelligence: while growing rapidly in volume, they remain highly incomplete for many taxonomic groups, often show conflicting signals from different sources, and are multi-modal and therefore constantly changing in structure. In this paper, we motivate, describe, and present a novel workflow combining machine learning and automated reasoning, to discover patterns of taxonomic identity and change - i.e. “taxonomic intelligence” - leading to scalable and broadly impactful AI solutions within the bio-data realm.",0.8,0.7692050933837891,True,0.3318122278318339,0.5505086606078115,True
Inductive Pairwise Ranking: Going Beyond the n log(n) Barrier,"
 
 We study the problem of ranking a set of items from nonactively chosen pairwise preferences where each item has feature information with it. We propose and characterize a very broad class of preference matrices giving rise to the Feature Low Rank (FLR) model, which subsumes several models ranging from the classic Bradley–Terry–Luce (BTL) (Bradley and Terry 1952) and Thurstone (Thurstone 1927) models to the recently proposed blade-chest (Chen and Joachims 2016) and generic low-rank preference (Rajkumar and Agarwal 2016) models. We use the technique of matrix completion in the presence of side information to develop the Inductive Pairwise Ranking (IPR) algorithm that provably learns a good ranking under the FLR model, in a sample-efficient manner. In practice, through systematic synthetic simulations, we confirm our theoretical findings regarding improvements in the sample complexity due to the use of feature information. Moreover, on popular real-world preference learning datasets, with as less as 10% sampling of the pairwise comparisons, our method recovers a good ranking.
 
",0.8,0.9154581427574158,True,0.3318122278318339,0.6236351852946248,True
Bag of Tricks for Long-Tailed Visual Recognition with Deep Convolutional Neural Networks,"In recent years, visual recognition on challenging long-tailed distributions, where classes often exhibit extremely imbalanced frequencies, has made great progress mostly based on various complex paradigms (e.g., meta learning). Apart from these complex methods, simple refinements on training procedures also make contributions. These refinements, also called tricks, are minor but effective, such as adjustments in the data distribution or loss functions. However, different tricks might conflict with each other. If users apply these long-tail related tricks inappropriately, it could cause worse recognition accuracy than expected. Unfortunately, there has not been a scientific guideline of these tricks in the literature. In this paper, we first collect existing tricks in long-tailed visual recognition and then perform extensive and systematic experiments, in order to give a detailed experimental guideline and obtain an effective combination of these tricks. Furthermore, we also propose a novel data augmentation approach based on class activation maps for long-tailed recognition, which can be friendly combined with re-sampling methods and shows excellent results. By assembling these tricks scientifically, we can outperform state-of-the-art methods on four long-tailed benchmark datasets, including ImageNet-LT and iNaturalist 2018. Our code is open-source and available at https://github.com/zhangyongshun/BagofTricks-LT.",1.0,0.7417328953742981,True,0.3775406687981454,0.5596367820862218,True
"Performance Evaluation in Machine Learning: The Good, the Bad, the Ugly, and the Way Forward","This paper gives an overview of some ways in which our understanding of performance evaluation measures for machine-learned classifiers has improved over the last twenty years. I also highlight a range of areas where this understanding is still lacking, leading to ill-advised practices in classifier evaluation. This suggests that in order to make further progress we need to develop a proper measurement theory of machine learning. I then demonstrate by example what such a measurement theory might look like and what kinds of new results it would entail. Finally, I argue that key properties such as classification ability and data set difficulty are unlikely to be directly observable, suggesting the need for latent-variable models and causal inference.",1.8,0.6490620970726013,True,0.574442516811659,0.6117523069421302,True
"Hey, Siri! Why Are You Biased against Women? (Student Abstract)","The intersection of pervasive technology and verbal communication has resulted in the creation of Automatic Speech Recognition Systems (ASRs), which automate the conversion of spontaneous speech into texts. ASR enables human-computer interactions through speech and is rapidly integrated into our daily lives. However, the research studies on current ASR technologies have reported unfulfilled social inclusivity and accentuated biases and stereotypes towards minorities. In this work, we provide a review of examples and evidence to demonstrate preexisting sexist behavior in ASR systems through a systematic review of research literature over the past five years. For each article, we also provide the ASR technology used, highlight specific instances of reported bias, discuss the impact of this bias on the female community, and suggest possible methods of mitigation. We believe this paper will provide insights into the harm that unchecked AI-powered technologies can have on a community by contributing to the growing body of research on this topic and underscoring the need for technological inclusivity for all demographics, especially women.",1.6,0.9484656453132629,True,0.52497918747894,0.7367224163961015,True
A Reinforcement Learning Badminton Environment for Simulating Player Tactics (Student Abstract),"Recent techniques for analyzing sports precisely has stimulated various approaches to improve player performance and fan engagement.
However, existing approaches are only able to evaluate offline performance since testing in real-time matches requires exhaustive costs and cannot be replicated.
To test in a safe and reproducible simulator, we focus on turn-based sports and introduce a badminton environment by simulating rallies with different angles of view and designing the states, actions, and training procedures.
This benefits not only coaches and players by simulating past matches for tactic investigation, but also researchers from rapidly evaluating their novel algorithms.
Our code is available at https://github.com/wywyWang/CoachAI-Projects/tree/main/Strategic%20Environment.",0.8,0.7713099718093872,True,0.3318122278318339,0.5515610998206105,True
Improving Search with Supervised Learning in Trick-Based Card Games,"In trick-taking card games, a two-step process of state sampling and evaluation is widely used to approximate move values. While the evaluation component is vital, the accuracy of move value estimates is also fundamentally linked to how well the sampling distribution corresponds the true distribution. Despite this, recent work in trick-taking card game AI has mainly focused on improving evaluation algorithms with limited work on improving sampling. In this paper, we focus on the effect of sampling on the strength of a player and propose a novel method of sampling more realistic states given move history. In particular, we use predictions about locations of individual cards made by a deep neural network — trained on data from human gameplay — in order to sample likely worlds for evaluation. This technique, used in conjunction with Perfect Information Monte Carlo (PIMC) search, provides a substantial increase in cardplay strength in the popular trick-taking card game of Skat.",1.0,0.9228269457817078,True,0.3775406687981454,0.6501838072899266,True
Preface of the 2018 symposium on adversary aware learning techniques and trends in cybersecurity (ALEC) (co-located with AAAI fall symposium series 2018),"Machine learning-based intelligent systems have experienced a massive growth over the past few years, and are close to becoming ubiquitous in the technology surrounding our daily lives. However, a critical challenge in machine learning-based systems is their vulnerability to security attacks from malicious adversaries. The vulnerability of these systems is further aggravated as it is non-trivial to establish the authenticity of data used to train the system, and even innocuous perturbations to the training data can be used to manipulate the systems behavior in unintended ways. Recent reports about malicious manipulation of social media feeds masquerading as authentic news items provide compelling evidence towards developing stronger and more resilient measures for combating adversarial attacks on machine learning-based systems. The ALEC’18 symposium was organized to address the overarching need towards making automated, machine learning-based systems more robust and resilient against adversarial attacks, so that humans can use them in a safe and sustained manner. The areas of interest of the symposium included the following topics:",0.8,0.8136654496192932,True,0.3318122278318339,0.5727388387255635,True
MoCaNet: Motion Retargeting in-the-wild via Canonicalization Networks,"We present a novel framework that brings the 3D motion retargeting task from controlled environments to in-the-wild scenarios. In particular, our method is capable of retargeting body motion from a character in a 2D monocular video to a 3D character without using any motion capture system or 3D reconstruction procedure. It is designed to leverage massive online videos for unsupervised training, needless of 3D annotations or motion-body pairing information. The proposed method is built upon two novel canonicalization operations, structure canonicalization and view canonicalization. Trained with the canonicalization operations and the derived regularizations, our method learns to factorize a skeleton sequence into three independent semantic subspaces, i.e., motion, structure, and view angle. The disentangled representation enables motion retargeting from 2D to 3D with high precision. Our method achieves superior performance on motion transfer benchmarks with large body variations and challenging actions. Notably, the canonicalized skeleton sequence could serve as a disentangled and interpretable representation of human motion that benefits action analysis and motion retrieval.",1.0,0.7287669777870178,True,0.3775406687981454,0.5531538232925817,True
Discriminative Sentence Modeling for Story Ending Prediction,"Story Ending Prediction is a task that needs to select an appropriate ending for the given story, which requires the machine to understand the story and sometimes needs commonsense knowledge. To tackle this task, we propose a new neural network called Diff-Net for better modeling the differences of each ending in this task. The proposed model could discriminate two endings in three semantic levels: contextual representation, story-aware representation, and discriminative representation. Experimental results on the Story Cloze Test dataset show that the proposed model siginificantly outperforms various systems by a large margin, and detailed ablation studies are given for better understanding our model. We also carefully examine the traditional and BERT-based models on both SCT v1.0 and v1.5 with interesting findings that may potentially help future studies.",1.0,0.8069457411766052,True,0.3775406687981454,0.5922432049873754,True
Learning from Noisy Labels with Complementary Loss Functions,"Recent researches reveal that deep neural networks are sensitive to label noises hence leading to poor generalization performance in some tasks. Although different robust loss functions have been proposed to remedy this issue, they suffer from an underfitting problem, thus are not sufficient to learn accurate models. On the other hand, the commonly used Cross Entropy (CE) loss, which shows high performance in standard supervised learning (with clean supervision), is non-robust to label noise. In this paper, we propose a general framework to learn robust deep neural networks with complementary loss functions. In our framework, CE and robust loss play complementary roles in a joint learning objective as per their learning sufficiency and robustness properties respectively. Specifically, we find that by exploiting the memorization effect of neural networks, we can easily filter out a proportion of hard samples and generate reliable pseudo labels for easy samples, and thus reduce the label noise to a quite low level. Then, we simply learn with CE on pseudo supervision and robust loss on original noisy supervision. In this procedure, CE can guarantee the sufficiency of optimization while the robust loss can be regarded as the supplement. Experimental results on benchmark classification datasets indicate that the proposed method helps achieve robust and sufficient deep neural network training simultaneously.",1.0,0.946718156337738,True,0.3775406687981454,0.6621294125679418,True
Controlling the Spread of Two Secrets in Diverse Social Networks (Student Abstract),"Information diffusion in social networks is a well-studied concept in social choice theory. We propose the study of the diffusion of two secrets in a heterogeneous environment from the complexity perspective, that is, there are two different networks with the same set of agents (e.g., the structure of the set of followers might be different in two distinct social networks).

Formally, our model combines two group identification processes for which we do have independent desiderata---either constructive, where we would like a given group of agents to be exposed to a secret, or destructive, where a given group of agents should not be exposed to a secret. To be able to reach these targets, we can either delete an agent or introduce a previously latent agent.

Our results are mostly negative---all of the problems are NP-hard. Therefore, we propose a parameterized study with respect to the natural parameters, the number of influenced agents, the size of the required/protected agent sets, and the duration of the diffusion process. Most of the studied problems remain W[1]-hard even for a combination of these parameters. We complement these results with nearly optimal XP algorithms.",0.8,0.7823125123977661,True,0.3318122278318339,0.5570623701148,True
SpotFake+: A Multimodal Framework for Fake News Detection via Transfer Learning (Student Abstract),"In recent years, there has been a substantial rise in the consumption of news via online platforms. The ease of publication and lack of editorial rigour in some of these platforms have further led to the proliferation of fake news. In this paper, we study the problem of detecting fake news on the FakeNewsNet repository, a collection of full length articles along with associated images. We present SpotFake+, a multimodal approach that leverages transfer learning to capture semantic and contextual information from the news articles and its associated images and achieves the better accuracy for fake news detection. To the best of our knowledge, this is the first work that performs a multimodal approach for fake news detection on a dataset that consists of full length articles. It outperforms the performance shown by both single modality and multiple-modality models. We also release the pretrained model for the benefit of the community.",0.8,0.893890917301178,True,0.3318122278318339,0.6128515725665059,True
Melodic Phrase Attention Network for Symbolic Data-based Music Genre Classification (Student Abstract),"Compared with audio data-based music genre classification, researches on symbolic data-based music are scarce. Existing methods generally utilize manually extracted features, which is very time-consuming and laborious, and use traditional classifiers for label prediction without considering specific music features. To tackle this issue, we propose the Melodic Phrase Attention Network (MPAN) for symbolic data-based music genre classification. Our model is trained in three steps: First, we adopt representation learning, instead of the traditional musical feature extraction method, to obtain a vectorized representation of the music pieces. Second, the music pieces are divided into several melodic phrases through melody segmentation. Finally, the Melodic Phrase Attention Network is designed according to music characteristics, to identify the reflection of each melodic phrase on the music genre, thereby generating more accurate predictions. Experimental results show that our proposed method is superior to baseline symbolic data-based music genre classification approaches, and has achieved significant performance improvements on two large datasets.",0.8,0.814010500907898,True,0.3318122278318339,0.5729113643698659,True
Label Smoothing for Emotion Detection (Student Abstract),"Automatically detecting emotions from text has countless
applications, ranging from large scale opinion mining to
social robots in healthcare and education. However, emotions
are subjective in nature and are often expressed in ambiguous
ways. At the same time, detecting emotions can also require
implicit reasoning, which may not be available as surface-
level, lexical information. In this work, we conjecture that
the overconfidence of pre-trained language models such as
BERT is a critical problem in emotion detection and show
that alleviating this problem can considerably improve the
generalization performance. We carry out comprehensive
experiments on four emotion detection benchmark datasets
and show that calibrating our model predictions leads to an
average improvement of 1.35% in weighted F1 score.",0.8,0.8193470239639282,True,0.3318122278318339,0.575579625897881,True
SimCTC: A Simple Contrast Learning Method of Text Clustering (Student Abstract),"This paper presents SimCTC, a simple contrastive learning (CL) framework that greatly advances the state-of-the-art text clustering models. In SimCTC, a pre-trained BERT model first maps the input sequence to the representation space, which is then followed by three different loss function heads: Clustering head, Instance-CL head and Cluster-CL head. Experimental results on multiple benchmark datasets demonstrate that SimCTC remarkably outperforms 6 competitive text clustering methods with 1%-6% improvement on Accuracy (ACC) and 1%-4% improvement on Normalized Mutual Information (NMI). Moreover, our results also show that the clustering performance can be further improved by setting an appropriate number of clusters in the cluster-level objective.",0.8,0.8731060028076172,True,0.3318122278318339,0.6024591153197255,True
Social Intelligence towards Human-AI Teambuilding (Student Abstract),"As Artificial Intelligence (AI) continues to develop, it becomes vital to understand more of the nuances of Human-AI interactions. This study aims to uncover how developers can design AI to feel more human in a work environment where only written feedback is possible. Participants will identify a location from Google Maps. To do this successfully, participants must rely on the answers provided by their teammates, one AI and one human. The experiment will run a 2x4 de-sign where AI's responses will either be designed in a human style (high humanness) or state a one-word answer (low humanness), the latter of which is more typical in machines and AI. The reliability of the AI will either be 60% or 90%, and the human will be 30%. Participants will be given a series of questionnaires to rate their opinions of the AI and rate feelings of trust, confidence and performance throughout the study. Following this study, the aim is to identify specific design elements that allow AI to feel human and successfully appear to have social intelligence in more interactive settings.",0.8,0.8856900930404663,True,0.3318122278318339,0.6087511604361501,True
DramaQA: Character-Centered Video Story Understanding with Hierarchical QA,"Despite recent progress on computer vision and natural language processing, developing a machine that can understand video story is still hard to achieve due to the intrinsic difficulty of video story. Moreover, researches on how to evaluate the degree of video understanding based on human cognitive process have not progressed as yet. In this paper, we propose a novel video question answering (Video QA) task, DramaQA, for a comprehensive understanding of the video story. The DramaQA focuses on two perspectives: 1) Hierarchical QAs as an evaluation metric based on the cognitive developmental stages of human intelligence. 2) Character-centered video annotations to model local coherence of the story. Our dataset is built upon the TV drama ""Another Miss Oh"" and it contains 17,983 QA pairs from 23,928 various length video clips, with each QA pair belonging to one of four difficulty levels. We provide 217,308 annotated images with rich character-centered annotations, including visual bounding boxes, behaviors and emotions of main characters, and coreference resolved scripts. Additionally, we suggest Multi-level Context Matching model which hierarchically understands character-centered representations of video to answer questions. We release our dataset and model publicly for research purposes, and we expect our work to provide a new perspective on video story understanding research.",1.0,0.8972665667533875,True,0.3775406687981454,0.6374036177757665,True
Dual Attention Network for Product Compatibility and Function Satisfiability Analysis,"
 
 Product compatibility and functionality are of utmost importance to customers when they purchase products, and to sellers and manufacturers when they sell products. Due to the huge number of products available online, it is infeasible to enumerate and test the compatibility and functionality of every product. In this paper, we address two closely related problems: product compatibility analysis and function satisfiability analysis, where the second problem is a generalization of the first problem (e.g., whether a product works with another product can be considered as a special function). We first identify a novel question and answering corpus that is up-to-date regarding product compatibility and functionality information. To allow automatic discovery product compatibility and functionality, we then propose a deep learning model called Dual Attention Network (DAN). Given a QA pair for a to-be-purchased product, DAN learns to 1) discover complementary products (or functions), and 2) accurately predict the actual compatibility (or satisfiability) of the discovered products (or functions). The challenges addressed by the model include the briefness of QAs, linguistic patterns indicating compatibility, and the appropriate fusion of questions and answers. We conduct experiments to quantitatively and qualitatively show that the identified products and functions have both high coverage and accuracy, compared with a wide spectrum of baselines.
 
",1.0,0.7781980037689209,True,0.3775406687981454,0.5778693362835332,True
BiRdQA: A Bilingual Dataset for Question Answering on Tricky Riddles,"A riddle is a question or statement with double or veiled meanings, followed by an unexpected answer. Solving riddle is a challenging task for both machine and human, testing the capability of understanding figurative, creative natural language and reasoning with commonsense knowledge. We introduce BiRdQA, a bilingual multiple-choice question answering dataset with 6614 English riddles and 8751 Chinese riddles. For each riddle-answer pair, we provide four distractors with additional information from Wikipedia. The distractors are automatically generated at scale with minimal bias. Existing monolingual and multilingual QA models fail to perform well on our dataset, indicating that there is a long way to go before machine can beat human on solving tricky riddles. The dataset is publicly available at https://forms.gle/NvT7DfWhAPhvoFvH7.",1.0,0.8702007532119751,True,0.3775406687981454,0.6238707110050603,True
A Character-Centric Neural Model for Automated Story Generation,"Automated story generation is a challenging task which aims to automatically generate convincing stories composed of successive plots correlated with consistent characters. Most recent generation models are built upon advanced neural networks, e.g., variational autoencoder, generative adversarial network, convolutional sequence to sequence model. Although these models have achieved prompting results on learning linguistic patterns, very few methods consider the attributes and prior knowledge of the story genre, especially from the perspectives of explainability and consistency. To fill this gap, we propose a character-centric neural storytelling model, where a story is created encircling the given character, i.e., each part of a story is conditioned on a given character and corresponded context environment. In this way, we explicitly capture the character information and the relations between plots and characters to improve explainability and consistency. Experimental results on open dataset indicate that our model yields meaningful improvements over several strong baselines on both human and automatic evaluations.",1.0,0.7536348104476929,True,0.3775406687981454,0.5655877396229192,True
SReN: Shape Regression Network for Comic Storyboard Extraction,"
 
 The goal of storyboard extraction is to decompose the comic image into several storyboards(or frames), which is the fundamental step of comic image understanding and producing digital comic documents suitable for mobile reading. Most of existing approaches are based on hand crafted low-level visual patters like edge segments and line segments, which do not capture high-level vision. To overcome shortcomings of the existing approaches, we propose a novel architecture based on deep convolutional neural network, namely Shape Regression Network(SReN), to detect storyboards within comic images. Firstly, we use Fast R-CNN to generate rectangle bounding boxes as storyboard proposals. Then we train a deep neural network to predict quadrangles for these propos- als. Unlike existing object detection methods which only output rectangle bounding boxes, SReN can produce more precise quadrangle bounding boxes. Experimental results, evaluating on 7382 comic pages, demonstrate that SReN outperforms the state-of-the-art methods by more than 10% in terms of F1-score and page correction rate.
 
",1.0,0.8601294159889221,True,0.3775406687981454,0.6188350423935338,True
SigMaNet: One Laplacian to Rule Them All,"This paper introduces SigMaNet, a generalized Graph Convolutional Network (GCN) capable of handling both undirected and directed graphs with weights not restricted in sign nor magnitude. The cornerstone of SigMaNet is the Sign-Magnetic Laplacian (LSM), a new Laplacian matrix that we introduce ex novo in this work. LSM allows us to bridge a gap in the current literature by extending the theory of spectral GCNs to (directed) graphs with both positive and negative weights. LSM exhibits several desirable properties not enjoyed by other Laplacian matrices on which several state-of-the-art architectures are based, among which encoding the edge direction and weight in a clear and natural way that is not negatively affected by the weight magnitude. LSM is also completely parameter-free, which is not the case of other Laplacian operators such as, e.g., the Magnetic Laplacian. The versatility and the performance of our proposed approach is amply demonstrated via computational experiments. Indeed, our results show that, for at least a metric, SigMaNet achieves the best performance in 15 out of 21 cases and either the first- or second-best performance in 21 cases out of 21, even when compared to architectures that are either more complex or that, due to being designed for a narrower class of graphs, should---but do not---achieve a better performance.",1.8,0.9176316857337952,True,0.574442516811659,0.7460371012727272,True
Exploiting High-Order Interaction Relations to Explore User Intent (Student Abstract),"This paper studies the problem of exploring the user intent for session-based recommendations. Its challenges come from the uncertainty of user behavior and limited information. However, current endeavors cannot fully explore the mutual interactions among sessions and do not explicitly model the complex high-order relations among items. To circumvent these critical issues, we innovatively propose a HyperGraph Convolutional Contrastive framework (termed HGCC) that consists of two crucial tasks: 1) The session-based recommendation (SBR task) that aims to capture the beyond pair-wise relationships between items and sessions. 2) The self-supervised learning (SSL task) acted as the auxiliary task to boost the former task. By jointly optimizing the two tasks, the performance of the recommendation task achieves decent gains. Experiments on multiple real-world datasets demonstrate the superiority of the proposed approach over the state-of-the-art methods.",0.8,0.7996387481689453,True,0.3318122278318339,0.5657254880003896,True
Novel Exploration Techniques (NETs) for Malaria Policy Interventions,"
 
 The task of decision-making under uncertainty is daunting, especially for problems which have significant complexity. Healthcare policy makers across the globe are facing problems under challenging constraints, with limited tools to help them make data driven decisions. In this work we frame the process of finding an optimal malaria policy as a stochastic multi-armed bandit problem, and implement three agent based strategies to explore the policy space. We apply a Gaussian Process regression to the findings of each agent, both for comparison and to account for stochastic results from simulating the spread of malaria in a fixed population. The generated policy spaces are compared with published results to give a direct reference with human expert decisions for the same simulated population. Our novel approach provides a powerful resource for policy makers, and a platform which can be readily extended to capture future more nuanced policy spaces.
 
",0.8,0.8229284882545471,True,0.3318122278318339,0.5773703580431905,True
StoryQ - an Online Environment for Machine Learning of Text Classification,"The StoryQ environment provides an intuitive graphical user interface for middle and high school students to create features from unstructured text data and train and test classification models using logistic regression. StoryQ runs in a web browser, is free and requires no installation. AI concepts addressed include: features, weights, accuracy, training, bias, error analysis and cross validation. Using the software in conjunction with curriculum currently under development is expected to lead to student understanding of machine learning concepts and workflow; developing the ability to use domain knowledge and basic linguistics to identify, create, analyze, and evaluate features; becoming aware of and appreciating the roles and responsibilities of AI developers;. This paper will consist of an online demo with a brief video walkthrough.",1.0,0.7281400561332703,True,0.3775406687981454,0.5528403624657079,True
Quantify the Political Bias in News Edits: Experiments with Few-Shot Learners (Student Abstract),"The rapid growth of information and communication technologies in recent years, and the different forms of digital connectivity, have profoundly affected how news is generated and consumed. Digital traces and computational methods offer new opportunities to model and track the provenance of news. This project is the first study to characterize and predict how prominent news outlets make edits to news frames and their implications for geopolitical relationships and attitudes. We evaluate the feasibility of training few-shot learners on the editing patterns of articles discussing different countries, for understanding their wider implications in preserving or damaging geopolitical relationships.",0.8,0.7944400310516357,True,0.3318122278318339,0.5631261294417348,True
A Bias Trick for Centered Robust Principal Component Analysis,Outlier based Robust Principal Component Analysis (RPCA) requires centering of the non-outliers. We show a “bias trick” that automatically centers these non-outliers. Using this bias trick we obtain the first RPCA algorithm that is optimal with respect to centering.,1.0,0.8199993968009949,True,0.3775406687981454,0.5987700327995702,True
AutoZOOM: Autoencoder-based Zeroth Order Optimization Method for Attacking Black-box Neural Networks,"Recent studies have shown that adversarial examples in state-of-the-art image classifiers trained by deep neural networks (DNN) can be easily generated when the target model is transparent to an attacker, known as the white-box setting. However, when attacking a deployed machine learning service, one can only acquire the input-output correspondences of the target model; this is the so-called black-box attack setting. The major drawback of existing black-box attacks is the need for excessive model queries, which may give a false sense of model robustness due to inefficient query designs. To bridge this gap, we propose a generic framework for query-efficient blackbox attacks. Our framework, AutoZOOM, which is short for Autoencoder-based Zeroth Order Optimization Method, has two novel building blocks towards efficient black-box attacks: (i) an adaptive random gradient estimation strategy to balance query counts and distortion, and (ii) an autoencoder that is either trained offline with unlabeled data or a bilinear resizing operation for attack acceleration. Experimental results suggest that, by applying AutoZOOM to a state-of-the-art black-box attack (ZOO), a significant reduction in model queries can be achieved without sacrificing the attack success rate and the visual quality of the resulting adversarial examples. In particular, when compared to the standard ZOO method, AutoZOOM can consistently reduce the mean query counts in finding successful adversarial examples (or reaching the same distortion level) by at least 93% on MNIST, CIFAR-10 and ImageNet datasets, leading to novel insights on adversarial robustness.",1.0,0.7917556166648865,True,0.3775406687981454,0.584648142731516,True
Options of Interest: Temporal Abstraction with Interest Functions,"Temporal abstraction refers to the ability of an agent to use behaviours of controllers which act for a limited, variable amount of time. The options framework describes such behaviours as consisting of a subset of states in which they can initiate, an internal policy and a stochastic termination condition. However, much of the subsequent work on option discovery has ignored the initiation set, because of difficulty in learning it from data. We provide a generalization of initiation sets suitable for general function approximation, by defining an interest function associated with an option. We derive a gradient-based learning algorithm for interest functions, leading to a new interest-option-critic architecture. We investigate how interest functions can be leveraged to learn interpretable and reusable temporal abstractions. We demonstrate the efficacy of the proposed approach through quantitative and qualitative results, in both discrete and continuous environments.",1.0,0.7811504006385803,True,0.3775406687981454,0.5793455347183629,True
Dethroning Aristocracy in Graphs via Adversarial Perturbations (Student Abstract),"Learning low-dimensional embeddings of graph data in curved Riemannian manifolds has gained traction due to their desirable property of acting as effective geometrical inductive biases. More specifically, models of Hyperbolic geometry such as Poincar\'{e} Ball and Lorentz/Hyperboloid Model have found applications for learning data with hierarchical anatomy. Gromov's hyperbolicity measures whether a graph can be isometrically embedded in hyperbolic space. This paper shows that adversarial attacks that perturb the network structure also affect the hyperbolicity of graphs rendering hyperbolic space less effective for learning low-dimensional node embeddings of the graph. To circumvent this problem, we introduce learning embeddings in pseudo-Riemannian manifolds such as Lorentzian manifolds and show empirically that they are robust to adversarial perturbations. Despite the recent proliferation of adversarial robustness methods in the graph data, this is the first work exploring the relationship between adversarial attacks and hyperbolicity while also providing resolution to navigate such vulnerabilities.",0.8,0.9418417811393738,True,0.3318122278318339,0.6368270044856038,True
Reinforcement Learning with a Disentangled Universal Value Function for Item Recommendation,"In recent years, there are great interests as well as many challenges in applying reinforcement learning (RL) to recommendation systems (RS). In this paper, we summarize three key practical challenges of large-scale RL-based recommender systems: massive state and action spaces, high-variance environment, and the unspecific reward setting in recommendation. All these problems remain largely unexplored in the existing literature and make the application of RL challenging. We develop a model-based reinforcement learning framework, called GoalRec. Inspired by the ideas of world model (model-based), value function estimation (model-free), and goal-based RL, a novel disentangled universal value function designed for item recommendation is proposed. It can generalize to various goals that the recommender may have, and disentangle the stochastic environmental dynamics and high-variance reward signals accordingly. As a part of the value function, free from the sparse and high-variance reward signals, a high-capacity reward-independent world model is trained to simulate complex environmental dynamics under a certain goal. Based on the predicted environmental dynamics, the disentangled universal value function is related to the user's future trajectory instead of a monolithic state and a scalar reward. We demonstrate the superiority of GoalRec over previous approaches in terms of the above three practical challenges in a series of simulations and a real application.",1.0,0.7652889490127563,True,0.3775406687981454,0.5714148089054509,True
Tricking the Hashing Trick: A Tight Lower Bound on the Robustness of CountSketch to Adaptive Inputs,"CountSketch and Feature Hashing (the ``hashing trick'') are popular randomized dimensionality reduction methods that support recovery of l2 -heavy hitters and approximate inner products. When the inputs are not adaptive (do not depend on prior outputs), classic estimators applied to a sketch of size O(l / epsilon) are accurate for a number of queries that is exponential in l. When inputs are adaptive, however, an adversarial input can be constructed after O(l) queries with the classic estimator and the best known robust estimator only supports ~O(l^2) queries. In this work we show that this quadratic dependence is in a sense inherent: We design an attack that after O(l^2) queries produces an adversarial input vector whose sketch is highly biased. Our attack uses ``natural'' non-adaptive inputs (only the final adversarial input is chosen adaptively) and universally applies with any correct estimator, including one that is unknown to the attacker. In that, we expose inherent vulnerability of this fundamental method.",1.0,0.964234471321106,True,0.3775406687981454,0.6708875700596257,True
The LOB Recreation Model: Predicting the Limit Order Book from TAQ History Using an Ordinary Differential Equation Recurrent Neural Network,"In an order-driven financial market, the price of a financial asset is discovered through the interaction of orders - requests to buy or sell at a particular price - that are posted to the public limit order book (LOB). Therefore, LOB data is extremely valuable for modelling market dynamics. However, LOB data is not freely accessible, which poses a challenge to market participants and researchers wishing to exploit this information. Fortunately, trades and quotes (TAQ) data - orders arriving at the top of the LOB, and trades executing in the market - are more readily available. In this paper, we present the LOB recreation model, a first attempt from a deep learning perspective to recreate the top five price levels of the LOB for small-tick stocks using only TAQ data. Volumes of orders sitting deep in the LOB are predicted by combining outputs from: (1) a history compiler that uses a Gated Recurrent Unit (GRU) module to selectively compile prediction relevant quote history; (2) a market events simulator, which uses an Ordinary Differential Equation Recurrent Neural Network (ODE-RNN) to simulate the accumulation of net order arrivals; and (3) a weighting scheme to adaptively combine the predictions generated by (1) and (2). By the paradigm of transfer learning, the core encoder trained on one stock can be fine-tuned to enable application to other financial assets of the same class with much lower demand on additional data. Comprehensive experiments conducted on two real world intraday LOB datasets demonstrate that the proposed model can efficiently recreate the LOB with high accuracy using only TAQ data as input.",1.0,0.8602489829063416,True,0.3775406687981454,0.6188948258522435,True
A Lyapunov-Based Methodology for Constrained Optimization with Bandit Feedback,"In a wide variety of applications including online advertising, contractual hiring, and wireless scheduling, the controller is constrained by a stringent budget constraint on the available resources, which are consumed in a random amount by each action, and a stochastic feasibility constraint that may impose important operational limitations on decision-making. In this work, we consider a general model to address such problems, where each action returns a random reward, cost, and penalty from an unknown joint distribution, and the decision-maker aims to maximize the total reward under a budget constraint B on the total cost and a stochastic constraint on the time-average penalty. We propose a novel low-complexity algorithm based on Lyapunov optimization methodology, named LyOn, and prove that for K arms it achieves square root of KBlog(B) regret and zero constraint-violation when B is sufficiently large. The low computational cost and sharp performance bounds of LyOn suggest that Lyapunov-based algorithm design methodology can be effective in solving constrained bandit optimization problems.",1.0,0.8982418775558472,True,0.3775406687981454,0.6378912731769963,True
Bison Hacks the Yard: Assisting Underrepresented Students Overcome Impostor Syndrome with Augmented Reality and Artificial Intelligence,"The prevalence of impostor syndrome in computer science students from underrepresented backgrounds contributes to low retention rates. Bison Hacks the Yard is an augmented reality game that aims to reduce impostor syndrome in underrepresented students by presenting a novel way to strengthen their knowledge of fundamental data structures and providing specialized videos of Historically Black College or University alumni, sharing their struggles with impostor syndrome.",1.0,0.9699453115463257,True,0.3775406687981454,0.6737429901722356,True
Does the Geometry of the Data Control the Geometry of Neural Predictions? (Student Abstract),"This paper studies the over-parameterization of deep neural networks using the Fisher Information Matrix from information geometry. We identify several surprising trends in the structure of its eigenspectrum, and how this structure relates to the eigenspectrum of the data correlation matrix. We identify how the eigenspectrum relates to the topology of the predictions of the model and develop a ""model reduction'' method for deep networks. This ongoing investigation hypothesizes certain universal trends in the FIM of deep networks that may shed light on their effectiveness.",1.1,0.7059258222579956,True,0.401312339887548,0.5536190810727718,True
Leveraging BERT with Mixup for Sentence Classification (Student Abstract),"Good generalization capability is an important quality of well-trained and robust neural networks. However, networks usually struggle when faced with samples outside the training distribution. Mixup is a technique that improves generalization, reduces memorization, and increases adversarial robustness. We apply a variant of Mixup called Manifold Mixup to the sentence classification problem, and present the results along with an ablation study. Our methodology outperforms CNN, LSTM, and vanilla BERT models in generalization.",0.8,0.8795673847198486,True,0.3318122278318339,0.6056898062758412,True
Learning Noise-Induced Reward Functions for Surpassing Demonstrations in Imitation Learning,"Imitation learning (IL) has recently shown impressive performance in training a reinforcement learning agent with human demonstrations, eliminating the difficulty of designing elaborate reward functions in complex environments. However, most IL methods work under the assumption of the optimality of the demonstrations and thus cannot learn policies to surpass the demonstrators. Some methods have been investigated to obtain better-than-demonstration (BD) performance with inner human feedback or preference labels. In this paper, we propose a method to learn rewards from suboptimal demonstrations via a weighted preference learning technique (LERP). Specifically, we first formulate the suboptimality of demonstrations as the inaccurate estimation of rewards. The inaccuracy is modeled with a reward noise random variable following the Gumbel distribution. Moreover, we derive an upper bound of the expected return with different noise coefficients and propose a theorem to surpass the demonstrations. Unlike existing literature, our analysis does not depend on the linear reward constraint. Consequently, we develop a BD model with a weighted preference learning technique. Experimental results on continuous control and high-dimensional discrete control tasks show the superiority of our LERP method over other state-of-the-art BD methods.",1.0,0.7924367189407349,True,0.3775406687981454,0.5849886938694402,True
Strictly Proper Contract Functions Can Be Arbitrage-Free,"We consider mechanisms for truthfully eliciting probabilistic predictions from a group of experts. The standard approach --- using a proper scoring rule to separately reward each expert --- is not robust to collusion: experts may collude to misreport their beliefs in a way that guarantees them a larger total reward no matter the eventual outcome. It is a long-standing open question whether there is a truthful elicitation mechanism that makes any such collusion (also called ""arbitrage"") impossible. We resolve this question positively, exhibiting a class of strictly proper arbitrage-free contract functions. These contract functions have two parts: one ensures that the total reward of a coalition of experts depends only on the average of their reports; the other ensures that changing this average report hurts the experts under at least one outcome.",1.0,0.8888194561004639,True,0.3775406687981454,0.6331800624493047,True
Bayesian Adversarial Attack on Graph Neural Networks (Student Abstract),"Adversarial attack on graph neural network (GNN) is distinctive as it often jointly trains the available nodes to generate a graph as an adversarial example. Existing attacking approaches usually consider the case that all the training set is available which may be impractical. In this paper, we propose a novel Bayesian adversarial attack approach based on projected gradient descent optimization, called Bayesian PGD attack, which gets more general attack examples than deterministic attack approaches. The generated adversarial examples by our approach using the same partial dataset as deterministic attack approaches would make the GNN have higher misclassification rate on graph node classification. Specifically, in our approach, the edge perturbation Z is used for generating adversarial examples, which is viewed as a random variable with scale constraint, and the optimization target of the edge perturbation is to maximize the KL divergence between its true posterior distribution p(Z|D) and its approximate variational distribution qθ(Z). We experimentally find that the attack performance will decrease with the reduction of available nodes, and the effect of attack using different nodes varies greatly especially when the number of nodes is small. Through experimental comparison with the state-of-the-art attack approaches on GNNs, our approach is demonstrated to have better and robust attack performance.",0.8,0.863429069519043,True,0.3318122278318339,0.5976206486754384,True
Can You Answer This? - Exploring Zero-Shot QA Generalization Capabilities in Large Language Models (Student Abstract),"The buzz around Transformer-based language models (TLM) such as BERT, RoBERTa, etc. is well-founded owing to their impressive results on an array of tasks. However, when applied to areas needing specialized knowledge (closed-domain), such as medical, finance, etc. their performance takes drastic hits, sometimes more than their older recurrent/convolutional counterparts. In this paper, we explore zero-shot capabilities of large LMs for extractive QA. Our objective is to examine performance change in the face of domain drift i.e. when the target domain data is vastly different in semantic and statistical properties from the source domain and attempt to explain the subsequent behavior. To this end, we present two studies in this paper while planning further experiments later down the road. Our findings indicate flaws in the current generation of TLM limiting their performance on closed-domain tasks.",1.1,0.7718602418899536,True,0.401312339887548,0.5865862908887508,True
What Makes A Good Story? Designing Composite Rewards for Visual Storytelling,"Previous storytelling approaches mostly focused on optimizing traditional metrics such as BLEU, ROUGE and CIDEr. In this paper, we re-examine this problem from a different angle, by looking deep into what defines a natural and topically-coherent story. To this end, we propose three assessment criteria: relevance, coherence and expressiveness, which we observe through empirical analysis could constitute a “high-quality” story to the human eye. We further propose a reinforcement learning framework, ReCo-RL, with reward functions designed to capture the essence of these quality criteria. Experiments on the Visual Storytelling Dataset (VIST) with both automatic and human evaluation demonstrate that our ReCo-RL model achieves better performance than state-of-the-art baselines on both traditional metrics and the proposed new criteria.",1.3,0.7693251967430115,True,0.45016600268752216,0.6097455997152668,True
A Double Phases Generation Network for Yes or No Question Generation (Student Abstract),"This paper aims to solve the task of generating yes or no questions, which generates yes/no questions based on given passages. These questions can be used for evaluation automatically. We propose a double phases generation network that can identify specific phrases related to facts from the input passage and use them as auxiliary information for generation. Specifically, the 1st-phase prediction uses the extracted phrases as assistance to generate an initial question. Then, the 2nd-phase prediction utilizes an attention network to focus on the relevant phrases related to the initial question in the passage to generate questions that are more relevant to the specific facts contained in the initial question. Extensive experiments we performed on BoolQ dataset demonstrate the effectiveness of our framework.",0.8,0.7967594861984253,True,0.3318122278318339,0.5642858570151296,True
Generating Adversarial yet Inconspicuous Patches with a Single Image (Student Abstract),"Deep neural networks have been shown vulnerable to adversarial patches, where exotic patterns can result in model’s wrong prediction. Nevertheless, existing approaches to adversarial patch generation hardly consider the contextual consistency between patches and the image background, causing such patches to be easily detected by human observation. Additionally, these methods require a large amount of data for training, which is computationally expensive. To overcome these challenges, we propose an approach to generate adversarial yet inconspicuous patches with one single image. In our approach, adversarial patches are produced in a coarse-to-fine way with multiple scales of generators and discriminators. The selection of patch location is based on the perceptual sensitivity of victim models. Contextual information is encoded during the Min-Max training to make patches consistent with surroundings.",0.8,0.9839692711830139,True,0.3318122278318339,0.6578907495074239,True
Combinatorial Civic Crowdfunding with Budgeted Agents: Welfare Optimality at Equilibrium and Optimal Deviation,"Civic Crowdfunding (CC) uses the ``power of the crowd"" to garner contributions towards public projects. As these projects are non-excludable, agents may prefer to ``free-ride,"" resulting in the project not being funded. Researchers introduce refunds for single project CC to incentivize agents to contribute, guaranteeing the project's funding. These funding guarantees are applicable only when agents have an unlimited budget. This paper focuses on a combinatorial setting, where multiple projects are available for CC and agents have a limited budget. We study specific conditions where funding can be guaranteed. Naturally, funding the optimal social welfare subset of projects is desirable when every available project cannot be funded due to budget restrictions. We prove the impossibility of achieving optimal welfare at equilibrium for any monotone refund scheme. Further, given the contributions of other agents, we prove that it is NP-Hard for an agent to determine its optimal strategy. That is, while profitable deviations may exist for agents instead of funding the optimal welfare subset, it is computationally hard for an agent to find its optimal deviation. Consequently, we study different heuristics agents can use to contribute to the projects in practice. We demonstrate the heuristics' performance as the average-case trade-off between the welfare obtained and an agent's utility through simulations.",1.0,0.7576828598976135,True,0.3775406687981454,0.5676117643478795,True
MAGIC: Mask-Guided Image Synthesis by Inverting a Quasi-Robust Classifier,"We offer a method for one-shot mask-guided image synthesis that allows controlling manipulations of a single image by inverting a quasi-robust classifier equipped with strong regularizers. Our proposed method, entitled MAGIC, leverages structured gradients from a pre-trained quasi-robust classifier to better preserve the input semantics while preserving its classification accuracy, thereby guaranteeing credibility in the synthesis.
Unlike current methods that use complex primitives to supervise the process or use attention maps as a weak supervisory signal, MAGIC aggregates gradients over the input, driven by a guide binary mask that enforces a strong, spatial prior. MAGIC implements a series of manipulations with a single framework achieving shape and location control, intense non-rigid shape deformations, and copy/move operations in the presence of repeating objects and gives users firm control over the synthesis by requiring to simply specify binary guide masks. 
Our study and findings are supported by various qualitative comparisons with the state-of-the-art on the same images sampled from ImageNet and quantitative analysis using machine perception along with a user survey of 100+ participants that endorse our synthesis quality.",1.0,0.8844786286354065,True,0.3775406687981454,0.631009648716776,True
Who Are Controlled by The Same User? Multiple Identities Deception Detection via Social Interaction Activity (Student Abstract),"Social media has become a preferential place for sharing information. However, some users may create multiple accounts and manipulate them to deceive legitimate users. Most previous studies utilize verbal or behavior features based methods to solve this problem, but they are only designed for some particular platforms, leading to low universalness.In this paper, to support multiple platforms, we construct interaction tree for each account based on their social interactions which is common characteristic of social platforms. Then we propose a new method to calculate the social interaction entropy of each account and detect the accounts which are controlled by the same user. Experimental results on two real-world datasets show that the method has robust superiority over state-of-the-art methods.",1.1,0.7218217253684998,True,0.401312339887548,0.5615670326280239,True
From Video to Images: Contrastive Pretraining for Emotion Recognition from Single Image (Student Abstract),"Emotion detection from face is an important problem and has received attention from industry and academia. Although emotion recognition from videos has a very high performance, emotion recognition from a single image stays a challenging task. In this paper, we try to use information from videos to do emotion recognition on a single image. More specifically, we leverage contrastive loss for pretraining the network on the videos and experiment with different sampling methods to select consistently hard triplets for continual learning of the network. Once the embeddings have been trained, we test them on a standard emotion classification task. Our method significantly improves the performance of the models and shows the efficacy of self-supervision in emotion recognition.",0.8,0.8078703284263611,True,0.3318122278318339,0.5698412781290975,True
BERT & Family Eat Word Salad: Experiments with Text Understanding,"In this paper, we study the response of large models from the BERT family to incoherent inputs that should confuse any model that claims to understand natural language. We define simple heuristics to construct such examples. Our experiments show that state-of-the-art models consistently fail to recognize them as ill-formed, and instead produce high confidence predictions on them. As a consequence of this phenomenon, models trained on sentences with randomly permuted word order perform close to state-of-the-art models. To alleviate these issues, we show that if models are explicitly trained to recognize invalid inputs, they can be robust to such attacks without a drop in performance.",0.8,0.8619393110275269,True,0.3318122278318339,0.5968757694296803,True
Gifting in Multi-Agent Reinforcement Learning (Student Abstract),This work performs a first study on multi-agent reinforcement learning with deliberate reward passing between agents. We empirically demonstrate that such mechanics can greatly improve the learning progression in a resource appropriation setting and provide a preliminary discussion of the complex effects of gifting on the learning dynamics.,0.8,0.8435797095298767,True,0.3318122278318339,0.5876959686808553,True
The Shape of Art History in the Eyes of the Machine,"
 
 How does the machine classify styles in art? And how does it relate to art historians' methods for analyzing style? Several studies showed the ability of the machine to learn and predict styles, such as Renaissance, Baroque, Impressionism, etc., from images of paintings. This implies that the machine can learn an internal representation encoding discriminative features through its visual analysis. However, such a representation is not necessarily interpretable. We conducted a comprehensive study of several of the state-of-the-art convolutional neural networks applied to the task of style classification on 67K images of paintings, and analyzed the learned representation through correlation analysis with concepts derived from art history. Surprisingly, the networks could place the works of art in a smooth temporal arrangement mainly based on learning style labels, without any a priori knowledge of time of creation, the historical time and context of styles, or relations between styles. The learned representations showed that there are a few underlying factors that explain the visual variations of style in art. Some of these factors were found to correlate with style patterns suggested by Heinrich Wölfflin (1846-1945). The learned representations also consistently highlighted certain artists as the extreme distinctive representative of their styles, which quantitatively confirms art historian observations.
 
",1.0,0.855742335319519,True,0.3775406687981454,0.6166415020588323,True
Do Not Have Enough Data? Deep Learning to the Rescue!,"Based on recent advances in natural language modeling and those in text generation capabilities, we propose a novel data augmentation method for text classification tasks. We use a powerful pre-trained neural network model to artificially synthesize new labeled data for supervised learning. We mainly focus on cases with scarce labeled data. Our method, referred to as language-model-based data augmentation (LAMBADA), involves fine-tuning a state-of-the-art language generator to a specific task through an initial training phase on the existing (usually small) labeled data. Using the fine-tuned model and given a class label, new sentences for the class are generated. Our process then filters these new sentences by using a classifier trained on the original data. In a series of experiments, we show that LAMBADA improves classifiers' performance on a variety of datasets. Moreover, LAMBADA significantly improves upon the state-of-the-art techniques for data augmentation, specifically those applicable to text classification tasks with little data.",0.8,0.8633671998977661,True,0.3318122278318339,0.5975897138648,True
Invertible Conditional GAN Revisited: Photo-to-Manga Face Translation with Modern Architectures (Student Abstract),"Recent style translation methods have extended their transferability from texture to geometry. However, performing translation while preserving image content when there is a significant style difference is still an open problem. To overcome this problem, we propose Invertible Conditional Fast GAN (IcFGAN) based on GAN inversion and cFGAN. It allows for unpaired photo-to-manga face translation. Experimental results show that our method could translate styles under significant style gaps, while the state-of-the-art methods could hardly preserve image content.",0.8,0.8301640748977661,True,0.3318122278318339,0.5809881513648,True
Fast Counterfactual Inference for History-Based Reinforcement Learning,"Incorporating sequence-to-sequence models into history-based Reinforcement Learning (RL) provides a general way to extend RL to partially-observable tasks. This method compresses history spaces according to the correlations between historical observations and the rewards. However, they do not adjust for the confounding correlations caused by data sampling and assign high beliefs to uninformative historical observations, leading to limited compression of history spaces. Counterfactual Inference (CI), which estimates causal effects by single-variable intervention, is a promising way to adjust for confounding. However, it is computationally infeasible to directly apply the single-variable intervention to a huge number of historical observations. This paper proposes to perform CI on observation sub-spaces instead of single observations and develop a coarse-to-fine CI algorithm, called Tree-based History Counterfactual Inference (T-HCI), to reduce the number of interventions exponentially. We show that T-HCI is computationally feasible in practice and brings significant sample efficiency gains in various challenging partially-observable tasks, including Maze, BabyAI, and robot manipulation tasks.",1.0,0.7372614741325378,True,0.3775406687981454,0.5574010714653417,True
"Robotic Manipulation with Reinforcement Learning, State Representation Learning, and Imitation Learning (Student Abstract)","Humans possess the advanced ability to grab, hold, and manipulate objects with dexterous hands. What about robots? Can they interact with the surrounding world intelligently to achieve certain goals (e.g., grasping, object-relocation)? Actually, robotic manipulation is central to achieving the premise of robotics and represents immense potential to be widely applied in various scenarios like industries, hospitals, and homes. In this work, we aim to address multiple robotic manipulation tasks like grasping, button-pushing, and door-opening with reinforcement learning (RL), state representation learning (SRL), and imitation learning. For diverse missions, we self-built the PyBullet or MuJoCo simulated environments and independently explored three different learning-style methods to successfully solve such tasks: (1) Normal reinforcement learning methods; (2) Combined state representation learning (SRL) and RL approaches; (3) Imitation learning bootstrapped RL algorithms.",0.8,0.7887696623802185,True,0.3318122278318339,0.5602909451060262,True
HGMAN: Multi-Hop and Multi-Answer Question Answering Based on Heterogeneous Knowledge Graph (Student Abstract),"Multi-hop question answering models based on knowledge graph have been extensively studied. Most existing models predict a single answer with the highest probability by ranking candidate answers. However, they are stuck in predicting all the right answers caused by the ranking method. In this paper, we propose a novel model that converts the ranking of candidate answers into individual predictions for each candidate, named heterogeneous knowledge graph based multi-hop and multi-answer model (HGMAN). HGMAN is capable of capturing more informative representations for relations assisted by our heterogeneous graph, which consists of multiple entity nodes and relation nodes. We rely on graph convolutional network for multi-hop reasoning and then binary classification for each node to get multiple answers. Experimental results on MetaQA dataset show the performance of our proposed model over all baselines.",0.8,0.9616246223449707,True,0.3318122278318339,0.6467184250884023,True
EnsNet: Ensconce Text in the Wild,"A new method is proposed for removing text from natural images. The challenge is to first accurately localize text on the stroke-level and then replace it with a visually plausible background. Unlike previous methods that require image patches to erase scene text, our method, namely ensconce network (EnsNet), can operate end-to-end on a single image without any prior knowledge. The overall structure is an end-to-end trainable FCN-ResNet-18 network with a conditional generative adversarial network (cGAN). The feature of the former is first enhanced by a novel lateral connection structure and then refined by four carefully designed losses: multiscale regression loss and content loss, which capture the global discrepancy of different level features; texture loss and total variation loss, which primarily target filling the text region and preserving the reality of the background. The latter is a novel local-sensitive GAN, which attentively assesses the local consistency of the text erased regions. Both qualitative and quantitative sensitivity experiments on synthetic images and the ICDAR 2013 dataset demonstrate that each component of the EnsNet is essential to achieve a good performance. Moreover, our EnsNet can significantly outperform previous state-of-the-art methods in terms of all metrics. In addition, a qualitative experiment conducted on the SBMNet dataset further demonstrates that the proposed method can also preform well on general object (such as pedestrians) removal tasks. EnsNet is extremely fast, which can preform at 333 fps on an i5-8600 CPU device.",1.0,0.8652961850166321,True,0.3775406687981454,0.6214184269073888,True
Story Ending Generation with Multi-Level Graph Convolutional Networks over Dependency Trees,"As an interesting and challenging task, story ending generation aims at generating a reasonable and coherent ending for a given story context. The key challenge of the task is to comprehend the context sufficiently and capture the hidden logic information effectively, which has not been well explored by most existing generative models. To tackle this issue, we propose a context-aware Multi-level Graph Convolutional Networks over Dependency Parse (MGCN-DP) trees to capture dependency relations and context clues more effectively. We utilize dependency parse trees to facilitate capturing relations and events in the context implicitly, and Multi-level Graph Convolutional Networks to update and deliver the representation crossing levels to obtain richer contextual information. Both automatic and manual evaluations show that our MGCN-DP can achieve comparable performance with state-of-the-art models. Our source code is available at https://github.com/VISLANG-Lab/MLGCN-DP.",1.0,0.793007493019104,True,0.3775406687981454,0.5852740809086248,True
Fraud's Bargain Attacks to Textual Classifiers via Metropolis-Hasting Sampling (Student Abstract),"Recent studies on adversarial examples expose vulnerabilities of natural language processing (NLP) models. Existing techniques for generating adversarial examples are typically driven by deterministic heuristic rules that are agnostic to the optimal adversarial examples, a strategy that often results in attack failures. To this end, this research proposes Fraud's Bargain Attack (FBA), which utilizes a novel randomization mechanism to enlarge the searching space and enables high-quality adversarial examples to be generated with high probabilities. FBA applies the Metropolis-Hasting algorithm to enhance the selection of adversarial examples from all candidates proposed by a customized Word Manipulation Process (WMP). WMP perturbs one word at a time via insertion, removal, or substitution in a contextual-aware manner. Extensive experiments demonstrate that FBA outperforms the baselines in terms of attack success rate and imperceptibility.",0.8,0.863010048866272,True,0.3318122278318339,0.5974111383490529,True
Interactive Semantic Parsing for If-Then Recipes via Hierarchical Reinforcement Learning,"Given a text description, most existing semantic parsers synthesize a program in one shot. However, it is quite challenging to produce a correct program solely based on the description, which in reality is often ambiguous or incomplete. In this paper, we investigate interactive semantic parsing, where the agent can ask the user clarification questions to resolve ambiguities via a multi-turn dialogue, on an important type of programs called “If-Then recipes.” We develop a hierarchical reinforcement learning (HRL) based agent that significantly improves the parsing performance with minimal questions to the user. Results under both simulation and human evaluation show that our agent substantially outperforms non-interactive semantic parsers and rule-based agents.1",1.0,0.8093473315238953,True,0.3775406687981454,0.5934440001610204,True
Photogrammetry and VR for Comparing 2D and Immersive Linguistic Data Collection (Student Abstract),"The overarching goal of this work is to enable the collection of language describing a wide variety of objects viewed in virtual reality. We aim to create full 3D models from a small number of ‘keyframe’ images of objects found in the publicly available Grounded Language Dataset (GoLD) using photogrammetry. We will then collect linguistic descriptions by placing our models in virtual reality and having volunteers describe them. To evaluate the impact of virtual reality immersion on linguistic descriptions of the objects, we intend to apply contrastive learning to perform grounded language learning, then compare the descriptions collected from images (in GoLD) versus our models.",0.8,0.7832653522491455,True,0.3318122278318339,0.5575387900404897,True
Introduction to Machine Learning with Robots and Playful Learning,"Inspired by explanations of machine learning concepts in children’s books, we developed an approach to introduce supervised, unsupervised, and reinforcement learning using a block-based programming language in combination with the benefits of educational robotics. Instead of using blocks as high-end APIs to access AI cloud services or to reproduce the machine learning algorithms, we use them as a means to put the student “in the algorithm’s shoes.” We adapt the training of neural networks, Q-learning, and k-means algorithms to a design and format suitable for children and equip the students with hands-on tools for playful experimentation. The children learn about direct supervision by modifying the weights in the neural networks and immediately observing the effects on the simulated robot. Following the ideas of constructionism, they experience how the algorithms and underlying machine learning concepts work in practice. We conducted and evaluated this approach with students in primary, middle, and high school. All the age groups perceived the topics to be very easy to moderately hard to grasp. Younger students experienced direct supervision as challenging, whereas they found Q-learning and k-means algorithms much more accessible. Most high-school students could cope with all the topics without particular difficulties.",1.0,0.9912296533584595,True,0.3775406687981454,0.6843851610783025,True
Holistic Multi-View Building Analysis in the Wild with Projection Pooling,"We address six different classification tasks related to fine-grained building attributes: construction type, number of floors, pitch and geometry of the roof, facade material, and occupancy class. Tackling such a remote building analysis problem became possible only recently due to growing large-scale datasets of urban scenes. To this end, we introduce a new benchmarking dataset, consisting of 49426 images (top-view and street-view) of 9674 buildings. These photos are further assembled, together with the geometric metadata. The dataset showcases various real-world challenges, such as occlusions, blur, partially visible objects, and a broad spectrum of buildings. We propose a new \emph{projection pooling layer}, creating a unified, top-view representation of the top-view and the side views in a high-dimensional space. It allows us to utilize the building and imagery metadata seamlessly. Introducing this layer improves classification accuracy -- compared to highly tuned baseline models -- indicating its suitability for building analysis.",1.0,0.9059531092643738,True,0.3775406687981454,0.6417468890312596,True
I Am Guessing You Can't Recognize This: Generating Adversarial Images for Object Detection Using Spatial Commonsense (Student Abstract),"Can we automatically predict failures of an object detection model on images from a target domain? We characterize errors of a state-of-the-art object detection model on the currently popular smart mobility domain, and find that a large number of errors can be identified using spatial commonsense. We propose ourmodel , a system that automatically identifies a large number of such errors based on commonsense knowledge. Our system does not require any new annotations and can still find object detection errors with high accuracy (more than 80% when measured by humans). This work lays the foundation to answer exciting research questions on domain adaptation including the ability to automatically create adversarial datasets for target domain.",0.8,0.8010701537132263,True,0.3318122278318339,0.5664411907725301,True
Finite Sample Analyses for TD(0) With Function Approximation,"
 
 TD(0) is one of the most commonly used algorithms in reinforcement learning. Despite this, there is no existing finite sample analysis for TD(0) with function approximation, even for the linear case. Our work is the first to provide such results. Existing convergence rates for Temporal Difference (TD) methods apply only to somewhat modified versions, e.g., projected variants or ones where stepsizes depend on unknown problem parameters. Our analyses obviate these artificial alterations by exploiting strong properties of TD(0). We provide convergence rates both in expectation and with high-probability. The two are obtained via different approaches that use relatively unknown, recently developed stochastic approximation techniques.
 
",1.8,0.6082115173339844,True,0.574442516811659,0.5913270170728218,True
Learning Options with Interest Functions,"Learning temporal abstractions which are partial solutions to a task and could be reused for solving other tasks is an ingredient that can help agents to plan and learn efficiently. In this work, we tackle this problem in the options framework. We aim to autonomously learn options which are specialized in different state space regions by proposing a notion of interest functions, which generalizes initiation sets from the options framework for function approximation. We build on the option-critic framework to derive policy gradient theorems for interest functions, leading to a new interest-option-critic architecture.",1.0,0.7487077116966248,True,0.3775406687981454,0.5631241902473851,True
FaceController: Controllable Attribute Editing for Face in the Wild,"Face attribute editing aims to generate faces with one or multiple desired face attributes manipulated while other details are preserved. Unlike prior works such as GAN inversion which has an expensive reverse mapping process, we propose a simple feed-forward network to generate high-fidelity manipulated faces. By simply employing some existing and easy-obtainable prior information, our method can control, transfer, and edit diverse attributes of faces in the wild. The proposed method can consequently be applied to various applications such as face swapping, face relighting, and makeup transfer. In our method, we decouple identity, expression, pose, and illumination by using 3D priors; separate texture and colors by using region-wise style codes. All the information is embedded into adversarial learning by our identity-style normalization module. Disentanglement losses are proposed to enhance the generator to extract information independently from each attribute. Comprehensive quantitative and qualitative evaluations have been conducted. In a single framework, our method achieves the best or competitive scores on a variety of face applications.",1.0,0.8440636992454529,True,0.3775406687981454,0.6108021840217992,True
The Surprising Power of Hiding Information in Facility Location,"Facility location is the problem of locating a public facility based on the preferences of multiple agents. In the classic framework, where each agent holds a single location on a line and can misreport it, strategyproof mechanisms for choosing the location of the facility are well-understood.We revisit this problem in a more general framework. We assume that each agent may hold several locations on the line with different degrees of importance to the agent. We study mechanisms which elicit the locations of the agents and different levels of information about their importance. Further, in addition to the classic manipulation of misreporting locations, we introduce and study a new manipulation, whereby agents may hide some of their locations. We argue for its novelty in facility location and applicability in practice. Our results provide a complete picture of the power of strategyproof mechanisms eliciting different levels of information and with respect to each type of manipulation. Surprisingly, we show that in some cases hiding locations can be a strictly more powerful manipulation than misreporting locations.",1.0,0.891755998134613,True,0.3775406687981454,0.6346483334663793,True
Double Policy Network for Aspect Sentiment Triplet Extraction (Student Abstract),"Aspect Sentiment Triplet Extraction (ASTE) is the task to extract aspects, opinions and associated sentiments from sentences. Previous studies do not adequately consider the complicated interactions between aspect and opinion terms in both extraction logic and strategy. We present a novel Double Policy Network with Multi-Tag based Reward model (DPN-MTR), which adopts two networks ATE, TSOTE and a Trigger Mechanism to execute ASTE task following a more logical framework. A Multi-Tag based reward is also proposed to solve the limitations of existing studies for identifying aspect/opinion terms with multiple tokens (one term may consist of two or more tokens) to a certain extent. Extensive experiments are conducted on four widely-used benchmark datasets, and demonstrate the effectiveness of our model in generally improving the performance on ASTE significantly.",0.8,0.8870243430137634,True,0.3318122278318339,0.6094182854227986,True
Learning to Model Opponent Learning (Student Abstract),"Multi-Agent Reinforcement Learning (MARL) considers settings in which a set of coexisting agents interact with one another and their environment. The adaptation and learning of other agents induces non-stationarity in the environment dynamics. This poses a great challenge for value function-based algorithms whose convergence usually relies on the assumption of a stationary environment. Policy search algorithms also struggle in multi-agent settings as the partial observability resulting from an opponent's actions not being known introduces high variance to policy training. Modelling an agent's opponent(s) is often pursued as a means of resolving the issues arising from the coexistence of learning opponents. An opponent model provides an agent with some ability to reason about other agents to aid its own decision making. Most prior works learn an opponent model by assuming the opponent is employing a stationary policy or switching between a set of stationary policies. Such an approach can reduce the variance of training signals for policy search algorithms. However, in the multi-agent setting, agents have an incentive to continually adapt and learn. This means that the assumptions concerning opponent stationarity are unrealistic. In this work, we develop a novel approach to modelling an opponent's learning dynamics which we term Learning to Model Opponent Learning (LeMOL). We show our structured opponent model is more accurate and stable than naive behaviour cloning baselines. We further show that opponent modelling can improve the performance of algorithmic agents in multi-agent settings.",0.8,0.7783414721488953,True,0.3318122278318339,0.5550768499903646,True
Using Graph-Aware Reinforcement Learning to Identify Winning Strategies in Diplomacy Games (Student Abstract),"This abstract proposes an approach towards goal-oriented modeling of the detection and modeling complex social phenomena in multiparty discourse in an online political strategy game.
We developed a two-tier approach that first encodes sociolinguistic behavior as linguistic features then use reinforcement learning to estimate the advantage afforded to any player. 
In the first tier, sociolinguistic behavior, such as Friendship and Reasoning, that speakers use to influence others are encoded as linguistic features to identify the persuasive strategies applied by each player in simultaneous two-party dialogues. In the second tier, a reinforcement learning approach is used to estimate a graph-aware reward function to quantify the advantage afforded to each player based on their standing in this multiparty setup. We apply this technique to the game Diplomacy, using a dataset comprising of over 15,000 messages exchanged between 78 users. Our graph-aware approach shows robust performance compared to a context-agnostic setup.",0.8,0.7983612418174744,True,0.3318122278318339,0.5650867348246541,True
Gerrymandering under Uncertain Preferences (Student Abstract),"Gerrymandering is the manipulating of redistricting for political gain. While many attempts to formalize and model gerrymandering have been made, the assumption of known voter preference, or perfect information, limits the applicability of these works to model real world scenarios. To more accurately reason about gerrymandering we investigate how to adapt existing models of the problem to work with imperfect information. In our work, we formalize a definition of the gerrymandering problem under probabilistic voter preferences, reason about its complexity compared to the deterministic version, and propose a greedy algorithm to approximate the problem in polynomial time under certain conditions.",0.8,0.8449590802192688,True,0.3318122278318339,0.5883856540255513,True
NEUROCRYPT: Coercion-Resistant Implicit Memory Authentication (Student Abstract),"Overcoming the threat of coercion attacks in a cryptographic system has been a top priority for system designers since the birth of cyber-security. One way to overcome such a threat is to leverage implicit memory to construct a defense against rubber-hose attacks where the users themselves do not possess conscious knowledge of the trained password. We propose NeuroCrypt, a coercion-resistant authentication system that uses an improved version of the Serial Interception Sequence Learning task, employing additional auditory and haptic modalities backed by concepts borrowed from cognitive psychology. We carefully modify the visual stimuli as well as add auditory and haptic stimuli to improve the implicit learning process, resulting in faster training and longer retention. Moreover, our improvements guarantee that explicit recognition of the trained passwords remains suppressed.",0.8,0.7839605212211609,True,0.3318122278318339,0.5578863745264974,True
Sketch and Customize: A Counterfactual Story Generator,"Recent text generation models are easy to generate relevant and fluent text for the given text, while lack of causal reasoning ability when we change some parts of the given text.
Counterfactual story rewriting is a recently proposed task to test the causal reasoning ability for text generation models, which requires a model to predict the corresponding story ending when the condition is modified to a counterfactual one. Previous works have shown that the traditional sequence-to-sequence model cannot well handle this problem, as it often captures some spurious correlations between the original and counterfactual endings, instead of the causal relations between conditions and endings.
To address this issue, we propose a sketch-and-customize generation model guided by the causality implicated in the conditions and endings. In the sketch stage, a skeleton is extracted by removing words which are conflict to the counterfactual condition, from the original ending. In the customize stage, a generation model is used to fill proper words in the skeleton under the guidance of the counterfactual condition. In this way, the obtained counterfactual ending is both relevant to the original ending and consistent with the counterfactual condition. Experimental results show that the proposed model generates much better endings, as compared with the traditional sequence-to-sequence model.",1.0,0.950579047203064,True,0.3775406687981454,0.6640598580006047,True
Third-Person Imitation Learning via Image Difference and Variational Discriminator Bottleneck (Student Abstract),"Third-person imitation learning (TPIL) is a variant of generative adversarial imitation learning and can learn an expert-like policy from third-person expert demonstrations. Third-person expert demonstrations usually exist in the form of videos recorded in a third-person perspective, and there is a lack of direct correspondence with samples generated by agent. To alleviate this problem, we improve TPIL by applying image difference and variational discriminator bottleneck. Empirically, our new method has better performance than TPIL on two MuJoCo tasks, Reacher and Inverted Pendulum.",0.8,0.7741097807884216,True,0.3318122278318339,0.5529610043101277,True
Contextual Bandits with Delayed Feedback and Semi-supervised Learning (Student Abstract),"Contextual multi-armed bandit (MAB) is a classic online learning problem, where a learner/agent selects actions (i.e., arms) given contextual information and discovers optimal actions based on reward feedback. Applications of contextual bandit have been increasingly expanding, including advertisement, personalization, resource allocation in wireless networks, among others. Nonetheless, the reward feedback is delayed in many applications (e.g., a user may only provide service ratings after a period of time), creating challenges for contextual bandits. In this paper, we address delayed feedback in contextual bandits by using semi-supervised learning — incorporate estimates of delayed rewards to improve the estimation of future rewards. Concretely, the reward feedback for an arm selected at the beginning of a round is only observed by the agent/learner with some observation noise and provided to the agent after some a priori unknown but bounded delays. Motivated by semi-supervised learning that produces pseudo labels for unlabeled data to further improve the model performance, we generate fictitious estimates of rewards that are delayed and have yet to arrive based on already-learnt reward functions. Thus, by combining semi-supervised learning with online contextual bandit learning, we propose a novel extension and design two algorithms, which estimate the values for currently unavailable reward feedbacks to minimize the maximum estimation error and average estimation error, respectively.",0.8,0.961007833480835,True,0.3318122278318339,0.6464100306563344,True
PoseBlocks: A Toolkit for Creating (and Dancing) with AI,"Body-tracking artificial intelligence (AI) systems like Kinect games, Snapchat Augmented Reality (AR) Lenses, and Instagram AR Filters are some of the most engaging ways students experience AI in their everyday lives. Additionally, many students have existing interests in physical hobbies like sports and dance. In this paper, we present PoseBlocks; a suite of block-based programming tools which enable students to build compelling body-interactive AI projects in any web browser, integrating camera/microphone inputs and body-sensing user interactions. To accomplish this, we provide a custom block-based programming environment building on the open source Scratch project, introducing new AI-model-powered blocks supporting body, hand, and face tracking, emotion recognition, and the ability to integrate custom image/pose/audio models from the online transfer learning tool Teachable Machine. We introduce editor functionality such as a project video recorder, pre-computed video loops, and integration with curriculum materials. We discuss deploying this toolkit with an accompanying curriculum in a series of synchronous online pilots with 46 students, aged 9-14. In analyzing class projects and discussions, we find that students learned to design, train, and integrate machine learning models in projects of their own devising while exploring ethical considerations such as stakeholder values and algorithmic bias in their interactive AI systems.",0.8,0.9931253790855408,True,0.3318122278318339,0.6624688034586873,True
Fairness Does Not Imply Satisfaction (Student Abstract),"Fair division is a subfield of multiagent systems that is concerned with object distribution. When objects are indivisible, the Maximin Share Guarantee (MMS) is a desirable fairness notion; however, it is not guaranteed to exist. While MMS allocations may not always exist, a relaxation of MMS is guaranteed to exist. We show that there exists a family of instances for which this relaxation fails to guarantee the MMS value for all but a small constant number of agents.",0.8,0.7913653254508972,True,0.3318122278318339,0.5615887766413655,True
Find a Reasonable Ending for Stories: Does Logic Relation Help the Story Cloze Test?,"Natural language understanding is a challenging problem that covers a wide range of tasks. While previous methods generally train each task separately, we consider combining the cross-task features to enhance the task performance. In this paper, we incorporate the logic information with the help of the Natural Language Inference (NLI) task to the Story Cloze Test (SCT). Previous work on SCT considered various semantic information, such as sentiment and topic, but lack the logic information between sentences which is an essential element of stories. Thus we propose to extract the logic information during the course of the story to improve the understanding of the whole story. The logic information is modeled with the help of the NLI task. Experimental results prove the strength of the logic information.",1.3,0.6856709122657776,True,0.45016600268752216,0.5679184574766498,True
"Where there's Smoke, there's Fire: Wildfire Risk Predictive Modeling via Historical Climate Data","Wildfire is a growing global crisis with devastating consequences. Uncontrolled wildfires take away human lives, destroy millions of animals and trees, degrade the air quality, impact the biodiversity of the planet and cause substantial economic costs.
It is incredibly challenging to predict the spatio-temporal likelihood of wildfires based on historical data, due to their stochastic nature. Crucially though, the accurate and reliable prediction of wildfires can help the stakeholders and decision-makers take timely, strategic and effective actions to prevent, detect and suppress the wildfires before they become unmanageable. Unfortunately, most previous studies developed predictive models that suffer from some shortcomings: (i) they do not take the temporal aspects into account precisely and they assume the independent and identically distributed random variables in the evaluation phase; (ii) they do not evaluate their approaches comprehensively, thus it is not clear if their proposed predictions and selected models are reliable across different locations and time steps for practical deployment; and (iii) for the supervised learning models, they use predictor features and fire observations from the same time step in the training phase, which makes the inference task infeasible for future fire prediction. In this paper, we revisit the wildfire predictive modeling, explore the inherent challenges from a practical perspective and evaluate our modeling approach comprehensively via historical burned areas, climate and geospatial data from three vast landscapes in India.",1.0,0.8559134006500244,True,0.3775406687981454,0.616727034724085,True
Real or Fake Text?: Investigating Human Ability to Detect Boundaries Between Human-Written and Machine-Generated Text,"As text generated by large language models proliferates, it becomes vital to understand how humans engage with such text, and whether or not they are able to detect when the text they are reading did not originate with a human writer. Prior work on human detection of generated text focuses on the case where an entire passage is either human-written or machine-generated. In this paper, we study a more realistic setting where text begins as human-written and transitions to being generated by state-of-the-art neural language models. We show that, while annotators often struggle at this task, there is substantial variance in annotator skill and that given proper incentives, annotators can improve at this task over time. Furthermore, we conduct a detailed comparison study and analyze how a variety of variables (model size, decoding strategy, fine-tuning, prompt genre, etc.) affect human detection performance. Finally, we collect error annotations from our participants and use them to show that certain textual genres influence models to make different types of errors and that certain sentence-level features correlate highly with annotator selection. We release the RoFT dataset: a collection of over 21,000 human annotations paired with error classifications to encourage future work in human detection and evaluation of generated text.",1.1,0.7754789590835571,True,0.401312339887548,0.5883956494855526,True
Solving JumpIN' Using Zero-Dependency Reinforcement Learning (Student Abstract),"Reinforcement learning seeks to teach agents to solve problems using numerical rewards as feedback. This makes it possible to incentivize actions that maximize returns despite having no initial strategy or knowledge of their environment. We implement a zero-external-dependency Q-learning algorithm using Python to optimally solve the single-player game JumpIn’ from SmartGames. We focus on interpretability of the model using Q-table parsing, and transferability to other games through a modular code structure. We observe rapid performance gains using our backtracking update algorithm.",0.8,0.9397857785224915,True,0.3318122278318339,0.6357990031771626,True
Visual Definition Modeling: Challenging Vision & Language Models to Define Words and Objects,"Architectures that model language and vision together havereceived much attention in recent years. Nonetheless, most tasks in this field focus on end-to-end applications without providing insights on whether it is the underlying semantics of visual objects or words that is captured. In this paper we draw on the established Definition Modeling paradigm and enhance it by grounding, for the first time, textual definitions to visual representations. We name this new task Visual Definition Modeling and put forward DEMETER and DIONYSUS, two benchmarks where, given an image as context, models have to generate a textual definition for a target being either i) a word that describes the image, or ii) an object patch therein. To measure the difficulty of our tasks we finetuned six different baselines and analyzed their performances, which show that a text-only encoder-decoder model is more effective than models pretrained for handling inputs of both modalities concurrently. This demonstrates the complexity of our benchmarks and encourages more research on text generation conditioned on multimodal inputs. The datasets for both benchmarks are available at https://github.com/SapienzaNLP/visual-definition-modeling as well as the code to reproduce our models.",0.8,0.906837522983551,True,0.3318122278318339,0.6193248754076924,True
Symbolic Metamodels for Interpreting Black-boxes Using Primitive Functions,"One approach for interpreting black-box machine learning models is to find a global approximation of the model using simple interpretable functions, which is called a metamodel (a model of the model). Approximating the black-box with
a metamodel can be used to 1) estimate instance-wise feature importance; 2) understand the functional form of the model; 3) analyze feature interactions. In this work, we propose a new method for finding interpretable metamodels. Our approach utilizes Kolmogorov superposition theorem, which expresses multivariate functions as a composition of univariate functions (our primitive parameterized
functions). This composition can be represented in the form of a tree. Inspired by symbolic regression, we use a modified form of genetic programming to search over different tree configurations. Gradient descent (GD) is used to optimize the parameters of a given configuration. Our method is a novel memetic algorithm that uses GD not only for training numerical constants but also for the training
of building blocks. Using several experiments, we show that our method outperforms recent metamodeling approaches suggested for interpreting black-boxes.",1.0,0.8075687289237976,True,0.3775406687981454,0.5925546988609716,True
Mask & Focus: Conversation Modelling by Learning Concepts,"Sequence to sequence models attempt to capture the correlation between all the words in the input and output sequences. While this is quite useful for machine translation where the correlation among the words is indeed quite strong, it becomes problematic for conversation modelling where the correlation is often at a much abstract level. In contrast, humans tend to focus on the essential concepts discussed in the conversation context and generate responses accordingly. In this paper, we attempt to mimic this response generating mechanism by learning the essential concepts in the context and response in an unsupervised manner. The proposed model, referred to as Mask & Focus maps the input context to a sequence of concepts which are then used to generate the response concepts. Together, the context and the response concepts generate the final response. In order to learn context concepts from the training data automatically, we mask words in the input and observe the effect of masking on response generation. We train our model to learn those response concepts that have high mutual information with respect to the context concepts, thereby guiding the model to focus on the context concepts. Mask & Focus achieves significant improvement over the existing baselines in several established metrics for dialogues.",0.8,0.85243159532547,True,0.3318122278318339,0.5921219115786519,True
Draft and Edit: Automatic Storytelling Through Multi-Pass Hierarchical Conditional Variational Autoencoder,"Automatic Storytelling has consistently been a challenging area in the field of natural language processing. Despite considerable achievements have been made, the gap between automatically generated stories and human-written stories is still significant. Moreover, the limitations of existing automatic storytelling methods are obvious, e.g., the consistency of content, wording diversity. In this paper, we proposed a multi-pass hierarchical conditional variational autoencoder model to overcome the challenges and limitations in existing automatic storytelling models. While the conditional variational autoencoder (CVAE) model has been employed to generate diversified content, the hierarchical structure and multi-pass editing scheme allow the story to create more consistent content. We conduct extensive experiments on the ROCStories Dataset. The results verified the validity and effectiveness of our proposed model and yields substantial improvement over the existing state-of-the-art approaches.",1.0,0.766287624835968,True,0.3775406687981454,0.5719141468170568,True
Fundamentals of Task-Agnostic Data Valuation,"We study valuing the data of a data owner/seller for a data seeker/buyer. Data valuation is often carried out for a specific task assuming a particular utility metric, such as test accuracy on a validation set, that may not exist in practice. In this work, we focus on task-agnostic data valuation without any validation requirements. The data buyer has access to a limited amount of data (which could be publicly available) and seeks more data samples from a data seller. We formulate the problem as estimating the differences in the statistical properties of the data at the seller with respect to the baseline data available at the buyer. We capture these statistical differences through second moment by measuring diversity and relevance of the seller’s data for the buyer; we estimate these measures through queries to the seller without requesting the raw data. We design the queries with the proposed approach so that the seller is blind to the buyer’s raw data and has no knowledge to fabricate responses to the queries to obtain a desired outcome of the diversity and relevance trade-off. We will show through extensive experiments on real tabular and image datasets that the proposed estimates capture the diversity and relevance of the seller’s data for the buyer.",1.0,0.8605346083641052,True,0.3775406687981454,0.6190376385811254,True
It Takes (Only) Two: Adversarial Generator-Encoder Networks,"
 
 We present a new autoencoder-type architecture that is trainable in an unsupervised mode, sustains both generation and inference, and has the quality of conditional and unconditional samples boosted by adversarial learning. Unlike previous hybrids of autoencoders and adversarial networks, the adversarial game in our approach is set up directly between the encoder and the generator, and no external mappings are trained in the process of learning.The game objective compares the divergences of each of the real and the generated data distributions with the prior distribution in the latent space. We show that direct generator-vs-encoder game leads to a tight coupling of the two components, resulting in samples and reconstructions of a comparable quality to some recently-proposed more complex architectures.
 
",0.8,0.8772884011268616,True,0.3318122278318339,0.6045503144793477,True
PulseSatellite: A tool using human-AI feedback loops for satellite image analysis in humanitarian contexts,"Humanitarian response to natural disasters and conflicts can be assisted by satellite image analysis. In a humanitarian context, very specific satellite image analysis tasks must be done accurately and in a timely manner to provide operational support. We present PulseSatellite, a collaborative satellite image analysis tool which leverages neural network models that can be retrained on-the fly and adapted to specific humanitarian contexts and geographies. We present two case studies, in mapping shelters and floods respectively, that illustrate the capabilities of PulseSatellite.",1.0,0.7402538657188416,True,0.3775406687981454,0.5588972672584935,True
An Emotion-Based Multi-Task Approach to Fake News Detection (Student Abstract),"Social media, blogs, and online articles are instant sources of news for internet users globally. But due to their unmoderated nature, a significant percentage of these texts are fake news or rumors. Their deceptive nature and ability to propagate instantly can have an adverse effect on society. In this work, we hypothesize that legitimacy of news has a correlation with its emotion, and propose a multi-task framework predicting both the emotion and legitimacy of news. Experimental results verify that our multi-task models outperform their single-task counterparts in terms of accuracy.",0.8,0.8688950538635254,True,0.3318122278318339,0.6003536408476796,True
FLAME: Free-form Language-based Motion Synthesis & Editing,"Text-based motion generation models are drawing a surge of interest for their potential for automating the motion-making process in the game, animation, or robot industries. In this paper, we propose a diffusion-based motion synthesis and editing model named FLAME. Inspired by the recent successes in diffusion models, we integrate diffusion-based generative models into the motion domain. FLAME can generate high-fidelity motions well aligned with the given text. Also, it can edit the parts of the motion, both frame-wise and joint-wise, without any fine-tuning. FLAME involves a new transformer-based architecture we devise to better handle motion data, which is found to be crucial to manage variable-length motions and well attend to free-form text. In experiments, we show that FLAME achieves state-of-the-art generation performances on three text-motion datasets: HumanML3D, BABEL, and KIT. We also demonstrate that FLAME’s editing capability can be extended to other tasks such as motion prediction or motion in-betweening, which have been previously covered by dedicated models.",0.8,0.8158601522445679,True,0.3318122278318339,0.5738361900382009,True
Combating False Negatives in Adversarial Imitation Learning (Student Abstract),"We define the False Negatives problem and show that it is a significant limitation in adversarial imitation learning. We propose a method that solves the problem by leveraging the nature of goal-conditioned tasks. The method, dubbed Fake Conditioning, is tested on instruction following tasks in BabyAI environments, where it improves sample efficiency over the baselines by at least an order of magnitude.",0.8,0.7808969616889954,True,0.3318122278318339,0.5563545947604146,True
SkateboardAI: The Coolest Video Action Recognition for Skateboarding (Student Abstract),"Impressed by the coolest skateboarding sports program from 2021 Tokyo Olympic Games, we are the first to curate the original real-world video datasets ""SkateboardAI"" in the wild, even self-design and implement diverse uni-modal and multi-modal video action recognition approaches to recognize different tricks accurately. For uni-modal methods, we separately apply (1)CNN and LSTM; (2)CNN and BiLSTM; (3)CNN and BiLSTM with effective attention mechanisms; (4)Transformer-based action recognition pipeline. Transferred to the multi-modal conditions, we investigated the two-stream Inflated-3D architecture on ""SkateboardAI"" datasets to compare its performance with uni-modal cases. In sum, our objective is developing an excellent AI sport referee for the coolest skateboarding competitions.",1.8,0.8673530220985413,True,0.574442516811659,0.7208977694551002,True
RL Generalization in a Theory of Mind Game Through a Sleep Metaphor (Student Abstract),"Training agents to learn efficiently in multi-agent environments can benefit from the explicit modelling of other agent's beliefs, especially in complex limited-information games such as the Hanabi card game. However, generalization is also highly relevant to performance in these games, though model comparisons at large training timescales can be difficult. In this work, we address this by introducing a novel model trained using a sleep metaphor on a reduced complexity version of the Hanabi game. This sleep metaphor consists an altered training regiment, as well as an information-theoretic constraint on the agent's policy. Results from experimentation demonstrate improved performance through this sleep-metaphor method, and provide a promising motivation for using similar techniques in more complex methods that incorporate explicit models of other agent's beliefs.",0.8,0.8662056922912598,True,0.3318122278318339,0.5990089600615468,True
Labor Division with Movable Walls: Composing Executable Specifications with Machine Learning and Search (Blue Sky Idea),"Artificial intelligence (AI) techniques, including, e.g., machine learning, multi-agent collaboration, planning, and heuristic search, are emerging as ever-stronger tools for solving hard problems in real-world applications. Executable specification techniques (ES), including, e.g., Statecharts and scenario-based programming, is a promising development approach, offering intuitiveness, ease of enhancement, compositionality, and amenability to formal analysis. We propose an approach for integrating AI and ES techniques in developing complex intelligent systems, which can greatly simplify agile/spiral development and maintenance processes. The approach calls for automated detection of whether certain goals and sub-goals are met; a clear division between sub-goals solved with AI and those solved with ES; compositional and incremental addition of AI-based or ES-based components, each focusing on a particular gap between a current capability and a well-stated goal; and, iterative refinement of sub-goals solved with AI into smaller sub-sub-goals where some are solved with ES, and some with AI. We describe the principles of the approach and its advantages, as well as key challenges and suggestions for how to tackle them.",0.8,0.9506182670593262,True,0.3318122278318339,0.64121524744558,True
Transformation of Emotions in Images Using Poisson Blended Generative Adversarial Networks (Student Abstract),"We propose a novel method for transforming the emotional content in an image to a specified target emotion. Existing techniques such as a single generative adversarial network (GAN) struggle to perform well on unconstrained images, especially when data is limited. Our method addresses this limitation by blending the outputs from two networks to better transform fine details (e.g., faces) while still operating on the broader styles of the full image. We demonstrate our method's potential through a proof-of-concept implementation.",0.8,0.8050358295440674,True,0.3318122278318339,0.5684240286879506,True
Incorporating Curiosity into Personalized Ranking for Collaborative Filtering (Student Abstract),"Curiosity affects users' selections of items, and it motivates them to explore the items regardless of their interests. This phenomenon is particularly common in social networks.
However, the existing social-based recommendation methods neglect such feature in social network, and it may cause the accuracy decease in recommendation. What's more, only focusing on simulating the users' preferences can lead to information cocoons. In order to tackle the problem, we propose a novel Curiosity Enhanced Bayesian Personalized Ranking (CBPR) model. Our model makes full use of the theories of psychology to model the users' curiosity aroused when facing different opinions. The experimental results on two public datasets demonstrate the advantages of our CBPR model over the existing models.",0.8,0.9072202444076538,True,0.3318122278318339,0.6195162361197438,True
A Multi-Task Learning Approach to Sarcasm Detection (Student Abstract),"Sarcasm detection plays an important role in natural language processing as it has been considered one of the most challenging subtasks in sentiment analysis and opinion mining applications. Our work aims to detect sarcasm in social media sites and discussion forums, exploiting the potential of deep neural networks and multi-task learning. Specifically, relying on the strong correlation between sarcasm and (implied negative) sentiment, we explore a multi-task learning framework that uses sentiment classification as an auxiliary task to inform the main task of sarcasm detection. Our proposed model outperforms many previous baseline methods on an existing large dataset annotated with sarcasm.",0.8,0.899135947227478,True,0.3318122278318339,0.6154740875296559,True
WildfireNet: Predicting Wildfire Profiles (Student Abstract),"Forecasting an accurate wildfire profile is an essential tool for firefighters when planning an evacuation strategy. Therefore, we propose a WildfireNet that can predict the shape of the wildfire of the next day, when given historical wildfire profiles, elevation, and weather data. The motivation behind WildfireNet is to locate fires in a precise manner and be able to accurately predict upcoming fires. The model’s architecture was built in the inspiration of U-Net, which is a Convolutional Neural Network (CNN) commonly used in a biomedical image segmentation. Intersection over Union (IoU) and recall were calculated to measure the performance of the model. The model achieved an IoU score of 0.997 in the test set. Since the objective of the model is to predict upcoming fires, pixels that were labeled as fire but not on the previous days were extracted to calculate recall. In the test set, Wild-fireNet scored a recall of around 0.75 for fires that grew slowly. Overall, WildfireNet is a novel wildfire spread model and has the potential to be a tool to aid firefighters in their decision making.",1.8,0.6601358652114868,True,0.574442516811659,0.617289191011573,True
Expert Data Augmentation in Imitation Learning (Student Abstract),"Behavioral Cloning (BC) is a simple and effective imitation learning algorithm, which suffers from compounding error due to covariate shift. One solution is to use enough data for training. However, the amount of expert demonstrations available is usually limited. So we propose an effective method to augment expert demonstrations to alleviate the problem of compounding error in BC. It operates by estimating the similarity of states and filtering out transitions that can go back to the states similar to ones in expert demonstrations during the process of sampling. The data filtered out along with original expert demonstrations are used for training. We evaluate the performance of our method on several Atari tasks and continuous MuJoCo control tasks. Empirically, BC trained with the augmented data significantly outperform BC trained with the original expert demonstrations.",0.8,0.7694321274757385,True,0.3318122278318339,0.5506221776537862,True
Coalition Structure Generation Utilizing Graphical Representation of Partition Function Games,"
 
 Forming effective coalition is a central research challenge in AI and multi-agent systems. The Coalition Structure Generation (CSG) problem is well-known as one of major research topics in coalitional games. The CSG problem is to partition a set of agents into coalitions so that the sum of utilities is maximized. This paper studies a CSG problem for partition function games (PFGs), where the value of a coalition differs depending on the formation of other coalitions generated by non-member agents. Traditionally, in PFGs, the input of a coalitional game is a black-box function called a partition function that maps an embedded coalition (a coalition and the coalition structure) to its value. Recently, a novel concise representation scheme called the Partition Decision Trees (PDTs) has been proposed. The PDTs is a graphical representation based on multiple rules. In this paper, we propose new algorithms that can solve a CSG problem by utilizing PDTs representation. More specifically, we modify PDTs representation to effectively handle negative value rules and apply the depth-first branch and bound algorithm. We experimentally show that our algorithm can solve a CSG problem well.
 
",1.0,0.9601898193359375,True,0.3775406687981454,0.6688652440670415,True
"POP ≡ POCL, Right? Complexity Results for Partial Order (Causal Link) Makespan Minimization","We study PO and POCL plans with regard to their makespan – the execution time when allowing the parallel execution of causally independent actions. Partially ordered (PO) plans are often assumed to be equivalent to partial order causal link (POCL) plans, where the causal relationships between actions are explicitly represented via causal links. As a first contribution, we study the similarities and differences of PO and POCL plans, thereby clarifying a common misconception about their relationship: There are PO plans for which there does not exist a POCL plan with the same orderings. We prove that we can still always find a POCL plan with the same makespan in polynomial time. As another main result we prove that turning a PO or POCL plan into one with minimal makespan by only removing ordering constraints (called deordering) is NP-complete. We provide a series of further results on special cases and implications, such as reordering, where orderings can be changed arbitrarily.",1.1,0.8390964865684509,True,0.401312339887548,0.6202044132279995,True
A Heuristic Evaluation Function for Hand Strength Estimation in Gin Rummy,"This paper describes a fast hand strength estimation mod-el for the game of Gin Rummy. The algorithm is computationally inexpensive, and it incorporates not only cards in the player’s hand but also cards known to be in the opponent’s hand, cards in the discard pile, and the current game stage. This algorithm is used in conjunction with counterfactual regret (CFR) minimization to develop a gin rummy bot. CFR strategies were developed for the knocking strategies. The hand strength estimation algorithm was used to select a discard that balances the goals of maximizing the utility of the player’s hand and minimizing the likelihood that a card will be useful to the opponent. A study of the parameterization of this estimation algorithm demonstrates the soundness of approach as well as good performance under a wide range of parameter values.",1.0,0.7700337767601013,True,0.3775406687981454,0.5737872227791234,True
Width & Depth Pruning for Vision Transformers,"Transformer models have demonstrated their promising potential and achieved excellent performance on a series of computer vision tasks. However, the huge computational cost of vision transformers hinders their deployment and application to edge devices. Recent works have proposed to ﬁnd and remove the unimportant units of vision transformers. Despite achieving remarkable results, these methods take one dimension of network width into consideration and ignore network depth, which is another important dimension for pruning vision transformers. Therefore, we propose a Width & Depth Pruning (WDPruning) framework that reduces both width and depth dimensions simultaneously. Speciﬁcally, for width pruning, a set of learnable pruning-related parameters is used to adaptively adjust the width of transformer. For depth pruning, we introduce several shallow classiﬁers by using the intermediate information of the transformer blocks, which allows images to be classiﬁed by shallow classiﬁers instead of the deeper classiﬁers. In the inference period, all of the blocks after shallow classiﬁers can be dropped so they don’t bring additional parameters and computation. Experimental results on benchmark datasets demonstrate that the proposed method can signiﬁcantly reduce the computational costs of mainstream vision transformers such as DeiT and Swin Transformer with a minor accuracy drop. In particular, on ILSVRC-12, we achieve over 22% pruning ratio of FLOPs by compressing DeiT-Base, even with an increase of 0.14% Top-1 accuracy.",0.8,0.8799648880958557,True,0.3318122278318339,0.6058885579638448,True
An Attention Based Multi-view Model for Sarcasm Cause Detection (Student Abstract),"Sarcasm often relates to people’s implicit discontent with certain products and policies. Existing research mainly focus on sarcasm detection, while the deep causal relationships in the full conversation remained unexplored. This paper formulates a novel research question of sarcasm cause detection, and proposes an attention based model that simultaneously captures different semantic associations as well as the inner causal logics in multi-view manner. Experiments on public Reddit dataset prove the efficacy of the proposed model.",0.8,0.8690306544303894,True,0.3318122278318339,0.6004214411311116,True
Spatio-Temporal Model for Wildlife Poaching Prediction Evaluated Through a Controlled Field Test in Uganda,"
 
 Worldwide, conservation agencies employ rangers to protect conservation areas from poachers. However, agencies lack the manpower to have rangers effectively patrol these vast areas frequently. While past work has modeled poachers’ behavior so as to aid rangers in planning future patrols, those models’ predictions were not validated by extensive field tests. In my thesis, I present a spatio-temporal model that predicts poaching threat levels and results from a five-month field test in Uganda’s Queen Elizabeth Protected Area (QEPA). To my knowledge, this is the first time that a predictive model has been evaluated through such an extensive field test in this domain. These field test will be extended to another park in Uganda, Murchison Fall Protected Area, shortly. Main goals of my thesis are to develop the best performing model in terms of speed and accuracy and use such model to generate efficient and feasible patrol routes for the park rangers.
 
",1.0,0.7825035452842712,True,0.3775406687981454,0.5800221070412084,True
HuggingMolecules: An Open-Source Library for Transformer-Based Molecular Property Prediction (Student Abstract),"Large-scale transformer-based methods are gaining popularity as a tool for predicting the properties of chemical compounds, which is of central importance to the drug discovery process. To accelerate their development and dissemination among the community, we are releasing HuggingMolecules -- an open-source library, with a simple and unified API, that provides the implementation of several state-of-the-art transformers for molecular property prediction. In addition, we add a comparison of these methods on several regression and classification datasets. HuggingMolecules package is available at: github.com/gmum/huggingmolecules.",0.8,0.7857818007469177,True,0.3318122278318339,0.5587970142893758,True
FakeKG: A Knowledge Graph of Fake Claims for Improving Automated Fact-Checking (Student Abstract),"False information could be dangerous if the claim is not debunked timely. Fact-checking organisations get a high volume of claims on different topics with immense velocity. The efficiency of the fact-checkers decreases due to 3V problems volume, velocity and variety. Especially during crises or elections, fact-checkers cannot handle user requests to verify the claim. Until now, no real-time curable centralised corpus of fact-checked articles is available. Also, the same claim is fact-checked by multiple fact-checking organisations with or without judgement. To fill this gap, we introduce FakeKG: A Knowledge Graph-Based approach for improving Automated Fact-checking. FakeKG is a centralised knowledge graph containing fact-checked articles from different sources that can be queried using the SPARQL endpoint. The proposed FakeKG can prescreen claim requests and filter them if the claim is already fact-checked and provide a judgement to the claim. It will also categorise the claim's domain so that the fact-checker can prioritise checking the incoming claims into different groups like health and election. This study proposes an approach for creating FakeKG and its future application for mitigating misinformation.",0.8,0.8819001913070679,True,0.3318122278318339,0.6068562095694509,True
What are GANs?: Introducing Generative Adversarial Networks to Middle School Students,"Applications of Generative Machine Learning techniques such as Generative Adversarial Networks (GANs) are used to generate new instances of images, music, text, and videos. While GANs have now become commonplace on social media, a part of children’s lives, and have considerable ethical implications, existing K-12 AI education curricula do not include generative AI. We present a new module, “What are GANs?”, that teaches middle school students how GANs work and how they can create media using GANs. We developed an online, team-based game to simulate how GANs work. Students also interacted with up to four web tools that apply GANs to generate media. This module was piloted with 72 middle school students in a series of online workshops. We provide insight into student usage, understanding, and attitudes towards this lesson. Finally, we give suggestions for integrating this lesson into AI education curricula.",1.1,0.8679505586624146,True,0.401312339887548,0.6346314492749813,True
Improving the Performance-Compatibility Tradeoff with Personalized Objective Functions,"AI-systems that model and interact with their users can up-date their models over time to reflect new information and changes in the environment. Although these updates may improve the overall performance of the AI-system, they may actually hurt the performance with respect to individual users. Prior work has studied the tradeoff between improving the system’s performance following an update and the compatibility of the updated system with prior user experience. The more the model is forced to be compatible with a prior version, the higher loss in performance it will incur. This paper challenges this assumption by showing that by personalizing the loss function to specific users, it is possible to increase the prediction performance of the AI-system while sacrificing less compatibility for these users. Our approach updates the sample weights to reflect their contribution to the compatibility of the model for a particular user following the update. We construct a portfolio of different models that vary in how they personalize the loss function for a user. We select the best model to use for a target user based on a validation set. We apply this approach to three supervised learning tasks commonly used in the human-computer decision-making literature. We show that using our approach leads to significant improvements in the performance-compatibility tradeoff over the non-personalized approach of Bansal et al., achieving up to 300% improvement for certain users. We present several use cases that illustrate the difference between the personalized and non-personalized approach for two of our domains.",1.0,0.7265080809593201,True,0.3775406687981454,0.5520243748787328,True
Manipulating SHAP via Adversarial Data Perturbations (Student Abstract),"We introduce a model-agnostic algorithm for manipulating SHapley Additive exPlanations (SHAP) with perturbation of tabular data. It is evaluated on predictive tasks from healthcare and financial domains to illustrate how crucial is the context of data distribution in interpreting machine learning models. Our method supports checking the stability of the explanations used by various stakeholders apparent in the domain of responsible AI; moreover, the result highlights the explanations' vulnerability that can be exploited by an adversary.",0.8,0.8981608152389526,True,0.3318122278318339,0.6149865215353932,True
Hide-and-Tell: Learning to Bridge Photo Streams for Visual Storytelling,"Visual storytelling is a task of creating a short story based on photo streams. Unlike existing visual captioning, storytelling aims to contain not only factual descriptions, but also human-like narration and semantics. However, the VIST dataset consists only of a small, fixed number of photos per story. Therefore, the main challenge of visual storytelling is to fill in the visual gap between photos with narrative and imaginative story. In this paper, we propose to explicitly learn to imagine a storyline that bridges the visual gap. During training, one or more photos is randomly omitted from the input stack, and we train the network to produce a full plausible story even with missing photo(s). Furthermore, we propose for visual storytelling a hide-and-tell model, which is designed to learn non-local relations across the photo streams and to refine and improve conventional RNN-based models. In experiments, we show that our scheme of hide-and-tell, and the network design are indeed effective at storytelling, and that our model outperforms previous state-of-the-art methods in automatic metrics. Finally, we qualitatively show the learned ability to interpolate storyline over visual gaps.",1.0,0.9658247828483582,True,0.3775406687981454,0.6716827258232518,True
Going Beyond Primal Treewidth for (M)ILP,"
 
 Integer Linear Programming (ILP) and its mixed variant (MILP) are archetypical examples of NP-complete optimization problems which have a wide range of applications in various areas of artificial intelligence. However, we still lack a thorough understanding of which structural restrictions make these problems tractable. Here we focus on structure captured via so-called decompositional parameters, which have been highly successful in fields such as boolean satisfiability and constraint satisfaction but have not yet reached their full potential in the ILP setting. In particular, primal treewidth (an established decompositional parameter) can only be algorithmically exploited to solve ILP under restricted circumstances. Our main contribution is the introduction and algorithmic exploitation of two new decompositional parameters for ILP and MILP. The first, torso-width, is specifically tailored to the linear programming setting and is the first decompositional parameter which can also be used for MILP. The latter, incidence treewidth, is a concept which originates from boolean satisfiability but has not yet been used in the ILP setting; here we obtain a full complexity landscape mapping the precise conditions under which incidence treewidth can be used to obtain efficient algorithms. Both of these parameters overcome previous shortcomings of primal treewidth for ILP in unique ways, and consequently push the frontiers of tractability for these important problems.
 
",0.8,0.8269607424736023,True,0.3318122278318339,0.5793864851527181,True
Active Preference Learning Based on Generalized Gini Functions: Application to the Multiagent Knapsack Problem,We consider the problem of actively eliciting preferences from a Decision Maker supervising a collective decision process in the context of fair multiagent combinatorial optimization. Individual preferences are supposed to be known and represented by linear utility functions defined on a combinatorial domain and the social utility is defined as a generalized Gini Social evaluation Function (GSF) for the sake of fairness. The GSF is a non-linear aggregation function parameterized by weighting coefficients which allow a fine control of the equity requirement in the aggregation of individual utilities. The paper focuses on the elicitation of these weights by active learning in the context of the fair multiagent knapsack problem. We introduce and compare several incremental decision procedures interleaving an adaptive preference elicitation procedure with a combinatorial optimization algorithm to determine a GSF-optimal solution. We establish an upper bound on the number of queries and provide numerical tests to show the efficiency of the proposed approach.,1.0,0.7396991848945618,True,0.3775406687981454,0.5586199268463536,True
Reinforced History Backtracking for Conversational Question Answering,"To model the context history in multi-turn conversations has become a critical step towards a better understanding of the user query in question answering systems. To utilize the context history, most existing studies treat the whole context as input, which will inevitably face the following two challenges. First, modeling a long history can be costly as it requires more computation resources. Second, the long context history consists of a lot of irrelevant information that makes it difficult to model appropriate information relevant to the user query. To alleviate these problems, we propose a reinforcement learning based method to capture and backtrack the related conversation history to boost model performance in this paper. Our method seeks to automatically backtrack the history information with the implicit feedback from the model performance. We further consider both immediate and delayed rewards to guide the reinforced backtracking policy. Extensive experiments on a large conversational question answering dataset show that the proposed method can help to alleviate the problems arising from longer context history. Meanwhile, experiments show that the method yields better performance than other strong baselines, and the actions made by the method are insightful.",1.0,0.8530459403991699,True,0.3775406687981454,0.6152933045986577,True
"Imagine, Reason and Write: Visual Storytelling with Graph Knowledge and Relational Reasoning","Visual storytelling is a task of creating a short story based on photo streams. Different from visual captions, stories contain not only factual descriptions, but also imaginary concepts that do not appear in the images. In this paper, we propose a novel imagine-reason-write generation framework (IRW) for visual storytelling, inspired by the logic of humans when they write the story. First, an imagine module is leveraged to learn the imaginative storyline explicitly, improving the coherence and reasonability of the generated story. Second, we employ a reason module to fully exploit the external knowledge (commonsense knowledge base) and task-specific knowledge (scene graph and event graph) with relational reasoning method based on the storyline. In this way, we can effectively capture the most informative commonsense and visual relationships among objects in images, which enhances the diversity and informativeness of the generated story. Finally, we integrate the imaginary concepts and relational knowledge to generate human-like story based on the original semantics of images. Extensive experiments on a benchmark dataset (i.e., VIST) demonstrate that the proposed IRW framework significantly outperforms the state-of-the-art methods across multiple evaluation metrics.",1.0,0.8245140314102173,True,0.3775406687981454,0.6010273501041814,True
AttnMove: History Enhanced Trajectory Recovery via Attentional Network,"A considerable amount of mobility data has been accumulated due to the proliferation of location-based service. Nevertheless, compared with mobility data from transportation systems like the GPS module in taxis, this kind of data is commonly sparse in terms of individual trajectories in the sense that users do not access mobile services and contribute their data all the time. Consequently, the sparsity inevitably weakens the practical value of the data even it has a high user penetration rate. To solve this problem, we propose a novel attentional neural network-based model, named AttnMove, to densify individual trajectories by recovering unobserved locations at a fine-grained spatial-temporal resolution. To tackle the challenges posed by sparsity, we design various intra- and inter- trajectory attention mechanisms to better model the mobility regularity of users and fully exploit the periodical pattern from long-term history. We evaluate our model on two real-world datasets, and extensive results demonstrate the performance gain compared with the state-of-the-art methods. This also shows that, by providing high-quality mobility data, our model can benefit a variety of mobility-oriented down-stream applications.",1.0,0.8041485548019409,True,0.3775406687981454,0.5908446118000432,True
Synthetic Depth Transfer for Monocular 3D Object Pose Estimation in the Wild,"Monocular object pose estimation is an important yet challenging computer vision problem. Depth features can provide useful information for pose estimation. However, existing methods rely on real depth images to extract depth features, leading to its difficulty on various applications. In this paper, we aim at extracting RGB and depth features from a single RGB image with the help of synthetic RGB-depth image pairs for object pose estimation. Specifically, a deep convolutional neural network is proposed with an RGB-to-Depth Embedding module and a Synthetic-Real Adaptation module. The embedding module is trained with synthetic pair data to learn a depth-oriented embedding space between RGB and depth images optimized for object pose estimation. The adaptation module is to further align distributions from synthetic to real data. Compared to existing methods, our method does not need any real depth images and can be trained easily with large-scale synthetic data. Extensive experiments and comparisons show that our method achieves best performance on a challenging public PASCAL 3D+ dataset in all the metrics, which substantiates the superiority of our method and the above modules.",1.0,0.777864933013916,True,0.3775406687981454,0.5777028009060308,True
Hybrid Deep Learning Model for Fake News Detection in Social Networks (Student Abstract),"The proliferation of fake news has grown into a global concern with adverse socio-political and economical impact. In recent years, machine learning has emerged as a promising approach to the automation of detecting and tracking fake news at scale. Current state of the art in the identification of fake news is generally focused on semantic analysis of the text, resulting in promising performance in automated detection of fake news. However, fake news campaigns are also evolving in response to such new technologies by mimicking semantic features of genuine news, which can significantly affect the performance of fake news classifiers trained on contextually limited features. In this work, we propose a novel hybrid deep learning model for fake news detection that augments the semantic characteristics of the news with features extracted from the structure of the dissemination network. To this end, we first extend the LIAR dataset by integrating sentiment and affective features to the data, and then use a BERT-based model to obtain a representation of the text. Moreover, we propose a novel approach for fake news detection based on Graph Attention Networks to leverage the user-centric features and graph features of news residing social network in addition to the features extracted in the previous steps. Experimental evaluation of our approach shows classification accuracy of 97% on the Politifact dataset. We also examined the generalizability of our proposed model on the BuzzFeed dataset, resulting in an accuracy 89.50%.",0.8,0.8589556217193604,True,0.3318122278318339,0.5953839247755971,True
Scaling Up Influence Functions,"We address efficient calculation of influence functions for tracking predictions back to the training data. We propose and analyze a new approach to speeding up the inverse Hessian calculation based on Arnoldi iteration. With this improvement, we achieve, to the best of our knowledge, the first successful implementation of influence functions that scales to full-size (language and vision) Transformer models with several hundreds of millions of parameters. We evaluate our approach in image classification and sequence-to-sequence tasks with tens to a hundred of millions of training examples. Our code is available at https://github.com/google-research/jax-influence.",1.0,0.8307348489761353,True,0.3775406687981454,0.6041377588871404,True
The Naughtyformer: A Transformer Understands and Moderates Adult Humor (Student Abstract),"Jokes are intentionally written to be funny, but not all jokes are created the same. While recent work has shown impressive results on humor detection in text, we instead investigate the more nuanced task of detecting humor subtypes, especially of the more adult variety. To that end, we introduce a novel jokes dataset filtered from Reddit and solve the subtype
classification task using a finetuned Transformer dubbed the Naughtyformer. Moreover, we show that our model is significantly better at detecting offensiveness in jokes compared to state-of-the-art methods.",0.8,0.9856117963790894,True,0.3318122278318339,0.6587120121054616,True
Complex Emotional Intelligence Learning Using Deep Neural Networks (Student Abstract),"Emotion recognition and mining tasks are often limited by the availability of manually annotated data. Several researchers have used emojis and specific hashtags as forms of training and supervision.This research paper proposes a new textual and social corpus, the corpus labeled using basic emotions following Plutchik's theory. Thus, This paper propose a first study for the representation and interpretation of complex emotional interactions, using deep neural networks.",0.8,0.7768833637237549,True,0.3318122278318339,0.5543477957777944,True
Augmenting the Power of (Partial) MaxSat Resolution with Extension,"The refutation power of SAT and MaxSAT resolution is challenged by problems like the soft and hard Pigeon Hole Problem PHP for which short refutations do not exist. In this paper we augment the MaxSAT resolution proof system with an extension rule. The new proof system MaxResE is sound and complete, and more powerful than plain MaxSAT resolution, since it can refute the soft and hard PHP in polynomial time. We show that MaxResE refutations actually subtract lower bounds from the objective function encoded by the formulas. The resulting formula is the residual after the lower bound extraction. We experimentally show that the residual of the soft PHP (once its necessary cost of 1 has been efficiently subtracted with MaxResE) is a concise, easy to solve, satisfiable problem.",0.8,0.8031894564628601,True,0.3318122278318339,0.567500842147347,True
What's Hot at CPAIOR (Extended Abstract),"
 
 The 13th International Conference on Integration of Artificial Intelligence and Operations Research Techniques in Constraint Programming (CPAIOR 2016), was held in Banff, Canada, May 29 - June 1, 2016. In order to trigger exchanges between the constraint programming and the operations research community, CPAIOR was co-located with CORS 2016, the Canadian Operational Research society's conference.
 
",0.8,0.8372916579246521,True,0.3318122278318339,0.584551942878243,True
Summarization Attack via Paraphrasing (Student Abstract),"Many natural language processing models are perceived to be fragile on adversarial attacks. Recent work on adversarial attack has demonstrated a high success rate on sentiment analysis as well as classification models. However, attacks to summarization models have not been well studied. Summarization tasks are rarely influenced by word substitution, since advanced abstractive summary models utilize sentence level information. In this paper, we propose a paraphrasing-based attack method to attack summarization models. We first rank the sentences in the document according to their impacts to summarization. Then, we apply paraphrasing procedure to generate adversarial samples. Finally, we test our algorithm on benchmarks datasets against others methods. Our approach achieved the highest success rate and the lowest sentence substitution rate. In addition, the adversarial samples have high semantic similarity with the original sentences.",0.8,0.9037609696388245,True,0.3318122278318339,0.6177865987353292,True
Scalable Partial Explainability in Neural Networks via Flexible Activation Functions (Student Abstract),"Current state-of-the-art neural network explanation methods (e.g. Saliency maps, DeepLIFT, LIME, etc.) focus more on the direct relationship between NN outputs and inputs rather than the NN structure and operations itself, hence there still exists uncertainty over the exact role played by neurons. In this paper, we propose a novel neural network structure with Kolmogorov-Arnold Superposition Theorem based topology and Gaussian Processes based flexible activation function to achieve partial explainability of the neuron inner reasoning. The model feasibility is verified in a case study on binary classification of the banknotes.",1.8,0.5910497903823853,False,0.574442516811659,0.5827461535970222,True
Re-Thinking LiDAR-Stereo Fusion Frameworks (Student Abstract),"In this paper, we present a 2-step framework for high-precision dense depth perception from stereo RGB images and sparse LiDAR input. In the first step, we train a deep neural network to predict dense depth map from the left image and sparse LiDAR data, in a novel self-supervised manner. Then in the second step, we compute a disparity map from the predicted depths, and refining the disparity map by making sure that for every pixel in the left, its match in the right image, according to the final disparity, is the local optimum.",0.8,0.7760589718818665,True,0.3318122278318339,0.5539355998568501,True
Enhanced Story Comprehension for Large Language Models through Dynamic Document-Based Knowledge Graphs,"Large transformer-based language models have achieved incredible success at various tasks which require narrative comprehension, including story completion, answering questions about stories, and generating stories ex nihilo. However, due to the limitations of finite context windows, these language models struggle to produce or understand stories longer than several thousand tokens. In order to mitigate the document length limitations that come with finite context windows, we introduce a novel architecture that augments story processing with an external dynamic knowledge graph. In contrast to static commonsense knowledge graphs which hold information about the real world, these dynamic knowledge graphs reflect facts extracted from the story being processed. Our architecture uses these knowledge graphs to create information-rich prompts which better facilitate story comprehension than prompts composed only of story text. We apply our architecture to the tasks of question answering and story completion. To complement this line of research, we introduce two long-form question answering tasks, LF-SQuAD and LF-QUOREF, in which the document length exceeds the size of the language model's context window, and introduce a story completion evaluation method that bypasses the stochastic nature of language model generation. We demonstrate broad improvement over typical prompt formulation methods for both question answering and story completion using GPT-2, GPT-3 and XLNet.",1.0,0.7728286385536194,True,0.3775406687981454,0.5751846536758825,True
Hierarchical Photo-Scene Encoder for Album Storytelling,"In this paper, we propose a novel model with a hierarchical photo-scene encoder and a reconstructor for the task of album storytelling. The photo-scene encoder contains two subencoders, namely the photo and scene encoders, which are stacked together and behave hierarchically to fully exploit the structure information of the photos within an album. Specifically, the photo encoder generates semantic representation for each photo while exploiting temporal relationships among them. The scene encoder, relying on the obtained photo representations, is responsible for detecting the scene changes and generating scene representations. Subsequently, the decoder dynamically and attentively summarizes the encoded photo and scene representations to generate a sequence of album representations, based on which a story consisting of multiple coherent sentences is generated. In order to fully extract the useful semantic information from an album, a reconstructor is employed to reproduce the summarized album representations based on the hidden states of the decoder. The proposed model can be trained in an end-to-end manner, which results in an improved performance over the state-of-the-arts on the public visual storytelling (VIST) dataset. Ablation studies further demonstrate the effectiveness of the proposed hierarchical photo-scene encoder and reconstructor.",1.0,0.7889618873596191,True,0.3775406687981454,0.5832512780788823,True
Generative Adversarial Imitation Learning from Failed Experiences (Student Abstract),"Imitation learning provides a family of promising methods that learn policies from expert demonstrations directly. As a model-free and on-line imitation learning method, generative adversarial imitation learning (GAIL) generalizes well to unseen situations and can handle complex problems. In this paper, we propose a novel variant of GAIL called GAIL from failed experiences (GAILFE). GAILFE allows an agent to utilize failed experiences in the training process. Moreover, a constrained optimization objective is formalized in GAILFE to balance learning from given demonstrations and from self-generated failed experiences. Empirically, compared with GAIL, GAILFE can improve sample efficiency and learning speed over different tasks.",0.8,0.9599305391311646,True,0.3318122278318339,0.6458713834814992,True
Anytime Anyspace AND/OR Search for Bounding the Partition Function,"
 
 Bounding the partition function is a key inference task in many graphical models. In this paper, we develop an anytime anyspace search algorithm taking advantage of AND/OR tree structure and optimized variational heuristics to tighten deterministic bounds on the partition function. We study how our priority-driven best-first search scheme can improve on state-of-the-art variational bounds in an anytime way within limited memory resources, as well as the effect of the AND/OR framework to exploit conditional independence structure within the search process within the context of summation. We compare our resulting bounds to a number of existing methods, and show that our approach offers a number of advantages on real-world problem instances taken from recent UAI competitions.
 
",1.0,0.7304307222366333,True,0.3775406687981454,0.5539856955173894,True
Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph,"Analyzing human multimodal language is an emerging area of research in NLP. Intrinsically this language is multimodal (heterogeneous), sequential and asynchronous; it consists of the language (words), visual (expressions) and acoustic (paralinguistic) modalities all in the form of asynchronous coordinated sequences. From a resource perspective, there is a genuine need for large scale datasets that allow for in-depth studies of this form of language. In this paper we introduce CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI), the largest dataset of sentiment analysis and emotion recognition to date. Using data from CMU-MOSEI and a novel multimodal fusion technique called the Dynamic Fusion Graph (DFG), we conduct experimentation to exploit how modalities interact with each other in human multimodal language. Unlike previously proposed fusion techniques, DFG is highly interpretable and achieves competative performance when compared to the previous state of the art.",1.0,0.8853347301483154,True,0.3775406687981454,0.6314376994732305,True
Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions,"Modern deep learning models for NLP are notoriously opaque. This has motivated the development of methods for interpreting such models, e.g., via gradient-based saliency maps or the visualization of attention weights. Such approaches aim to provide explanations for a particular model prediction by highlighting important words in the corresponding input text. While this might be useful for tasks where decisions are explicitly influenced by individual tokens in the input, we suspect that such highlighting is not suitable for tasks where model decisions should be driven by more complex reasoning. In this work, we investigate the use of influence functions for NLP, providing an alternative approach to interpreting neural text classifiers. Influence functions explain the decisions of a model by identifying influential training examples. Despite the promise of this approach, influence functions have not yet been extensively evaluated in the context of NLP, a gap addressed by this work. We conduct a comparison between influence functions and common word-saliency methods on representative tasks. As suspected, we find that influence functions are particularly useful for natural language inference, a task in which ‘saliency maps’ may not have clear interpretation. Furthermore, we develop a new quantitative measure based on influence functions that can reveal artifacts in training data.",1.0,0.7695208787918091,True,0.3775406687981454,0.5735307737949773,True
No Metrics Are Perfect: Adversarial Reward Learning for Visual Storytelling,"Though impressive results have been achieved in visual captioning, the task of generating abstract stories from photo streams is still a little-tapped problem. Different from captions, stories have more expressive language styles and contain many imaginary concepts that do not appear in the images. Thus it poses challenges to behavioral cloning algorithms. Furthermore, due to the limitations of automatic metrics on evaluating story quality, reinforcement learning methods with hand-crafted rewards also face difficulties in gaining an overall performance boost. Therefore, we propose an Adversarial REward Learning (AREL) framework to learn an implicit reward function from human demonstrations, and then optimize policy search with the learned reward function. Though automatic evaluation indicates slight performance boost over state-of-the-art (SOTA) methods in cloning expert behaviors, human evaluation shows that our approach achieves significant improvement in generating more human-like stories than SOTA systems.",1.0,0.8816441893577576,True,0.3775406687981454,0.6295924290779515,True
Storytelling with Dialogue: A Critical Role Dungeons and Dragons Dataset,"This paper describes the Critical Role Dungeons and Dragons Dataset (CRD3) and related analyses. Critical Role is an unscripted, live-streamed show where a fixed group of people play Dungeons and Dragons, an open-ended role-playing game. The dataset is collected from 159 Critical Role episodes transcribed to text dialogues, consisting of 398,682 turns. It also includes corresponding abstractive summaries collected from the Fandom wiki. The dataset is linguistically unique in that the narratives are generated entirely through player collaboration and spoken interaction. For each dialogue, there are a large number of turns, multiple abstractive summaries with varying levels of detail, and semantic ties to the previous dialogues. In addition, we provide a data augmentation method that produces 34,243 summary-dialogue chunk pairs to support current neural ML approaches, and we provide an abstractive summarization benchmark and evaluation.",1.0,0.8158634305000305,True,0.3775406687981454,0.596702049649088,True
Sense-Aware Neural Models for Pun Location in Texts,"A homographic pun is a form of wordplay in which one signifier (usually a word) suggests two or more meanings by exploiting polysemy for an intended humorous or rhetorical effect. In this paper, we focus on the task of pun location, which aims to identify the pun word in a given short text. We propose a sense-aware neural model to address this challenging task. Our model first obtains several WSD results for the text, and then leverages a bidirectional LSTM network to model each sequence of word senses. The outputs at each time step for different LSTM networks are then concatenated for prediction. Evaluation results on the benchmark SemEval 2017 dataset demonstrate the efficacy of our proposed model.",1.0,0.9028915762901306,True,0.3775406687981454,0.6402161225441381,True
Learning bilingual word embeddings with (almost) no bilingual data,"Most methods to learn bilingual word embeddings rely on large parallel corpora, which is difficult to obtain for most language pairs. This has motivated an active research line to relax this requirement, with methods that use document-aligned corpora or bilingual dictionaries of a few thousand words instead. In this work, we further reduce the need of bilingual resources using a very simple self-learning approach that can be combined with any dictionary-based mapping technique. Our method exploits the structural similarity of embedding spaces, and works with as little bilingual evidence as a 25 word dictionary or even an automatically generated list of numerals, obtaining results comparable to those of systems that use richer resources.",0.8,0.8459376096725464,True,0.3318122278318339,0.5888749187521901,True
Are Fairy Tales Fair? Analyzing Gender Bias in Temporal Narrative Event Chains of Children’s Fairy Tales,"Social biases and stereotypes are embedded in our culture in part through their presence in our stories, as evidenced by the rich history of humanities and social science literature analyzing such biases in children stories. Because these analyses are often conducted manually and at a small scale, such investigations can benefit from the use of more recent natural language processing (NLP) methods that examine social bias in models and data corpora. Our work joins this interdisciplinary effort and makes a unique contribution by taking into account the event narrative structures when analyzing the social bias of stories. We propose a computational pipeline that automatically extracts a story’s temporal narrative verb-based event chain for each of its characters as well as character attributes such as gender. We also present a verb-based event annotation scheme that can facilitate bias analysis by including categories such as those that align with traditional stereotypes. Through a case study analyzing gender bias in fairy tales, we demonstrate that our framework can reveal bias in not only the unigram verb-based events in which female and male characters participate but also in the temporal narrative order of such event participation.",1.3,0.7937725186347961,True,0.45016600268752216,0.6219692606611591,True
ARBERT & MARBERT: Deep Bidirectional Transformers for Arabic,"Pre-trained language models (LMs) are currently integral to many natural language processing systems. Although multilingual LMs were also introduced to serve many languages, these have limitations such as being costly at inference time and the size and diversity of non-English data involved in their pre-training. We remedy these issues for a collection of diverse Arabic varieties by introducing two powerful deep bidirectional transformer-based models, ARBERT and MARBERT. To evaluate our models, we also introduce ARLUE, a new benchmark for multi-dialectal Arabic language understanding evaluation. ARLUE is built using 42 datasets targeting six different task clusters, allowing us to offer a series of standardized experiments under rich conditions. When fine-tuned on ARLUE, our models collectively achieve new state-of-the-art results across the majority of tasks (37 out of 48 classification tasks, on the 42 datasets). Our best model acquires the highest ARLUE score (77.40) across all six task clusters, outperforming all other models including XLM-R Large ( 3.4x larger size). Our models are publicly available at https://github.com/UBC-NLP/marbert and ARLUE will be released through the same repository.",0.8,0.9005910158157349,True,0.3318122278318339,0.6162016218237844,True
Dialogue-Act Prediction of Future Responses Based on Conversation History,"Sequence-to-sequence models are a common approach to develop a chatbot. They can train a conversational model in an end-to-end manner. One significant drawback of such a neural network based approach is that the response generation process is a black-box, and how a specific response is generated is unclear. To tackle this problem, an interpretable response generation mechanism is desired. As a step toward this direction, we focus on dialogue-acts (DAs) that may provide insight to understand the response generation process. In particular, we propose a method to predict a DA of the next response based on the history of previous utterances and their DAs. Experiments using a Switch Board Dialogue Act corpus show that compared to the baseline considering only a single utterance, our model achieves 10.8% higher F1-score and 3.0% higher accuracy on DA prediction.",1.0,0.8215669989585876,True,0.3775406687981454,0.5995538338783666,True
Supervised Grapheme-to-Phoneme Conversion of Orthographic Schwas in Hindi and Punjabi,"Hindi grapheme-to-phoneme (G2P) conversion is mostly trivial, with one exception: whether a schwa represented in the orthography is pronounced or unpronounced (deleted). Previous work has attempted to predict schwa deletion in a rule-based fashion using prosodic or phonetic analysis. We present the first statistical schwa deletion classifier for Hindi, which relies solely on the orthography as the input and outperforms previous approaches. We trained our model on a newly-compiled pronunciation lexicon extracted from various online dictionaries. Our best Hindi model achieves state of the art performance, and also achieves good performance on a closely related language, Punjabi, without modification.",1.0,0.7701556086540222,True,0.3775406687981454,0.5738481387260839,True
HateCheck: Functional Tests for Hate Speech Detection Models,"Detecting online hate is a difficult task that even state-of-the-art models struggle with. Typically, hate speech detection models are evaluated by measuring their performance on held-out test data using metrics such as accuracy and F1 score. However, this approach makes it difficult to identify specific model weak points. It also risks overestimating generalisable model performance due to increasingly well-evidenced systematic gaps and biases in hate speech datasets. To enable more targeted diagnostic insights, we introduce HateCheck, a suite of functional tests for hate speech detection models. We specify 29 model functionalities motivated by a review of previous research and a series of interviews with civil society stakeholders. We craft test cases for each functionality and validate their quality through a structured annotation process. To illustrate HateCheck’s utility, we test near-state-of-the-art transformer models as well as two popular commercial models, revealing critical model weaknesses.",1.0,0.7425904273986816,True,0.3775406687981454,0.5600655480984136,True
World Models for Math Story Problems,"Solving math story problems is a complex task for students and NLP models alike, requiring them to understand the world as described in the story and reason over it to compute an answer. Recent years have seen impressive performance on automatically solving these problems with large pre-trained language models and innovative techniques to prompt them. However, it remains unclear if these models possess accurate representations of mathematical concepts. This leads to lack of interpretability and trustworthiness which impedes their usefulness in various applications. In this paper, we consolidate previous work on categorizing and representing math story problems and develop MathWorld, which is a graph-based semantic formalism specific for the domain of math story problems. With MathWorld, we can assign world models to math story problems which represent the situations and actions introduced in the text and their mathematical relationships. We combine math story problems from several existing datasets and annotate a corpus of 1,019 problems and 3,204 logical forms with MathWorld. Using this data, we demonstrate the following use cases of MathWorld: (1) prompting language models with synthetically generated question-answer pairs to probe their reasoning and world modeling abilities, and (2) generating new problems by using the world models as a design space.",1.0,0.7336809039115906,True,0.3775406687981454,0.555610786354868,True
Understanding Programs by Exploiting (Fuzzing) Test Cases,"Semantic understanding of programs has attracted great attention in the community. Inspired by recent successes of large language models (LLMs) in natural language understanding, tremendous progress has been made by treating programming language as another sort of natural language and training LLMs on corpora of program code. However, programs are essentially different from texts after all, in a sense that they are normally heavily structured and syntax-strict. In particular, programs and their basic units (i.e., functions and subroutines) are designed to demonstrate a variety of behaviors and/or provide possible outputs, given different inputs. The relationship between inputs and possible outputs/behaviors represents the functions/subroutines and profiles the program as a whole. Therefore, we propose to incorporate such a relationship into learning, for achieving a deeper semantic understanding of programs. To obtain inputs that are representative enough to trigger the execution of most part of the code, we resort to fuzz testing and propose fuzz tuning to boost the performance of program understanding and code representation learning, given a pre-trained LLM. The effectiveness of the proposed method is verified on two program understanding tasks including code clone detection and code classification, and it outperforms current state-of-the-arts by large margins. Code is available at https://github.com/rabbitjy/FuzzTuning.",0.8,0.9677495956420898,True,0.3318122278318339,0.6497809117369618,True
Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP,"Graph neural networks have triggered a resurgence of graph-based text classification methods, defining today’s state of the art. We show that a wide multi-layer perceptron (MLP) using a Bag-of-Words (BoW) outperforms the recent graph-based models TextGCN and HeteGCN in an inductive text classification setting and is comparable with HyperGAT. Moreover, we fine-tune a sequence-based BERT and a lightweight DistilBERT model, which both outperform all state-of-the-art models. These results question the importance of synthetic graphs used in modern text classifiers. In terms of efficiency, DistilBERT is still twice as large as our BoW-based wide MLP, while graph-based models like TextGCN require setting up an \mathcal{O}(N^2) graph, where N is the vocabulary plus corpus size. Finally, since Transformers need to compute \mathcal{O}(L^2) attention weights with sequence length L, the MLP models show higher training and inference speeds on datasets with long sequences.",1.0,0.8509624004364014,True,0.3775406687981454,0.6142515346172734,True
(QA)^2: Question Answering with Questionable Assumptions,"Naturally occurring information-seeking questions often contain questionable assumptions—assumptions that are false or unverifiable. Questions containing questionable assumptions are challenging because they require a distinct answer strategy that deviates from typical answers for information-seeking questions. For instance, the question “When did Marie Curie discover Uranium?” cannot be answered as a typical “when” question without addressing the false assumption “Marie Curie discovered Uranium”. In this work, we propose (QA)2 (Question Answering with Questionable Assumptions), an open-domain evaluation dataset consisting of naturally occurring search engine queries that may or may not contain questionable assumptions. To be successful on (QA)2, systems must be able to detect questionable assumptions and also be able to produce adequate responses for both typical information-seeking questions and ones with questionable assumptions. Through human rater acceptability on end-to-end QA with (QA)2, we find that current models do struggle with handling questionable assumptions, leaving substantial headroom for progress.",0.8,0.8324213027954102,True,0.3318122278318339,0.582116765313622,True
100 Things You Always Wanted to Know about Semantics & Pragmatics But Were Afraid to Ask,"Meaning is a fundamental concept in Natural Language Processing (NLP), given its aim to build systems that mean what they say to you, and understand what you say to them. In order for NLP to scale beyond partial, task-specific solutions, it must be informed by what is known about how humans use language to express and understand communicative intents. The purpose of this tutorial is to present a selection of useful information about semantics and pragmatics, as understood in linguistics, in a way that’s accessible to and useful for NLP practitioners with minimal (or even no) prior training in linguistics. The tutorial content is based on a manuscript in progress I am co-authoring with Prof. Alex Lascarides of the University of Edinburgh.",0.8,0.7767305970191956,True,0.3318122278318339,0.5542714124255147,True
COINS: Dynamically Generating COntextualized Inference Rules for Narrative Story Completion,"Despite recent successes of large pre-trained language models in solving reasoning tasks, their inference capabilities remain opaque. We posit that such models can be made more interpretable by explicitly generating interim inference rules, and using them to guide the generation of task-specific textual outputs. In this paper we present Coins, a recursive inference framework that i) iteratively reads context sentences, ii) dynamically generates contextualized inference rules, encodes them, and iii) uses them to guide task-specific output generation. We apply to a Narrative Story Completion task that asks a model to complete a story with missing sentences, to produce a coherent story with plausible logical connections, causal relationships, and temporal dependencies. By modularizing inference and sentence generation steps in a recurrent model, we aim to make reasoning steps and their effects on next sentence generation transparent. Our automatic and manual evaluations show that the model generates better story sentences than SOTA baselines, especially in terms of coherence. We further demonstrate improved performance over strong pre-trained LMs in generating commonsense inference rules. The recursive nature of holds the potential for controlled generation of longer sequences.",1.0,0.7436904311180115,True,0.3775406687981454,0.5606155499580785,True
Attractive Storyteller: Stylized Visual Storytelling with Unpaired Text,"Most research on stylized image captioning aims to generate style-specific captions using unpaired text, and has achieved impressive performance for simple styles like positive and negative. However, unlike previous single-sentence captions whose style is mostly embodied in distinctive words or phrases, real-world styles are likely to be implied at the syntactic and discourse levels. In this work, we introduce a new task of Stylized Visual Storytelling (SVST), which aims to describe a photo stream with stylized stories that are more expressive and attractive. We propose a multitasking memory-augmented framework called StyleVSG, which is jointly trained on factual visual storytelling data and unpaired style corpus, achieving a trade-off between style accuracy and visual relevance. Particularly for unpaired stylized text, StyleVSG learns to reconstruct the stylistic story from roughly parallel visual inputs mined with the CLIP model, avoiding problems caused by random mapping in previous methods. Furthermore, a memory module is designed to preserve the consistency and coherence of generated stories. Experiments show that our method can generate attractive and coherent stories with different styles such as fairy tale, romance, and humor. The overall performance of our StyleVSG surpasses state-of-the-art methods on both automatic and human evaluation metrics.",1.0,0.7986906170845032,True,0.3775406687981454,0.5881156429413243,True
Suspense in Short Stories is Predicted By Uncertainty Reduction over Neural Story Representation,,1.0,0.8155227303504944,True,0.3775406687981454,0.59653169957432,True
From SPMRL to NMRL: What Did We Learn (and Unlearn) in a Decade of Parsing Morphologically-Rich Languages (MRLs)?,"It has been exactly a decade since the first establishment of SPMRL, a research initiative unifying multiple research efforts to address the peculiar challenges of Statistical Parsing for Morphologically-Rich Languages (MRLs). Here we reflect on parsing MRLs in that decade, highlight the solutions and lessons learned for the architectural, modeling and lexical challenges in the pre-neural era, and argue that similar challenges re-emerge in neural architectures for MRLs. We then aim to offer a climax, suggesting that incorporating symbolic ideas proposed in SPMRL terms into nowadays neural architectures has the potential to push NLP for MRLs to a new level. We sketch a strategies for designing Neural Models for MRLs (NMRL), and showcase preliminary support for these strategies via investigating the task of multi-tagging in Hebrew, a morphologically-rich, high-fusion, language.",1.1,0.793616533279419,True,0.401312339887548,0.5974644365834835,True
The Magic of IF: Investigating Causal Reasoning Abilities in Large Language Models of Code,"Causal reasoning, the ability to identify cause-and-effect relationship, is crucial in human thinking. Although large language models (LLMs) succeed in many NLP tasks, it is still challenging for them to conduct complex causal reasoning like abductive reasoning and counterfactual reasoning. Given the fact that programming code may express causal relations more often and explicitly with conditional statements like ``if``, we want to explore whether Code-LLMs acquire better causal reasoning abilities. Our experiments show that compared to text-only LLMs, Code-LLMs with code prompts are significantly better in causal reasoning. We further intervene on the prompts from different aspects, and discover that the programming structure is crucial in code prompt design, while Code-LLMs are robust towards format perturbations.",1.0,0.7411582469940186,True,0.3775406687981454,0.559349457896082,True
A dynamic programming algorithm for span-based nested named-entity recognition in O(n^2),"Span-based nested named-entity recognition (NER) has a cubic-time complexity using avariant of the CYK algorithm. We show that by adding a supplementary structural constraint on the search space, nested NER has a quadratic-time complexity, that is the same asymptotic complexity than the non-nested case. The proposed algorithm covers a large part of three standard English benchmarks and delivers comparable experimental results.",0.8,0.7834002375602722,True,0.3318122278318339,0.557606232696053,True
Story-level Text Style Transfer: A Proposal,"Text style transfer aims to change the style of the input text to the target style while preserving the content to some extent. Previous works on this task are on the sentence level. We aim to work on story-level text style transfer to generate stories that preserve the plot of the input story while exhibiting a strong target style. The challenge in this task compared to previous work is that the structure of the input story, consisting of named entities and their relations with each other, needs to be preserved, and that the generated story needs to be consistent after adding flavors. We plan to explore three methods including the BERT-based method, the Story Realization method, and the Graph-based method.",1.0,0.7901777625083923,True,0.3775406687981454,0.5838592156532689,True
Interoperable annotation of (co)references in the Democrat project,"This paper proposes XML-TEI-URS, a generic TEI-based format for the annotation of coreferences in arbitrary corpora. This proposal is made in the context of Democrat, a French Agence Nationale de la Recherche project that aims to produce a large corpus of written French with coreference annotations, in an attempt to design a corpus that is usable both by humans and automated tools and as compatible as possible with future concurrent annotations.",0.8,0.7973345518112183,True,0.3318122278318339,0.564573389821526,True
Multidirectional Associative Optimization of Function-Specific Word Representations,"We present a neural framework for learning associations between interrelated groups of words such as the ones found in Subject-Verb-Object (SVO) structures. Our model induces a joint function-specific word vector space, where vectors of e.g. plausible SVO compositions lie close together. The model retains information about word group membership even in the joint space, and can thereby effectively be applied to a number of tasks reasoning over the SVO structure. We show the robustness and versatility of the proposed framework by reporting state-of-the-art results on the tasks of estimating selectional preference and event similarity. The results indicate that the combinations of representations learned with our task-independent model outperform task-specific architectures from prior work, while reducing the number of parameters by up to 95%.",1.0,0.7856813669204712,True,0.3775406687981454,0.5816110178593084,True
Sentence Suggestion of Japanese Functional Expressions for Chinese-speaking Learners,"We present a computer-assisted learning system, Jastudy, which is particularly designed for Chinese-speaking learners of Japanese as a second language (JSL) to learn Japanese functional expressions with suggestion of appropriate example sentences. The system automatically recognizes Japanese functional expressions using a free Japanese morphological analyzer MeCab, which is retrained on a new Conditional Random Fields (CRF) model. In order to select appropriate example sentences, we apply a pairwise-based machine learning tool, Support Vector Machine for Ranking (SVMrank) to estimate the complexity of the example sentences using Japanese–Chinese homographs as an important feature. In addition, we cluster the example sentences that contain Japanese functional expressions with two or more meanings and usages, based on part-of-speech, conjugation forms of verbs and semantic attributes, using the K-means clustering algorithm in Scikit-Learn. Experimental results demonstrate the effectiveness of our approach.",1.0,0.751095175743103,True,0.3775406687981454,0.5643179222706243,True
“The Boating Store Had Its Best Sail Ever”: Pronunciation-attentive Contextualized Pun Recognition,"Humor plays an important role in human languages and it is essential to model humor when building intelligence systems. Among different forms of humor, puns perform wordplay for humorous effects by employing words with double entendre and high phonetic similarity. However, identifying and modeling puns are challenging as puns usually involved implicit semantic or phonological tricks. In this paper, we propose Pronunciation-attentive Contextualized Pun Recognition (PCPR) to perceive human humor, detect if a sentence contains puns and locate them in the sentence. PCPR derives contextualized representation for each word in a sentence by capturing the association between the surrounding context and its corresponding phonetic symbols. Extensive experiments are conducted on two benchmark datasets. Results demonstrate that the proposed approach significantly outperforms the state-of-the-art methods in pun detection and location tasks. In-depth analyses verify the effectiveness and robustness of PCPR.",1.0,0.9717382788658142,True,0.3775406687981454,0.6746394738319799,True
Tackling the Biases in The Story Cloze Test,,1.0,0.7500925660133362,True,0.3775406687981454,0.5638166174057408,True
A Neural Approach to Pun Generation,"Automatic pun generation is an interesting and challenging text generation task. Previous efforts rely on templates or laboriously manually annotated pun datasets, which heavily constrains the quality and diversity of generated puns. Since sequence-to-sequence models provide an effective technique for text generation, it is promising to investigate these models on the pun generation task. In this paper, we propose neural network models for homographic pun generation, and they can generate puns without requiring any pun data for training. We first train a conditional neural language model from a general text corpus, and then generate puns from the language model with an elaborately designed decoding algorithm. Automatic and human evaluations show that our models are able to generate homographic puns of good readability and quality.",1.0,0.9717498421669006,True,0.3775406687981454,0.6746452554825231,True
“I’ve Seen Things You People Wouldn’t Believe”: Hallucinating Entities in GuessWhat?!,"Natural language generation systems have witnessed important progress in the last years, but they are shown to generate tokens that are unrelated to the source input. This problem affects computational models in many NLP tasks, and it is particularly unpleasant in multimodal systems. In this work, we assess the rate of object hallucination in multimodal conversational agents playing the GuessWhat?! referential game. Better visual processing has been shown to mitigate this issue in image captioning; hence, we adapt to the GuessWhat?! task the best visual processing models at disposal, and propose two new models to play the Questioner agent. We show that the new models generate few hallucinations compared to other renowned models available in the literature. Moreover, their hallucinations are less severe (affect task-accuracy less) and are more human-like. We also analyse where hallucinations tend to occur more often through the dialogue: hallucinations are less frequent in earlier turns, cause a cascade hallucination effect, and are often preceded by negative answers, which have been shown to be harder to ground.",1.6,0.973371684551239,True,0.52497918747894,0.7491754360150895,True
Reducing Gender Bias in Word-Level Language Models with a Gender-Equalizing Loss Function,"Gender bias exists in natural language datasets, which neural language models tend to learn, resulting in biased text generation. In this research, we propose a debiasing approach based on the loss function modification. We introduce a new term to the loss function which attempts to equalize the probabilities of male and female words in the output. Using an array of bias evaluation metrics, we provide empirical evidence that our approach successfully mitigates gender bias in language models without increasing perplexity. In comparison to existing debiasing strategies, data augmentation, and word embedding debiasing, our method performs better in several aspects, especially in reducing gender bias in occupation words. Finally, we introduce a combination of data augmentation and our approach and show that it outperforms existing strategies in all bias evaluation metrics.",1.0,0.7891970276832581,True,0.3775406687981454,0.5833688482407018,True
Pay Attention to the Ending:Strong Neural Baselines for the ROC Story Cloze Task,"We consider the ROC story cloze task (Mostafazadeh et al., 2016) and present several findings. We develop a model that uses hierarchical recurrent networks with attention to encode the sentences in the story and score candidate endings. By discarding the large training set and only training on the validation set, we achieve an accuracy of 74.7%. Even when we discard the story plots (sentences before the ending) and only train to choose the better of two endings, we can still reach 72.5%. We then analyze this “ending-only” task setting. We estimate human accuracy to be 78% and find several types of clues that lead to this high accuracy, including those related to sentiment, negation, and general ending likelihood regardless of the story context.",1.0,0.8216091394424438,True,0.3775406687981454,0.5995749041202947,True
Measuring Your ASTE Models in The Wild: A Diversified Multi-domain Dataset For Aspect Sentiment Triplet Extraction,"Aspect Sentiment Triplet Extraction (ASTE) is widely used in various applications. However, existing ASTE datasets are limited in their ability to represent real-world scenarios, hindering the advancement of research in this area. In this paper, we introduce a new dataset, named DMASTE, which is manually annotated to better fit real-world scenarios by providing more diverse and realistic reviews for the task. The dataset includes various lengths, diverse expressions, more aspect types, and more domains than existing datasets. We conduct extensive experiments on DMASTE in multiple settings to evaluate previous ASTE approaches. Empirical results demonstrate that DMASTE is a more challenging ASTE dataset. Further analyses of in-domain and cross-domain settings provide promising directions for future research. Our code and dataset are available at https://github.com/NJUNLP/DMASTE.",1.0,0.8971350193023682,True,0.3775406687981454,0.6373378440502568,True
StoryARG: a corpus of narratives and personal experiences in argumentative texts,"Humans are storytellers, even in communication scenarios which are assumed to be more rationality-oriented, such as argumentation. Indeed, supporting arguments with narratives or personal experiences (henceforth, stories) is a very natural thing to do – and yet, this phenomenon is largely unexplored in computational argumentation. Which role do stories play in an argument? Do they make the argument more effective? What are their narrative properties? To address these questions, we collected and annotated StoryARG, a dataset sampled from well-established corpora in computational argumentation (ChangeMyView and RegulationRoom), and the Social Sciences (Europolis), as well as comments to New York Times articles. StoryARG contains 2451 textual spans annotated at two levels. At the argumentative level, we annotate the function of the story (e.g., clarification, disclosure of harm, search for a solution, establishing speaker’s authority), as well as its impact on the effectiveness of the argument and its emotional load. At the level of narrative properties, we annotate whether the story has a plot-like development, is factual or hypothetical, and who the protagonist is.What makes a story effective in an argument? Our analysis of the annotations in StoryARG uncover a positive impact on effectiveness for stories which illustrate a solution to a problem, and in general, annotator-specific preferences that we investigate with regression analysis.",1.0,0.8587646484375,True,0.3775406687981454,0.6181526586178228,True
Stimulating Creativity with FunLines: A Case Study of Humor Generation in Headlines,"Building datasets of creative text, such as humor, is quite challenging. We introduce FunLines, a competitive game where players edit news headlines to make them funny, and where they rate the funniness of headlines edited by others. FunLines makes the humor generation process fun, interactive, collaborative, rewarding and educational, keeping players engaged and providing humor data at a very low cost compared to traditional crowdsourcing approaches. FunLines offers useful performance feedback, assisting players in getting better over time at generating and assessing humor, as our analysis shows. This helps to further increase the quality of the generated dataset. We show the effectiveness of this data by training humor classification models that outperform a previous benchmark, and we release this dataset to the public.",1.0,0.9930124282836914,True,0.3775406687981454,0.6852765485409185,True
A New Direction in Stance Detection: Target-Stance Extraction in the Wild,"Stance detection aims to detect the stance toward a corresponding target. Existing works use the assumption that the target is known in advance, which is often not the case in the wild. Given a text from social media platforms, the target information is often unknown due to implicit mentions in the source text and it is infeasible to have manual target annotations at a large scale. Therefore, in this paper, we propose a new task Target-Stance Extraction (TSE) that aims to extract the (target, stance) pair from the text. We benchmark the task by proposing a two-stage framework that first identifies the relevant target in the text and then detects the stance given the predicted target and text. Specifically, we first propose two different settings: Target Classification and Target Generation, to identify the potential target from a given text. Then we propose a multi-task approach that takes target prediction as the auxiliary task to detect the stance toward the predicted target. We evaluate the proposed framework on both in-target stance detection in which the test target is always seen in the training stage and zero-shot stance detection that needs to detect the stance for the targets that are unseen during the training phase. The new TSE task can facilitate future research in the field of stance detection.",1.0,0.7448909282684326,True,0.3775406687981454,0.5612157985332891,True
Storyboarding of Recipes: Grounded Contextual Generation,"Information need of humans is essentially multimodal in nature, enabling maximum exploitation of situated context. We introduce a dataset for sequential procedural (how-to) text generation from images in cooking domain. The dataset consists of 16,441 cooking recipes with 160,479 photos associated with different steps. We setup a baseline motivated by the best performing model in terms of human evaluation for the Visual Story Telling (ViST) task. In addition, we introduce two models to incorporate high level structure learnt by a Finite State Machine (FSM) in neural sequential generation process by: (1) Scaffolding Structure in Decoder (SSiD) (2) Scaffolding Structure in Loss (SSiL). Our best performing model (SSiL) achieves a METEOR score of 0.31, which is an improvement of 0.6 over the baseline model. We also conducted human evaluation of the generated grounded recipes, which reveal that 61% found that our proposed (SSiL) model is better than the baseline model in terms of overall recipes. We also discuss analysis of the output highlighting key important NLP issues for prospective directions.",2.0,0.6045106649398804,True,0.6224593312018546,0.6134849980708674,True
UniSumm and SummZoo: Unified Model and Diverse Benchmark for Few-Shot Summarization,"The high annotation costs and diverse demands of various summarization tasks motivate the development of few-shot summarization.However, despite the emergence of many summarization tasks and datasets, the current training paradigm for few-shot summarization systems ignores potentially shareable knowledge in heterogeneous datasets.To this end, we propose UniSumm, a unified few-shot summarization model pre-trained with multiple summarization tasks and can be prefix-tuned to excel at any few-shot summarization task.Meanwhile, to better evaluate few-shot summarizers, under the principles of diversity and robustness, we assemble and release a new benchmark SummZoo. It consists of 8 summarization tasks with multiple sets of few-shot samples for each task, covering diverse domains.Experimental results and analysis show that UniSumm outperforms strong baselines by a large margin across all sub-tasks in SummZoo under both automatic and human evaluations and achieves comparable results in human evaluation compared with a GPT-3.5 model.",1.0,0.7260721921920776,True,0.3775406687981454,0.5518064304951116,True
Generating Informative Responses with Controlled Sentence Function,"Sentence function is a significant factor to achieve the purpose of the speaker, which, however, has not been touched in large-scale conversation generation so far. In this paper, we present a model to generate informative responses with controlled sentence function. Our model utilizes a continuous latent variable to capture various word patterns that realize the expected sentence function, and introduces a type controller to deal with the compatibility of controlling sentence function and generating informative content. Conditioned on the latent variable, the type controller determines the type (i.e., function-related, topic, and ordinary word) of a word to be generated at each decoding position. Experiments show that our model outperforms state-of-the-art baselines, and it has the ability to generate responses with both controlled sentence function and informative content.",1.0,0.8828389644622803,True,0.3775406687981454,0.6301898166302129,True
Stereotypes and Smut: The (Mis)representation of Non-cisgender Identities by Text-to-Image Models,"Cutting-edge image generation has been praised for producing high-quality images, suggesting a ubiquitous future in a variety of applications. However, initial studies have pointed to the potential for harm due to predictive bias, reflecting and potentially reinforcing cultural stereotypes. In this work, we are the first to investigate how multimodal models handle diverse gender identities. Concretely, we conduct a thorough analysis in which we compare the output of three image generation models for prompts containing cisgender vs. non-cisgender identity terms. Our findings demonstrate that certain non-cisgender identities are consistently (mis)represented as less human, more stereotyped and more sexualised. We complement our experimental analysis with (a)~a survey among non-cisgender individuals and (b) a series of interviews, to establish which harms affected individuals anticipate, and how they would like to be represented. We find respondents are particularly concerned about misrepresentation, and the potential to drive harmful behaviours and beliefs. Simple heuristics to limit offensive content are widely rejected, and instead respondents call for community involvement, curated training data and the ability to customise. These improvements could pave the way for a future where change is led by the affected community, and technology is used to positively ``[portray] queerness in ways that we haven't even thought of'' rather than reproducing stale, offensive stereotypes.",0.8,0.9702154397964478,True,0.3318122278318339,0.6510138338141408,True
A Recipe for Arbitrary Text Style Transfer with Large Language Models,"In this paper, we leverage large language models (LLMs) to perform zero-shot text style transfer. We present a prompting method that we call augmented zero-shot learning, which frames style transfer as a sentence rewriting task and requires only a natural language instruction, without model fine-tuning or exemplars in the target style. Augmented zero-shot learning is simple and demonstrates promising results not just on standard style transfer tasks such as sentiment, but also on arbitrary transformations such as ‘make this melodramatic’ or ‘insert a metaphor.’",1.0,0.862480640411377,True,0.3775406687981454,0.6200106546047612,True
Modeling Intra-Relation in Math Word Problems with Different Functional Multi-Head Attentions,"Several deep learning models have been proposed for solving math word problems (MWPs) automatically. Although these models have the ability to capture features without manual efforts, their approaches to capturing features are not specifically designed for MWPs. To utilize the merits of deep learning models with simultaneous consideration of MWPs’ specific features, we propose a group attention mechanism to extract global features, quantity-related features, quantity-pair features and question-related features in MWPs respectively. The experimental results show that the proposed approach performs significantly better than previous state-of-the-art methods, and boost performance from 66.9% to 69.5% on Math23K with training-test split, from 65.8% to 66.9% on Math23K with 5-fold cross-validation and from 69.2% to 76.1% on MAWPS.",1.0,0.7273224592208862,True,0.3775406687981454,0.5524315640095159,True
How reparametrization trick broke differentially-private text representation learning,"As privacy gains traction in the NLP community, researchers have started adopting various approaches to privacy-preserving methods. One of the favorite privacy frameworks, differential privacy (DP), is perhaps the most compelling thanks to its fundamental theoretical guarantees. Despite the apparent simplicity of the general concept of differential privacy, it seems non-trivial to get it right when applying it to NLP. In this short paper, we formally analyze several recent NLP papers proposing text representation learning using DPText (Beigi et al., 2019a,b; Alnasser et al., 2021; Beigi et al., 2021) and reveal their false claims of being differentially private. Furthermore, we also show a simple yet general empirical sanity check to determine whether a given implementation of a DP mechanism almost certainly violates the privacy loss guarantees. Our main goal is to raise awareness and help the community understand potential pitfalls of applying differential privacy to text representation learning.",1.0,0.8787818551063538,True,0.3775406687981454,0.6281612619522496,True
Large Dataset and Language Model Fun-Tuning for Humor Recognition,"The task of humor recognition has attracted a lot of attention recently due to the urge to process large amounts of user-generated texts and rise of conversational agents. We collected a dataset of jokes and funny dialogues in Russian from various online resources and complemented them carefully with unfunny texts with similar lexical properties. The dataset comprises of more than 300,000 short texts, which is significantly larger than any previous humor-related corpus. Manual annotation of 2,000 items proved the reliability of the corpus construction approach. Further, we applied language model fine-tuning for text classification and obtained an F1 score of 0.91 on a test set, which constitutes a considerable gain over baseline methods. The dataset is freely available for research community.",1.0,0.9908143877983093,True,0.3775406687981454,0.6841775282982274,True
StoryTrans: Non-Parallel Story Author-Style Transfer with Discourse Representations and Content Enhancing,"Non-parallel text style transfer is an important task in natural language generation. However, previous studies concentrate on the token or sentence level, such as sentence sentiment and formality transfer, but neglect long style transfer at the discourse level. Long texts usually involve more complicated author linguistic preferences such as discourse structures than sentences. In this paper, we formulate the task of non-parallel story author-style transfer, which requires transferring an input story into a specified author style while maintaining source semantics. To tackle this problem, we propose a generation model, named StoryTrans, which leverages discourse representations to capture source content information and transfer them to target styles with learnable style embeddings. We use an additional training objective to disentangle stylistic features from the learned discourse representation to prevent the model from degenerating to an auto-encoder. Moreover, to enhance content preservation, we design a mask-and-fill framework to explicitly fuse style-specific keywords of source texts into generation. Furthermore, we constructed new datasets for this task in Chinese and English, respectively. Extensive experiments show that our model outperforms strong baselines in overall performance of style transfer and content preservation.",1.0,0.8105257749557495,True,0.3775406687981454,0.5940332218769475,True
The (Non-)Utility of Structural Features in BiLSTM-based Dependency Parsers,"Classical non-neural dependency parsers put considerable effort on the design of feature functions. Especially, they benefit from information coming from structural features, such as features drawn from neighboring tokens in the dependency tree. In contrast, their BiLSTM-based successors achieve state-of-the-art performance without explicit information about the structural context. In this paper we aim to answer the question: How much structural context are the BiLSTM representations able to capture implicitly? We show that features drawn from partial subtrees become redundant when the BiLSTMs are used. We provide a deep insight into information flow in transition- and graph-based neural architectures to demonstrate where the implicit information comes from when the parsers make their decisions. Finally, with model ablations we demonstrate that the structural context is not only present in the models, but it significantly influences their performance.",0.8,0.8454116582870483,True,0.3318122278318339,0.5886119430594411,True
It is AI’s Turn to Ask Humans a Question: Question-Answer Pair Generation for Children’s Story Books,"Existing question answering (QA) techniques are created mainly to answer questions asked by humans. But in educational applications, teachers often need to decide what questions they should ask, in order to help students to improve their narrative understanding capabilities. We design an automated question-answer generation (QAG) system for this education scenario: given a story book at the kindergarten to eighth-grade level as input, our system can automatically generate QA pairs that are capable of testing a variety of dimensions of a student’s comprehension skills. Our proposed QAG model architecture is demonstrated using a new expert-annotated FairytaleQA dataset, which has 278 child-friendly storybooks with 10,580 QA pairs. Automatic and human evaluations show that our model outperforms state-of-the-art QAG baseline systems. On top of our QAG system, we also start to build an interactive story-telling application for the future real-world deployment in this educational scenario.",1.0,0.9364216923713684,True,0.3775406687981454,0.656981180584757,True
Tackling the Story Ending Biases in The Story Cloze Test,"The Story Cloze Test (SCT) is a recent framework for evaluating story comprehension and script learning. There have been a variety of models tackling the SCT so far. Although the original goal behind the SCT was to require systems to perform deep language understanding and commonsense reasoning for successful narrative understanding, some recent models could perform significantly better than the initial baselines by leveraging human-authorship biases discovered in the SCT dataset. In order to shed some light on this issue, we have performed various data analysis and analyzed a variety of top performing models presented for this task. Given the statistics we have aggregated, we have designed a new crowdsourcing scheme that creates a new SCT dataset, which overcomes some of the biases. We benchmark a few models on the new dataset and show that the top-performing model on the original SCT dataset fails to keep up its performance. Our findings further signify the importance of benchmarking NLP systems on various evolving test sets.",1.0,0.8014660477638245,True,0.3775406687981454,0.589503358280985,True
Pulling Out All The Full Stops: Punctuation Sensitivity in Neural Machine Translation and Evaluation,",",1.0,0.9118812084197998,True,0.3775406687981454,0.6447109386089727,True
A Simple Recipe for Multilingual Grammatical Error Correction,"This paper presents a simple recipe to trainstate-of-the-art multilingual Grammatical Error Correction (GEC) models. We achieve this by first proposing a language-agnostic method to generate a large number of synthetic examples. The second ingredient is to use large-scale multilingual language models (up to 11B parameters). Once fine-tuned on language-specific supervised sets we surpass the previous state-of-the-art results on GEC benchmarks in four languages: English, Czech, German and Russian. Having established a new set of baselines for GEC, we make our results easily reproducible and accessible by releasing a CLANG-8 dataset. It is produced by using our best model, which we call gT5, to clean the targets of a widely used yet noisy Lang-8 dataset. cLang-8 greatly simplifies typical GEC training pipelines composed of multiple fine-tuning stages – we demonstrate that performing a single fine-tuning stepon cLang-8 with the off-the-shelf language models yields further accuracy improvements over an already top-performing gT5 model for English.",1.0,0.7855944633483887,True,0.3775406687981454,0.5815675660732671,True
A Surprisingly Robust Trick for the Winograd Schema Challenge,"The Winograd Schema Challenge (WSC) dataset WSC273 and its inference counterpart WNLI are popular benchmarks for natural language understanding and commonsense reasoning. In this paper, we show that the performance of three language models on WSC273 strongly improves when fine-tuned on a similar pronoun disambiguation problem dataset (denoted WSCR). We additionally generate a large unsupervised WSC-like dataset. By fine-tuning the BERT language model both on the introduced and on the WSCR dataset, we achieve overall accuracies of 72.2% and 71.9% on WSC273 and WNLI, improving the previous state-of-the-art solutions by 8.5% and 6.8%, respectively. Furthermore, our fine-tuned models are also consistently more robust on the “complex” subsets of WSC273, introduced by Trichelair et al. (2018).",2.0,0.8564761281013489,True,0.6224593312018546,0.7394677296516017,True
How do different tokenizers perform on downstream tasks in scriptio continua languages?: A case study in Japanese,"We investigate the impact of different tokenizers on downstream performance in Japanese NLP, with the case of BERT architecture.",1.1,0.7011102437973022,True,0.401312339887548,0.5512112918424251,True
Varying Linguistic Purposes of Emoji in (Twitter) Context,"Early research into emoji in textual communication has focused largely on high-frequency usages and ambiguity of interpretations. Investigation of a wide range of emoji usage shows these glyphs serving at least two very different purposes: as content and function words, or as multimodal affective markers. Identifying where an emoji is replacing textual content allows NLP tools the possibility of parsing them as any other word or phrase. Recognizing the import of non-content emoji can be a a signiﬁcant part of understanding a message as well. We report on an annotation task on English Twitter data with the goal of classifying emoji uses by these categories, and on the effectiveness of a classiﬁer trained on these annotations. We ﬁnd that it is possible to train a classiﬁer to tell the difference between those emoji used as linguistic content words and those used as par-alinguistic or affective multimodal markers even with a small amount of training data, but that accurate sub-classiﬁcation of these multimodal emoji into speciﬁc classes like attitude, topic, or gesture will require more data and more feature engineering.",0.8,0.899258553981781,True,0.3318122278318339,0.6155353909068074,True
"Trillion Dollar Words: A New Financial Dataset, Task & Market Analysis","Monetary policy pronouncements by Federal Open Market Committee (FOMC) are a major driver of financial market returns. We construct the largest tokenized and annotated dataset of FOMC speeches, meeting minutes, and press conference transcripts in order to understand how monetary policy influences financial markets. In this study, we develop a novel task of hawkish-dovish classification and benchmark various pre-trained language models on the proposed dataset. Using the best-performing model (RoBERTa-large), we construct a measure of monetary policy stance for the FOMC document release days. To evaluate the constructed measure, we study its impact on the treasury market, stock market, and macroeconomic indicators. Our dataset, models, and code are publicly available on Huggingface and GitHub under CC BY-NC 4.0 license.",0.8,0.7874443531036377,True,0.3318122278318339,0.5596282904677358,True
Automatic Generation of Jokes in Hindi,"When it comes to computational language generation systems, humour is a relatively unexplored domain, especially more so for Hindi (or rather, for most languages other than English). Most researchers agree that a joke consists of two main parts - the setup and the punchline, with humour being encoded in the incongruity between the two. In this paper, we look at Dur se Dekha jokes, a restricted domain of hu-morous three liner poetry in Hindi. We analyze their structure to understand how humour is encoded in them and formalize it. We then develop a system which is successfully able to generate a basic form of these jokes.",1.0,0.9786522388458252,True,0.3775406687981454,0.6780964538219854,True
Mars: Modeling Context & State Representations with Contrastive Learning for End-to-End Task-Oriented Dialog,"Traditional end-to-end task-oriented dialog systems first convert dialog context into belief state and action state before generating the system response. The system response performance is significantly affected by the quality of the belief state and action state. We first explore what dialog context representation is beneficial to improving the quality of the belief state and action state, which further enhances the generated response quality. To tackle our exploration, we propose Mars, an end-to-end task-oriented dialog system with two contrastive learning strategies to model the relationship between dialog context and belief/action state representations. Empirical results show dialog context representations, which are more different from semantic state representations, are more conducive to multi-turn task-oriented dialog. Moreover, our proposed Mars achieves state-of-the-art performance on the MultiWOZ 2.0, CamRest676, and CrossWOZ.",0.8,0.8147401809692383,True,0.3318122278318339,0.5732762044005361,True
Storytelling from Structured Data and Knowledge Graphs : An NLG Perspective,"In this tutorial, we wish to cover the foundational, methodological, and system development aspects of translating structured data (such as data in tabular form) and knowledge bases (such as knowledge graphs) into natural language. The attendees of the tutorial will be able to take away from this tutorial, (1) the basic ideas around how modern NLP and NLG techniques could be applied to describe and summarize textual data in format that is non-linguistic in nature or has some structure, and (2) a few interesting open-ended questions, which could lead to significant research contributions in future. The tutorial aims to convey challenges and nuances in structured data translation, data representation techniques, and domain adaptable solutions for translation of the data into natural language form. Various solutions, starting from traditional rule based/heuristic driven and modern data-driven and ultra-modern deep-neural style architectures will be discussed, followed by a brief discussion on evaluation and quality estimation. A significant portion of the tutorial will be dedicated towards unsupervised, scalable, and adaptable solutions, given that systems for such an important task will never naturally enjoy sustainable large scale domain independent labeled (parallel) data.",1.0,0.736534595489502,True,0.3775406687981454,0.5570376321438237,True
StoryWars: A Dataset and Instruction Tuning Baselines for Collaborative Story Understanding and Generation,"Collaborative stories, which are texts created through the collaborative efforts of multiple authors with different writing styles and intentions, pose unique challenges for NLP models. Understanding and generating such stories remains an underexplored area due to the lack of open-domain corpora.To address this, we introduce StoryWars, a new dataset of over 40,000 collaborative stories written by 9,400 different authors from an online platform. We design 12 task types, comprising 7 understanding and 5 generation task types, on {pasted macro ‘STORYWARS’}, deriving 101 diverse story-related tasks in total as a multi-task benchmark covering all fully-supervised, few-shot, and zero-shot scenarios.Furthermore, we present our instruction-tuned model, InstructStory, for the story tasks showing that instruction tuning, in addition to achieving superior results in zero-shot and few-shot scenarios, can also obtain the best performance on the fully-supervised tasks in StoryWars, establishing strong multi-task benchmark performances on StoryWars.",1.0,0.9697876572608948,True,0.3775406687981454,0.6736641630295201,True
Minding Language Models’ (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker,"Theory of Mind (ToM)—the ability to reason about the mental states of other people—is a key element of our social intelligence. Yet, despite their ever more impressive performance, large-scale neural language models still lack basic theory of mind capabilities out-of-the-box. We posit that simply scaling up models will not imbue them with theory of mind due to the inherently symbolic and implicit nature of the phenomenon, and instead investigate an alternative: can we design a decoding-time algorithm that enhances theory of mind of off-the-shelf neural language models without explicit supervision? We present SymbolicToM, a plug-and-play approach to reason about the belief states of multiple characters in reading comprehension tasks via explicit symbolic representation. More concretely, our approach tracks each entity’s beliefs, their estimation of other entities’ beliefs, and higher-order levels of reasoning, all through graphical representations, allowing for more precise and interpretable reasoning than previous approaches. Empirical results on the well-known ToMi benchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances off-the-shelf neural networks’ theory of mind in a zero-shot setting while showing robust out-of-distribution performance compared to supervised baselines. Our work also reveals spurious patterns in existing theory of mind benchmarks, emphasizing the importance of out-of-distribution evaluation and methods that do not overfit a particular dataset.",0.8,0.956044614315033,True,0.3318122278318339,0.6439284210734334,True
Uncertainty and Surprisal Jointly Deliver the Punchline: Exploiting Incongruity-Based Features for Humor Recognition,"Humor recognition has been widely studied as a text classification problem using data-driven approaches. However, most existing work does not examine the actual joke mechanism to understand humor. We break down any joke into two distinct components: the set-up and the punchline, and further explore the special relationship between them. Inspired by the incongruity theory of humor, we model the set-up as the part developing semantic uncertainty, and the punchline disrupting audience expectations. With increasingly powerful language models, we were able to feed the set-up along with the punchline into the GPT-2 language model, and calculate the uncertainty and surprisal values of the jokes. By conducting experiments on the SemEval 2021 Task 7 dataset, we found that these two features have better capabilities of telling jokes from non-jokes, compared with existing baselines.",1.0,0.992262065410614,True,0.3775406687981454,0.6849013671043798,True
"When did you become so smart, oh wise one?! Sarcasm Explanation in Multi-modal Multi-party Dialogues","Indirect speech such as sarcasm achieves a constellation of discourse goals in human communication. While the indirectness of figurative language warrants speakers to achieve certain pragmatic goals, it is challenging for AI agents to comprehend such idiosyncrasies of human communication. Though sarcasm identification has been a well-explored topic in dialogue analysis, for conversational systems to truly grasp a conversation’s innate meaning and generate appropriate responses, simply detecting sarcasm is not enough; it is vital to explain its underlying sarcastic connotation to capture its true essence. In this work, we study the discourse structure of sarcastic conversations and propose a novel task – Sarcasm Explanation in Dialogue (SED). Set in a multimodal and code-mixed setting, the task aims to generate natural language explanations of satirical conversations. To this end, we curate WITS, a new dataset to support our task. We propose MAF (Modality Aware Fusion), a multimodal context-aware attention and global information fusion module to capture multimodality and use it to benchmark WITS. The proposed attention module surpasses the traditional multimodal fusion baselines and reports the best performance on almost all metrics. Lastly, we carry out detailed analysis both quantitatively and qualitatively.",1.6,0.9889048337936401,True,0.52497918747894,0.7569420106362901,True
Zoom Out and Observe: News Environment Perception for Fake News Detection,"Fake news detection is crucial for preventing the dissemination of misinformation on social media. To differentiate fake news from real ones, existing methods observe the language patterns of the news post and “zoom in” to verify its content with knowledge sources or check its readers’ replies. However, these methods neglect the information in the external news environment where a fake news post is created and disseminated. The news environment represents recent mainstream media opinion and public attention, which is an important inspiration of fake news fabrication because fake news is often designed to ride the wave of popular events and catch public attention with unexpected novel content for greater exposure and spread. To capture the environmental signals of news posts, we “zoom out” to observe the news environment and propose the News Environment Perception Framework (NEP). For each post, we construct its macro and micro news environment from recent mainstream news. Then we design a popularity-oriented and a novelty-oriented module to perceive useful signals and further assist final prediction. Experiments on our newly built datasets show that the NEP can efficiently improve the performance of basic fake news detectors.",1.0,0.8482036590576172,True,0.3775406687981454,0.6128721639278814,True
What about “em”? How Commercial Machine Translation Fails to Handle (Neo-)Pronouns,"As 3rd-person pronoun usage shifts to include novel forms, e.g., neopronouns, we need more research on identity-inclusive NLP. Exclusion is particularly harmful in one of the most popular NLP applications, machine translation (MT). Wrong pronoun translations can discriminate against marginalized groups, e.g., non-binary individuals (Dev et al., 2021). In this “reality check”, we study how three commercial MT systems translate 3rd-person pronouns. Concretely, we compare the translations of gendered vs. gender-neutral pronouns from English to five other languages (Danish, Farsi, French, German, Italian), and vice versa, from Danish to English.Our error analysis shows that the presence of a gender-neutral pronoun often leads to grammatical and semantic translation errors. Similarly, gender neutrality is often not preserved. By surveying the opinions of affected native speakers from diverse languages, we provide recommendations to address the issue in future MT research.",1.1,0.8507627844810486,True,0.401312339887548,0.6260375621842983,True
Multi-agent Communication meets Natural Language: Synergies between Functional and Structural Language Learning,"We present a method for combining multi-agent communication and traditional data-driven approaches to natural language learning, with an end goal of teaching agents to communicate with humans in natural language. Our starting point is a language model that has been trained on generic, not task-specific language data. We then place this model in a multi-agent self-play environment that generates task-specific rewards used to adapt or modulate the model, turning it into a task-conditional language model. We introduce a new way for combining the two types of learning based on the idea of reranking language model samples, and show that this method outperforms others in communicating with humans in a visual referential communication task. Finally, we present a taxonomy of different types of language drift that can occur alongside a set of measures to detect them.",1.0,0.8191778659820557,True,0.3775406687981454,0.5983592673901006,True
Trick Me If You Can: Adversarial Writing of Trivia Challenge Questions,"Modern question answering systems have been touted as approaching human performance. However, existing question answering datasets are imperfect tests. Questions are written with humans in mind, not computers, and often do not properly expose model limitations. To address this, we develop an adversarial writing setting, where humans interact with trained models and try to break them. This annotation process yields a challenge set, which despite being easy for trivia players to answer, systematically stumps automated question answering systems. Diagnosing model errors on the evaluation data provides actionable insights to explore in developing robust and generalizable question answering systems.",1.0,0.9963585734367371,True,0.3775406687981454,0.6869496211174413,True
What is the best recipe for character-level encoder-only modelling?,"This paper aims to benchmark recent progress in language understanding models that output contextualised representations at the character level. Many such modelling architectures and methods to train those architectures have been proposed, but it is currently unclear what the relative contributions of the architecture vs. the pretraining objective are to final model performance. We explore the design space of such models, comparing architectural innovations (Clark et al., 2022, Jaegle et al., 2022, Tay et al., 2021) and a variety of different pretraining objectives on a suite of evaluation tasks with a fixed training procedure in order to find the currently optimal way to build and train character-level BERT-like models. We find that our best performing character-level model exceeds the performance of a token-based model trained with the same settings on the same data, suggesting that character-level models are ready for more widespread adoption. Unfortunately, the best method to train character-level models still relies on a subword-level tokeniser during pretraining, and final model performance is highly dependent on tokeniser quality. We believe our results demonstrate the readiness of character-level models for multilingual language representation, and encourage NLP practitioners to try them as drop-in replacements for token-based models.",1.3,0.8416036367416382,True,0.45016600268752216,0.6458848197145801,True
Autoencoding Pixies: Amortised Variational Inference with Graph Convolutions for Functional Distributional Semantics,"Functional Distributional Semantics provides a linguistically interpretable framework for distributional semantics, by representing the meaning of a word as a function (a binary classifier), instead of a vector. However, the large number of latent variables means that inference is computationally expensive, and training a model is therefore slow to converge. In this paper, I introduce the Pixie Autoencoder, which augments the generative model of Functional Distributional Semantics with a graph-convolutional neural network to perform amortised variational inference. This allows the model to be trained more effectively, achieving better results on two tasks (semantic similarity in context and semantic composition), and outperforming BERT, a large pre-trained language model.",1.0,0.9186800122261047,True,0.3775406687981454,0.6481103405121251,True
How (not) to train a dependency parser: The curious case of jackknifing part-of-speech taggers,"In dependency parsing, jackknifing taggers is indiscriminately used as a simple adaptation strategy. Here, we empirically evaluate when and how (not) to use jackknifing in parsing. On 26 languages, we reveal a preference that conflicts with, and surpasses the ubiquitous ten-folding. We show no clear benefits of tagging the training data in cross-lingual parsing.",0.8,0.7962875366210938,True,0.3318122278318339,0.5640498822264638,True
Not Enough Data to Pre-train Your Language Model? MT to the Rescue!,"In recent years, pre-trained transformer-based language models (LM) have become a key resource for implementing most NLP tasks. However, pre-training such models demands large text collections not available in most languages. In this paper, we study the use of machine-translated corpora for pre-training LMs. We answer the following research questions: RQ1: Is MT-based data an alternative to real data for learning a LM?; RQ2: Can real data be complemented with translated data and improve the resulting LM? In order to validate these two questions, several BERT models for Basque have been trained, combining real data and synthetic data translated from Spanish. The evaluation carried out on 9 NLU tasks indicates that models trained exclusively on translated data offer competitive results. Furthermore, models trained with real data can be improved with synthetic data, although further research is needed on the matter.",0.8,0.8667933940887451,True,0.3318122278318339,0.5993028109602895,True
Unsupervised multiple-choice question generation for out-of-domain Q&A fine-tuning,"Pre-trained models have shown very good performances on a number of question answering benchmarks especially when fine-tuned on multiple question answering datasets at once. In this work, we propose an approach for generating a fine-tuning dataset thanks to a rule-based algorithm that generates questions and answers from unannotated sentences. We show that the state-of-the-art model UnifiedQA can greatly benefit from such a system on a multiple-choice benchmark about physics, biology and chemistry it has never been trained on. We further show that improved performances may be obtained by selecting the most challenging distractors (wrong answers), with a dedicated ranker based on a pretrained RoBERTa model.",0.8,0.8464310169219971,True,0.3318122278318339,0.5891216223769155,True
An (unhelpful) guide to selecting the best ASR architecture for your under-resourced language,"Advances in deep neural models for automatic speech recognition (ASR) have yielded dramatic improvements in ASR quality for resource-rich languages, with English ASR now achieving word error rates comparable to that of human transcribers. The vast majority of the world’s languages, however, lack the quantity of data necessary to approach this level of accuracy. In this paper we use four of the most popular ASR toolkits to train ASR models for eleven languages with limited ASR training resources: eleven widely spoken languages of Africa, Asia, and South America, one endangered language of Central America, and three critically endangered languages of North America. We find that no single architecture consistently outperforms any other. These differences in performance so far do not appear to be related to any particular feature of the datasets or characteristics of the languages. These findings have important implications for future research in ASR for under-resourced languages. ASR systems for languages with abundant existing media and available speakers may derive the most benefit simply by collecting large amounts of additional acoustic and textual training data. Communities using ASR to support endangered language documentation efforts, who cannot easily collect more data, might instead focus on exploring multiple architectures and hyperparameterizations to optimize performance within the constraints of their available data and resources.",0.8,0.9706792831420898,True,0.3318122278318339,0.6512457554869618,True
Can Diffusion Model Achieve Better Performance in Text Generation? Bridging the Gap between Training and Inference!,"Diffusion models have been successfully adapted to text generation tasks by mapping the discrete text into the continuous space. However, there exist nonnegligible gaps between training and inference, owing to the absence of the forward process during inference. Thus, the model only predicts based on the previously generated reverse noise rather than the noise computed by the forward process. Besides, the widely-used downsampling strategy in speeding up the inference will cause the mismatch of diffusion trajectories between training and inference. To understand and mitigate the above two types of training-inference discrepancies, we launch a thorough preliminary study. Based on our observations, we propose two simple yet effective methods to bridge the gaps mentioned above, named Distance Penalty and Adaptive Decay Sampling. Extensive experiments on \textbf{6} generation tasks confirm the superiority of our methods, which can achieve $100\times \rightarrow 200\times$ speedup with better performance.",0.8,0.8146210312843323,True,0.3318122278318339,0.5732166295580831,True
Do Neural Dialog Systems Use the Conversation History Effectively? An Empirical Study,"Neural generative models have been become increasingly popular when building conversational agents. They offer flexibility, can be easily adapted to new domains, and require minimal domain engineering. A common criticism of these systems is that they seldom understand or use the available dialog history effectively. In this paper, we take an empirical approach to understanding how these models use the available dialog history by studying the sensitivity of the models to artificially introduced unnatural changes or perturbations to their context at test time. We experiment with 10 different types of perturbations on 4 multi-turn dialog datasets and find that commonly used neural dialog architectures like recurrent and transformer-based seq2seq models are rarely sensitive to most perturbations such as missing or reordering utterances, shuffling words, etc. Also, by open-sourcing our code, we believe that it will serve as a useful diagnostic tool for evaluating dialog systems in the future.",1.3,0.6885501742362976,True,0.45016600268752216,0.5693580884619098,True
Can Language Models Make Fun? A Case Study in Chinese Comical Crosstalk,"Language is the principal tool for human communication, in which humor is one of the most attractive parts. Producing natural language like humans using computers, a.k.a, Natural Language Generation (NLG), has been widely used for dialogue systems, chatbots, machine translation, as well as computer-aid creation e.g., idea generations, scriptwriting. However, the humor aspect of natural language is relatively under-investigated, especially in the age of pre-trained language models. In this work, we aim to preliminarily test *whether NLG can generate humor as humans do*. We build a largest dataset consisting of numerous **C**hinese **C**omical **C**rosstalk scripts (called **C**3 in short), which is for a popular Chinese performing art called ‘Xiangsheng’ or ‘相声’ since 1800s.We benchmark various generation approaches including training-from-scratch Seq2seq, fine-tuned middle-scale PLMs, and large-scale PLMs (with and without fine-tuning). Moreover, we also conduct a human assessment, showing that 1) *large-scale pretraining largely improves crosstalk generation quality*; and 2) *even the scripts generated from the best PLM is far from what we expect*. We conclude humor generation could be largely improved using large-scaled PLMs, but it is still in its infancy. The data and benchmarking code are publicly available in [https://github.com/anonNo2/crosstalk-generation](https://github.com/anonNo2/crosstalk-generation).",1.3,0.9855919480323792,True,0.45016600268752216,0.7178789753599506,True
Simplicity Bias in Transformers and their Ability to Learn Sparse Boolean Functions,"Despite the widespread success of Transformers on NLP tasks, recent works have found that they struggle to model several formal languages when compared to recurrent models. This raises the question of why Transformers perform well in practice and whether they have any properties that enable them to generalize better than recurrent models. In this work, we conduct an extensive empirical study on Boolean functions to demonstrate the following: (i) Random Transformers are relatively more biased towards functions of low sensitivity. (ii) When trained on Boolean functions, both Transformers and LSTMs prioritize learning functions of low sensitivity, with Transformers ultimately converging to functions of lower sensitivity. (iii) On sparse Boolean functions which have low sensitivity, we find that Transformers generalize near perfectly even in the presence of noisy labels whereas LSTMs overfit and achieve poor generalization accuracy. Overall, our results provide strong quantifiable evidence that suggests differences in the inductive biases of Transformers and recurrent models which may help explain Transformer’s effective generalization performance despite relatively limited expressiveness.",1.0,0.773112416267395,True,0.3775406687981454,0.5753265425327703,True
CompGuessWhat?!: A Multi-task Evaluation Framework for Grounded Language Learning,"Approaches to Grounded Language Learning are commonly focused on a single task-based final performance measure which may not depend on desirable properties of the learned hidden representations, such as their ability to predict object attributes or generalize to unseen situations. To remedy this, we present GroLLA, an evaluation framework for Grounded Language Learning with Attributes based on three sub-tasks: 1) Goal-oriented evaluation; 2) Object attribute prediction evaluation; and 3) Zero-shot evaluation. We also propose a new dataset CompGuessWhat?! as an instance of this framework for evaluating the quality of learned neural representations, in particular with respect to attribute grounding. To this end, we extend the original GuessWhat?! dataset by including a semantic layer on top of the perceptual one. Specifically, we enrich the VisualGenome scene graphs associated with the GuessWhat?! images with several attributes from resources such as VISA and ImSitu. We then compare several hidden state representations from current state-of-the-art approaches to Grounded Language Learning. By using diagnostic classifiers, we show that current models’ learned representations are not expressive enough to encode object attributes (average F1 of 44.27). In addition, they do not learn strategies nor representations that are robust enough to perform well when novel scenes or objects are involved in gameplay (zero-shot best accuracy 50.06%).",1.6,0.9552192687988281,True,0.52497918747894,0.7400992281388841,True
Downstream Datasets Make Surprisingly Good Pretraining Corpora,"For most natural language processing tasks, the dominant practice is to finetune large pretrained transformer models (e.g., BERT) using smaller downstream datasets.Despite the success of this approach, it remains unclear to what extent these gainsare attributable to the massive background corpora employed for pretraining versus to the pretraining objectives themselves. This paper introduces a large-scale study of self-pretraining, where the same (downstream) training data is used for both pretraining and finetuning.In experiments addressing both ELECTRA and RoBERTa models and 10 distinct downstream classification datasets, we observe that self-pretraining rivals standard pretraining on the BookWiki corpus (despite using around 10x–500x less data), outperforming the latter on 7 and 5 datasets, respectively.Surprisingly, these task-specific pretrained models often perform well on other tasks,including the GLUE benchmark. Besides classification tasks, self-pretraining also provides benefits on structured output prediction tasks such as span based question answering and commonsense inference, often providing more than 50% of the performance boosts provided by pretraining on the BookWiki corpus. Our results hint that in many scenarios, performance gains attributable to pretraining are driven primarily by the pretraining objective itself and are not always attributable to the use of external pretraining data in massive amounts.These findings are especially relevant in light of concerns about intellectual property and offensive content in web-scale pretraining data.",1.0,0.9213222861289978,True,0.3775406687981454,0.6494314774635717,True
Rewire-then-Probe: A Contrastive Recipe for Probing Biomedical Knowledge of Pre-trained Language Models,"Knowledge probing is crucial for understanding the knowledge transfer mechanism behind the pre-trained language models (PLMs). Despite the growing progress of probing knowledge for PLMs in the general domain, specialised areas such as the biomedical domain are vastly under-explored. To facilitate this, we release a well-curated biomedical knowledge probing benchmark, MedLAMA, constructed based on the Unified Medical Language System (UMLS) Metathesaurus. We test a wide spectrum of state-of-the-art PLMs and probing approaches on our benchmark, reaching at most 3% of acc@10. While highlighting various sources of domain-specific challenges that amount to this underwhelming performance, we illustrate that the underlying PLMs have a higher potential for probing tasks. To achieve this, we propose Contrastive-Probe, a novel self-supervised contrastive probing approach, that adjusts the underlying PLMs without using any probing data. While Contrastive-Probe pushes the acc@10 to 28%, the performance gap still remains notable. Our human expert evaluation suggests that the probing performance of our Contrastive-Probe is still under-estimated as UMLS still does not include the full spectrum of factual knowledge. We hope MedLAMA and Contrastive-Probe facilitate further developments of more suited probing techniques for this domain. Our code and dataset are publicly available at https://github.com/cambridgeltl/medlama.",1.0,0.90468430519104,True,0.3775406687981454,0.6411124869945928,True
Variance reduction properties of the reparameterization trick,"The reparameterization trick is widely used in variational inference as it yields more accurate estimates of the gradient of the variational objective than alternative approaches such as the score function method. Although there is overwhelming empirical evidence in the literature showing its success, there is relatively little research exploring why the reparameterization trick is so effective. We explore this under the idealized assumptions that the variational approximation is a mean-field Gaussian density and that the log of the joint density of the model parameters and the data is a quadratic function that depends on the variational mean. From this, we show that the marginal variances of the reparameterization gradient estimator are smaller than those of the score function gradient estimator. We apply the result of our idealized analysis to real-world examples.",1.0,0.8156102299690247,True,0.3775406687981454,0.5965754493835851,True
Threading the Needle of On and Off-Manifold Value Functions for Shapley Explanations,"A popular explainable AI (XAI) approach to quantify feature importance of a given model is via Shapley values. These Shapley values arose in cooperative games, and hence a critical ingredient to compute these in an XAI context is a so-called value function, that computes the""value""of a subset of features, and which connects machine learning models to cooperative games. There are many possible choices for such value functions, which broadly fall into two categories: on-manifold and off-manifold value functions, which take an observational and an interventional viewpoint respectively. Both these classes however have their respective flaws, where on-manifold value functions violate key axiomatic properties and are computationally expensive, while off-manifold value functions pay less heed to the data manifold and evaluate the model on regions for which it wasn't trained. Thus, there is no consensus on which class of value functions to use. In this paper, we show that in addition to these existing issues, both classes of value functions are prone to adversarial manipulations on low density regions. We formalize the desiderata of value functions that respect both the model and the data manifold in a set of axioms and are robust to perturbation on off-manifold regions, and show that there exists a unique value function that satisfies these axioms, which we term the Joint Baseline value function, and the resulting Shapley value the Joint Baseline Shapley (JBshap), and validate the effectiveness of JBshap in experiments.",1.0,0.7873430252075195,True,0.3775406687981454,0.5824418470028325,True
Extragradient Method: O(1/K) Last-Iterate Convergence for Monotone Variational Inequalities and Connections With Cocoercivity,"Extragradient method (EG) (Korpelevich, 1976) is one of the most popular methods for solving saddle point and variational inequalities problems (VIP). Despite its long history and significant attention in the optimization community, there remain important open questions about convergence of EG. In this paper, we resolve one of such questions and derive the first last-iterate $O(1/K)$ convergence rate for EG for monotone and Lipschitz VIP without any additional assumptions on the operator unlike the only known result of this type (Golowich et al., 2020) that relies on the Lipschitzness of the Jacobian of the operator. The rate is given in terms of reducing the squared norm of the operator. Moreover, we establish several results on the (non-)cocoercivity of the update operators of EG, Optimistic Gradient Method, and Hamiltonian Gradient Method, when the original operator is monotone and Lipschitz.",0.8,0.7940183877944946,True,0.3318122278318339,0.5629153078131642,True
Mind the (optimality) Gap: A Gap-Aware Learning Rate Scheduler for Adversarial Nets,"Adversarial nets have proved to be powerful in various domains including generative modeling (GANs), transfer learning, and fairness. However, successfully training adversarial nets using first-order methods remains a major challenge. Typically, careful choices of the learning rates are needed to maintain the delicate balance between the competing networks. In this paper, we design a novel learning rate scheduler that dynamically adapts the learning rate of the adversary to maintain the right balance. The scheduler is driven by the fact that the loss of an ideal adversarial net is a constant known a priori. The scheduler is thus designed to keep the loss of the optimized adversarial net close to that of an ideal network. We run large-scale experiments to study the effectiveness of the scheduler on two popular applications: GANs for image generation and adversarial nets for domain adaptation. Our experiments indicate that adversarial nets trained with the scheduler are less likely to diverge and require significantly less tuning. For example, on CelebA, a GAN with the scheduler requires only one-tenth of the tuning budget needed without a scheduler. Moreover, the scheduler leads to statistically significant improvements in model quality, reaching up to $27\%$ in Frechet Inception Distance for image generation and $3\%$ in test accuracy for domain adaptation.",0.8,0.8019090890884399,True,0.3318122278318339,0.5668606584601369,True
"Distributed Maximization of ""Submodular plus Diversity"" Functions for Multi-label Feature Selection on Huge Datasets","There are many problems in machine learning and data mining which are equivalent to selecting a non-redundant, high ""quality"" set of objects. Recommender systems, feature selection, and data summarization are among many applications of this. In this paper, we consider this problem as an optimization problem that seeks to maximize the sum of a sum-sum diversity function and a non-negative monotone submodular function. The diversity function addresses the redundancy, and the submodular function controls the predictive quality. We consider the problem in big data settings (in other words, distributed and streaming settings) where the data cannot be stored on a single machine or the process time is too high for a single machine. We show that a greedy algorithm achieves a constant factor approximation of the optimal solution in these settings. Moreover, we formulate the multi-label feature selection problem as such an optimization problem. This formulation combined with our algorithm leads to the first distributed multi-label feature selection method. We compare the performance of this method with centralized multi-label feature selection methods in the literature, and we show that its performance is comparable or in some cases is even better than current centralized multi-label feature selection methods.",1.0,0.745255172252655,True,0.3775406687981454,0.5613979205254003,True
Optimal Rates of (Locally) Differentially Private Heavy-tailed Multi-Armed Bandits,"In this paper we investigate the problem of stochastic multi-armed bandits (MAB) in the (local) differential privacy (DP/LDP) model. Unlike previous results that assume bounded/sub-Gaussian reward distributions, we focus on the setting where each arm's reward distribution only has $(1+v)$-th moment with some $v\in (0, 1]$. In the first part, we study the problem in the central $\epsilon$-DP model. We first provide a near-optimal result by developing a private and robust Upper Confidence Bound (UCB) algorithm. Then, we improve the result via a private and robust version of the Successive Elimination (SE) algorithm. Finally, we establish the lower bound to show that the instance-dependent regret of our improved algorithm is optimal. In the second part, we study the problem in the $\epsilon$-LDP model. We propose an algorithm that can be seen as locally private and robust version of SE algorithm, which provably achieves (near) optimal rates for both instance-dependent and instance-independent regret. Our results reveal differences between the problem of private MAB with bounded/sub-Gaussian rewards and heavy-tailed rewards. To achieve these (near) optimal rates, we develop several new hard instances and private robust estimators as byproducts, which might be used to other related problems. Finally, experiments also support our theoretical findings and show the effectiveness of our algorithms.",0.8,0.7727944850921631,True,0.3318122278318339,0.5523033564619985,True
Sample Complexity of Policy-Based Methods under Off-Policy Sampling and Linear Function Approximation,"In this work, we study policy-based methods for solving the reinforcement learning problem, where off-policy sampling and linear function approximation are employed for policy evaluation, and various policy update rules (including natural policy gradient) are considered for policy improvement. To solve the policy evaluation sub-problem in the presence of the deadly triad, we propose a generic algorithm framework of multi-step TD-learning with generalized importance sampling ratios, which includes two specific algorithms: the λ -averaged Q -trace and the two-sided Q -trace. The generic algorithm is single time-scale, has provable finite-sample guarantees, and overcomes the high variance issue in off-policy learning. As for the policy improvement, we provide a univer-sal analysis that establishes geometric convergence of various policy update rules, which leads to an overall ˜ O ( ϵ − 2 ) sample complexity.",1.0,0.8098382353782654,True,0.3775406687981454,0.5936894520882054,True
Additive Tree-Structured Covariance Function for Conditional Parameter Spaces in Bayesian Optimization,"Bayesian optimization (BO) is a sample-efficient global optimization algorithm for black-box functions which are expensive to evaluate. Existing literature on model based optimization in conditional parameter spaces are usually built on trees. In this work, we generalize the additive assumption to tree-structured functions and propose an additive tree-structured covariance function, showing improved sample-efficiency, wider applicability and greater flexibility. Furthermore, by incorporating the structure information of parameter spaces and the additive assumption in the BO loop, we develop a parallel algorithm to optimize the acquisition function and this optimization can be performed in a low dimensional space. We demonstrate our method on an optimization benchmark function, as well as on a neural network model compression problem, and experimental results show our approach significantly outperforms the current state of the art for conditional parameter optimization including SMAC, TPE and Jenatton et al. (2017).",1.0,0.7759255766868591,True,0.3775406687981454,0.5767331227425023,True
Multivariate Quantile Function Forecaster,"We propose Multivariate Quantile Function Forecaster (MQF$^2$), a global probabilistic forecasting method constructed using a multivariate quantile function and investigate its application to multi-horizon forecasting. Prior approaches are either autoregressive, implicitly capturing the dependency structure across time but exhibiting error accumulation with increasing forecast horizons, or multi-horizon sequence-to-sequence models, which do not exhibit error accumulation, but also do typically not model the dependency structure across time steps. MQF$^2$ combines the benefits of both approaches, by directly making predictions in the form of a multivariate quantile function, defined as the gradient of a convex function which we parametrize using input-convex neural networks. By design, the quantile function is monotone with respect to the input quantile levels and hence avoids quantile crossing. We provide two options to train MQF$^2$: with energy score or with maximum likelihood. Experimental results on real-world and synthetic datasets show that our model has comparable performance with state-of-the-art methods in terms of single time step metrics while capturing the time dependency structure.",1.0,0.7233931422233582,True,0.3775406687981454,0.5504669055107518,True
Hogwild! over Distributed Local Data Sets with Linearly Increasing Mini-Batch Sizes,"Hogwild! implements asynchronous Stochastic Gradient Descent (SGD) where multiple threads in parallel access a common repository containing training data, perform SGD iterations and update shared state that represents a jointly learned (global) model. We consider big data analysis where training data is distributed among local data sets -- and we wish to move SGD computations to local compute nodes where local data resides. The results of these local SGD computations are aggregated by a central ""aggregator"" which mimics Hogwild!. We show how local compute nodes can start choosing small mini-batch sizes which increase to larger ones in order to reduce communication cost (round interaction with the aggregator). We prove a tight and novel non-trivial convergence analysis for strongly convex problems which does not use the bounded gradient assumption as seen in many existing publications. The tightness is a consequence of our proofs for lower and upper bounds of the convergence rate, which show a constant factor difference. We show experimental results for plain convex and non-convex problems for biased and unbiased local data sets.",1.5,0.9950898289680481,True,0.5,0.747544914484024,True
Can 5th} Generation Local Training Methods Support Client Sampling? Yes!,"The celebrated FedAvg algorithm of McMahan et al. (2017) is based on three components: client sampling (CS), data sampling (DS) and local training (LT). While the first two are reasonably well understood, the third component, whose role is to reduce the number of communication rounds needed to train the model, resisted all attempts at a satisfactory theoretical explanation. Malinovsky et al. (2022) identified four distinct generations of LT methods based on the quality of the provided theoretical communication complexity guarantees. Despite a lot of progress in this area, none of the existing works were able to show that it is theoretically better to employ multiple local gradient-type steps (i.e., to engage in LT) than to rely on a single local gradient-type step only in the important heterogeneous data regime. In a recent breakthrough embodied in their ProxSkip method and its theoretical analysis, Mishchenko et al. (2022) showed that LT indeed leads to provable communication acceleration for arbitrarily heterogeneous data, thus jump-starting the $5^{\rm th}$ generation of LT methods. However, while these latest generation LT methods are compatible with DS, none of them support CS. We resolve this open problem in the affirmative. In order to do so, we had to base our algorithmic development on new algorithmic and theoretical foundations.",0.8,0.8541814684867859,True,0.3318122278318339,0.5929968481593099,True
Learning piecewise Lipschitz functions in changing environments,"Optimization in the presence of sharp (non-Lipschitz), unpredictable (w.r.t.\ time and amount) changes is a challenging and largely unexplored problem of great significance. We consider the class of piecewise Lipschitz functions, which is the most general online setting considered in the literature for the problem, and arises naturally in various combinatorial algorithm selection problems where utility functions can have sharp discontinuities. The usual performance metric of `static' regret minimizes the gap between the payoff accumulated and that of the best fixed point for the entire duration, and thus fails to capture changing environments. Shifting regret is a useful alternative, which allows for up to $s$ environment {\it shifts}. In this work we provide an $O(\sqrt{sdT\log T}+sT^{1-\beta})$ regret bound for $\beta$-dispersed functions, where $\beta$ roughly quantifies the rate at which discontinuities appear in the utility functions in expectation (typically $\beta\ge1/2$ in problems of practical interest). We also present a lower bound tight up to sub-logarithmic factors. We further obtain improved bounds when selecting from a small pool of experts. We empirically demonstrate a key application of our algorithms to online clustering problems on popular benchmarks.",1.0,0.7658462524414062,True,0.3775406687981454,0.5716934606197759,True
Continuum-Armed Bandits: A Function Space Perspective,"Continuum-armed bandits (a.k.a., black-box or $0^{th}$-order optimization) involves optimizing an unknown objective function given an oracle that evaluates the function at a query point, with the goal of using as few query points as possible. In the most well-studied case, the objective function is assumed to be Lipschitz continuous and minimax rates of simple and cumulative regrets are known in both noiseless and noisy settings. This paper studies continuum-armed bandits under more general smoothness conditions, namely Besov smoothness conditions, on the objective function. In both noiseless and noisy conditions, we derive minimax rates under simple and cumulative regrets. Our results show that minimax rates over objective functions in a Besov space are identical to minimax rates over objective functions in the smallest Holder space into which the Besov space embeds.",1.0,0.854285717010498,True,0.3775406687981454,0.6159131929043218,True
Adversarial Noises Are Linearly Separable for (Nearly) Random Neural Networks,"Adversarial examples, which are usually generated for specific inputs with a specific model, are ubiquitous for neural networks. In this paper we unveil a surprising property of adversarial noises when they are put together, i.e., adversarial noises crafted by one-step gradient methods are linearly separable if equipped with the corresponding labels. We theoretically prove this property for a two-layer network with randomly initialized entries and the neural tangent kernel setup where the parameters are not far from initialization. The proof idea is to show the label information can be efficiently backpropagated to the input while keeping the linear separability. Our theory and experimental evidence further show that the linear classifier trained with the adversarial noises of the training data can well classify the adversarial noises of the test data, indicating that adversarial noises actually inject a distributional perturbation to the original data distribution. Furthermore, we empirically demonstrate that the adversarial noises may become less linearly separable when the above conditions are compromised while they are still much easier to classify than original features.",0.8,0.8822065591812134,True,0.3318122278318339,0.6070093935065236,True
Approximate Function Evaluation via Multi-Armed Bandits,"We study the problem of estimating the value of a known smooth function $f$ at an unknown point $\boldsymbol{\mu} \in \mathbb{R}^n$, where each component $\mu_i$ can be sampled via a noisy oracle. Sampling more frequently components of $\boldsymbol{\mu}$ corresponding to directions of the function with larger directional derivatives is more sample-efficient. However, as $\boldsymbol{\mu}$ is unknown, the optimal sampling frequencies are also unknown. We design an instance-adaptive algorithm that learns to sample according to the importance of each coordinate, and with probability at least $1-\delta$ returns an $\epsilon$ accurate estimate of $f(\boldsymbol{\mu})$. We generalize our algorithm to adapt to heteroskedastic noise, and prove asymptotic optimality when $f$ is linear. We corroborate our theoretical results with numerical experiments, showing the dramatic gains afforded by adaptivity.",1.0,0.925518274307251,True,0.3775406687981454,0.6515294715526982,True
Nearly Minimax Optimal Regret for Learning Infinite-horizon Average-reward MDPs with Linear Function Approximation,"We study reinforcement learning in an infinite-horizon average-reward setting with linear function approximation, where the transition probability function of the underlying Markov Decision Process (MDP) admits a linear form over a feature mapping of the current state, action, and next state. We propose a new algorithm UCRL2-VTR, which can be seen as an extension of the UCRL2 algorithm with linear function approximation. We show that UCRL2-VTR with Bernstein-type bonus can achieve a regret of $\tilde{O}(d\sqrt{DT})$, where $d$ is the dimension of the feature mapping, $T$ is the horizon, and $\sqrt{D}$ is the diameter of the MDP. We also prove a matching lower bound $\tilde{\Omega}(d\sqrt{DT})$, which suggests that the proposed UCRL2-VTR is minimax optimal up to logarithmic factors. To the best of our knowledge, our algorithm is the first nearly minimax optimal RL algorithm with function approximation in the infinite-horizon average-reward setting.",1.0,0.7442542314529419,True,0.3775406687981454,0.5608974501255437,True
Learning the Truth From Only One Side of the Story,"Learning under one-sided feedback (i.e., where examples arrive in an online fashion and the learner only sees the labels for examples it predicted positively on) is a fundamental problem in machine learning -- applications include lending and recommendation systems. Despite this, there has been surprisingly little progress made in ways to mitigate the effects of the sampling bias that arises. 
We focus on generalized linear models and show that without adjusting for this sampling bias, the model may converge sub-optimally or even fail to converge to the optimal solution. We propose an adaptive Upper Confidence Bound approach that comes with rigorous regret guarantees and we show that it outperforms several existing methods experimentally. Our method leverages uncertainty estimation techniques for generalized linear models to more efficiently explore uncertain areas than existing approaches which explore randomly.",1.0,0.7347594499588013,True,0.3775406687981454,0.5561500593784734,True
Can Functional Transfer Methods Capture Simple Inductive Biases?,"Transferring knowledge embedded in trained neural networks is a core problem in areas like model compression and continual learning. Among knowledge transfer approaches, functional transfer methods such as knowledge distillation and representational distance learning are particularly promising, since they allow for transferring knowledge across different architectures and tasks. Considering various characteristics of networks that are desirable to transfer, equivariance is a notable property that enables a network to capture valuable relationships in the data. We assess existing functional transfer methods on their ability to transfer equivariance and empirically show that they fail to even transfer shift equivariance, one of the simplest equiv-ariances. Further theoretical analysis demonstrates that representational similarity meth-ods, in fact, cannot guarantee the transfer of the intended equivariance. Motivated by these ﬁndings, we develop a novel transfer method that learns an equivariance model from a given teacher network and encourages the student network to acquire the same equiv-ariance, via regularization. Experiments show that our method successfully transfers equiv-ariance even in cases where highly restrictive methods, such as directly matching student and teacher representations, fail. 1",1.3,0.6975235939025879,True,0.45016600268752216,0.573844798295055,True
"Regret, stability & fairness in matching markets with bandit learners","Making an informed decision -- for example, when choosing a career or housing -- requires knowledge about the available options. Such knowledge is generally acquired through costly trial and error, but this learning process can be disrupted by competition. In this work, we study how competition affects the long-term outcomes of individuals as they learn. We build on a line of work that models this setting as a two-sided matching market with bandit learners. A recent result in this area states that it is impossible to simultaneously guarantee two natural desiderata: stability and low optimal regret for all agents. Resource-allocating platforms can point to this result as a justification for assigning good long-term outcomes to some agents and poor ones to others. We show that this impossibility need not hold true. In particular, by modeling two additional components of competition -- namely, costs and transfers -- we prove that it is possible to simultaneously guarantee four desiderata: stability, low optimal regret, fairness in the distribution of regret, and high social welfare.",0.8,0.9099998474121094,True,0.3318122278318339,0.6209060376219716,True
Old Dog Learns New Tricks: Randomized UCB for Bandit Problems,"We propose $\tt RandUCB$, a bandit strategy that uses theoretically derived confidence intervals similar to upper confidence bound (UCB) algorithms, but akin to Thompson sampling (TS), uses randomization to trade off exploration and exploitation. In the $K$-armed bandit setting, we show that there are infinitely many variants of $\tt RandUCB$, all of which achieve the minimax-optimal $\widetilde{O}(\sqrt{K T})$ regret after $T$ rounds. Moreover, in a specific multi-armed bandit setting, we show that both UCB and TS can be recovered as special cases of $\tt RandUCB.$ For structured bandits, where each arm is associated with a $d$-dimensional feature vector and rewards are distributed according to a linear or generalized linear model, we prove that $\tt RandUCB$ achieves the minimax-optimal $\widetilde{O}(d \sqrt{T})$ regret even in the case of infinite arms. We demonstrate the practical effectiveness of $\tt RandUCB$ with experiments in both the multi-armed and structured bandit settings. Our results illustrate that $\tt RandUCB$ matches the empirical performance of TS while obtaining the theoretically optimal regret bounds of UCB algorithms, thus achieving the best of both worlds.",1.0,0.9243127107620239,True,0.3775406687981454,0.6509266897800847,True
Learning Infinite-horizon Average-reward MDPs with Linear Function Approximation,"We develop several new algorithms for learning Markov Decision Processes in an infinite-horizon average-reward setting with linear function approximation. Using the optimism principle and assuming that the MDP has a linear structure, we first propose a computationally inefficient algorithm with optimal $\widetilde{O}(\sqrt{T})$ regret and another computationally efficient variant with $\widetilde{O}(T^{3/4})$ regret, where $T$ is the number of interactions. Next, taking inspiration from adversarial linear bandits, we develop yet another efficient algorithm with $\widetilde{O}(\sqrt{T})$ regret under a different set of assumptions, improving the best existing result by Hao et al. (2020) with $\widetilde{O}(T^{2/3})$ regret. Moreover, we draw a connection between this algorithm and the Natural Policy Gradient algorithm proposed by Kakade (2002), and show that our analysis improves the sample complexity bound recently given by Agarwal et al. (2020).",1.0,0.8277735114097595,True,0.3775406687981454,0.6026570901039525,True
Bandit optimisation of functions in the Matérn kernel RKHS,"We consider the problem of optimising functions in the reproducing kernel Hilbert space (RKHS) of a Mat\'ern kernel with smoothness parameter $\nu$ over the domain $[0,1]^d$ under noisy bandit feedback. Our contribution, the $\pi$-GP-UCB algorithm, is the first practical approach with guaranteed sublinear regret for all $\nu>1$ and $d \geq 1$. Empirical validation suggests better performance and drastically improved computational scalablity compared with its predecessor, Improved GP-UCB.",1.0,0.9390163421630859,True,0.3775406687981454,0.6582785054806157,True
Polynomial Time Reinforcement Learning in Factored State MDPs with Linear Value Functions,"Many reinforcement learning (RL) environments in practice feature enormous state spaces that may be described compactly by a""factored""structure, that may be modeled by Factored Markov Decision Processes (FMDPs). We present the first polynomial-time algorithm for RL in Factored State MDPs (generalizing FMDPs) that neither relies on an oracle planner nor requires a linear transition model; it only requires a linear value function with a suitable local basis with respect to the factorization, permitting efficient variable elimination. With this assumption, we can solve this family of Factored State MDPs in polynomial time by constructing an efficient separation oracle for convex optimization. Importantly, and in contrast to prior work on FMDPs, we do not assume that the transitions on various factors are conditionally independent.",1.0,0.7424142360687256,True,0.3775406687981454,0.5599774524334356,True
Multi-Agent congestion cost minimization with linear function approximation,"This work considers multiple agents traversing a network from a source node to the goal node. The cost to an agent for traveling a link has a private as well as a congestion component. The agent's objective is to find a path to the goal node with minimum overall cost in a decentralized way. We model this as a fully decentralized multi-agent reinforcement learning problem and propose a novel multi-agent congestion cost minimization (MACCM) algorithm. Our MACCM algorithm uses linear function approximations of transition probabilities and the global cost function. In the absence of a central controller and to preserve privacy, agents communicate the cost function parameters to their neighbors via a time-varying communication network. Moreover, each agent maintains its estimate of the global state-action value, which is updated via a multi-agent extended value iteration (MAEVI) sub-routine. We show that our MACCM algorithm achieves a sub-linear regret. The proof requires the convergence of cost function parameters, the MAEVI algorithm, and analysis of the regret bounds induced by the MAEVI triggering condition for each agent. We implement our algorithm on a two node network with multiple links to validate it. We first identify the optimal policy, the optimal number of agents going to the goal node in each period. We observe that the average regret is close to zero for 2 and 3 agents. The optimal policy captures the trade-off between the minimum cost of staying at a node and the congestion cost of going to the goal node. Our work is a generalization of learning the stochastic shortest path problem.",1.0,0.7853033542633057,True,0.3775406687981454,0.5814220115307256,True
Differentiating the Value Function by using Convex Duality,"We consider the differentiation of the value function for parametric optimization problems. Such problems are ubiquitous in Machine Learning applications such as structured support vector machines, matrix factorization and min-min or minimax problems in general. Existing approaches for computing the derivative rely on strong assumptions of the parametric function. Therefore, in several scenarios there is no theoretical evidence that a given algorithmic differentiation strategy computes the true gradient information of the value function. We leverage a well known result from convex duality theory to relax the conditions and to derive convergence rates of the derivative approximation for several classes of parametric optimization problems in Machine Learning. We demonstrate the versatility of our approach in several experiments, including non-smooth parametric functions. Even in settings where other approaches are applicable, our duality based strategy shows a favorable performance.",1.0,0.7536618709564209,True,0.3775406687981454,0.5656012698772832,True
The Sylvester Graphical Lasso (SyGlasso),"This paper introduces the Sylvester graphical lasso (SyGlasso) that captures multiway dependencies present in tensor-valued data. The model is based on the Sylvester equation that defines a generative model. The proposed model complements the tensor graphical lasso (Greenewald et al., 2019) that imposes a Kronecker sum model for the inverse covariance matrix by providing an alternative Kronecker sum model that is generative and interpretable. A nodewise regression approach is adopted for estimating the conditional independence relationships among variables. The statistical convergence of the method is established, and empirical studies are provided to demonstrate the recovery of meaningful conditional dependency graphs. We apply the SyGlasso to an electroencephalography (EEG) study to compare the brain connectivity of alcoholic and nonalcoholic subjects. We demonstrate that our model can simultaneously estimate both the brain connectivity and its temporal dependencies.",0.8,0.7807028293609619,True,0.3318122278318339,0.5562575285963979,True
Direct Mind-Machine Teaming (Keynote),"Direct mind-machine teaming will help us treat brain disorders, augment the healthy brain, and shed light on how the brain as an organ gives rise to the mind. Delivering on this promise requires the design of computer systems that delicately balance the tight power, latency, and bandwidth trade-offs needed to decode brain activity, stimulate biological neurons, and control assistive devices most effectively. This talk presents my group’s design of a standardized and general computer architecture for future brain interfacing. Our design enables the treatment of several neurological disorders (most notably, epilepsy and movement disorders) and lays the groundwork for brain interfacing techniques that can help augment cognitive control and decision-making in the healthy brain. Central to our design is end-to-end hardware acceleration, from the microarchitectural to the distributed system level. Key insights are undergirded via detailed physical synthesis models and chip tape-outs in a 12nm CMOS process.",0.8,0.8344230651855469,True,0.3318122278318339,0.5831176465086904,True
LEGO: Empowering Chip-Level Functionality Plug-and-Play for Next-Generation IoT Devices,"Versatile Internet of Things (IoT) applications call for re-configurable IoT devices that can easily extend new functionality on demand. However, the heterogeneity of functional chips brings difficulties in device customization, leading to inadequate flexibility. In this paper, we propose LEGO, a novel architecture for chip-level re-configurable IoT devices that supports plug-and-play with Commercial Off-The-Shelf (COTS) chips. To combat the heterogeneity of functional chips, we first design a novel Unified Chip Description Language (UCDL) with meta-operation and chip specifications to access various types of functional chips uniformly. Then, to achieve chips plug-and-play, we build up a novel platform and shift all chip control logic to the gateway, which makes IoT devices entirely decoupled from specific applications and does not need to make any changes when plugging in new functional chips. Finally, to handle communications overheads, we built up a novel orchestration architecture for gateway instructions, which minimizes instruction transmission frequency in remote chip control. We implement the prototype and conduct extensive evaluations with 100+ types of COTS functional chips. The results show that new functional chips can be automatically accessed by the system within 0.13 seconds after being plugged in, and only bringing 0.53 kb of communication load on average, demonstrating the efficacy of LEGO design.",1.0,0.9763568639755249,True,0.3775406687981454,0.6769487663868352,True
KIT: Testing OS-Level Virtualization for Functional Interference Bugs,"Container isolation is implemented through OS-level virtualization, such as Linux namespaces. Unfortunately, these mechanisms are extremely challenging to implement correctly and, in practice, suffer from functional interference bugs, which compromise container security. In particular, functional interference bugs allow an attacker to extract information from another container running on the same machine or impact its integrity by modifying kernel resources that are incorrectly isolated. Despite their impact, functional interference bugs in OS-level virtualization have received limited attention in part due to the challenges in detecting them. Instead of causing memory errors or crashes, many functional interference bugs involve hard-to-catch logic errors that silently produce semantically incorrect results. This paper proposes KIT, a dynamic testing framework that discovers functional interference bugs in OS-level virtualization mechanisms, such as Linux namespaces. The key idea of KIT is to detect inter-container functional interference by comparing the system call traces of a container across two executions, where it runs with and without the preceding execution of another container. To achieve high efficiency and accuracy, KIT includes two critical components: an efficient algorithm to generate test cases that exercise inter-container data flows and a system call trace analysis framework that detects functional interference bugs and clusters bug reports. KIT discovered 9 functional interference bugs in Linux kernel 5.13, of which 6 have been confirmed. All bugs are caused by logic errors, showing that this approach is able to detect hard-to-catch semantic bugs.",1.0,0.7242292165756226,True,0.3775406687981454,0.550884942686884,True
"Protect the System Call, Protect (Most of) the World with BASTION","System calls are a critical building block in many serious security attacks, such as control-flow hijacking and privilege escalation attacks. Security-sensitive system calls (e.g., execve, mprotect), especially play a major role in completing attacks. Yet, few defense efforts focus to ensure their legitimate usage, allowing attackers to maliciously leverage system calls in attacks. In this paper, we propose a novel System Call Integrity, which enforces the correct use of system calls throughout runtime. We propose three new contexts enforcing (1) which system call is called and how it is invoked (Call Type), (2) how a system call is reached (Control Flow), and (3) that arguments are not corrupted (Argument Integrity). Our defense mechanism thwarts attacks by breaking the critical building block in their attack chains. We implement BASTION, as a compiler and runtime monitor system, to demonstrate the efficacy of the three system call contexts. Our security case study shows that BASTION can effectively stop all the attacks including real-world exploits and recent advanced attack strategies. Deploying BASTION on three popular system call-intensive programs, NGINX, SQLite, and vsFTPd, we show BASTION is secure and practical, demonstrating overhead of 0.60%, 2.01%, and 1.65%, respectively.",0.8,0.9207520484924316,True,0.3318122278318339,0.6262821381621327,True
Computing with time: microarchitectural weird machines,"Side-channel attacks such as Spectre rely on properties of modern CPUs that permit discovery of microarchitectural state via timing of various operations. The Weird Machine concept is an increasingly popular model for characterization of emergent execution that arises from side-effects of conventional computing constructs. In this work we introduce Microarchitectural Weird Machines (µWM): code constructions that allow performing computation through the means of side effects and conflicts between microarchitectual entities such as branch predictors and caches. The results of such computations are observed as timing variations. We demonstrate how µWMs can be used as a powerful obfuscation engine where computation operates based on events unobservable to conventional anti-obfuscation tools based on emulation, debugging, static and dynamic analysis techniques. We demonstrate that µWMs can be used to reliably perform arbitrary computation by implementing a SHA-1 hash function. We then present a practical example in which we use a µWM to obfuscate malware code such that its passive operation is invisible to an observer with full power to view the architectural state of the system until the code receives a trigger. When the trigger is received the malware decrypts and executes its payload. To show the effectiveness of obfuscation we demonstrate its use in the concealment and subsequent execution of a payload that exfiltrates a shadow password file, and a payload that creates a reverse shell.",1.0,0.8723267316818237,True,0.3775406687981454,0.6249337002399846,True
Judging a type by its pointer: optimizing GPU virtual functions,"Programmable accelerators aim to provide the flexibility of traditional CPUs with significantly improved performance. A well-known impediment to the widespread adoption of programmable accelerators, like GPUs, is the software engineering overhead involved in porting the code. Existing support for C++ on GPUs allows programmers to port polymorphic code with little effort. However, the overhead from the virtual functions introduced by polymorphic code has not been well studied or mitigated on GPUs. To alleviate the performance cost of virtual functions, we propose two novel techniques that determine an object’s type based only on the object’s address, without accessing the object’s embedded virtual table pointer. The first technique, Coordinated Object Allocation and function Lookup (COAL), is a software-only solution that allocates objects by type and uses the compiler and runtime to find the object’s vTable without accessing an embedded pointer. COAL improves performance by 80%, 47%, and 6% over contemporary CUDA, prior research, and our newly-proposed type-based allocator, respectively. The second solution, TypePointer, introduces a hardware modification that allows unused bits in the object pointer to encode the object’s type, improving performance by 90%, 56%, and 12% over CUDA, prior work, and our new allocator. TypePointer can also be used with the default CUDA allocator to achieve an 18% performance improvement without modifying object allocation.",1.0,0.7308316230773926,True,0.3775406687981454,0.554186145937769,True
IceBreaker: warming serverless functions better with heterogeneity,"Serverless computing, an emerging computing model, relies on ""warming up"" functions prior to its anticipated execution for faster and cost-effective service to users. Unfortunately, warming up functions can be inaccurate and incur prohibitively expensive cost during the warmup period (i.e., keep-alive cost). In this paper, we introduce IceBreaker, a novel technique that reduces the service time and the ""keep-alive"" cost by composing a system with heterogeneous nodes (costly and cheaper). IceBreaker does so by dynamically determining the cost-effective node type to warm up a function based on the function's time-varying probability of the next invocation. By employing heterogeneity, IceBreaker allows for more number of nodes under the same cost budget and hence, keeps more number of functions warm and reduces the wait time during high load. Our real-system evaluation confirms that IceBreaker reduces the overall keep-alive cost by 45% and execution time by 27% using representative serverless applications and industry-grade workload trace. IceBreaker is the first technique to employ and leverage the idea of mixing expensive and cheaper nodes to improve both service time and keep-alive cost for serverless functions -- opening up a new research avenue of serverless computing on heterogeneous servers for researchers and practitioners.",1.0,0.7907874584197998,True,0.3775406687981454,0.5841640636089727,True
"BOGO: Buy Spatial Memory Safety, Get Temporal Memory Safety (Almost) Free","A memory safety violation occurs when a program has an out-of-bound (spatial safety) or use-after-free (temporal safety) memory access. Given its importance as a security vulnerability, recent Intel processors support hardware-accelerated bound checks, called Memory Protection Extensions (MPX). Unfortunately, MPX provides no temporal safety. This paper presents BOGO, a lightweight full memory safety enforcement scheme that transparently guarantees temporal safety on top of MPX's spatial safety. Instead of tracking separate metadata for temporal safety, BOGO reuses the bounds metadata maintained by MPX for both spatial and temporal safety. On free, BOGO scans the MPX bound tables to invalidate the bound of dangling pointers; any following use-after-free error can be detected by MPX as an out-of-bound error. Since scanning the entire MPX bound tables could be expensive, BOGO tracks a small set of hot MPX bound table pages to check on free, and relies on the page fault mechanism to detect any potentially missing dangling pointer, ensuring sound temporal safety protection. Our evaluation shows that BOGO provides full memory safety at 60% runtime overhead and at 36% memory overhead for SPEC CPU 2006 benchmarks. We also show that BOGO incurs reasonable 2.7x slowdown for the worst-case malloc-free intensive benchmarks; and moderate 1.34x overhead for real-world applications.",0.8,0.888726532459259,True,0.3318122278318339,0.6102693801455464,True
Beyond Static Parallel Loops: Supporting Dynamic Task Parallelism on Manycore Architectures with Software-Managed Scratchpad Memories,"Manycore architectures integrate hundreds of cores on a single chip by using simple cores and simple memory systems usually based on software-managed scratchpad memories (SPMs). However, such architectures are notoriously challenging to program, since the programmers need to manually manage all aspects of data movement and synchronization for both correctness and performance. We argue that this manycore programmability challenge is one of the key barriers to achieving the promise of manycore architectures. At the same time, the dynamic task parallel programming model is enjoying considerable success in addressing the programmability challenge of multi-core processors with tens of complex cores and hardware cache coherence. Conventional wisdom suggests a work-stealing runtime, which forms the core of most dynamic task parallel programming models, is ill-suited for manycore architectures. In this work, we demonstrate that a work-stealing runtime is not just feasible on manycore architectures with SPMs, but such a runtime can also significantly improve the performance of irregular workloads when executing on these architectures. We also explore three optimizations that allow the runtime to leverage unused SPM space for further performance benefit. Our dynamic task parallel programming framework achieves 1.2–28.5× speedup on workloads that benefit from our techniques, and only induces minimal overhead for workloads that do not.",1.0,0.794321596622467,True,0.3775406687981454,0.5859311327103063,True
History-Based Arbitration for Fairness in Processor-Interconnect of NUMA Servers,"NUMA (non-uniform memory access) servers are commonly used in high-performance computing and datacenters. Within each server, a processor-interconnect (e.g., Intel QPI, AMD HyperTransport) is used to communicate between the different sockets or nodes. In this work, we explore the impact of the processor-interconnect on overall performance -- in particular, the performance un- fairness caused by processor-interconnect arbitration. It is well known that locally-fair arbitration does not guarantee globally-fair bandwidth sharing as closer nodes receive more bandwidth in a multi-hop network. However, this work demonstrates that the opposite can occur in a commodity NUMA server where remote nodes receive higher bandwidth (and perform better). We analyze this problem and iden- tify that this occurs because of external concentration used in router micro-architectures for processor-interconnects without globally-aware arbitration. While accessing remote memory can occur in any NUMA system, performance un- fairness (or performance variation) is more critical in cloud computing and virtual machines with shared resources. We demonstrate how this unfairness creates significant performance variation when a workload is executed on the Xen virtualization platform. We then provide analysis using synthetic workloads to better understand the source of unfair- ness and eliminate the impact of other shared resources, including the shared last-level cache and main memory. To provide fairness, we propose a novel, history-based arbitration that tracks the history of arbitration grants made in the previous history window. A weighted arbitration is done based on the history to provide global fairness. Through simulations, we show our proposed history-based arbitration can provide global fairness and minimize the processor- interconnect performance unfairness at low cost.",1.0,0.739459753036499,True,0.3775406687981454,0.5585002109173223,True
A one-for-all and o(v log(v ))-cost solution for parallel merge style operations on sorted key-value arrays,"The processing of sorted key-value arrays using a “merge style operation (MSO)” is a very basic and important problem in domains like scientific computing, deep learning, database, graph analysis, sorting, set-operation etc. MSOs dominate the execution time in some important applications like SpGEMM and graph mining. For example, sparse vector addition as an MSO takes up to 98% execution time in SpGEMM in our experiment. For this reason, accelerating MSOs on CPU, GPU, and accelerators using parallel execution has been extensively studied but the solutions in prior work have three major limitations. (1) They treat different MSOs as isolated problems using incompatible methods and an unified solution is still lacking. (2) They do not have the flexibility to support variable key/value sizes and value calculations in the runtime given a fixed hardware design. (3) They require a quadratic hardware cost (O(V2)) for given parallelism V in most cases. To address above three limitations, we make the following efforts. (1) We present a one-for-all solution to support all interested MSOs based on a unified abstraction model “restricted zip machine (RZM)”. (2) We propose a set of composable and parallel primitives for RZM to provide the flexibility to support variable key/value sizes and value calculations. (3) We provide the hardware design to implement the proposed primitives using only O(Vlog(V)) resource. With the above techniques, a flexible and efficient solution for MSOs has been built. Our design can be used either as a drop-in replacement of the merge unit in prior accelerators to reduce the cost from O(V2) to O(Vlog(V)), or as an extension to the SIMD ISA of CPU and GPU. In our evaluation on CPU, when V=16 (512-bit SIMD, 32-bit element), we achieve significant speedup on a range of representative kernels including set operations (8.4×), database joins (7.3×), sparse vector/matrix/tensor addition/multiplication on real/complex numbers (6.5×), merge sort (8.0× over scalar, 3.4× over the state-of-the-art SIMD), and SpGEMM (4.4× over the best one in the baseline collection).",0.8,0.8013125658035278,True,0.3318122278318339,0.5665623968176808,True
Hacky Racers: Exploiting Instruction-Level Parallelism to Generate Stealthy Fine-Grained Timers,"Side-channel attacks pose serious threats to many security models, especially sandbox-based browsers. While transient-execution side channels in out-of-order processors have previously been blamed for vulnerabilities such as Spectre and Meltdown, we show that in fact, the capability of out-of-order execution itself to cause mayhem is far more general. We develop Hacky Racers, a new type of timing gadget that uses instruction-level parallelism, another key feature of out-of-order execution, to measure arbitrary fine-grained timing differences, even in the presence of highly restricted JavaScript sandbox environments. While such environments try to mitigate timing side channels by reducing timer precision and removing language features such as SharedArrayBuffer that can be used to indirectly generate timers via thread-level parallelism, no such restrictions can be designed to limit Hacky Racers. We also design versions of Hacky Racers that require no misspeculation whatsoever, demonstrating that transient execution is not the only threat to security from modern microarchitectural performance optimization. We use Hacky Racers to construct novel backwards-in-time Spectre gadgets, which break many hardware countermeasures in the literature by leaking secrets before misspeculation is discovered. We also use them to generate the first known last-level cache eviction set generator in JavaScript that does not require SharedArrayBuffer support.",1.0,0.9850339293479919,True,0.3775406687981454,0.6812872990730687,True
1 Trillion Dollar Refund: How To Spoof PDF Signatures,"The Portable Document Format (PDF) is the de-facto standard for document exchange worldwide. To guarantee the authenticity and integrity of documents, digital signatures are used. Several public and private services ranging from governments, public enterprises, banks, and payment services rely on the security of PDF signatures. In this paper, we present the first comprehensive security evaluation on digital signatures in PDFs. We introduce three novel attack classes which bypass the cryptographic protection of digitally signed PDF files allowing an attacker to spoof the content of a signed PDF. We analyzed 22 different PDF viewers and found 21 of them to be vulnerable, including prominent and widely used applications such as Adobe Reader DC and Foxit. We additionally evaluated eight online validation services and found six to be vulnerable. A possible explanation for these results could be the absence of a standard algorithm to verify PDF signatures -- each client verifies signatures differently, and attacks can be tailored to these differences. We, therefore, propose the standardization of a secure verification algorithm, which we describe in this paper. All findings have been responsibly disclosed, and the affected vendors were supported during fixing the issues. As a result, three generic CVEs for each attack class were issued [50-52]. Our research on PDF signatures and more information is also online available at https://www.pdf-insecurity.org/.",1.0,0.896904706954956,True,0.3775406687981454,0.6372226878765508,True
C3PO: Large-Scale Study Of Covert Monitoring of C&C Servers via Over-Permissioned Protocol Infiltration,"Current techniques to monitor botnets towards disruption or takedown are likely to result in inaccurate data gathered about the botnet or be detected by C&C orchestrators. Seeking a covert and scalable solution, we look to an evolving pattern in modern malware that integrates standardized over-permissioned protocols, exposing privileged access to C&C servers. We implement techniques to detect and exploit these protocols from over-permissioned bots toward covert C&C server monitoring. Our empirical study of 200k malware captured since 2006 revealed 62,202 over-permissioned bots (nearly 1 in 3) and 443,905 C&C monitoring capabilities, with a steady increase of over-permissioned protocol use over the last 15 years. Due to their ubiquity, we conclude that even though over-permissioned protocols allow for C&C server infiltration, the efficiency and ease of use they provide continue to make them prevalent in the malware operational landscape. This paper presents C3PO, a pipeline that enables our study and empowers incident responders to automatically identify over-permissioned protocols, infiltration vectors to spoof bot-to-C&C communication, and C&C monitoring capabilities that guide covert monitoring post infiltration. Our findings suggest the over-permissioned protocol weakness provides a scalable approach to covertly monitor C&C servers, which is a fundamental enabler of botnet disruptions and takedowns.",0.8,0.9684221148490906,True,0.3318122278318339,0.6501171713404622,True
Meet our Editor (Energy),,0.8,0.7888606786727905,True,0.3318122278318339,0.5603364532523122,True
Where the Wild Warnings Are: Root Causes of Chrome HTTPS Certificate Errors,"HTTPS error warnings are supposed to alert browser users to network attacks. Unfortunately, a wide range of non-attack circumstances trigger hundreds of millions of spurious browser warnings per month. Spurious warnings frustrate users, hinder the widespread adoption of HTTPS, and undermine trust in browser warnings. We investigate the root causes of HTTPS error warnings in the field, with the goal of resolving benign errors. We study a sample of over 300 million errors that Google Chrome users encountered in the course of normal browsing. After manually reviewing more than 2,000 error reports, we developed automated rules to classify the top causes of HTTPS error warnings. We are able to automatically diagnose the root causes of two-thirds of error reports. To our surprise, we find that more than half of errors are caused by client-side or network issues instead of server misconfigurations. Based on these findings, we implemented more actionable warnings and other browser changes to address client-side error causes. We further propose solutions for other classes of root causes.",1.0,0.9019337296485901,True,0.3775406687981454,0.6397371992233678,True
Why So Toxic?: Measuring and Triggering Toxic Behavior in Open-Domain Chatbots,"Chatbots are used in many applications, e.g., automated agents, smart home assistants, interactive characters in online games, etc. Therefore, it is crucial to ensure they do not behave in undesired manners, providing offensive or toxic responses to users. This is not a trivial task as state-of-the-art chatbot models are trained on large, public datasets openly collected from the Internet. This paper presents a first-of-its-kind, large-scale measurement of toxicity in chatbots. We show that publicly available chatbots are prone to providing toxic responses when fed toxic queries. Even more worryingly, some non-toxic queries can trigger toxic responses too. We then set out to design and experiment with an attack, ToxicBuddy, which relies on fine-tuning GPT-2 to generate non-toxic queries that make chatbots respond in a toxic manner. Our extensive experimental evaluation demonstrates that our attack is effective against public chatbot models and outperforms manually-crafted malicious queries proposed by previous work. We also evaluate three defense mechanisms against ToxicBuddy, showing that they either reduce the attack performance at the cost of affecting the chatbot's utility or are only effective at mitigating a portion of the attack. This highlights the need for more research from the computer security and online safety communities to ensure that chatbot models do not hurt their users. Overall, we are confident that ToxicBuddy can be used as an auditing tool and that our work will pave the way toward designing more effective defenses for chatbot safety.",1.1,0.701524019241333,True,0.401312339887548,0.5514181795644405,True
How Unique is Your .onion?: An Analysis of the Fingerprintability of Tor Onion Services,"Recent studies have shown that Tor onion (hidden) service websites are particularly vulnerable to website fingerprinting attacks due to their limited number and sensitive nature. In this work we present a multi-level feature analysis of onion site fingerprintability, considering three state-of-the-art website fingerprinting methods and 482 Tor onion services, making this the largest analysis of this kind completed on onion services to date. Prior studies typically report average performance results for a given website fingerprinting method or countermeasure. We investigate which sites are more or less vulnerable to fingerprinting and which features make them so. We find that there is a high variability in the rate at which sites are classified (and misclassified) by these attacks, implying that average performance figures may not be informative of the risks that website fingerprinting attacks pose to particular sites. We analyze the features exploited by the different website fingerprinting methods and discuss what makes onion service sites more or less easily identifiable, both in terms of their traffic traces as well as their webpage design. We study misclassifications to understand how onion services sites can be redesigned to be less vulnerable to website fingerprinting attacks. Our results also inform the design of website fingerprinting countermeasures and their evaluation considering disparate impact across sites.",1.1,0.7342490553855896,True,0.401312339887548,0.5677806976365688,True
ALCHEMY: A Language and Compiler for Homomorphic Encryption Made easY,"Fully Homomorphic Encryption (FHE) is a cryptographic ""holy grail"" that allows a worker to perform arbitrary computations on client-encrypted data, without learning anything about the data itself. Since the first plausible construction in 2009, a variety of FHE implementations have been given and used for particular applications of interest. Unfortunately, using FHE is currently very complicated, and a great deal of expertise is required to properly implement nontrivial homomorphic computations. This work introduces ALCHEMY, a modular and extensible system that simplifies and accelerates the use of FHE. ALCHEMY compiles ""in-the-clear"" computations on plaintexts, written in a modular domain-specific language~(DSL), into corresponding homomorphic computations on ciphertexts---with no special knowledge of FHE required of the programmer. The compiler automatically chooses (most of the) parameters by statically inferring ciphertext noise rates, generates keys and ""key-switching hints,"" schedules appropriate ciphertext ""maintenance"" operations, and more. In addition, its components can be combined modularly to provide other useful functionality, such logging the empirical noise rates of ciphertexts throughout a computation, without requiring any changes to the original DSL code. As a testbed application, we demonstrate fast homomorphic evaluation of a pseudorandom function~(PRF) based on Ring-LWR, whose entire implementation is only a few dozen lines of simple DSL code. For a single (non-batched) evaluation, our unoptimized implementation takes only about 10 seconds on a commodity PC, which is more than an order of magnitude faster than state-of-the-art homomorphic evaluations of other PRFs, including some specifically designed for amenability to homomorphic evaluation.",1.0,0.8311671614646912,True,0.3775406687981454,0.6043539151314183,True
Alert Alchemy: SOC Workflows and Decisions in the Management of NIDS Rules,"Signature-based network intrusion detection systems (NIDSs) and network intrusion prevention systems (NIPSs) remain at the heart of network defense, along with the rules that enable them to detect threats. These rules allow Security Operation Centers (SOCs) to properly defend a network, yet we know almost nothing about how rules are created, evaluated and managed from an organizational standpoint. In this work, we analyze the processes surrounding the creation, management, and acquisition of rules for network intrusion detection. To understand these processes, we conducted interviews with 17 professionals who work at Managed Security Service Providers (MSSPs) or other organizations that provide network monitoring as a service or conduct their own network monitoring internally. We discovered numerous critical factors, such as rule specificity and total number of alerts and false positives, that guide SOCs in their rule management processes. These lower-level aspects of network monitoring processes have generally been regarded as immutable by prior work, which has mainly focused on designing systems that handle the resulting alert flows by dynamically reducing the number of noisy alerts SOC analysts need to sift through. Instead, we present several recommendations that address these lower-level aspects to help improve alert quality and allow SOCs to better optimize workflows and use of available resources. These recommendations include increasing the specificity of rules, explicitly defining feedback loops from detection to rule development, and setting up organizational processes to improve the transfer of tacit knowledge.",1.0,0.9295024275779724,True,0.3775406687981454,0.653521548188059,True
Verifying Security Policies in Multi-agent Workflows with Loops,"We consider the automatic verification of information flow security policies of web-based workflows, such as conference submission systems like EasyChair. Our workflow description language allows for loops, non-deterministic choice, and an unbounded number of participating agents. The information flow policies are specified in a temporal logic for hyperproperties. We show that the verification problem can be reduced to the satisfiability of a formula of first-order linear-time temporal logic, and provide decidability results for relevant classes of workflows and specifications. We report on experimental results obtained with an implementation of our approach on a series of benchmarks.",1.0,0.8651101589202881,True,0.3775406687981454,0.6213254138592168,True
Trick or Heat?: Manipulating Critical Temperature-Based Control Systems Using Rectification Attacks,"Temperature sensing and control systems are widely used in the closed-loop control of critical processes such as maintaining the thermal stability of patients, or in alarm systems for detecting temperature-related hazards. However, the security of these systems has yet to be completely explored, leaving potential attack surfaces that can be exploited to take control over critical systems. In this paper we investigate the reliability of temperature-based control systems from a security and safety perspective. We show how unexpected consequences and safety risks can be induced by physical-level attacks on analog temperature sensing components. For instance, we demonstrate that an adversary could remotely manipulate the temperature sensor measurements of an infant incubator to cause potential safety issues, without tampering with the victim system or triggering automatic temperature alarms. This attack exploits the unintended rectification effect that can be induced in operational and instrumentation amplifiers to control the sensor output, tricking the internal control loop of the victim system to heat up or cool down. Furthermore, we show how the exploit of this hardware-level vulnerability could affect different classes of analog sensors that share similar signal conditioning processes. Our experimental results indicate that conventional defenses commonly deployed in these systems are not sufficient to mitigate the threat, so we propose a prototype design of a low-cost anomaly detector for critical applications to ensure the integrity of temperature sensor signals.",2.1,0.9305434823036194,True,0.6456563062257954,0.7880998942647074,True
POSTER: Cyber Attack Prediction of Threats from Unconventional Resources (CAPTURE),"This paper outlines the design, implementation and evaluation of CAPTURE - a novel automated, continuously working cyber attack forecast system. It uses a broad range of unconventional signals from various public and private data sources and a set of signals forecasted via the Auto-Regressive Integrated Moving Average (ARIMA) model. While generating signals, auto cross correlation is used to find out the optimum signal aggregation and lead times. Generated signals are used to train a Bayesian classifier against the ground truth of each attack type. We show that it is possible to forecast future cyber incidents using CAPTURE and the consideration of the lead time could improve forecast performance.",0.8,0.8529762625694275,True,0.3318122278318339,0.5923942452006307,True
Session details: Malware & Machine Learning 2,,0.8,0.7932823300361633,True,0.3318122278318339,0.5625472789339986,True
Speculative Probing: Hacking Blind in the Spectre Era,"To defeat ASLR or more advanced fine-grained and leakage-resistant code randomization schemes, modern software exploits rely on information disclosure to locate gadgets inside the victim's code. In the absence of such info-leak vulnerabilities, attackers can still hack blind and derandomize the address space by repeatedly probing the victim's memory while observing crash side effects, but doing so is only feasible for crash-resistant programs. However, high-value targets such as the Linux kernel are not crash-resistant. Moreover, the anomalously large number of crashes is often easily detectable. In this paper, we show that the Spectre era enables an attacker armed with a single memory corruption vulnerability to hack blind without triggering any crashes. Using speculative execution for crash suppression allows the elevation of basic memory write vulnerabilities into powerful speculative probing primitives that leak through microarchitectural side effects. Such primitives can repeatedly probe victim memory and break strong randomization schemes without crashes and bypass all deployed mitigations against Spectre-like attacks. The key idea behind speculative probing is to break Spectre mitigations using memory corruption and resurrect Spectre-style disclosure primitives to mount practical blind software exploits. To showcase speculative probing, we target the Linux kernel, a crash-sensitive victim that has so far been out of reach of blind attacks, mount end-to-end exploits that compromise the system with just-in-time code reuse and data-only attacks from a single memory write vulnerability, and bypass strong Spectre and strong randomization defenses. Our results show that it is crucial to consider synergies between different (Spectre vs. code reuse) threat models to fully comprehend the attack surface of modern systems.",1.0,0.944008469581604,True,0.3775406687981454,0.6607745691898748,True
« Face chevaline » et « tête d’échassier » : la caricature anthropozoomorphe dans l’œuvre de Claude Simon,"De nombreux personnages simoniens sont decrits selon des procedes de deconstruction largement employes dans la caricature : la distorsion des traits de leur visage et leur disproportion anatomique les dotent de caracteristiques physiques animales et les metamorphosent en figures hybrides. Pour autant, le caractere satirique de la caricature animaliere realisee dans les descriptions simoniennes pose question, dans la mesure ou l’auteur revendique de ne pas etre un moraliste. L’article se propose ainsi d’interroger l’influence de la caricature anthropozoomorphe du xixe siecle sur l’ecriture de Claude Simon, a la fois dans ses dimensions esthetique et ethique, entre effet de collage, satire sceptique et figures grotesques.",1.0,0.9612329006195068,True,0.3775406687981454,0.6693867847088262,True
Counterculture Studies - Contents and Editorial 1(1) 2018,Table of,0.8,0.8167795538902283,True,0.3318122278318339,0.574295890861031,True
POSTER: A Comprehensive Study of Forged Certificates in the Wild,"With the widespread use of SSL, many issues have been exposed as well. Forged certificates used for MITM attacks or proxies can make SSL encryption useless easily, leading to privacy disclosure and property loss of careless victims. In this paper, we implement a large scale of passive measurement of SSL/TLS and analyze the forged certificates in the wild comprehensively. We measured SSL/TLS connection for 16 months on two large research networks, which provided a total of 100 Gbps bandwidth. We gathered nearly 135 million leaf certificates and studied the forged ones. Our findings reveal main reasons of signing forged certificates, and show the preference of them. Finally, we find out several suspicious servers that might be used for MITM.",1.0,0.7288894057273865,True,0.3775406687981454,0.553215037262766,True
Poster: Multi-target & Multi-trigger Backdoor Attacks on Graph Neural Networks,"Recent research has indicated that Graph Neural Networks (GNNs) are vulnerable to backdoor attacks, and existing studies focus on the One-to-One attack where there is a single target triggered by a single backdoor. In this work, we explore two advanced backdoor attacks, i.e., the multi-target and multi-trigger backdoor attacks, on GNNs: 1) One-to-N attack, where there are multiple backdoor targets triggered by controlling different values of the trigger; 2) N-to-One attack, where the attack is only triggered when all the N triggers are present. The initial experimental results illustrate that both attacks can achieve a high attack success rate (up to 99.72%) on GNNs for the node classification task.",0.8,0.8414329290390015,True,0.3318122278318339,0.5866225784354177,True
Re-Presence A Theory of Power Analysis in Times of Radical Changes of Media (15th century/20th century),,0.8,0.8900464177131653,True,0.3318122278318339,0.6109293227724996,True
Irony of The Phoenix Project (2008-2015) in the Global City,,0.8,0.9963865876197815,True,0.3318122278318339,0.6640994077258077,True
Dissecting Click Fraud Autonomy in the Wild,"Although the use of pay-per-click mechanisms stimulates the prosperity of the mobile advertisement network, fraudulent ad clicks result in huge financial losses for advertisers. Extensive studies identify click fraud according to click/traffic patterns based on dynamic analysis. However, in this study, we identify a novel click fraud, named humanoid attack, which can circumvent existing detection schemes by generating fraudulent clicks with similar patterns to normal clicks. We implement the first tool ClickScanner to detect humanoid attacks on Android apps based on static analysis and variational AutoEncoders (VAEs) with limited knowledge of fraudulent examples. We define novel features to characterize the patterns of humanoid attacks in the apps' bytecode level. ClickScanner builds a data dependency graph (DDG) based on static analysis to extract these key features and form a feature vector. We then propose a classification model only trained on benign datasets to overcome the limited knowledge of humanoid attacks. We leverage ClickScanner to conduct the first large-scale measurement on app markets (i.e., 120,000 apps from Google Play and Huawei AppGallery) and reveal several unprecedented phenomena. First, even for the top-rated 20,000 apps, ClickScanner still identifies 157 apps as fraudulent, which shows the prevalence of humanoid attacks. Second, it is observed that the ad SDK-based attack (i.e., the fraudulent codes are in the third-party ad SDKs) is now a dominant attack approach. Third, the manner of attack is notably different across apps of various categories and popularities. Finally, we notice there are several existing variants of the humanoid attack. Additionally, our measurements demonstrate the proposed ClickScanner is accurate and time-efficient (i.e., the detection overhead is only 15.35% of those of existing schemes).",1.0,0.8045824766159058,True,0.3775406687981454,0.5910615727070256,True
If This Then What?: Controlling Flows in IoT Apps,"IoT apps empower users by connecting a variety of otherwise unconnected services. These apps (or applets ) are triggered by external information sources to perform actions on external information sinks. We demonstrate that the popular IoT app platforms, including IFTTT (If This Then That), Zapier, and Microsoft Flow are susceptible to attacks by malicious applet makers, including stealthy privacy attacks to exfiltrate private photos, leak user location, and eavesdrop on user input to voice-controlled assistants. We study a dataset of 279,828 IFTTT applets from more than 400 services, classify the applets according to the sensitivity of their sources, and find that 30% of the applets may violate privacy. We propose two countermeasures for short- and longterm protection: access control and information flow control. For short-term protection, we suggest that access control classifies an applet as either exclusively private or exclusively public, thus breaking flows from private sources to sensitive sinks. For longterm protection, we develop a framework for information flow tracking in IoT apps. The framework models applet reactivity and timing behavior, while at the same time faithfully capturing the subtleties of attacker observations caused by applet output. We show how to implement the approach for an IFTTT-inspired setting leveraging state-of-the-art information flow tracking techniques for JavaScript based on the JSFlow tool and evaluate its effectiveness on a collection of applets.",1.1,0.7636623978614807,True,0.401312339887548,0.5824873688745144,True
Fraud De-Anonymization for Fun and Profit,"The persistence of search rank fraud in online, peer-opinion systems, made possible by crowdsourcing sites and specialized fraud workers, shows that the current approach of detecting and filtering fraud is inefficient. We introduce a fraud de-anonymization approach to disincentivize search rank fraud: attribute user accounts flagged by fraud detection algorithms in online peer-opinion systems, to the human workers in crowdsourcing sites, who control them. We model fraud de-anonymization as a maximum likelihood estimation problem, and introduce UODA, an unconstrained optimization solution. We develop a graph based deep learning approach to predict ownership of account pairs by the same fraudster and use it to build discriminative fraud de-anonymization (DDA) and pseudonymous fraudster discovery algorithms (PFD). To address the lack of ground truth fraud data and its pernicious impacts on online systems that employ fraud detection, we propose the first cheating-resistant fraud de-anonymization validation protocol, that transforms human fraud workers into ground truth, performance evaluation oracles. In a user study with 16 human fraud workers, UODA achieved a precision of 91%. On ground truth data that we collected starting from other 23 fraud workers, our co-ownership predictor significantly outperformed a state-of-the-art competitor, and enabled DDA and PFD to discover tens of new fraud workers, and attribute thousands of suspicious user accounts to existing and newly discovered fraudsters.",1.0,0.9861134886741638,True,0.3775406687981454,0.6818270787361547,True
Warmonger: Inflicting Denial-of-Service via Serverless Functions in the Cloud,"We debut the Warmonger attack, a novel attack vector that can cause denial-of-service between a serverless computing platform and an external content server. The Warmonger attack exploits the fact that a serverless computing platform shares the same set of egress IPs among all serverless functions, which belong to different users, to access an external content server. As a result, a malicious user on this platform can purposefully misbehave and cause these egress IPs to be blocked by the content server, resulting in a platform-wide denial of service. To validate the Warmonger attack, we ran months-long experiments, collected and analyzed the egress IP usage pattern of four major serverless service providers (SSPs). We also conducted an in-depth evaluation of an attacker's possible moves to inflict an external server and cause IP-blockage. We demonstrate that some SSPs use surprisingly small numbers of egress IPs (as little as only four) and share them among their users, and that the serverless platform provides sufficient leverage for a malicious user to conduct well-known misbehaviors and cause IP-blockage. Our study unveiled a potential security threat on the emerging serverless computing platform, and shed light on potential mitigation approaches.",1.0,0.9758671522140503,True,0.3775406687981454,0.6767039105060979,True
Be Selfish and Avoid Dilemmas: Fork After Withholding (FAW) Attacks on Bitcoin,"In the Bitcoin system, participants are rewarded for solving cryptographic puzzles. In order to receive more consistent rewards over time, some participants organize mining pools and split the rewards from the pool in proportion to each participant's contribution. However, several attacks threaten the ability to participate in pools. The block withholding (BWH) attack makes the pool reward system unfair by letting malicious participants receive unearned wages while only pretending to contribute work. When two pools launch BWH attacks against each other, they encounter the miner's dilemma: in a Nash equilibrium, the revenue of both pools is diminished. In another attack called selfish mining, an attacker can unfairly earn extra rewards by deliberately generating forks. In this paper, we propose a novel attack called a fork after withholding (FAW) attack. FAW is not just another attack. The reward for an FAW attacker is always equal to or greater than that for a BWH attacker, and it is usable up to four times more often per pool than in BWH attack. When considering multiple pools --- the current state of the Bitcoin network -- the extra reward for an FAW attack is about 56% more than that for a BWH attack. Furthermore, when two pools execute FAW attacks on each other, the miner's dilemma may not hold: under certain circumstances, the larger pool can consistently win. More importantly, an FAW attack, while using intentional forks, does not suffer from practicality issues, unlike selfish mining. We also discuss partial countermeasures against the FAW attack, but finding a cheap and efficient countermeasure remains an open problem. As a result, we expect to see FAW attacks among mining pools.",0.8,0.8851041197776794,True,0.3318122278318339,0.6084581738047566,True
Under the Dark: A Systematical Study of Stealthy Mining Pools (Ab)use in the Wild,"Cryptocurrency mining is a crucial operation in blockchains, and miners often join mining pools to increase their chances of earning rewards. However, the energy-intensive nature of PoW cryptocurrency mining has led to its ban in New York State of the United States, China, and India. As a result, mining pools, serving as a central hub for mining activities, have become prime targets for regulatory enforcement. Furthermore, cryptojacking malware refers to self-owned stealthy mining pools to evade detection techniques and conceal profit wallet addresses. However, no systematic research has been conducted to analyze it, largely due to a lack of full understanding of the protocol implementation, usage, and port distribution of the stealth mining pool. To the best of our knowledge, we carry out the first large-scale and longitudinal measurement research of stealthy mining pools to fill this gap. We report 7,629 stealthy mining pools among 59 countries. Further, we study the inner mechanisms of stealthy mining pools. By examining the 19,601 stealthy mining pool domains and IPs, our analysis reveals that stealthy mining pools carefully craft their domain semantics, protocol support, and lifespan to provide underground, user-friendly, and robust mining services. What's worse, we uncover a strong correlation between stealthy mining pools and malware, with 23.3% of them being labeled as malicious. Besides, we evaluate the tricks used to evade state-of-the-art mining detection, including migrating domain name resolution methods, leveraging the botnet, and enabling TLS encryption. Finally, we conduct a qualitative study to evaluate the profit gains of malicious cryptomining activities through the stealthy pool from an insider perspective. Our results show that criminals have the potential to earn more than 1 million USD per year, boasting an average ROI of 2,750%. We have informed the relevant ISPs about uncovered stealthy mining pools and have received their acknowledgments.",1.8,0.6198286414146423,True,0.574442516811659,0.5971355791131507,True
Hacksaw: Hardware-Centric Kernel Debloating via Device Inventory and Dependency Analysis,"Kernel debloating is a practical mechanism to mitigate the security problems of the operating system kernel by reducing its attack surface. Existing kernel debloating mechanisms focus on specializing a kernel to run a target application based on its dynamic traces collected in the past - they remove functions from the kernel which are not used by the application according to the traces. However, since the dynamic traces do not ensure full coverage, false removals of required functions are unavoidable. This paper proposes Hacksaw, a novel mechanism to debloat a kernel for a target machine based on its hardware device inventory. Hacksaw accurately debloats a kernel without false removals because figuring out which hardware components are attached to the machine as well as which device drivers manage them is comprehensive and deterministic. Hacksaw removes not only inoperative device drivers that do not control any attached hardware components but also other kernel modules and functions which are associated with the inoperative drivers according to three dependency analysis approaches: call-graph, driver-model, and compilation-unit analyses. Our evaluation shows that Hacksaw effectively removes inoperative kernel modules and functions (i.e., their respective reduction ratios are 45% and 30% on average) while ensuring validity and compatibility.",1.0,0.8007520437240601,True,0.3775406687981454,0.5891463562611028,True
"Grotto: Screaming fast (2+1)-PC or ℤ2n via (2,2)-DPFs","We introduce Grotto, a framework and C++ library for space- and time-efficient (2+1)-party piecewise polynomial (i.e., spline) evaluation on secrets additively shared over ℤ2n. Grotto improves on the state-of-the-art approaches based on distributed comparison functions (DCFs) in almost every metric, offering asymptotically superior communication and computation costs with the same or lower round complexity. At the heart of Grotto is a novel observation about the structure of the ''tree'' representation underlying the most efficient distributed point functions (DPFs) from the literature, alongside an efficient algorithm that leverages this structure to do with a lightweight DPF what state-of-the-art approaches require comparatively heavyweight DCFs to do. Our open-source Grotto implementation supports dozens of useful functions out of the box, including trigonometric and hyperbolic functions with their inverses; various logarithms; roots, reciprocals, and reciprocal roots; sign testing and bit counting; and over two dozen of the most common univariate activation functions from the deep-learning literature.",0.8,0.9521099925041199,True,0.3318122278318339,0.6419611101679769,True
TypeSqueezer: When Static Recovery of Function Signatures for Binary Executables Meets Dynamic Analysis,"Control-Flow Integrity (CFI) is considered a promising solution in thwarting advanced code-reuse attacks. While the problem of backward-edge protection in CFI is nearly closed, effective forward-edge protection is still a major challenge. The keystone of protecting the forward edge is to resolve indirect call targets, which although can be done quite accurately using type-based solutions given the program source code, it faces difficulties when carried out at the binary level. Since the actual type information is unavailable in COTS binaries, type-based indirect call target matching typically resorts to approximate function signatures inferred using the arity and argument width of indirect callsites and calltargets. Doing so with static analysis, therefore, forces the existing solutions to assume the arity/width boundaries in a too-permissive way to defeat sophisticated attacks. In this paper, we propose a novel hybrid approach to recover fine-grained function signatures at the binary level, called TypeSqueezer. By observing program behaviors dynamically, TypeSqueezer combines the static analysis results on indirect callsites and calltargets together, so that both the lower and the upper bounds of their arity/width can be computed according to a philosophy similar to the squeeze theorem. Moreover, the introduction of dynamic analysis also enables TypeSqueezer to approximate the actual type of function arguments instead of only representing them using their widths. These together allow TypeSqueezer to significantly refine the capability of indirect call target resolving, and generate the approximate CFGs with better accuracy. We have evaluated TypeSqueezer on the SPEC CPU2006 benchmarks as well as several real-world applications. The experimental results suggest that TypeSqueezer achieves higher type-matching precision compared to existing binary-level type-based solutions. Moreover, we also discuss the intrinsic limitations of static analysis and show that it is not enough in defeating certain type of practical attacks; while on the other hand, the same attacks can be successfully thwarted with the hybrid analysis result of our approach.",1.0,0.9344953894615173,True,0.3775406687981454,0.6560180291298314,True
5Gen-C: Multi-input Functional Encryption and Program Obfuscation for Arithmetic Circuits,"Program obfuscation is a powerful security primitive with many applications. White-box cryptography studies a particular subset of program obfuscation targeting keyed pseudorandom functions (PRFs), a core component of systems such as mobile payment and digital rights management. Although the white-box obfuscators currently used in practice do not come with security proofs and are thus routinely broken, recent years have seen an explosion of cryptographic techniques for obfuscation, with the goal of avoiding this build-and-break cycle. In this work, we explore in detail cryptographic program obfuscation and the related primitive of multi-input functional encryption (MIFE). In particular, we extend the 5Gen framework (CCS 2016) to support circuit-based MIFE and program obfuscation, implementing both existing and new constructions. We then evaluate and compare the efficiency of these constructions in the context of PRF obfuscation. As part of this work we (1) introduce a novel instantiation of MIFE that works directly on functions represented as arithmetic circuits, (2) use a known transformation from MIFE to obfuscation to give us an obfuscator that performs better than all prior constructions, and (3) develop a compiler for generating circuits optimized for our schemes. Finally, we provide detailed experiments, demonstrating, among other things, the ability to obfuscate a PRF with a 64-bit key and 12 bits of input (containing 62k gates) in under 4 hours, with evaluation taking around 1 hour. This is by far the most complex function obfuscated to date.",1.0,0.7747443318367004,True,0.3775406687981454,0.576142500317423,True
CCS 2017: Women in Cyber Security (CyberW) Workshop,"The CyberW workshop is motivated by the significant gender imbalance in all security conferences, in terms of the number of publishing authors, PC members, organizers, and attendees. What causes this gender imbalance remains unclear. However, multiple research studies have shown that a diverse group is more creative, diligent, and productive than a homogeneous group. Achieving cyber security requires a diverse group. To maintain a sustainable and creative workforce, substantial efforts need to be made by the security community to broaden the participation from underrepresented groups in cyber security research conferences. We hope this workshop can attract all underrepresented cybersecurity professionals, students, and researchers to attend top security and privacy conferences, engage in cutting-edge security and privacy research, excel in cyber security professions, and ultimately take on leadership positions.",0.8,0.8013610243797302,True,0.3318122278318339,0.566586626105782,True
User Story Driven Adaptive Planning Framework in Personal Daily Context,"This paper proposes a just-in-time approach to introduce adaptive planning in personal daily context. Adaptive planning is known to be effective in agile development, which is expected to be useful for our daily life as well. The chatbot-based approach has been proposed for modeling personal daily context as user story graph. This paper extends this approach by adopting the design of sprint planning. To evaluate the effectiveness of the proposed method, a short-term real-world simulation using a storytelling interface is conducted. The result shows that the proposed adaptive planning framework could lead to better decision-making during individual’s daily life.",1.0,0.7636264562606812,True,0.3775406687981454,0.5705835625294133,True
Certificate Transparency in the Wild: Exploring the Reliability of Monitors,"To detect fraudulent TLS server certificates and improve the accountability of certification authorities (CAs), certificate transparency (CT) is proposed to record certificates in publicly-visible logs, from which the monitors fetch all certificates and watch for suspicious ones. However, if the monitors, either domain owners themselves or third-party services, fail to return a complete set of certificates issued for a domain of interest, potentially fraudulent certificates may not be detected and then the CT framework becomes less reliable. This paper presents the first systematic study on CT monitors. We analyze the data in 88 public logs and the services of 5 active third-party monitors regarding 3,000,431 certificates of 6,000 selected Alexa Top-1M websites. We find that although CT allows ordinary domain owners to act as monitors, it is impractical for them to perform reliable processing by themselves, due to the rapidly increasing volume of certificates in public logs (e.g., on average 5 million records or 28.29 GB daily for the minimal set of logs that need to be monitored). Moreover, our study discloses that (a) none of the third-party monitors guarantees to return the complete set of certificates for a domain, and (b) for some domains, even the union of the certificates returned by the five third-party monitors can probably be incomplete. As a result, the certificates accepted by CT-enabled browsers are not absolutely visible to the claimed domain owners, even when CT is adopted with well-functioning logs. The risk of invisible fraudulent certificates in public logs raises doubts on the reliability of CT in practice.",1.0,0.7955823540687561,True,0.3775406687981454,0.5865615114334508,True
Morpheus: Bringing The (PKCS) One To Meet the Oracle,"This paper focuses on developing an automatic, black-box testing approach called Morpheus to check the non-compliance of libraries implementing PKCS#1-v1.5 signature verification with the PKCS#1-v1.5 standard. Non-compliance can not only make implementations vulnerable to Bleichenbacher-style RSA signature forgery attacks but also can induce interoperability issues. For checking non-compliance, Morpheus adaptively generates interesting test cases and then takes advantage of an oracle, a formally proven correct implementation of PKCS#1-v1.5 signature standard, to detect non-compliance in an implementation under test. We have used Morpheus to test 45 implementations of PKCS#1-v1.5 signature verification and discovered that 6 of them are susceptible to variants of the Bleichenbacher-style low public exponent RSA signature forgery attack, 1 implementation has a buffer overflow, 33 implementations have incompatibility issues, and 8 implementations have minor leniencies. Our findings have been responsibly disclosed and positively acknowledged by the developers.",0.8,0.7984755635261536,True,0.3318122278318339,0.5651438956789937,True
"Lacan’s Desire in Wong kar-wai’s In the Mood for Love(2000), The Hand(2004)",,0.8,0.8945715427398682,True,0.3318122278318339,0.613191885285851,True
BlackMirror: Preventing Wallhacks in 3D Online FPS Games,"Online gaming, with a reported 152 billion US dollar market, is immensely popular today. One of the critical issues in multiplayer online games is cheating, in which a player uses an illegal methodology to create an advantage beyond honest game play. For example, wallhacks, the main focus of this work, animate enemy objects on a cheating player's screen, despite being actually hidden behind walls (or other occluding objects). Since such cheats discourage honest players and cause game companies to lose revenue, gaming companies deploy mitigation solutions alongside game applications on the player's machine. However, their solutions are fundamentally flawed since they are deployed on a machine where the attacker has absolute control.",1.0,0.8575100302696228,True,0.3775406687981454,0.6175253495338842,True
Rewriting History: Changing the Archived Web from the Present,"The Internet Archive's Wayback Machine is the largest modern web archive, preserving web content since 1996. We discover and analyze several vulnerabilities in how the Wayback Machine archives data, and then leverage these vulnerabilities to create what are to our knowledge the first attacks against a user's view of the archived web. Our vulnerabilities are enabled by the unique interaction between the Wayback Machine's archives, other websites, and a user's browser, and attackers do not need to compromise the archives in order to compromise users' views of a stored page. We demonstrate the effectiveness of our attacks through proof-of-concept implementations. Then, we conduct a measurement study to quantify the prevalence of vulnerabilities in the archive. Finally, we explore defenses which might be deployed by archives, website publishers, and the users of archives, and present the prototype of a defense for clients of the Wayback Machine, ArchiveWatcher.",1.0,0.7828010320663452,True,0.3775406687981454,0.5801708504322454,True
"Data Breaches, Phishing, or Malware?: Understanding the Risks of Stolen Credentials","In this paper, we present the first longitudinal measurement study of the underground ecosystem fueling credential theft and assess the risk it poses to millions of users. Over the course of March, 2016--March, 2017, we identify 788,000 potential victims of off-the-shelf keyloggers; 12.4 million potential victims of phishing kits; and 1.9 billion usernames and passwords exposed via data breaches and traded on blackmarket forums. Using this dataset, we explore to what degree the stolen passwords---which originate from thousands of online services---enable an attacker to obtain a victim's valid email credentials---and thus complete control of their online identity due to transitive trust. Drawing upon Google as a case study, we find 7--25% of exposed passwords match a victim's Google account. For these accounts, we show how hardening authentication mechanisms to include additional risk signals such as a user's historical geolocations and device profiles helps to mitigate the risk of hijacking. Beyond these risk metrics, we delve into the global reach of the miscreants involved in credential theft and the blackhat tools they rely on. We observe a remarkable lack of external pressure on bad actors, with phishing kit playbooks and keylogger capabilities remaining largely unchanged since the mid-2000s.",1.1,0.7723801732063293,True,0.401312339887548,0.5868462565469387,True
Poster: Let History not Repeat Itself (this Time) -- Tackling WebAuthn Developer Issues Early On,"The FIDO2 open authentication standard, developed jointly by the FIDO Alliance and the W3C, provides end-users with the means to use public-key cryptography in addition to or even instead of text-based passwords for authentication on the web. Its WebAuthn protocol has been adopted by all major browser vendors and recently also by major service providers (e.g., Google, GitHub, Dropbox, Microsoft, and others). Thus, FIDO2 is a very strong contender for finally tackling the problem of insecure user authentication on the web. However, there remain a number of open questions to be answered for FIDO2 to succeed as expected. In this poster, we focus specifically on the critical question of how well web-service developers can securely roll out WebAuthn in their own services and which issues have to be tackled to help developers in this task. The past has unfortunately shown that software developers struggle with correctly implementing or using security-critical APIs, such as TLS/SSL, password storage, or cryptographic APIs. We report here on ongoing work that investigates potential problem areas and concrete pitfalls for adopters of WebAuthn and tries to lay out a plan of how our community can help developers. We believe that raising awareness for foreseeable developer problems and calling for action to support developers early on is critical on the path for establishing FIDO2 as a de-facto authentication solution.",1.8,0.7254897356033325,True,0.574442516811659,0.6499661262074958,True
Password-Stealing without Hacking: Wi-Fi Enabled Practical Keystroke Eavesdropping,"The contact-free sensing nature of Wi-Fi has been leveraged to achieve privacy breaches, yet existing attacks relying on Wi-Fi CSI (channel state information) demand hacking Wi-Fi hardware to obtain desired CSIs. Since such hacking has proven prohibitively hard due to compact hardware, its feasibility in keeping up with fast-developing Wi-Fi technology becomes very questionable. To this end, we propose WiKI-Eve to eavesdrop keystrokes on smartphones without the need for hacking. WiKI-Eve exploits a new feature, BFI (beamforming feedback information), offered by latest Wi-Fi hardware: since BFI is transmitted from a smartphone to an AP in clear-text, it can be overheard (hence eavesdropped) by any other Wi-Fi devices switching to monitor mode. As existing keystroke inference methods offer very limited generalizability, WiKI-Eve further innovates in an adversarial learning scheme to enable its inference generalizable towards unseen scenarios. We implement WiKI-Eve and conduct extensive evaluation on it; the results demonstrate that WiKI-Eve achieves 88.9% inference accuracy for individual keystrokes and up to 65.8% top-10 accuracy for stealing passwords of mobile applications (e.g., WeChat).",1.0,0.7497296333312988,True,0.3775406687981454,0.5636351510647222,True
Checkmate '22: Research on offensive and defensive techniques in the context of Man At The End (MATE) attacks,"The MATE (Man-At-The-End) model, in which an attacker has access to the target software and/or hardware environment to be exploited and the ability to observe and modify that environment, poses unique challenges for both defense and offense. The CheckMATE workshop focuses on exploration of both offensive and defensives techniques under this model. CheckMATE will provide a discussion forum for researchers and industrial practitioners that are exploring theorentical, practical, and emperical studies in this interesting area of security.",0.8,0.9048810601234436,True,0.3318122278318339,0.6183466439776387,True
Contexualizing the Problem of Body and History of Nursing,,1.0,0.9748740792274475,True,0.3775406687981454,0.6762073740127965,True
A Run a Day Won't Keep the Hacker Away: Inference Attacks on Endpoint Privacy Zones in Fitness Tracking Social Networks,"Fitness tracking social networks such as Strava allow users to record sports activities and share them publicly. Sharing encourages peer interaction but also constitutes a risk, because an activity's start or finish may inadvertently reveal privacy-sensitive locations such as a home or workplace. To mitigate this risk, networks introduced endpoint privacy zones (EPZs), which hide track portions around protected locations. In this paper, we show that EPZ implementations of major services remain vulnerable to inference attacks that significantly reduce the effective anonymity provided by the EPZ, and even reveal the protected location. Our attack leverages distance information leaked in activity metadata, street grid data, and the locations of the entry points into the EPZ. This yields a constrained search space where we use regression analysis to predict protected locations. Our evaluation on 1.4 million Strava activities shows that our attack discovers the protected location for up to 85% of EPZs. Larger EPZs reduce the performance of our attack, while geographically dispersed activities in sparser street grids yield better performance. We propose six countermeasures, that, however, come with a usability trade-off, and responsibly disclosed our findings and countermeasures to the major networks.",1.0,0.8970339894294739,True,0.3775406687981454,0.6372873291138097,True
One Glitch to Rule Them All: Fault Injection Attacks Against AMD's Secure Encrypted Virtualization,"AMD Secure Encrypted Virtualization (SEV) offers protection mechanisms for virtual machines in untrusted environments through memory and register encryption. To separate security-sensitive operations from software executing on the main x86 cores, SEV leverages the AMD Secure Processor (AMD-SP). This paper introduces a new approach to attack SEV-protected virtual machines (VMs) by targeting the AMD-SP. We present a voltage glitching attack that allows an attacker to execute custom payloads on the AMD-SPs of all microarchitectures that support SEV currently on the market (Zen 1, Zen 2, and Zen 3). The presented methods allow us to deploy a custom SEV firmware on the AMD-SP, which enables an adversary to decrypt a VM's memory. Furthermore, using our approach, we can extract endorsement keys of SEV-enabled CPUs, which allows us to fake attestation reports or to pose as a valid target for VM migration without requiring physical access to the target host. Moreover, we reverse-engineered the Versioned Chip Endorsement Key (VCEK) mechanism introduced with SEV Secure Nested Paging (SEV-SNP). The VCEK binds the endorsement keys to the firmware version of TCB components relevant for SEV. Building on the ability to extract the endorsement keys, we show how to derive valid VCEKs for arbitrary firmware versions. With our findings, we prove that SEV cannot adequately protect confidential data in cloud environments from insider attackers, such as rogue administrators, on currently available CPUs.",1.8,0.6956484913825989,True,0.574442516811659,0.635045504097129,True
"Sharing Communities: The Good, the Bad, and the Ugly","There are many mysteries surrounding sharing communities, mainly due to their hidden workings and the complexity of joining. Nevertheless, these communities are critical to the security ecosystem, so a more profound understanding is necessary. In addition, they face challenges such as building trust, communicating effectively, and addressing social problems. This work aims to understand better the working methods, organizational structures, goals, benefits, and challenges of sharing communities to help improve their effectiveness and efficiency. To achieve this goal, we conducted video interviews with 25 experts from different countries worldwide who participate in various types of sharing communities. In addition, we applied socio-technical systems (STS) theory in our analysis process to elaborate on our findings from the interviews, identify correlations between them, and explore the interrelationships between social and technical elements of sharing communities. Our findings underscore the need for a holistic view of how sharing communities work. Instead of looking at individual aspects in isolation, considering the interrelationships between the different elements, especially the social, is crucial. This holistic perspective allows us to understand better the complexity and dynamics of sharing communities and how they can function effectively and efficiently. The findings of this study provide valuable impetus for the further development of sharing communities and can serve as a basis for future research.",1.8,0.6965694427490234,True,0.574442516811659,0.6355059797803413,True
"Am I Private and If So, how Many?: Communicating Privacy Guarantees of Differential Privacy with Risk Communication Formats","Every day, we have to decide multiple times, whether and how much personal data we allow to be collected. This decision is not trivial, since there are many legitimate and important purposes for data collection, for examples, the analysis of mobility data to improve urban traffic and transportation. However, often the collected data can reveal sensitive information about individuals. Recently visited locations can, for example, reveal information about political or religious views or even about an individual's health. Privacy-preserving technologies, such as differential privacy (DP), can be employed to protect the privacy of individuals and, furthermore, provide mathematically sound guarantees on the maximum privacy risk. However, they can only support informed privacy decisions, if individuals understand the provided privacy guarantees. This article proposes a novel approach for communicating privacy guarantees to support individuals in their privacy decisions when sharing data. For this, we adopt risk communication formats from the medical domain in conjunction with a model for privacy guarantees of DP to create quantitative privacy risk notifications. We conducted a crowd-sourced study with 343 participants to evaluate how well our notifications conveyed the privacy risk information and how confident participants were about their own understanding of the privacy risk. Our findings suggest that these new notifications can communicate the objective information similarly well to currently used qualitative notifications, but left individuals less confident in their understanding. We also discovered that several of our notifications and the currently used qualitative notification disadvantage individuals with low numeracy: these individuals appear overconfident compared to their actual understanding of the associated privacy risks and are, therefore, less likely to seek the needed additional information before an informed decision. The promising results allow for multiple directions in future research, for example, adding visual aids or tailoring privacy risk communication to characteristics of the individuals.",1.1,0.8391388058662415,True,0.401312339887548,0.6202255728768947,True
"Machine Learning and Security: The Good, The Bad, and The Ugly","I would like to share my thoughts on the interactions between machine learning and security. The good: We now have more data, more powerful machines and algorithms, and better yet, we don't need to always manually engineered the features. The ML process is now much more automated and the learned models are more powerful, and this is a positive feedback loop: more data leads to better models, which lead to more deployments, which lead to more data. All security vendors now advertise that they use ML in their products. The bad: There are more unknowns. In the past, we knew the capabilities and limitations of our security models, including the ML-based models, and understood how they can be evaded. But the state-of-the-art models such as deep neural networks are not as intelligible as classical models such as decision trees. How do we decide to deploy a deep learning-based model for security when we don't know for sure it is learned correctly? Data poisoning becomes easier. On-line learning and web-based learning use data collected in run-time and often from an open environment. Since such data is often resulted from human actions, it can be intentionally polluted, e.g., in misinformation campaigns. How do we make it harder for attackers to manipulate the training data? The ugly: Attackers will keep on exploiting the holes in ML, and automate their attacks using ML. Why don't we just secure ML? This would be no different than trying to secure our programs, and systems, and networks, so we can't. We have to prepare for ML failures. Ultimately, humans have to be involved. The question is how and when? For example, what information should a ML-based system present to humans and what input can humans provide to the system?",1.8,0.5330641269683838,False,0.574442516811659,0.5537533218900215,True
Critical-Playful Speculations with Cameras in the Home,"Smart home cameras present new challenges for understanding behaviors and relationships surrounding always-on, domestic recording systems. We designed a series of discursive activities involving 16 individuals from ten households for six weeks in their everyday settings. These activities functioned as speculative probes—prompting participants to reflect on themes of privacy and power through filming with cameras in their households. Our research design foregrounded critical-playful enactments that allowed participants to speculate potentials for relationships with cameras in the home beyond everyday use. We present four key dynamics with participants and home cameras by examining their relationships to: the camera's eye, filming, their data, and camera's societal contexts. We contribute discussions about the mundane, information privacy, and post-hoc reflection with one's camera footage. Overall, our findings reveal the camera as a strange, yet banal entity in the home—interrogating how participants compose and handle their own and others’ video data.",1.0,0.994137704372406,True,0.3775406687981454,0.6858391865852758,True
Bendtroller:: An Exploration of In-Game Action Mappings with a Deformable Game Controller,"We explore controller input mappings for games using a deformable prototype that combines deformation gestures with standard button input. In study one, we tested discrete gestures using three simple games. We categorized the control schemes as binary (button only), action, and navigation, the latter two named based on the game mechanics mapped to the gestures. We found that the binary scheme performed the best, but gesture-based control schemes are stimulating and appealing. Results also suggest that the deformation gestures are best mapped to simple and natural tasks. In study two, we tested continuous gestures in a 3D racing game using the same control scheme categorization. Results were mostly consistent with study one but showed an improvement in performance and preference for the action control scheme.",0.8,0.8574755787849426,True,0.3318122278318339,0.5946439033083882,True
NurseCare: Design and 'In-The-Wild' Evaluation of a Mobile System to Promote the Ergonomic Transfer of Patients,"Nurses are frequently required to transfer patients as part of their daily duties. However, the manual transfer of patients is a major risk factor for injuries to the back. Although the Kinaesthetics Care Conception can help to address this issue, existing support for the integration of the concept into nursing-care practice is low. We present NurseCare, a mobile system that aims to promote the practical application of ergonomic patient transfers based on the Kinaesthetics Care Conception. NurseCare consists of a wearable and a smartphone app. Key features of NurseCare include mobile accessible instructions for ergonomic patient transfers, in-situ feedback for the risky bending of the back, and long-term feedback. We evaluated NurseCare in a nine participant 'in-the-wild' evaluation. Results indicate that NurseCare can facilitate ergonomic work while providing a high user experience adequate to the nurses' work domain, and reveal how NurseCare can be incorporated in given practices.",1.0,0.9179905652999878,True,0.3775406687981454,0.6477656170490667,True
Taking an (Embodied) Cue From Community Health: Designing Dementia Caregiver Support Technology to Advance Health Equity,"Dementia affects >50 million worldwide, causing progressive cognitive and physical disabilities. Its caregiving burden falls largely onto informal caregivers, who experience their own health problems, and face tremendous stress with little support–all exacerbated during COVID-19. In this paper, we present a new caregiver support perspective, where the lenses of health equity and community health can shape future technology design. Through a 1.5 year long, in-depth research process with dementia community health workers, we learned how caregiving support technology can reflect key concepts in dementia community health practice. This paper makes two contributions: 1) We propose employing embodied cueing, such as imitation or action mimicry, as a communication modality that can align technology with community caregiving approaches, promote agency in people with dementia, and relieve caregiver burden, and 2) We suggest new avenues for HCI research to advance health equity in the context of dementia technology design.",0.8,0.9273074865341187,True,0.3318122278318339,0.6295598571829762,True
Kinecting with Orangutans: Zoo Visitors' Empathetic Responses to Animals' Use of Interactive Technology,"Animal conservation organisations occasionally harness depictions of animals using digital technology to inspire interest in, and concern for animals. To better understand the forms of empathy experienced by people observing animal-computer interaction, we designed and studied an interactive installation for orangutans at a zoo. Through collaborative design we established an understanding of zoos' objectives and strategies related to empathy in the zoo context. We deployed a prototype installation, and observed and interviewed visitors who watched orangutans use the installation. Analysis of observations and interviews revealed that visitors responded with cognitive, affective and motor empathy for the animals. We propose that these empathetic responses are prompted by the visibility of orangutans' bodily movements, by the ""anthropic frame"" provided by digital technology, and by prompting reflection on animals' cognitive processes and affective states. This paper contributes new evidence and understanding of people's empathetic responses to observing animal-computer interaction and confirms the value of designing for empathy in its various forms",1.0,0.7943205237388611,True,0.3775406687981454,0.5859305962685033,True
How WEIRD is CHI?,"Computer technology is often designed in technology hubs in Western countries, invariably making it “WEIRD”, because it is based on the intuition, knowledge, and values of people who are Western, Educated, Industrialized, Rich, and Democratic. Developing technology that is universally useful and engaging requires knowledge about members of WEIRD and non-WEIRD societies alike. In other words, it requires us, the CHI community, to generate this knowledge by studying representative participant samples. To find out to what extent CHI participant samples are from Western societies, we analyzed papers published in the CHI proceedings between 2016-2020. Our findings show that 73% of CHI study findings are based on Western participant samples, representing less than 12% of the world’s population. Furthermore, we show that most participant samples at CHI tend to come from industrialized, rich, and democratic countries with generally highly educated populations. Encouragingly, recent years have seen a slight increase in non-Western samples and those that include several countries. We discuss suggestions for further broadening the international representation of CHI participant samples.",1.3,0.9544959664344788,True,0.45016600268752216,0.7023309845610004,True
The Adventures of Older Authors: Exploring Futures through Co-Design Fictions,"This paper presents co-design fiction as an approach to engaging users in imagining, envisioning and speculating not just on future technology but future life through co-created fictional works. Design fiction in research is often created or written by researchers. There is relatively little critical discussion of how to co-create design fictions with end-users, with the concomitant opportunities and challenges this poses. To fill this gap in knowledge, we conducted co-design fiction workshops with nine older creative writers, utilising prompts to inspire discussion and engage their imaginative writing about the trend towards tracking and monitoring older people. Their stories revealed futures of neither dystopia nor utopia but of social and moral dilemmas narrating their wish not just to ""maintain their independence"", but a palpable desire for adventure and very nuanced senses of how they wish to take control. We discuss inherent tensions in the control of the co-design fiction process; balancing the author's need for freedom and creativity with the researcher's desire to guide the process toward the design investigation at hand.",1.0,0.9548603892326355,True,0.3775406687981454,0.6662005290153905,True
PunchPrint: Creating Composite Fiber-Filament Craft Artifacts by Integrating Punch Needle Embroidery and 3D Printing,"New printing strategies have enabled 3D-printed materials that imitate traditional textiles. These filament-based textiles are easy to fabricate but lack the look and feel of fiber textiles. We seek to augment 3D-printed textiles with needlecraft to produce composite materials that integrate the programmability of additive fabrication with the richness of traditional textile craft. We present PunchPrint: a technique for integrating fiber and filament in a textile by combining punch needle embroidery and 3D printing. Using a toolpath that imitates textile weave structure, we print a flexible fabric that provides a substrate for punch needle production. We evaluate our material’s robustness through tensile strength and needle compatibility tests. We integrate our technique into a parametric design tool and produce functional artifacts that show how PunchPrint broadens punch needle craft by reducing labor in small, detailed artifacts, enabling the integration of openings and multiple yarn weights, and scaffolding soft 3D structures.",1.0,0.8354108333587646,True,0.3775406687981454,0.6064757510784551,True
"Who Gets to Future?: Race, Representation, and Design Methods in Africatown","This paper draws on a collaborative project called the Africatown Activation to examine the role design practices play in contributing to (or conspiring against) the flourishing of the Black community in Seattle, Washington. Specifically, we describe the efforts of a community group called Africatown to design and build an installation that counters decades of disinvestment and ongoing displacement in the historically Black Central Area neighborhood. Our analysis suggests that despite efforts to include community, conventional design practices may perpetuate forms of institutional racism: enabling activities of community engagement that may further legitimate racialized forms of displacement. We discuss how focusing on amplifying the legacies of imagination already at work may help us move beyond a simple reading of design as the solution to systemic forms of oppression.",1.1,0.9336022138595581,True,0.401312339887548,0.667457276873553,True
"""Could You Define That in Bot Terms""?: Requesting, Creating and Using Bots on Reddit","Bots are estimated to account for well over half of all web traffic, yet they remain an understudied topic in HCI. In this paper we present the findings of an analysis of 2284 submissions across three discussion groups dedicated to the request, creation and discussion of bots on Reddit. We set out to examine the qualities and functionalities of bots and the practical and social challenges surrounding their creation and use. Our findings highlight the prevalence of misunderstandings around the capabilities of bots, misalignments in discourse between novices who request and more expert members who create them, and the prevalence of requests that are deemed to be inappropriate for the Reddit community. In discussing our findings, we suggest future directions for the design and development of tools that support more carefully guided and reflective approaches to bot development for novices, and tools to support exploring the consequences of contextually-inappropriate bot ideas.",1.1,0.8316842913627625,True,0.401312339887548,0.6164983156251552,True
Taking Mental Health & Well-Being to the Streets: An Exploratory Evaluation of In-Vehicle Interventions in the Wild,"The increasing number of mental disorders worldwide calls for novel types of prevention measures. Given the number of commuters who spend a substantial amount of time on the road, the car offers an opportune environment. This paper presents the first in-vehicle intervention study affecting mental health and well-being on public roads. We designed and implemented two in-vehicle interventions based on proven psychotherapy interventions. Whereas the first intervention uses mindfulness exercises while driving, the second intervention induces positive emotions through music. Ten ordinary and healthy commuters completed 313 of these interventions on their daily drives over two months. We collected drivers’ immediate and post-driving feedback for each intervention and conducted interviews with the drivers after the end of the study. The results show that both interventions have improved drivers’ well-being. While the participants rated the music intervention very positively, the reception of the mindfulness intervention was more ambivalent.",1.8,0.7936705946922302,True,0.574442516811659,0.6840565557519447,True
Pedagogical Agents in Educational VR: An in the Wild Study,"Pedagogical agents are theorized to increase humans’ effort to understand computerized instructions. Despite the pedagogical promises of VR, the usefulness of pedagogical agents in VR remains uncertain. Based on this gap, and inspired by global efforts to advance remote learning during the COVID-19 pandemic, we conducted an educational VR study in-the-wild (N = 161). With a 2 × 2 + 1 between subjects design, we manipulated the appearance and behavior of a virtual museum guide in an exhibition about viruses. Factual and conceptual learning outcomes as well as subjective learning experience measures were collected. In general, participants reported high enjoyment and had significant knowledge acquisition. We found that the agent’s appearance and behavior impacted factual knowledge gain. We also report an interaction effect between behavioral and visual realism for conceptual knowledge gain. Our findings nuance classical multimedia learning theories and provide directions for employing agents in immersive learning environments.",1.0,0.8637887835502625,True,0.3775406687981454,0.620664726174204,True
Be Our Guest: Intercultural Heritage Exchange through Augmented Reality (AR),"This paper explores how interactive applications can help mitigate the adversity of facing cultural differences between migrants and the host community, and between migrants of diverse backgrounds to foster intercultural exchange. Based on literature about situated cognition, immersive theater, and affordance, we designed and built Be Our Guest: an augmented reality application where a user is invited to the houses of people from different cultures and is asked to help with one of their cultural rituals around simple everyday objects. We detail the various phases we took to collect the cultural stories and construct the application. We then report the results of a user study with the developed application. Our findings show that participants were easily immersed in the augmented space due to the app’s narrative, visuals, and interactive nature. Moreover, they enjoyed exploring cultural rituals, including their own, and felt more confident connecting with people from other cultures.",0.8,0.9650691747665405,True,0.3318122278318339,0.6484407012991872,True
Stay Cool! Understanding Thermal Attacks on Mobile-based User Authentication,"PINs and patterns remain among the most widely used knowledge-based authentication schemes. As thermal cameras become ubiquitous and affordable, we foresee a new form of threat to user privacy on mobile devices. Thermal cameras allow performing thermal attacks, where heat traces, resulting from authentication, can be used to reconstruct passwords. In this work we investigate in details the viability of exploiting thermal imaging to infer PINs and patterns on mobile devices. We present a study (N=18) where we evaluated how properties of PINs and patterns influence their thermal attacks resistance. We found that thermal attacks are indeed viable on mobile devices; overlapping patterns significantly decrease successful thermal attack rate from 100% to 16.67%, while PINs remain vulnerable (>72% success rate) even with duplicate digits. We conclude by recommendations for users and designers of authentication schemes on how to resist thermal attacks.",1.5,0.8441773653030396,True,0.5,0.6720886826515198,True
CandyFly: Bringing fun to drone pilots with disabilities through adapted and adaptable interactions,"Flying drones is an increasingly popular activity. However, it is challenging due to the required perceptual and motor skills for following and stabilizing the drone, especially for people with special needs. This paper describes CandyFly, an application supporting people with diverse sensory, cognitive and motor impairments to pilot drones. We observed an existing accessible piloting workshop and evaluated CandyFly during eight additional workshops over three and a half years using a research-through-design process and ability-based design methods. We identified users’ needs, formulated requirements and explored adaptive interactions such as using pressure-sensitive keys, adjusting controls to the pilots’ range of motion, or limiting the drone’s degrees of freedom to cope with a broad range of disabilities. Our results show that the pilots and their caregivers enjoyed flying and emphasized CandyFly’s ability to be tailored to specific needs. Our findings offer a framework for designing adaptable systems and can support the design of future assistive and recreational systems.",1.0,0.9902710914611816,True,0.3775406687981454,0.6839058801296636,True
"""Arseing around was Fun!""  Humor as a Resource in Design and Making","Humor is an inevitable part of human life. Most of us are capable of experiencing and appreciating humor. From this perspective, surprisingly little HCI research can be found scrutinizing the existence, role, and potential of humor in our design practice. The gap remains also related to children and teenagers; there is a lack of studies appreciating the emergence and existence of humor in the design process without intentionally evoking it. Thus, this study examines humor as a naturally occurring phenomenon in the design process. The study was conducted in collaboration with a class of teenagers and their teachers. The study identifies various forms and functions of humor in the design process and reveals its situated, emergent nature as a resource in interaction within design. The study proposes a practical tool for designers for anticipating and potentially facilitating the emergence, forms and usages of humor as an interactional resource in design.",1.5,0.9939470291137695,True,0.5,0.7469735145568848,True
StoryMap: Using Social Modeling and Self-Modeling to Support Physical Activity Among Families of Low-SES Backgrounds,"Physical activity (PA) is crucial for reducing the risk of obesity, an epidemic that disproportionately burdens families of low-socioeconomic status (SES). While fitness tracking tools can increase PA awareness, more work is needed to examine (1) how such tools can help people benefit from their social environment, and (2) how reflections can help enhance PA attitudes. We investigated how fitness tracking tools for families can support social modeling and self-modeling (through reflection), two critical processes in Social Cognitive Theory. We developed StoryMap, a novel fitness tracking app for families aimed at supporting both modes of modeling. Then, we conducted a five-week qualitative study evaluating StoryMap with 16 low-SES families. Our findings contribute an understanding of how social and self-modeling can be implemented in fitness tracking tools and how both modes of modeling can enhance key PA attitudes: self-efficacy and outcome expectations. Finally, we propose design recommendations for social personal informatics tools.",1.0,0.769358217716217,True,0.3775406687981454,0.5734494432571813,True
Vibrotactile Funneling Illusion and Localization Performance on the Head,"The vibrotactile funneling illusion is the sensation of a single (non-existing) stimulus somewhere in-between the actual stimulus locations. Its occurrence depends upon body location, distance between the actuators, signal synchronization, and intensity. Related work has shown that the funneling illusion may occur on the forehead. We were able to reproduce these findings and explored five further regions to get a more complete picture of the occurrence of the funneling illusion on the head. The results of our study (24 participants) show that the actuator distance, for which the funneling illusion occurs, strongly depends upon the head region. Moreover, we evaluated the centralizing bias (smaller perceived than actual actuator distances) for different head regions, which also showed widely varying characteristics. We computed a detailed heat map of vibrotactile localization accuracies on the head. The results inform the design of future tactile head-mounted displays that aim to support the funneling illusion.",1.0,0.8978394269943237,True,0.3775406687981454,0.6376900478962346,True
"Am I a Bunny?: The Impact of High and Low Immersion Platforms and Viewers' Perceptions of Role on Presence, Narrative Engagement, and Empathy during an Animated 360° Video","This study used both quantitative and qualitative data to assess whether a High Immersion viewing platform (virtual reality headset) elicits stronger feelings of narrative engagement and empathy compared to a Low Immersion platform (smartphone) when viewing an animated 360° video. In line with prior research, participants (N = 65) reported greater feelings of presence in the High Immersion condition compared to Low Immersion. However, immersive condition was not significantly related to narrative engagement or empathy. Interview responses revealed that participants' perceptions of their role in the film experience (i.e., Character, Observer, or Other/Not Sure) varied and were significantly related to narrative engagement. Participants who saw themselves as a Character (versus Observer) reported higher narrative engagement and empathy. Findings suggest that although a more immersive viewing platform can enhance presence during a 360° video experience, a clear understanding of viewer role is both difficult to achieve and critical to story comprehension and empathy.",1.1,0.9500870704650879,True,0.401312339887548,0.6756997051763179,True
"From Her Story, to Our Story: Digital Storytelling as Public Engagement around Abortion Rights Advocacy in Ireland","Despite the divisive nature of abortion within the Republic of Ireland and Northern Ireland, where access to safe, legal abortion is severely restricted, effecting legislative reform demands widespread public support. In light of a building pro-choice counter-voice, this work contributes to a growing body of HCI research that takes an activist approach to design. We report findings from four design workshops with 31 pro-choice stakeholders across Ireland in which we positioned an exploratory protosite, HerStoryTold, to engender critical conversations around the use of sensitive abortion narratives as a tool for engagement. Our analysis shows how digital storytelling can help reject false narratives and raise awareness of the realities of abortion laws. It suggests design directions to curate narratives that provoke empathy, foster polyvocality, and ultimately expand the engaged community. Furthermore, this research calls for designers to actively support community mobilization through providing 'stepping stones' to activism.",1.0,0.802312433719635,True,0.3775406687981454,0.5899265512588903,True
The Role of Gamification in Participatory Environmental Sensing: A Study In the Wild,"Participatory sensing (PS) and citizen science hold promises for a genuinely interactive and inclusive citizen engagement in meaningful and sustained collection of data about social and environmental phenomena. Yet the underlying motivations for public engagement in PS remain still unclear particularly regarding the role of gamification, for which HCI research findings are often inconclusive. This paper reports the findings of an experimental study specifically designed to further understand the effects of gamification on citizen engagement. Our study involved the development and implementation of two versions (gamified and non-gamified) of a mobile application designed to capture lake ice coverage data in the sub-arctic region. Emerging findings indicate a statistically significant effect of gamification on participants' engagement levels in PS. The motivation, approach and results of our study are outlined and implications of the findings for future PS design are reflected.",1.0,0.778508186340332,True,0.3775406687981454,0.5780244275692388,True
“Why Are You Playing Games? You Are a Girl!”: Exploring Gender Biases in Esports,"Esports are rapidly growing within academia. In HCI, earlier work explored how problematic behaviors emerging from gender biases (e.g., toxicity) negatively impact female participation in esports. Here, we further explore gender biases in esports by interviewing 19 self-identified female and male professional gamers and event organizers. We inquire our interviewees about personal experiences with gender biases in esports and their perspective on how these biases impact participation, inclusivity, and career prospects. Our interviewees see gender biases in esports as a consequence of stereotypical gender roles in gaming tout-court (e.g., girls do not like violence, boys are competitive by nature). The rationale for separating male and female in esports, however, seems rooted in the need for female gamers to create role-models and grow in self-confidence. We scrutinize the considerations emerging from our interviews under a Feminist HCI lens and discuss how HCI research can help design equitable environments in esports.",0.8,0.9852740168571472,True,0.3318122278318339,0.6585431223444905,True
Your Photo is so Funny that I don’t Mind Violating Your Privacy by Sharing it: Effects of Individual Humor Styles on Online Photo-sharing Behaviors,"We investigate how people’s ‘humor style’ relates to their online photo-sharing behaviors and reactions to ‘privacy primes’. In an online experiment, we queried 437 participants about their humor style, likelihood to share photo-memes, and history of sharing others’ photos. In two treatment conditions, participants were either primed to imagine themselves as the photo-subjects or to consider the photo-subjects’ privacy before sharing memes. We found that participants who frequently use aggressive and self-deprecating humor were more likely to violate others’ privacy by sharing photos. We also replicated the interventions’ paradoxical effects – increasing sharing likelihood – as reported in earlier work and identified the subgroups that demonstrated this behavior through interaction analyses. When primed to consider the subjects’ privacy, only humor deniers (participants who use humor infrequently) demonstrated increased sharing. In contrast, when imagining themselves as the photo-subjects, humor deniers, unlike other participants, did not increase the sharing of photos.",2.0,0.9872196912765503,True,0.6224593312018546,0.8048395112392024,True
Zoom Obscura: Counterfunctional Design for Video-Conferencing,"This paper reports on Zoom Obscura – an artist-based design research project, responding to the ubiquity of video-conferencing as a technical and cultural phenomenon throughout the Covid-19 pandemic. As enterprise software, such as Zoom, rapidly came to mediate even the most personal and intimate interactions, we supported and collaborated with seven independent artists to explore technical and creative interventions in video-conferencing. Our call for participation sought critical interventions that would help users counter, and regain agency in regard to the various ways in which personal data is captured, transmitted and processed in video-conferencing tools. In this design study, we analyse post-hoc how each of the seven projects employed aspects of counterfunctional design to achieve these aims. Each project reveals different avenues and strategies for counterfunctionality in video-conferencing software, as well as opportunities to design critically towards interactions and experiences that challenge existing norms and expectations around these platforms.",2.0,0.9169691801071167,True,0.6224593312018546,0.7697142556544856,True
Pet-Robot or Appliance? Care Home Residents with Dementia Respond to a Zoomorphic Floor Washing Robot,"Any active entity that shares space with people is interpreted as a social actor. Based on this notion, we explore how robots that integrate functional utility with a social role and character can integrate meaningfully into daily practice. Informed by interviews and observations, we designed a zoomorphic floor cleaning robot which playfully interacts with care home residents affected by dementia. A field study shows that playful interaction can facilitate the introduction of utilitarian robots in care homes, being nonthreatening and easy to make sense of. Residents previously reacted with distress to a Roomba robot, but were now amused by and played with our cartoonish cat robot or simply tolerated its presence. They showed awareness of the machine-nature of the robot, even while engaging in pretend-play. A playful approach to the design of functional robots can thus explicitly conceptualize such robots as social actors in their context of use.",1.3,0.9050832390785217,True,0.45016600268752216,0.6776246208830219,True
Tricks and Treats: Designing Technology to Support Mobility Assistance Dogs,"Assistance dogs are a key intervention to support the autonomy of people with tetraplegia. Previous research on assistive technologies have investigated ways to, ultimately, replace their labour using technology, for instance through the design of smart home environments. However, both the disability studies literature and our interviews suggest there is an immediate need to support these relationships, both in terms of training and bonding. Through a case study of an accessible dog treats dispenser, we investigate a technological intervention responding to these needs, detailing an appropriate design methodology and contributing insights into user requirements and preferences.",1.0,0.9833574295043945,True,0.3775406687981454,0.68044904915127,True
Can I Think of Something Else when Using a BCI?: Cognitive Demand of an SSVEP-based BCI,"BCIs are presumably supposed to require the full attention of their users and to lose accuracy if they pay attention to another task. This assertion has been verified with several BCI paradigms (e.g. P300). But the cognitive demand of the promising SSVEP paradigm had never been specifically assessed yet. We measured the accuracy of an SSVEP-based BCI used by 26 participants in various conditions of mental workload. Our analysis revealed that surprisingly, for this type of BCI, little attention is actually needed from participants to reach optimal accuracy: participants were able to successfully perform a complex secondary task (N-back) without degrading the BCI accuracy. The same observation was made whether visual or auditive attention was solicited. These results indicate that SSVEP is a low-demanding paradigm in terms of cognitive resources, and are encouraging for its use in complex interaction settings.",1.1,0.7645082473754883,True,0.401312339887548,0.5829102936315181,True
"Toggles, Dollar Signs, and Triangles: How to (In)Effectively Convey Privacy Choices with Icons and Link Texts","Increasingly, icons are being proposed to concisely convey privacy-related information and choices to users. However, complex privacy concepts can be difficult to communicate. We investigate which icons effectively signal the presence of privacy choices. In a series of user studies, we designed and evaluated icons and accompanying textual descriptions (link texts) conveying choice, opting-out, and sale of personal information — the latter an opt-out mandated by the California Consumer Privacy Act (CCPA). We identified icon-link text pairings that conveyed the presence of privacy choices without creating misconceptions, with a blue stylized toggle icon paired with “Privacy Options” performing best. The two CCPA-mandated link texts (“Do Not Sell My Personal Information” and “Do Not Sell My Info”) accurately communicated the presence of do-not-sell opt-outs with most icons. Our results provide insights for the design of privacy choice indicators and highlight the necessity of incorporating user testing into policy making.",0.8,0.9881599545478821,True,0.3318122278318339,0.659986091189858,True
How Human Am I?: EEG-based Evaluation of Virtual Characters,"There is a continuous effort by animation experts to create increasingly realistic and more human-like digital characters. However, as virtual characters become more human they risk evoking a sense of unease in their audience. This sensation, called the Uncanny Valley effect, is widely acknowledged both in the popular media and scientific research but empirical evidence for the hypothesis has remained inconsistent. In this paper, we investigate the neural responses to computer-generated faces in a cognitive neuroscience study. We record brain activity from participants (N = 40)} using electroencephalography (EEG) while they watch videos of real humans and computer-generated virtual characters. Our results show distinct differences in neural responses for highly realistic computer-generated faces such as Digital Emily compared with real humans. These differences are unique only to agents that are highly photorealistic, i.e. the `uncanny' response. Based on these specific neural correlates we train a support vector machine~(SVM) to measure the probability of an uncanny response for any given computer-generated character from EEG data. This allows the ordering of animated characters based on their level of `uncanniness'.",1.1,0.797690212726593,True,0.401312339887548,0.5995012763070705,True
Applying Computational Analysis to Textual Data from the Wild: A Feminist Perspective,"With technologies that afford much larger-scale data collection than previously imagined, new ways of processing and interpreting qualitative textual data are required. HCI researchers use a range of methods for interpreting the 'full range of human experience' from qualitative data, however, such approaches are not always scalable. Feminist geography seeks to explore how diverse and varied accounts of place can be understood and represented, whilst avoiding reductive classification systems. In this paper, we assess the extent to which unsupervised topic models can support such a research agenda. Drawing on literature from Feminist and Critical GIS, we present a case study analysis of a Volunteered Geographic Information dataset of reviews about breastfeeding in public spaces. We demonstrate that topic modelling can offer novel insights and nuanced interpretations of complex concepts such as privacy and be integrated into a critically reflexive feminist data analysis approach that captures and represents diverse experiences of place.",1.0,0.898607075214386,True,0.3775406687981454,0.6380738720062658,True
"""They're Just Tixel Pits, Man"": Disputing the 'Reality' of Virtual Reality Pornography through the Story Completion Method","Pornography is a substantial part of humans' everyday interaction with computers, yet to date the topic has been underconsidered by HCI. Here, we examine some of the common cultural ideals non-experts constructed of a ""new"" pornographic experience - Virtual Reality (VR) Porn - through use of the ""Story Completion Method"". Forty five participants completed a story stem about a male character who was about to have his ""very first virtual reality porn experience"". Through our analysis, we demonstrate a narrative of a ""perfect"", idealised sexual experience, as well as one which emphasised the imagined ""precarious"" and dangerous consequences around this technology use. We indicate how the stories reproduced ideals around heteronormativity and hegemonic masculinity, suggesting an agenda of ""Designing for Eroticism"" as a tactic which could avoid such problematic discourses. We also suggest the opportunities and challenges presented through use of the ""Story Completion Method"".",1.0,0.9495089650154114,True,0.3775406687981454,0.6635248169067784,True
Can Children Understand Machine Learning Concepts?: The Effect of Uncovering Black Boxes,"Machine Learning services are integrated into various aspects of everyday life. Their underlying processes are typically black-boxed to increase ease-of-use. Consequently, children lack the opportunity to explore such processes and develop essential mental models. We present a gesture recognition research platform, designed to support learning from experience by uncovering Machine Learning building blocks: Data Labeling and Evaluation. Children used the platform to perform physical gestures, iterating between sampling and evaluation. Their understanding was tested in a pre/post experimental design, in three conditions: learning activity uncovering Data Labeling only, Evaluation only, or both. Our findings show that both building blocks are imperative to enhance children's understanding of basic Machine Learning concepts. Children were able to apply their new knowledge to everyday life context, including personally meaningful applications. We conclude that children's interaction with uncovered black boxes of Machine Learning contributes to a better understanding of the world around them.",1.1,0.8264468908309937,True,0.401312339887548,0.6138796153592708,True
Trajectories of Engagement and Disengagement with a Story-Based Smoking Cessation App,"Strong user engagement with digital technologies for behaviour change is often taken as a precursor to their longer-term efficacy. We critically examine this assumption through a qualitative study of a smoking cessation app, called NewLeaf, which allows quitters to swap personal stories. The study examined what influenced people to engage or disengage with NewLeaf, and how the app was deployed in quit attempts during a four week trial. Several properties of swapped stories were reported to promote engagement, including: authenticity, currency, contextualization of advice, and evoking a sense of community. But while the resulting engagement was sometimes productive in supporting quitting, other trajectories of use were observed involving counterproductive engagement, and a surprising pattern of productive disengagement especially among stronger quitters. We discuss how this analysis of different trajectories problematizes any simple interpretation of user engagement as an early indicator of success for behaviour change technologies.",1.0,0.8693444728851318,True,0.3775406687981454,0.6234425708416387,True
How Far Is Up?: Bringing the Counterpointed Triad Technique to Digital Storybook Apps,"Interactive storybooks, such as those available on the iPad, offer multiple ways to convey a story, mostly through visual, textual and audio content. How to effectively deliver this combination of content so that it supports positive social and educational development in pre-literate children is relatively underexplored. In order to address this issue we introduce the ""Counterpointed Triad Technique"". Drawing from traditional literary theory we design visual, textual and audio content that each conveys different aspects of a story. We explore the use of this technique through a storybook we designed ourselves called ""How Far Is Up?"". A study involving 26 kindergarten children shows that ""How Far Is Up?"" can engage pre-literature children while they are reading alone and also when they are reading with an adult. Based on our craft knowledge and study findings, we present a set of design strategies that aim to provide designers with practical guidance on how to create engaging interactive digital storybooks.",2.1,0.889707088470459,True,0.6456563062257954,0.7676816973481272,True
“Awesomely freaky!” The impact of type on children's social-emotional perceptions of virtual reality characters,"While VR, through decades of research, has shown to successfully improve young children's lives, more research needs to examine the appropriateness of VR for children, including its design. The type of character in combination with the perceptual realism of virtual reality (VR) may influence children's perceptions of VR experiences. A within-participant experiment examined 5- to 9-year-old children's (N = 25) perceptions of three different character types in VR (i.e., human, animal, and anthropomorphized creature) based on their level of social realism. Results showed that character type impacted children's (a) social-emotional descriptions of the VR experience, (b) if VR's realism was an asset or a hindrance, and (c) primed thoughts about fantasy versus reality. However, children experienced the embodiment and personification of the characters similarly across all character types. Finally, children recalled the salient aspects of the characters they remembered and identified elements to improve the VR characters’ design.",1.5,0.9901759028434753,True,0.5,0.7450879514217377,True
It Takes (at least) Two: The Work to Make Romance Work,"Digitalization has motivated romance novelists to move from traditional to self-publishing online. However, engagement with flexible and responsive, yet precarious and biased algorithmic systems online pose challenges for novelists. Through surveying and interviewing the novelists, and using the lens of feminist political economy, we investigate how digitalization has impacted the novelists’ work practices. Our findings detail the increased agency afforded by self-publishing online, which comes at the expense of performing new forms of work individually, collectively, and with assistance, otherwise performed by publishing houses. We focus on the immaterial, invisible, and unpaid work that the novelists and the ecology of workers surrounding them conducted. We make recommendations for designing digital labor platforms that support the work practices of self-employed digital workers toward a more sustainable, collective, and inclusive future(s) of work.",0.8,0.7777439951896667,True,0.3318122278318339,0.5547781115107503,True
Method for Exploring Generative Adversarial Networks (GANs) via Automatically Generated Image Galleries,"Generative Adversarial Networks (GANs) can automatically generate quality images from learned model parameters. However, it remains challenging to explore and objectively assess the quality of all possible images generated using a GAN. Currently, model creators evaluate their GANs via tedious visual examination of generated images sampled from narrow prior probability distributions on model parameters. Here, we introduce an interactive method to explore and sample quality images from GANs. Our first two user studies showed that participants can use the tool to explore a GAN and select quality images. Our third user study showed that images sampled from a posterior probability distribution using a Markov Chain Monte Carlo (MCMC) method on parameters of images collected in our first study resulted in on average higher quality and more diverse images than existing baselines. Our work enables principled qualitative GAN exploration and evaluation.",0.8,0.8500073552131653,True,0.3318122278318339,0.5909097915224996,True
CakeVR: A Social Virtual Reality (VR) Tool for Co-designing Cakes,"Cake customization services allow clients to collaboratively personalize cakes with pastry chefs. However, remote (e.g., email) and in-person co-design sessions are prone to miscommunication, due to natural restrictions in visualizing cake size, decoration, and celebration context. This paper presents the design, implementation, and expert evaluation of a social VR application (CakeVR) that allows a client to remotely co-design cakes with a pastry chef, through real-time realistic 3D visualizations. Drawing on expert semi-structured interviews (4 clients, 5 pastry chefs), we distill and incorporate 8 design requirements into our CakeVR prototype. We evaluate CakeVR with 10 experts (6 clients, 4 pastry chefs) using cognitive walkthroughs, and find that it supports ideation and decision making through intuitive size manipulation, color/flavor selection, decoration design, and custom celebration theme fitting. Our findings provide recommendations for enabling co-design in social VR and highlight CakeVR’s potential to transform product design communication through remote interactive and immersive co-design.",0.8,0.8714601397514343,True,0.3318122278318339,0.6016361837916341,True
Visual StoryCoder: A Multimodal Programming Environment for Children’s Creation of Stories,"Computational thinking (CT) education reaches only a fraction of young children, in part because CT learning tools often require expensive hardware or fluent literacy. Block-based programming environments address these challenges through symbolic graphical interfaces, but users often need instructor support to advance. Alternatively, voice-based tools provide direct instruction on CT concepts but can present memory and navigation challenges to users. In this work, we present Visual StoryCoder, a multimodal tablet application that combines the strengths of each of these approaches to overcome their respective weaknesses. Visual StoryCoder introduces children ages 5–8 to CT through creative storytelling, offers direct instruction via a pedagogical voice agent, and eases use through a block-like graphical interface. In a between-subjects evaluation comparing Visual StoryCoder to a leading block-based programming app for this age group (N = 24), we show that Visual StoryCoder is more understandable to independent learners, leads to higher-quality code after app familiarization, and encourages personally meaningful projects.",1.0,0.7870087623596191,True,0.3775406687981454,0.5822747155788823,True
Will Deleting History Make Alexa More Trustworthy?: Effects of Privacy and Content Customization on User Experience of Smart Speakers,"""Always-on"" smart speakers have raised privacy and security concerns, to address which vendors have introduced customizable privacy settings. But, does the act of customizing one's privacy preferences have any effects on user experience and trust? To address this question, we developed an app for Amazon Alexa and conducted a user study (N = 90). Our data show that the affordance to customize privacy settings enhances trust and usability for regular users, while it has adverse effects on power users. In addition, only enabling privacy-setting customization without allowing content customization negatively affects trust among users with higher privacy concerns. When they can customize both content and privacy settings, user trust is highest. That is, while privacy customization may cause reactance among power users, allowing privacy-concerned individuals to simultaneously customize content can help to alleviate the resultant negative effect on trust. These findings have implications for designing more privacy-sensitive and trustworthy smart speakers.",2.1,0.714785635471344,True,0.6456563062257954,0.6802209708485697,True
Designing Future Social Wearables with Live Action Role Play (Larp) Designers,"Designing wearable technology that supports physical and social engagement in a collocated setting is challenging. In this research, we reached out to an expert community of crafters of social experiences: larpers (live action role players). Larpers and larp designers have a longstanding tradition of designing and making use of a variety of elements, such as costumes, physical objects, environments, and recently also digital artifacts. These are crafted in support of co-experience values that we argue can inform the design of social wearables. We engaged in a co-design process with a game designer and co-founder of a larp production company, and embedded the resulting social wearables in a larp. Here, we present the results of this design and implementation process, and articulate design affordances that resonate with our larp designer' values. This work may inspire and inform researchers and designers creating wearable technology that is aimed at supporting collocated engagement.",0.8,0.9530425667762756,True,0.3318122278318339,0.6424273973040547,True
The Challenge of (Non-)Disclosure: Exploring the Lived Experience of Ethiopian Adolescents with HIV and Their Attitudes Toward Technology,"Adolescents in sub-Saharan Africa are at the epicenter of the global HIV epidemic. Yet, technology to support HIV management overwhelmingly focuses on adult medication adherence, neglecting the complex lives of adolescents in low-income regions. We present findings from interviews and focus groups that included twelve HIV-positive adolescents in Ethiopia, and eleven adults from their care circles. We leverage the Integrated Behavioral Model to examine the lived experience of HIV and the space for technology. Additionally, we present an inductive thematic analysis, which highlights non-disclosure as a central theme, i.e., adolescents remaining unaware of their HIV status. Drawing from these findings, we discuss how to account for (the lack of) disclosure in the design of technology to support HIV management, and reflect on whether technology could (and should) support the process. We further highlight the risks that researchers and designers need to be aware of when designing HIV management technology for this audience.",0.8,0.8715943098068237,True,0.3318122278318339,0.6017032688193288,True
Deus EM Machina: On-Touch Contextual Functionality for Smart IoT Appliances,"Homes, offices and many other environments will be increasingly saturated with connected, computational appliances, forming the ""Internet of Things"" (IoT). At present, most of these devices rely on mechanical inputs, webpages, or smartphone apps for control. However, as IoT devices proliferate, these existing interaction methods will become increasingly cumbersome. Will future smart-home owners have to scroll though pages of apps to select and dim their lights? We propose an approach where users simply tap a smartphone to an appliance to discover and rapidly utilize contextual functionality. To achieve this, our prototype smartphone recognizes physical contact with uninstrumented appliances, and summons appliance-specific interfaces. Our user study suggests high accuracy 98.8% recognition accuracy among 17 appliances. Finally, to underscore the immediate feasibility and utility of our system, we built twelve example applications, including six fully functional end-to-end demonstrations.",1.0,0.8229676485061646,True,0.3775406687981454,0.600254158652155,True
Which one is me?: Identifying Oneself on Public Displays,"While user representations are extensively used on public displays, it remains unclear how well users can recognize their own representation among those of surrounding users. We study the most widely used representations: abstract objects, skeletons, silhouettes and mirrors. In a prestudy (N=12), we identify five strategies that users follow to recognize themselves on public displays. In a second study (N=19), we quantify the users' recognition time and accuracy with respect to each representation type. Our findings suggest that there is a significant effect of (1) the representation type, (2) the strategies performed by users, and (3) the combination of both on recognition time and accuracy. We discuss the suitability of each representation for different settings and provide specific recommendations as to how user representations should be applied in multi-user scenarios. These recommendations guide practitioners and researchers in selecting the representation that optimizes the most for the deployment's requirements, and for the user strategies that are feasible in that environment.",1.1,0.8339012861251831,True,0.401312339887548,0.6176068130063656,True
TurnAhead: Designing 3-DoF Rotational Haptic Cues to Improve First-person Viewing (FPV) Experiences,"First-Person View (FPV) drone is a recently developed category of drones designed for precision flying and for capturing exhilarating experiences that could not be captured before, such as navigating through tight indoor spaces and flying extremely close to subjects of interest. FPV viewing experiences, while exhilarating, typically have frequent rotations that can lead to visually induced discomfort. We present TurnAhead, which uses 3-DoF rotational haptic cues that correspond to camera rotations to improve the comfort, immersion, and enjoyment of FPV experiences. It uses headset-mounted air jets to provide ungrounded rotational forces and is the first device to support rotation around all 3 axes: yaw, pitch, and roll. We conducted a series of perception and formative studies to explore the design space of timing and intensity of haptic cues, followed by user experience evaluation, for a combined total of 44 participants (n=12, 8, 6, 18). Results showed that TurnAhead significantly improved overall comfort, immersion, and enjoyment, and was preferred by 89% of participants.",0.8,0.8591032028198242,True,0.3318122278318339,0.595457715325829,True
Can Mobile Augmented Reality Stimulate a Honeypot Effect?: Observations from Santa's Lil Helper,"In HCI, the honeypot effect describes a form of audience engagement in which a person's interaction with a technology stimulates passers-by to observe, approach and engage in an interaction themselves. In this paper we explore the potential for honeypot effects to arise in the use of mobile augmented reality (AR) applications in urban spaces. We present an observational study of Santa's Lil Helper, a mobile AR game that created a Christmas-themed treasure hunt in a metropolitan area. Our study supports a consideration of three factors that may impede the honeypot effect: the presence of people in relation to the game and its interactive components; the visibility of gameplay in urban space; and the extent to which the game permits a shared experience. We consider how these factors can inform the design of future AR experiences that are capable of stimulating honeypot effects in public space.",1.1,0.9447877407073975,True,0.401312339887548,0.6730500402974727,True
Envisioning Narrative Intelligence: A Creative Visual Storytelling Anthology,"In this paper, we collect an anthology of 100 visual stories from authors who participated in our systematic creative process of improvised story-building based on image sequences. Following close reading and thematic analysis of our anthology, we present five themes that characterize the variations found in this creative visual storytelling process: (1) Narrating What is in Vision vs. Envisioning; (2) Dynamically Characterizing Entities/Objects; (3) Sensing Experiential Information About the Scenery; (4) Modulating the Mood; (5) Encoding Narrative Biases. In understanding the varied ways that people derive stories from images, we offer considerations for collecting story-driven training data to inform automatic story generation. In correspondence with each theme, we envision narrative intelligence criteria for computational visual storytelling as: creative, reliable, expressive, grounded, and responsible. From these criteria, we discuss how to foreground creative expression, account for biases, and operate in the bounds of visual storyworlds.",1.0,0.8355948328971863,True,0.3775406687981454,0.6065677508476659,True
Chasing Play on TikTok from Populations with Disabilities to Inspire Playful and Inclusive Technology Design,"There is an open call for technology to be more playful [5, 79] and for tech design to be more inclusive of people with disabilities [80]. In the era of COVID19, it is often unsafe for the public in general and people with disabilities, in particular, to engage in in-person design exercises using traditional methods. This presents a missed opportunity as these populations are already sharing playful content rich with tacit design knowledge that can be used to inspire the design of playful everyday technology. We present our process of scraping play potentials [4] from TikTok from content creators with disabilities to generate design concepts that may inspire future technology design. We share 7 emerging themes from the scraped content, a catalog of design concepts that may inspire designers, and discuss the relevance of the emerging themes and possible implications for the design concepts.",1.0,0.9889276027679443,True,0.3775406687981454,0.6832341357830449,True
Social Influences on Executive Functioning in Autism: Design of a Mobile Gaming Platform,"Most studies of executive function (EF) in Autism Spectrum Disorder (ASD) focus on cognitive information processing, emphasizing less the social interaction deficits core to ASD. We designed a mobile game that uses social and nonsocial stimuli to assess children's EF skills. The game comprised three components involving different EF skills: cognitive flexibility (shifting/inference), inhibitory control, and short-term memory. By recruiting 65 children with and without ASD to play the mobile game, we investigated the potential of such platforms for capturing important phenotypic characteristics of individuals with autism. Results highlighted between-diagnostic-group differences in playing patterns with children with ASD showing broad patterns of EF deficits, but with relative strengths in nonsocial short-term memory, and preserved response to emotional inhibition cues. We showed the system could predict IQ, an important target for clinical treatment, towards the goal of developing platforms to act as long-term, efficient, and effective behavioral biomarkers for ASD.",1.0,0.870126485824585,True,0.3775406687981454,0.6238335773113652,True
The Show Must Go On:: A Conceptual Model of Conducting Synchronous Participatory Design With Children Online,"Co-designing with children in an online environment is increasingly important due to external factors, such as the COVID-19 pandemic, and the diversification and inclusion of youth participants. Many prior studies about co-design with youth focus on co-located or asynchronous online sessions. However, conducting synchronous online co-design sessions adds layers of complexity and uncertainty to collaboration. This paper introduces a model explicating factors to consider when co-designing with children synchronously in an online space. We examined ten consecutive intergenerational participatory design sessions online where children (ages 7-11) and adults designed new technologies. Along with highlighting unexpected moments and interactions, we use theories of improvisation to guide our understanding of dynamic situations that are out of the control of researchers. This work contributes to improving theoretical understanding of improvisation as a method of inquiry for co-designing with youth, and offers practical suggestions for suitable online co-design techniques and implementation.",0.8,0.9741291999816895,True,0.3318122278318339,0.6529707139067616,True
"The Critical Catalog: Library Information Systems, Tricksterism, and Social Justice","In this paper, we describe the Critical Catalog, a grant-funded research through design project intended to investigate metadata elements, values, and organizational structures necessary to intentionally advocate for diversity and expose library users to resources from populations traditionally marginalized in literature and publishing. Drawing on principles from critical design, the prototype functions as a critical intervention intended to raise questions and stimulate debate, rather than a purely technical fix to deeply social concerns. A detailed reflective discussion of the design process reveals how existing infrastructural constraints shaped design decisions that led to increased advocacy and a stronger activist standpoint. We discuss the use of metadata as design material for social justice, the application of tricksterism in HCI, and how both practical limitations from professional contexts and imposed limitations based on identities and positions of power can lead to surprising places, meanings, and questions.",1.0,0.9969136118888855,True,0.3775406687981454,0.6872271403435155,True
“Look! It’s a Computer Program! It’s an Algorithm! It’s AI!”: Does Terminology Affect Human Perceptions and Evaluations of Algorithmic Decision-Making Systems?,"In the media, in policy-making, but also in research articles, algorithmic decision-making (ADM) systems are referred to as algorithms, artificial intelligence, and computer programs, amongst other terms. We hypothesize that such terminological differences can affect people’s perceptions of properties of ADM systems, people’s evaluations of systems in application contexts, and the replicability of research as findings may be influenced by terminological differences. In two studies (N = 397, N = 622), we show that terminology does indeed affect laypeople’s perceptions of system properties (e.g., perceived complexity) and evaluations of systems (e.g., trust). Our findings highlight the need to be mindful when choosing terms to describe ADM systems, because terminology can have unintended consequences, and may impact the robustness and replicability of HCI research. Additionally, our findings indicate that terminology can be used strategically (e.g., in communication about ADM systems) to influence people’s perceptions and evaluations of these systems.",0.8,0.9840179681777954,True,0.3318122278318339,0.6579150980048146,True
ExtraSensory App: Data Collection In-the-Wild with Rich User Interface to Self-Report Behavior,"We introduce a mobile app for collecting in-the-wild data, including sensor measurements and self-reported labels describing people's behavioral context (e.g., driving, eating, in class, shower). Labeled data is necessary for developing context-recognition systems that serve health monitoring, aging care, and more. Acquiring labels without observers is challenging and previous solutions compromised ecological validity, range of behaviors, or amount of data. Our user interface combines past and near-future self-reporting of combinations of relevant context-labels. We deployed the app on the personal smartphones of 60 users and analyzed quantitative data collected in-the-wild and qualitative user-experience reports. The interface's flexibility was important to gain frequent, detailed labels, support diverse behavioral situations, and engage different users: most preferred reporting their past behavior through a daily journal, but some preferred reporting what they're about to do. We integrated insights from this work back into the app, which we make available to researchers for conducting in-the-wild studies.",1.0,0.8693105578422546,True,0.3775406687981454,0.6234256133202001,True
Why is This Happening to Me?: How Player Attribution can Broaden our Understanding of Player Experience,"Games user research (GUR) measures the performance and preference of digital game players, and interprets these measurements in the context of theories that explain human behavior. There are many validated approaches for measuring player experience that are grounded in psychological theories on motivation and emotion. Attribution theory explains how people assign causes to events and how these attributions affect peoples' emotional reactions and motivations. In this paper we argue that attribution theory can provide additional value to the existing suite of GUR tools; however, there are currently no validated tools to assess player attribution in the context of games. This paper describes the conceptualization of player attribution based on literature, presents the development and validation of a scale to assess player attribution in games, and discusses the implications of adding player attribution to the toolbox of methods for the design and evaluation of digital games.",1.1,0.7874776721000671,True,0.401312339887548,0.5943950059938076,True
Be Me or Be Mii?: A Study of Self-Presentation and Interaction in the Miitomo Mobile Application,"In this study, we consider what Nintendo's widely downloaded Miitomo mobile application, which simultaneously promotes non-idealized self-fictionalization and authentic self-presentation, can suggest to us about self-presentation and technology design. Ten groups of four friends each (N=40), all novice users, engaged with Miitomo for one week, and completed supplementary pre- and post-use surveys. The data were analyzed to assess the extent to which participants' engagement in Miitomo reflected their ""real life"" selves and correlated with in-app and ""real life"" features, respectively. Although most participants believed that their behaviors within the app accurately reflected their ""true selves,"" we found that in-app traits generally correlated more strongly with Miitomo engagement patterns than did users' ""real life"" traits and qualities. We discuss implications for social network and online community design, and propose future plans to study authenticity and self-distancing in online self-presentation.",1.1,0.8081071972846985,True,0.401312339887548,0.6047097685861232,True
The Story in the Notebook: Exploratory Data Science using a Literate Programming Tool,"Literate programming tools are used by millions of programmers today, and are intended to facilitate presenting data analyses in the form of a narrative. We interviewed 21 data scientists to study coding behaviors in a literate programming environment and how data scientists kept track of variants they explored. For participants who tried to keep a detailed history of their experimentation, both informal and formal versioning attempts led to problems, such as reduced notebook readability. During iteration, participants actively curated their notebooks into narratives, although primarily through cell structure rather than markdown explanations. Next, we surveyed 45 data scientists and asked them to envision how they might use their past history in an future version control system. Based on these results, we give design guidance for future literate programming tools, such as providing history search based on how programmers recall their explorations, through contextual details including images and parameters.",1.0,0.8786966800689697,True,0.3775406687981454,0.6281186744335576,True
Exploring Situated & Embodied Support for Youth’s Mental Health: Design Opportunities for Interactive Tangible Device,"The ability to manage emotions effectively is critical to healthy psychological and social development in youth. Prior work has focused on investigating the design of mental health technologies for this population, yet it is still unclear how to help them cope with emotionally difficult situations in-the-moment. In this paper, we aim to explore the appropriation, naturally emerging engagement patterns, and perceived psychological impact of an exemplar interactive tangible device intervention designed to provide in-situ support, when deployed with n=109 youth for 1.5 months. Our findings from semi-structured interviews and co-design workshops with a subset of participants (n=44 and n=25, respectively) suggest the potential of using technology-enabled objects to aid with down-regulation and self-compassion in moments of heightened emotion, to facilitate the practice of cognitive strategies, and to act as emotional companions. Lastly, we discuss design opportunities for integrating situated and embodied support in mental health interventions for youth.",0.8,0.8703022003173828,True,0.3318122278318339,0.6010572140746083,True
Introducing Gamettes: A Playful Approach for Capturing Decision-Making for Informing Behavioral Models,"Agent-based simulations are widely used for modeling human behavior in various contexts. However, such simulations may oversimplify human decision-making. We propose the use of Gamettes to extract rich data on human decision-making and help in improving the human behavioral aspects of models underlying agent-based simulations. We show how Gamettes are designed and provide empirical validation for using Gamettes in an experimental supply chain setting to study human decision-making. Our results show that Gamettes are successful in capturing the expected behaviors and patterns in supply chain decisions, and, thus, we find evidence for the capability of Gamettes to inform behavioral models.",1.0,0.9937360882759094,True,0.3775406687981454,0.6856383785370275,True
The Magic Machine Workshops: Making Personal Design Knowledge,"New technologies emerge into an increasingly complex everyday life. How can we engage users further into material practices that explore ideas and notions of these new things? This paper proposes a set of qualities for short, intense, workshop-like experiences, created to generate strong individual commitments, and expose underlying personal desires as drivers for ideas. By making use of open-ended making to engage participants in the imagination of new things, we aim to allow a broad range of knowledge to materialise, focused on the making of work that is about technology, rather than of technology.",1.0,0.9194632768630981,True,0.3775406687981454,0.6485019728306218,True
"Better, Funner, Stronger: A Gameful Approach to Nudge People into Making Less Predictable Graphical Password Choices","Graphical user authentication (GUA) is a common alternative to text-based user authentication, where people are required to draw graphical passwords on background images. Such schemes are theoretically considered remarkably secure because they offer a large password space. However, people tend to create their passwords on salient image areas introducing high password predictability. Aiming to help people use the password space more effectively, we propose a gameful password creation process. In this paper, we present GamePass, a gamified mechanism that integrates the GUA password creation process. We provide the first evidence that it is possible to nudge people towards better password choices by gamifying the process. GamePass randomly guides participants’ attention to areas other than the salient areas of authentication images, makes the password creation process more fun, and people are more engaged. Gamifying the password creation process enables users to interact better and make less predictable graphical password choices instead of being forced to use a strict password policy.",1.0,0.9984668493270874,True,0.3775406687981454,0.6880037590626165,True
"What Makes a Dark Pattern... Dark?: Design Attributes, Normative Considerations, and Measurement Methods","There is a rapidly growing literature on dark patterns, user interface designs—typically related to shopping or privacy—that researchers deem problematic. Recent work has been predominantly descriptive, documenting and categorizing objectionable user interfaces. These contributions have been invaluable in highlighting specific designs for researchers and policymakers. But the current literature lacks a conceptual foundation: What makes a user interface a dark pattern? Why are certain designs problematic for users or society? We review recent work on dark patterns and demonstrate that the literature does not reflect a singular concern or consistent definition, but rather, a set of thematically related considerations. Drawing from scholarship in psychology, economics, ethics, philosophy, and law, we articulate a set of normative perspectives for analyzing dark patterns and their effects on individuals and society. We then show how future research on dark patterns can go beyond subjective criticism of user interface designs and apply empirical methods grounded in normative perspectives.",1.1,0.8377355933189392,True,0.401312339887548,0.6195239666032436,True
I Don't Even Have to Bother Them!: Using Social Media to Automate the Authentication Ceremony in Secure Messaging,"The privacy guaranteed by secure messaging applications relies on users completing an authentication ceremony to verify they are using the proper encryption keys. We examine the feasibility of social authentication, which partially automates the ceremony using social media accounts. We implemented social authentication in Signal and conducted a within-subject user study with 42 participants to compare this with existing methods. To generalize our results, we conducted a Mechanical Turk survey involving 421 respondents. Our results show that users found social authentication to be convenient and fast. They particularly liked verifying keys asynchronously, and viewing social media profiles naturally coincided with how participants thought of verification. However, some participants reacted negatively to integrating social media with Signal, primarily because they distrust social media services. Overall, automating the authentication ceremony and distributing trust with additional service providers is promising, but this infrastructure needs to be more trusted than social media companies.",1.3,0.7670313119888306,True,0.45016600268752216,0.6085986573381763,True
Chibitronics in the Wild: Engaging New Communities in Creating Technology with Paper Electronics,"We share a study on the public adoption the Chibitronics circuit sticker toolkit, an open source, commercially available hardware toolkit for learning and creating electronics on paper. We examine sales data over a two-and-a-half-year period from November 2013, when the kit was launched commercially, to June 2016. We also look at publicly available project documentation from users during this period. We find that the Chibitronics user community confounds norms for traditional technology-making communities, especially in gender demographics. We explore the artifacts and types of documentation produced by users to learn about the various backgrounds, values, and goals of subcommunities, which includes educators, Makers, and crafters. In particular, we focus on artifacts from the craft community as a surprising and distinctive subset of technology creators. The diversity in public engagement shows how paper electronics tools like Chibitronics can be an effective approach for engaging new and broader audiences to participate in technology creation.",1.0,0.92156982421875,True,0.3775406687981454,0.6495552465084478,True
"Paths Explored, Paths Omitted, Paths Obscured: Decision Points & Selective Reporting in End-to-End Data Analysis","Drawing reliable inferences from data involves many, sometimes arbitrary, decisions across phases of data collection, wrangling, and modeling. As different choices can lead to diverging conclusions, understanding how researchers make analytic decisions is important for supporting robust and replicable analysis. In this study, we pore over nine published research studies and conduct semi-structured interviews with their authors. We observe that researchers often base their decisions on methodological or theoretical concerns, but subject to constraints arising from the data, expertise, or perceived interpretability. We confirm that researchers may experiment with choices in search of desirable results, but also identify other reasons why researchers explore alternatives yet omit findings. In concert with our interviews, we also contribute visualizations for communicating decision processes throughout an analysis. Based on our results, we identify design opportunities for strengthening end-to-end analysis, for instance via tracking and meta-analysis of multiple decision paths.",0.8,0.7943851947784424,True,0.3318122278318339,0.5630987113051381,True
What is Sensitive About (Sensitive) Data? Characterizing Sensitivity and Intimacy with Google Assistant Users,"Digital technologies have increasingly integrated into people’s lives, continuously capturing their behavior through potentially sensitive data. In the context of voice assistants, there is a misalignment between experts, regulators, and users on whether and what data is ‘sensitive’, partly due to how data is presented to users; as single interactions. We investigate users’ perspectives on the sensitivity and intimacy of their Google Assistant speech records, introduced comprehensively as single interactions, patterns, and inferences. We collect speech records through data donation and explore them in collaboration with 17 users during interviews based on predefined data-sharing scenarios. Our results indicate a tipping point in perceived sensitivity and intimacy as participants delve deeper into their data and the information derived from it. We propose a conceptualization of sensitivity and intimacy that accounts for the fuzzy nature of data and must disentangle from it. We discuss the implications of our findings and provide recommendations.",1.1,0.7784592509269714,True,0.401312339887548,0.5898857954072597,True
Creative Transactions: Special Digital Monies in ‘Break Kickstarter’ Crowdfunding Campaigns,"This paper conceptualizes ‘creative transactions’ – payment for creative work – as a rich site for the study, design and innovation of new financial technologies, and ‘special digital monies’. For most, creative labor remains highly precarious and underfunded and those working in the creative industries frequently rely on diverse forms of funding for their work. As a case study, we draw on a corpus of 87 ‘Break Kickstarter’ crowdfunding campaigns, where project creators were encouraged to break conventions and “rethink what a Kickstarter campaign can be”. By studying how these innovative projects broke fundraising conventions and experimented with the transactional attributes of a Kickstarter campaign, we show how they reconfigured the payment for creative work, and developed new relations between creators and their audiences. Drawing on these analyses, we derive new ideas and opportunities for the design of special digital monies to support novel creative transactions beyond crowdfunding campaigns.",1.0,0.983940064907074,True,0.3775406687981454,0.6807403668526097,True
StoryMakAR: Bringing Stories to Life With An Augmented Reality & Physical Prototyping Toolkit for Youth,"Makerspaces can support educational experiences in prototyping for children. Storytelling platforms enable high levels of creativity and expression, but have high barriers of entry. We introduce StoryMakAR, which combines making and storytelling. StoryMakAR is a new AR-IoT system for children that uses block programming, physical prototyping, and event-based storytelling to bring stories to life. We reduce the barriers to entry for youth (Age=14-18) by designing an accessible, plug-and-play system through merging both electro-mechanical devices and virtual characters to create stories. We describe our initial design process, the evolution and workflow of StoryMakAR, and results from multiple single-session workshops with 33 high school students. Our preliminary studies led us to understand what students want to make. We provide evidence of how students both engage and have difficulties with maker-based storytelling. We also discuss the potential for StoryMakAR to be used as a learning environment for classrooms and younger students.",1.8,0.9027451872825623,True,0.574442516811659,0.7385938520471107,True
Together in Bed?: Couples' Mobile Technology Use in Bed,"In this paper, we investigate the use of mobile technology in an underexplored context, the bed that couples share. Despite large amounts of research on the impact of pre-bedtime technology use on our sleep and mental state, scant research in the HCI field focuses on the physical bed as a negotiated site of technology use by couples. This paper explores (a) the meaning of the bed accessed by mobile technology and (b) the strategies of both individual and shared technology use in bed, in the context of couple's relationships. We investigate the effects of mobile technology to couples' bed-sharing practices through in-depth interviews (n = 12) and an online survey (n = 117). We report on creative and negotiated bodily practices of mobile technology use by couples in bed, and the perceived effects on couples' verbal and physical interaction and the intimacy of the bed.",1.1,0.764428436756134,True,0.401312339887548,0.582870388321841,True
Picturing It!: The Effect of Image Styles on User Perceptions of Personas,"Though photographs of real people are typically used to portray personas, there is little research into the potential advantages or disadvantages of using such images, relative to other image styles. We conducted an experiment with 149 participants, testing the effects of six different image styles on user perceptions and personality traits that are attributed to personas by the participants. Results show that perceptions of clarity, completeness, consistency, credibility, and empathy for a persona increase with picture realism. Personas with more realistic pictures are also perceived as more agreeable, open, and emotionally stable, with higher confidence in these assessments. We also find evidence of the uncanny valley effect, with realistic cartoon personas experiencing a decrease in the user perception scores.",1.3,0.7656585574150085,True,0.45016600268752216,0.6079122800512653,True
What's the Difference?: Evaluating Variations of Multi-Series Bar Charts for Visual Comparison Tasks,"An increasingly common approach to data analysis involves using information dashboards to visually compare changing data. However, layout constraints coupled with varying levels of visualization literacy among dashboard users make facilitating visual comparison in dashboards a challenging task. In this paper, we evaluate variants of bar charts, one of the most prevalent class of charts used in dashboards. We report an online experiment (N = 74) conducted to evaluate four alternative designs: 1) grouped bar chart, 2) grouped bar chart with difference overlays, 3) bar chart with difference overlays, and 4) difference bar chart. Results show that charts with difference overlays facilitate a wider range of comparison tasks while performing comparably to charts without them on individual tasks. Finally, we discuss the implications of our findings, with a focus on supporting visual comparison in dashboards.",1.1,0.7051881551742554,True,0.401312339887548,0.5532502475309017,True
ARMY’s Magic Shop: Understanding the Collaborative Construction of Playful Places in Online Communities,"Play is an essential part of the human experience and can be found throughout the lifespan. While play has long been of interest to the HCI community, research has often focused on the technologies supporting game play, the potential outcomes of play (e.g., skill-building, health improvements), or play among children. This paper explores what play looks like in online communities that are not specifically game-based and consist primarily of adults. From online ethnographic work of the ARMY (i.e., Adorable Representative M.C. for Youth), fandom of the South Korean musical group BTS, we explore how BTS and ARMY collaboratively construct a playful social environment using various social media platforms. A contribution of this work is to expand our conceptualization of how adults create playful places that are not specifically game-based and highlights the role of socio-technical systems in their community building.",2.0,0.9810755252838135,True,0.6224593312018546,0.801767428242834,True
The Geometry of Storytelling: Theatrical Use of Space for 360-degree Videos and Virtual Reality,"360-degree filming and head-mounted displays (HMDs) give recorded media a new sense of space. Theatre practitioners' expertise in manipulating spatial interactions has much to contribute to immersive recorded content. Four theatre directors led teams of three actors to stage the same scene for both immersive theatre and for 360-degree filming. Each team was recorded performing the scene at least six times, three in each condition, to extract actors' coordinates. This study establishes how to quantify theatre practitioners' use of spatial interactions and examines the spatial adaptations made when transferring these relationships to 360-degree filming. Staging for a 360-degree camera compared to staging for an audience member had shorter distances from the camera and between performers, along with fewer instances of the camera being in the middle of the action. Across all groups, interpersonal distance between characters and between the audience/camera dropped at the end of the scene when the characters come together as a team, suggesting that elements of Proxemics may be applicable to narrative performance.",1.0,0.7870157361030579,True,0.3775406687981454,0.5822782024506017,True
Bottom-Up Imaginaries: The Cultural-Technical Practice of Inventing Regional Advantage through IT R&D,"Recent HCI research on social creativity and bottom-up innovation has highlighted how concerted efforts by the government policy and business communities to develop innovation ecosystems are increasingly intertwined with IT research and development. We note that many such efforts focus on cultivating regional advantage [20] in the form of innovation hubs that are situated in and leverage distinct sociocultural histories and geographies. Cultivating regional advantage entails achieving broad consensus about what that region's advantage might be, that is, the construction of a regional advantage imaginary beyond the policies, IT supports, and practices to make it happen. Here, we document how an ongoing public debate among makers and manufacturers in Taiwan as a region-distinguished by direct engagement with design, fabrication, prototyping, and manufacturing processes-are proposing pathways toward a regional advantage that both reflects Taiwan's recent sociocultural and economic histories and also its near future aspirations.",0.8,0.7782021760940552,True,0.3318122278318339,0.5550072019629445,True
Visualization Accessibility in the Wild: Challenges Faced by Visualization Designers,"Data visualizations are now widely used across many disciplines. However, many of them are not easily accessible for visually impaired people. In this work, we use three-staged mixed methods to understand the current practice of accessible visualization design for visually impaired people. We analyzed 95 visualizations from various venues to inspect how they are made inaccessible. To understand the rationale and context behind the design choices, we also conducted surveys with 144 practitioners in the U.S. and follow-up interviews with ten selected survey participants. Our findings include the difficulties of handling modern complex and interactive visualizations and the lack of accessibility support from visualization tools in addition to personal and organizational factors making it challenging to perform accessible design practices.",1.0,0.8093393445014954,True,0.3775406687981454,0.5934400066498204,True
"Examining the Intersections of Race, Religion & Community Technologies: A Photovoice Study","Churches have historically played an important role in Black American communities, catalyzing the pursuit of aims such as social justice, community organization, and health promotion. However, researchers have rarely examined how technology can support an assets-based approach to these efforts, nor the implications of race, traditions, and history when creating such systems. Addressing this gap, we conducted research with two predominantly Black churches to explore health promotion design opportunities. We used photovoice, a research method where participants led their own data collection and analysis. Participants provided nuanced descriptions of the racial and ethnic identities of their communities, and how church history and aspirations for the future impacted these identities. Our findings characterize tensions between tradition and ‘modernization,’ implications for technology design, and the need for a temporal approach to understanding communities. We conclude with broader implications for studying the intersection of race and religion in community technology design.",0.8,0.8627238869667053,True,0.3318122278318339,0.5972680573992696,True
The Labor of Fun: Understanding the Social Relationships between Gamers and Paid Gaming Teammates in China,"Online video games support the development of social relationships through gameplay, however, gamers often cannot cultivate and maintain relationships based on social factors such as personality when using in-game matchmaking services. To address this, teammate matching sites external to games have emerged and enable gamers to offer to play games with others in exchange for payment. The affordances of these services are different from other existing gamer social sites, e.g., live streaming. Interviews were conducted with 16 dedicated users on Bixin, one of China’s largest paid teammate matching sites, to examine user motivations, practices, and perceptions. The interviews found that gamers selected paid teammates on Bixin using different criteria compared to in-game matchmaking services and emphasized the importance of real-life characteristics such as voice. To maintain connections, paid teammates often also extended communication to external communication services such as WeChat. Although most gamers expected to communicate with paid teammates as if they were friends, very few reported building real friendships with their matched counterparts.",1.0,0.984820544719696,True,0.3775406687981454,0.6811806067589208,True
(Re-)Framing Menopause Experiences for HCI and Design,"Informed by considerations from medicine and wellness research, experience design, investigations of new and emerging technologies, and sociopolitical critique, HCI researchers have demonstrated that women's health is a complex and rich topic. Turning these research outputs into productive interventions, however, is difficult. We argue that design is well positioned to address such a challenge thanks to its methodological traditions of problem setting and framing situated in synthetic (rather than analytic) knowledge production. In this paper, we focus on designing for experiences of menopause. Building on our prior empirical work on menopause and our commitment to pursue design informed by women's lived experience, we iteratively generated dozens of design frames and accompanying design crits. We document the unfolding of our design reasoning, showing how good-seeming insights nonetheless often lead to bad designs, while working progressively towards stronger insights and design constructs. The latter we offer as a contribution to researchers and practitioners who work at the intersections of women's health and design.",0.8,0.9566020369529724,True,0.3318122278318339,0.6442071323924031,True
Would you do it?: Enacting Moral Dilemmas in Virtual Reality for Understanding Ethical Decision-Making,"A moral dilemma is a decision-making paradox without unambiguously acceptable or preferable options. This paper investigates if and how the virtual enactment of two renowned moral dilemmas---the Trolley and the Mad Bomber---influence decision-making when compared with mentally visualizing such situations. We conducted two user studies with two gender-balanced samples of 60 participants in total that compared between paper-based and virtual-reality (VR) conditions, while simulating 5 distinct scenarios for the Trolley dilemma, and 4 storyline scenarios for the Mad Bomber's dilemma. Our findings suggest that the VR enactment of moral dilemmas further fosters utilitarian decision-making, while it amplifies biases such as sparing juveniles and seeking retribution. Ultimately, we theorize that the VR enactment of renowned moral dilemmas can yield ecologically-valid data for training future Artificial Intelligence (AI) systems on ethical decision-making, and we elicit early design principles for the training of such systems.",1.1,0.7230371236801147,True,0.401312339887548,0.5621747317838314,True
Evaluating Pan and Zoom Timelines and Sliders,"Pan and zoom timelines and sliders help us navigate large time series data. However, designing efficient interactions can be difficult. We study pan and zoom methods via crowd-sourced experiments on mobile and computer devices, asking which designs and interactions provide faster target acquisition. We find that visual context should be limited for low-distance navigation, but added for far-distance navigation; that timelines should be oriented along the longer axis, especially on mobile; and that, as compared to default techniques, double click, hold, and rub zoom appear to scale worse with task difficulty, whereas brush and especially ortho zoom seem to scale better. Software and data used in this research are available as open source.",1.0,0.8563891649246216,True,0.3775406687981454,0.6169649168613835,True
Is This An Ad?: Automatically Disclosing Online Endorsements On YouTube With AdIntuition,"Undisclosed online endorsements on social media can be misleading to users who may not know when viewed content contains advertisements. Despite federal regulations requiring content creators to disclose online endorsements, studies suggest that less than 10% do so in practice. To overcome this issue, we need knowledge of how to best detect online endorsements, knowledge about how prevalent online endorsements are in the wild, and ways to design systems to automatically disclose advertising content to viewers. To that end, we designed, implemented, and evaluated a tool called AdIntuition which automatically discloses when YouTube videos contain affiliate marketing, a type of social media endorsement. We evaluated AdIntuition with 783 users using a survey, field deployment, and diary study. We discuss our findings and recommendations for future measurements of and tools to detect and alert users about affiliate marketing content.",1.1,0.8622708916664124,True,0.401312339887548,0.6317916157769802,True
"Who Provides Phishing Training?: Facts, Stories, and People Like Me","Humans represent one of the most persistent vulnerabilities in many computing systems. Since human users are independent agents who make their own choices, closing these vulnerabilities means persuading users to make different choices. Focusing on one specific human choice -- clicking on a link in a phishing email -- we conducted an experiment to identify better ways to train users to make more secure decisions. We compared traditional facts-and-advice training against training that uses a simple story to convey the same lessons. We found a surprising interaction effect: facts-and-advice training works better than not training users, but only when presented by a security expert. Stories don't work quite as well as facts-and-advice, but work much better when told by a peer. This suggests that the perceived origin of training materials can have a surprisingly large effect on security outcomes.",1.1,0.8263159394264221,True,0.401312339887548,0.6138141396569851,True
Fast & Furious: Detecting Stress with a Car Steering Wheel,"Stress affects the lives of millions of people every day. In-situ sensing could enable just-in-time stress management interventions. We present the first work to detect stress using the movements of a car's existing steering wheel. We extend prior work on PC peripherals and demonstrate that stress, expressed through muscle tension in the limbs, can be measured through the way we drive a car. We collected data in a driving simulator under controlled circumstances to vary the levels of induced stress, within subjects. We analyze angular displacement data to estimate coefficients related to muscle tension using an inverse filtering technique. We prove that the damped frequency of a mass spring damper model representing the arm is significantly higher during stress. Stress can be detected with only a few turns during driving. We validate these measures against a known stressor and calibrate our sensor against known stress measurements.",0.8,0.9485036134719849,True,0.3318122278318339,0.6401579206519094,True
"Printflatables: Printing Human-Scale, Functional and Dynamic Inflatable Objects","Printflatables is a design and fabrication system for human-scale, functional and dynamic inflatable objects. We use inextensible thermoplastic fabric as the raw material with the key principle of introducing folds and thermal sealing. Upon inflation, the sealed object takes the expected three dimensional shape. The workflow begins with the user specifying an intended 3D model which is decomposed to two dimensional fabrication geometry. This forms the input for a numerically controlled thermal contact iron that seals layers of thermoplastic fabric. In this paper, we discuss the system design in detail, the pneumatic primitives that this technique enables and merits of being able to make large, functional and dynamic pneumatic artifacts. We demonstrate the design output through multiple objects which could motivate fabrication of inflatable media and pressure-based interfaces.",1.0,0.8034211993217468,True,0.3775406687981454,0.5904809340599462,True
Squeeze the Ball: Designing an Interactive Playground towards Aiding Social Activities of Children with Low-Function Autism,"Most intervention methods used for social skills training in children with autism are dedicated to high-functioning autism (HFA). However, extensive neurological and developmental disorders of low-functioning autism (LFA) have hampered their adoption. In this study, we observed and interviewed children with LFA, and their teachers, from a local educational institution, to better understand the children's social needs and barriers. Then, with the aim of aiding the children with their social activities, we illustrate the design process of SqueeBall, an interactive playground equipment. We evaluated the design with 18 children (16 with LFA and 2 with HFA) between 2.5 and 7 years of age. Results showed that these children had a pleasant game experience when the group bonded, and the equipment had a positive effect on aiding them in various ways. Finally, we discuss the challenges and opportunities of multimedia interaction techniques in aiding children with LFA.",1.0,0.9885557889938354,True,0.3775406687981454,0.6830482288959905,True
Around the (Virtual) World: Infinite Walking in Virtual Reality Using Electrical Muscle Stimulation,"Virtual worlds are infinite environments in which the user can move around freely. When shifting from controller-based movement to regular walking as an input, the limitation of the real world also limits the virtual world. Tackling this challenge, we propose the use of electrical muscle stimulation to limit the necessary real-world space to create an unlimited walking experience. We thereby actuate the users` legs in a way that they deviate from their straight route and thus, walk in circles in the real world while still walking straight in the virtual world. We report on a study comparing this approach to vision shift - the state of the art approach - as well as combining both approaches. The results show that particularly combining both approaches yield high potential to create an infinite walking experience.",0.8,0.7813157439231873,True,0.3318122278318339,0.5565639858775105,True
Who Are You Asking?: Qualitative Methods for Involving AAC Users as Primary Research Participants,"When trying to understand people's perspectives, qualitative researchers in HCI often use methods which assume participants can easily communicate verbally. There are few dedicated resources in HCI which provide an overview of qualitative methods to effectively gather the perspectives of people who cannot easily communicate verbally; specifically, people who use Augmentative and Alternative Communication (AAC). As a result, AAC users might be excluded from studies using methods such as interviews or focus groups, even if they fit the researcher's target population. To address this problem, I review literature from both HCI and therapeutic AAC research fields to discuss methods used with AAC users. In addition, I present relevant case examples from my own qualitative research and propose a framework to guide HCI researchers on choosing appropriate methods when involving AAC users as central research participants. I also identify design opportunities for HCI researchers to innovate on the tools and methods used for qualitative research with AAC users. This paper provides an easily accessible overview of qualitative methods HCI researchers can use with AAC users as participants.",1.1,0.7153034806251526,True,0.401312339887548,0.5583079102563503,True
Only one item left?: Heuristic Information Trumps Calorie Count When Supporting Healthy Snacking Under Low Self-Control,"Pursuing the goal of a healthy diet may be challenging, especially when self-control resources are low. Yet many persuasive user interfaces fostering healthy choices are designed for situations with ample self-control, e.g. showing nutritional information to support reflective decision making. In this paper we propose that under low self-control, persuasive user interfaces need to rely on simple heuristic decision making to be successful. We report an experiment that tested this assumption in a 2 (low vs. high self-control) x 2 (calorie vs. heuristic information) design. The results reveal a significant interaction effect. Participants with low self-control resources chose the healthy snack more often when snacks were labelled with heuristic information than when they were labelled with calorie information. Both strategies were about equally successful for participants with high self-control. Exploiting situations of low self-control with heuristic information is a new and promising approach to designing persuasive technology for healthy eating.",1.1,0.7906707525253296,True,0.401312339887548,0.5959915462064388,True
Algorithmic Power or Punishment: Information Worker Perspectives on Passive Sensing Enabled AI Phenotyping of Performance and Wellbeing,"We are witnessing an emergence in Passive Sensing enabled AI (PSAI) to provide dynamic insights for performance and wellbeing of information workers. Hybrid work paradigms have simultaneously created new opportunities for PSAI, but have also fostered anxieties of misuse and privacy intrusions within a power asymmetry. At this juncture, it is unclear if those who are sensed can find these systems acceptable. We conducted scenario-based interviews of 28 information workers to highlight their perspectives as data subjects in PSAI. We unpack their expectations using the Contextual Integrity framework of privacy and information gathering. Participants described appropriateness of PSAI based on its impact on job consequences, work-life boundaries, and preservation of flexibility. They perceived that PSAI inferences could be shared with selected stakeholders if they could negotiate the algorithmic inferences. Our findings help envision worker-centric approaches to implementing PSAI as an empowering tool in the future of work.",1.0,0.7350796461105347,True,0.3775406687981454,0.5563101574543401,True
"Co-Imagining the Future of Playable Cities: A Bottom-Up, Multi-Stakeholder Speculative Inquiry into the Playful Potential of Urban Technology","Here we present a co-design exploration into the potential of technology to playfully re-signify urban spaces. We created a speculative catalog of urban tech and used it to facilitate multi-stakeholder discussions about the playful potential of smart cities. The learnings from our co-design engagements embody different people's ideas of how tech might and might not support rich forms of urban play, and contribute to ongoing efforts at exploring how to playfully reconfigure our cities. We present: (1) a list of inspirational play potentials of urban spaces—i.e. playful things already people do, and enjoy, in the public space; (2) a portfolio of speculative ideas that show how tech might help to realize that potential; and (3) a discussion of stakeholders’ responses to these ideas. Our work can provide designers with inspiration and actionable advice for cultivating forms of urban play that cater to people's socio-emotional needs.",1.0,0.9896369576454163,True,0.3775406687981454,0.6835888132217809,True
Pushing the (Visual) Narrative: The Effects of Prior Knowledge Elicitation in Provocative Topics,"Narrative visualization is a popular style of data-driven storytelling. Authors use this medium to engage viewers with complex and sometimes controversial issues. A challenge for authors is to not only deliver new information, but to also overcome people's biases and misconceptions. We study how people adjust their attitudes toward (or away from) a message experienced through a narrative visualization. In a mixed-methods analysis, we investigate whether eliciting participants' prior beliefs, and visualizing those beliefs alongside actual data, can increase narrative persuasiveness. We find that incorporating priors does not significantly affect attitudinal change. However, participants who externalized their beliefs expressed greater surprise at the data. Their comments also indicated a greater likelihood of acquiring new information, despite the minimal change in attitude. Our results also extend prior findings, showing that visualizations are more persuasive than equivalent textual data representations for exposing contentious issues. We discuss the implications and outline future research directions.",0.8,0.9797444343566895,True,0.3318122278318339,0.6557783310942616,True
Cinehacking Cape Town - Embracing Informality in Pursuit of High Quality Media,"Although many common tools of media making such as video cameras have become more accessible in recent years, many remain inaccessible. Cinematography, lighting and sound-recording equipment for example can be prohibitively expensive to obtain, complex to configure, and/or require specialist knowledge to operate effectively. These barriers can prevent non-professionals who want to produce high-quality media from being able to. Cinehack is an ongoing project to research ways to overcome these barriers. In this paper, we specifically report on Cinehack: Cape Town, a participatory media making project. By co-producing hip hop videos within a community for whom media making is often a ""means-to-an-end"", we were able gain insights into the kinds of support needed to enable high quality media making by non-professionals. Specifically, we highlight ways to meet users' needs by embracing informal codes of practice via experimental making and peer-support.",1.0,0.9533205032348633,True,0.3775406687981454,0.6654305860165044,True
"Nice Guys, Virgins, and Incels: Gender in Remixing and Sharing Memes at Hackathons","This paper investigates how the conceptions of gender in memes are central to socializing at hackathons. Drawing on a multi-sited ethnography of seven hackathons, I provide insight into how references to memes and informal technology culture shape interaction in local manifestations of this culture. The contribution of this paper is twofold. First, I show how vocabularies and artifacts of technology culture move between on and offline spaces. These findings have implications for HCI research that investigates questions of materiality in computer-mediated communication. Second, I show how even the mundane memes of technology culture can reveal the toxic masculinity and ideology of Incels. By tying these internet memes to a physical context, I unpack how humor can reveal and perpetuate the enduring masculine dominance of technology. I end with recommendations for increasing inclusivity at hackathons, based on how HCI is uniquely positioned to understand how Internet symbols and interactions manifest offline.",1.0,0.9468147158622742,True,0.3775406687981454,0.6621776923302098,True
Crowdfunding Platforms and the Design of Paying Publics,"Crowdfunding enables groups to self-fund the changes they want to make in the world. In other words, digital financial platforms are proving capable of supporting new relations between groups of people as well as offering new ways to organize money. Taking an HCI lens, we look at how some crowdfunding platform owners are approaching social innovation, not only at the level of supporting individual community initiatives, but at the broader level of using their platform to change societal behavior. Through four case studies, we show how crowdfunding has been chosen as a tool to redesign society by promoting environmental or social sustainability. We argue that the groups constituted through these interactions are not merely ""crowds"", but deliberate constellations built round a thing of interest (or ""paying publics""). Our interviews with managers and owners explore how interactions with and around platforms work to achieve these ends and we conclude with design considerations.",1.0,0.7465159296989441,True,0.3775406687981454,0.5620282992485448,True
"""It Should Be a Game for Fun, Not Exercise"": Tensions in Designing Health-Related Features for Pokémon GO","Leveraging existing popular games such as Pokémon GO to promote health can engage people in healthy activities without sacrificing gaming appeal. However, little is known about what potential tensions arise from incorporating new health-related features to already existing and popular games and how to resolve those tensions from players' perspectives. In this paper, we identify design tensions surrounding the appeals of Pokémon GO, perspectives on different health needs, and mobile health technologies. By conducting surveys and design workshops with 20 avid Pokémon GO players, we demonstrate four design tensions: (1) diverse goals and rewards vs. data accuracy, (2) strong bonds between players and characters vs. gaming obsession, (3) collaborative play vs. social anxiety, and (4) connection of in-real-life experiences with the game vs. different individual contexts. We provide design implications to resolve these tensions in Pokémon GO and discuss how to extend our findings to the broader context of health promotion in location-based games.",1.0,0.9042922854423523,True,0.3775406687981454,0.6409164771202489,True
Redlining Maps and Terrains of Sustainability:: Interdisciplinary Mapping of Racialized Redlining to Present-Day Sustainability Agendas in HCI,"We ask how historic redlining, a US government run, racially discriminatory practice of assessing and mapping property values for federally subsidized home loan eligibility in the 1930s, is tied to current issues of sustainability. We frame redlining as a historic data practice, tied to ongoing exposure to environmental harms and difficulty building generational wealth in African American communities in Indianapolis. To address this, we made maps to ground interdisciplinary discourse between the authors: two who research sustainable human computer interaction (SHCI) and one who researches sustainable food systems, including issues of food security. Our maps, which combine historical redlining maps and contemporary sustainability issues facing Indianapolis, helped us explore the ongoing impacts of redlining across our disciplines. We develop the term ‘sustainability’ for HCI across racial, socioeconomic, and environmental tensions and reflect on how SHCI's emerging posthuman emphasis on human/non-human relations are associated with human/human challenges like redlining.",0.8,0.869431734085083,True,0.3318122278318339,0.6006219809584584,True
Storytelling to Sensemaking: A Systematic Framework for Designing Auditory Description Display for Interactives,"Auditory description display is verbalized text typically used to describe live, recorded, or graphical displays to support access for people who are blind or visually impaired. Significant prior research has resulted in guidelines for auditory description for non-interactive or minimally interactive contexts. A lack of auditory description for complex interactive environments remains a tremendous barrier to access for people with visual impairments. In this work, we present a systematic design framework for designing auditory description within complex interactive environments. We illustrate how modular descriptions aligned with this framework can result in an interactive storytelling experience constructed through user interactions. This framework has been used in a set of published and widely used interactive science simulations, and in its generalized form could be applied to a variety of contexts.",1.0,0.7690249085426331,True,0.3775406687981454,0.5732827886703893,True
Heartbeats in the Wild: A Field Study Exploring ECG Biometrics in Everyday Life,"This paper reports on an in-depth study of electrocardiogram (ECG) biometrics in everyday life. We collected ECG data from 20 people over a week, using a non-medical chest tracker. We evaluated user identification accuracy in several scenarios and observed equal error rates of 9.15% to 21.91%, heavily depending on 1) the number of days used for training, and 2) the number of heartbeats used per identification decision. We conclude that ECG biometrics can work in the wild but are less robust than expected based on the literature, highlighting that previous lab studies obtained highly optimistic results with regard to real life deployments. We explain this with noise due to changing body postures and states as well as interrupted measures. We conclude with implications for future research and the design of ECG biometrics systems for real world deployments, including critical reflections on privacy.",1.0,0.7505466938018799,True,0.3775406687981454,0.5640436813000127,True
A Bermuda Triangle?: A Review of Method Application and Triangulation in User Experience Evaluation,"User experience (UX) evaluation is a growing field with diverse approaches. To understand the development since previous meta-review efforts, we conducted a state-of-the-art review of UX evaluation techniques with special attention to the triangulation between methods. We systematically selected and analyzed 100 papers from recent years and while we found an increase of relevant UX studies, we also saw a remaining overlap with pure usability evaluations. Positive trends include an increasing percentage of field rather than lab studies and a tendency to combine several methods in UX studies. Triangulation was applied in more than two thirds of the studies, and the most common method combination was questionnaires and interviews. Based on our analysis, we derive common patterns for triangulation in UX evaluation efforts. A critical discussion about existing approaches should help to obtain stronger results, especially when evaluating new technologies.",1.1,0.8994796276092529,True,0.401312339887548,0.6503959837484005,True
"WritLarge: Ink Unleashed by Unified Scope, Action, & Zoom","WritLarge is a freeform canvas for early-stage design on electronic whiteboards with pen+touch input. The system aims to support a higher-level flow of interaction by 'chunking' the traditionally disjoint steps of selection and action into unified selection-action phrases. This holistic goal led us to address two complementary aspects: SELECTION, for which we devise a new technique known as the Zoom-Catcher that integrates pinch-to-zoom and selection in a single gesture for fluidly selecting and acting on content; plus: ACTION, where we demonstrate how this addresses the combined issues of navigating, selecting, and manipulating content. In particular, the designer can transform select ink strokes in flexible and easily-reversible representations via semantic, structural, and temporal axes of movement that are defined as conceptual 'moves' relative to the specified content. This approach dovetails zooming with lightweight specification of scope as well as the evocation of context-appropriate commands, at-hand, in a location-independent manner. This establishes powerful new primitives that can help to scaffold higher-level tasks, thereby unleashing the expressive power of ink in a compelling manner.",1.0,0.9533633589744568,True,0.3775406687981454,0.6654520138863012,True
To Distort or Not to Distort: Distance Cartograms in the Wild,"Distance Cartograms (DC) distort geographical features so that the measured distance between a single location and any other location on a map indicates absolute travel time. Although studies show that users can efficiently assess travel time with DC, distortion applied in DC may confuse users, and its usefulness ""in the wild"" is unknown. To understand how real world users perceive DC's benefits and drawbacks, we devise techniques that improve DC's presentation (preserving topological relationships among map features while aiming at retaining shapes) and scalability (presenting accurate live travel time). We developed a DC-enabled system with these techniques, and deployed it to 20 participants for 4 weeks. During this period, participants spent, on average, more than 50% of their time with DC as opposed to a standard map. Participants felt DC to be intuitive and useful for assessing travel time. They indicated intent in adopting DC in their real-life scenarios.",1.0,0.8813490271568298,True,0.3775406687981454,0.6294448479774877,True
Who's In Control?: Interactions In Multi-User Smart Homes,"Adoption of commercial smart home devices is rapidly increasing, allowing in-situ research in people's homes. As these technologies are deployed in shared spaces, we seek to understand interactions among multiple people and devices in a smart home. We conducted a mixed-methods study with 18 participants (primarily people who drive smart device adoption in their homes) living in multi-user smart homes, combining semi-structured interviews and experience sampling. Our findings surface tensions and cooperation among users in several phases of smart device use: device selection and installation, ordinary use, when the smart home does not work as expected, and over longer term use. We observe an outsized role of the person who installs devices in terms of selecting, controlling, and fixing them; negotiations between parents and children; and minimally voiced privacy concerns among co-occupants, possibly due to participant sampling. We make design recommendations for supporting long-term smart homes and non-expert household members.",1.1,0.8284058570861816,True,0.401312339887548,0.6148590984868648,True
Does Being Verified Make You More Credible?: Account Verification's Effect on Tweet Credibility,"Many popular social networking and microblogging sites support verified accounts---user accounts that are deemed of public interest and whose owners have been authenticated by the site. Importantly, the content of messages contributed by verified account owners is not verified. Such messages may be factually correct, or not. This paper investigates whether users confuse authenticity with credibility by posing the question: Are users more likely to believe content from verified accounts than from non-verified accounts? We conduct two online studies, a year apart, with 748 and 2041 participants respectively, to assess how the presence or absence of verified account indicators influences users' perceptions of tweets. Surprisingly, across both studies, we find that---in the context of unfamiliar accounts---most users can effectively distinguish between authenticity and credibility. The presence or absence of an authenticity indicator has no significant effect on willingness to share a tweet or take action based on its contents.",1.1,0.7607178092002869,True,0.401312339887548,0.5810150745439174,True
To Asymmetry and Beyond!: Improving Social Connectedness by Increasing Designed Interdependence in Cooperative Play,"Social play can have numerous health benefits but research has shown that not all multiplayer games are effective at promoting social engagement. Asymmetric cooperative games have shown promise in this regard but the design and dynamics of this unique style of play is not yet well understood. To address this, we present the results of two player experience studies using our custom prototype game Beam Me 'Round, Scotty! 2: the first comparing symmetric cooperative play (e.g., where players have the same interface, goals, mechanics, etc.) to asymmetric cooperative play (e.g., where players have differing roles, abilities, interfaces, etc.) and the second comparing the effect of increasing degrees of interdependence between play partners. Our results not only indicate that asymmetric cooperative games may enhance players' perceptions of connectedness, social engagement, immersion, and comfort with a game's controls, but also demonstrate how to further improve these outcomes via deliberate mechanical design changes, such as changes in cooperative action timing and direction of dependence.",1.3,0.9663116931915283,True,0.45016600268752216,0.7082388479395252,True
Re-imagining the Power of Priming and Framing Effects in the Context of Political Crowdfunding Campaigns,"In recent years, political crowdfunding campaigns have emerged through which politicians raise money to fund their election campaigns. Divisive issues discussed in these campaigns may not only motivate donations but also could have a broader priming effect on people’s social opinions. In the U.S., more than one-third of the population with moderate opinions show a tendency to swing their opinion based on recent and more accessible events. In this paper, we ask: can such campaigns further prime people’s responses to partisan topics, even when we discuss those topics in a non-political context? To answer this question, we analyzed the influence of exposure to a political candidate’s crowdfunding campaign on responses to a subsequently seen, unrelated scientific topic that is not inherently political but is seen as partisan in the U.S. (climate change). We found that exposure to an attitude-inconsistent political candidate’s crowdfunding campaign (a campaign that is counter to someone’s existing political beliefs) can have a significant priming effect on subsequently seen politically charged topics. This effect may occur due to the activation of in-group identity by the candidate’s partisan campaign. Guided by these findings, we investigated elements that can mitigate this self-categorization effect. We found that carefully designed content following framing techniques such as schema framing and threat/safety framing can mitigate people’s sense of self-categorization toward non-political topics.",1.0,0.9202245473861694,True,0.3775406687981454,0.6488826080921575,True
StoryBlocks: A Tangible Programming Game To Create Accessible Audio Stories,"Block-based programming languages can support novice programmers through features such as simplified code syntax and user-friendly libraries. However, most block-based programming languages are highly visual, which makes them inaccessible to blind and visually impaired students. To address the inaccessibility of block-based languages, we introduce StoryBlocks, a tangible block-based game that enables blind programmers to learn basic programming concepts by creating audio stories. In this paper, we document the design of StoryBlocks and report on a series of design activities with groups of teachers, Braille experts, and students. Participants in our design sessions worked together to create accessible stories, and their feedback offers insights for the future development of accessible, tangible programming tools.",1.0,0.975479781627655,True,0.3775406687981454,0.6765102252129003,True
"How to Work in the Car of the Future?: A Neuroergonomical Study Assessing Concentration, Performance and Workload Based on Subjective, Behavioral and Neurophysiological Insights","Autonomous driving provides new opportunities for the use of time during a car ride. One such important scenario is working. We conducted a neuroergonomical study to compare three configurations of a car interior (based on lighting, visual stimulation, sound) regarding their potential to support productive work. We assessed participants? concentration, performance and workload with subjective, behavioral and EEG measures while they carried out two different concentration tasks during simulated autonomous driving. Our results show that a configuration with a large-area, bright light with high blue components, and reduced visual and auditory stimuli promote performance, quality, efficiency, increased concentration and lower cognitive workload. Increased visual and auditory stimulation paired with linear, darker light with very few blue components resulted in lower performance, reduced subjective concentration, and higher cognitive workload, but did not differ from a normal car configuration. Our multi-method approach thus reveals possible car interior configurations for an ideal workspace.",1.1,0.9083498120307922,True,0.401312339887548,0.6548310759591701,True
"Understanding the Role Fluidity of Stakeholders During Assistive Technology Research ""In the Wild""","Deploying novel technologies requires the coordinated efforts of the research team, research participants, and a variety of community members and project stakeholders. To ensure that the project is completed successfully, these disparate groups of people engage in articulation work, which is the meta-work that supports the use of collaborative systems. In this paper, we examine the articulation work surrounding the deployment of systems that have found limited long-term adoption: assistive technology. Specifically, we examine three research deployments of a collaborative game for children with autism. Analysis of the articulation work performed during these studies demonstrates how research deployments of technologies create conditions in which stakeholders must take on additional roles to make the deployment work. By understanding the articulation work surrounding deployment studies engendered in this role fluidity, we can improve both research design and the analysis of data emergent from these studies.",1.0,0.854860246181488,True,0.3775406687981454,0.6162004574898168,True
Shift+Tap or Tap+LongPress?: The Upper Bound of Typing Speed on InScript,"This paper presents the results of a within-subject longitudinal evaluation on Inscript keyboard, which is the national standard layout for Indian scripts. We studied the practical upper bound speed and accuracy as well as the effect of practice. Through longitudinal transcription task of 400 repeated attempts, we observed typing speeds for highly experienced users consistently peak close to 120 cpm i.e. 2.5 times that of fastest speeds reported in literature. Our analysis compared the lower bound times for Tap, Tap+LongPress and Shift+Tap, the three text input mechanisms in this keyboard. Among the two alternative methods, our findings established Tap+LongPress method to be faster than Shift+Tap method and almost equally accurate. Also, we derived a model which explains the influence of corrected errors and number of practice attempts on the typing speed.",1.1,0.9075909852981567,True,0.401312339887548,0.6544516625928524,True
What do Teens Make of Personal Informatics?: Young People's Responses to Self-Tracking Practices for Self-Determined Motives,"Personal informatics (PI) technologies allow users to collect data about aspects of their lifestyle like mood or step count. Though teens increasingly encounter and use such technologies, little is known about how they ascribe meaning to their own PI activities. We report a qualitative study of the PI experiences of eighteen teens (aged 14 – 17). Following a learning phase focused on interpreting PI data, participants chose a personal goal that interested them and a PI tool to track it for 4-8 weeks in everyday contexts. Participants proved to be competent, flexible users of PI tools, tracking a range of meaningful life factors, from ‘worries’ to ‘exercise’; they valued learning about ‘natural patterns’ in their lives and were motivated to manage their emotions and evaluate whether they were doing the right thing. Our findings contribute to understanding how young people can engage in appropriation and interpretation of PI data – suggesting opportunities for educational interventions and design.",1.1,0.7559257745742798,True,0.401312339887548,0.5786190572309139,True
"Where is Community Among Online Learners?: Identity, Efficacy and Personal Ties","Research questions about community among online learners are gaining importance as enrollments in online programs explode. However, what community means for this context has not been studied in a comprehensive way. We contribute a quantitative study of learners' feelings and behavior expectations about online community, adapting scales for sense of community (SOC) and developing an instrument to assess community collective efficacy (CCE). Our analysis of students' responses to these scales revealed two factors underlying SOC (shared identity and interpersonal friendship) and three factors underlying CCE (identity regulation, coordination and social support). We used these factors to discuss contrasting definitions of community (shared identity versus ego networks). Exploratory data analyses also revealed relationships to other student variables that begin to articulate roles and mechanisms for online students' felt community, and raise design implications about what we might do with and for the community structure.",1.1,0.7215973734855652,True,0.401312339887548,0.5614548566865566,True
You Want Me to Work with Who?: Stakeholder Perceptions of Automated Team Formation in Project-based Courses,"Instructors are increasingly using algorithmic tools for team formation, yet little is known about how these tools are applied or how students and instructors perceive their use. We studied a representative team formation tool (CATME) in eight project-based courses. An instructor uses the tool to form teams by surveying students' working styles, skills, and demographics; then configuring these criteria as input into an algorithm that assigns teams. We surveyed students (N=277) in the courses to gauge their perceptions of the strengths and weaknesses of the tool and ideas for improving it. We also interviewed instructors (N=13) different from those who taught the eight courses to learn about their criteria selections and perceptions of the tool. Students valued the rational basis for forming teams but desired a stronger voice in criteria selection and explanations as to why they were assigned to a particular team. Instructors appreciated the efficiency of team formation but wanted to view exemplars of criteria used in similar courses. This work contributes recommendations for deploying team formation tools in educational settings and for better satisfying the goals of all stakeholders.",1.1,0.8451501727104187,True,0.401312339887548,0.6232312562989833,True
Reappropriating Hackathons: The Production Work of the CHI4Good Day of Service,"The popularity of hackathons has increased as technology pervades more facets of our lives. Originally designed for programmers, hackathons are now being appropriated by new stakeholders across diverse sectors. Yet with this evolution in hackathons, we no longer adequately understand what is produced and, thereby, the value of these events. We conducted an interview study with 22 stakeholders - participants, representatives of nonprofit organizations, and organizers - of the CHI4Good Day of Service to understand what is produced through philanthropic hackathons. Whereas traditional hackathons are oriented around the production of code or prototypes, our analysis of interview data suggests that the production work of philanthropic hackathons also includes technical capacity and expertise, expanded social networks, an exposure to design process, affective experiences, and an opportunity for participants to shape their identities against a cross-sectoral, interdisciplinary backdrop. We conclude by reflecting on implications for the CHI community in carrying out philanthropic events styled after hackathons.",1.0,0.9456914663314819,True,0.3775406687981454,0.6616160675648137,True
Engaging with Nature Sounds & Citizen Science by Designing for Creative & Contextual Audio Encounters,"Wildlife calls are the best witnesses to the health of ecosystems, if only we know how to listen to them. Efforts to understand and inform restoration of healthy ecosystems with environmental audio recordings languish from insufficient tools to learn and identify sounds in recordings. To address this problem, we designed and playtested the Bristle Whistle Challenge prototype with ten players. We explored how to design delightful interactions with audio for gaining awareness of nature sounds and supporting wildlife conservation through citizen science. We found that rather than presenting audio alone, it was necessary to connect sounds to other senses and experiences in creative ways to impart meaning and enhance engagement. We offer recommendations to design creative and contextual interactions with media to build awareness of nature's wonders. We call for greater efforts in interaction design to engage people with nature, which is the key to turning around our environmental crisis.",0.8,0.8720826506614685,True,0.3318122278318339,0.6019474392466512,True
Mix&Match: Towards Omitting Modelling Through In-situ Remixing of Model Repository Artifacts in Mixed Reality,"The accessibility of tools to model artifacts is one of the core driving factors for the adoption of Personal Fabrication. Subsequently, model repositories like Thingiverse became important tools in (novice) makers' processes. They allow them to shorten or even omit the design process, offloading a majority of the effort to other parties. However, steps like measurement of surrounding constraints (e.g., clearance) which exist only inside the users' environment, can not be similarly outsourced. We propose Mix&Match a mixed-reality-based system which allows users to browse model repositories, preview the models in-situ, and adapt them to their environment in a simple and immediate fashion. Mix&Match aims to provide users with CSG operations which can be based on both virtual and real geometry. We present interaction patterns and scenarios for Mix&Match, arguing for the combination of mixed reality and model repositories. This enables almost modelling-free personal fabrication for both novices and expert makers.",0.8,0.8522760272026062,True,0.3318122278318339,0.59204412751722,True
Virtual Performance Augmentation in an Immersive Jump & Run Exergame,"Human performance augmentation through technology has been a recurring theme in science and culture, aiming to increase human capabilities and accessibility. We investigate a related concept: virtual performance augmentation (VPA), using VR to give users the illusion of greater capabilities than they actually have. We propose a method for VPA of running and jumping, based on in place movements, and studied its effects in a VR exergame. We found that in place running and jumping in VR can be used to create a somewhat natural experience and can elicit medium to high physical exertion in an immersive and intrinsically motivating manner. We also found that virtually augmenting running and jumping can increase intrinsic motivation, perceived competence and flow, and may also increase motivation for physical activity in general. We discuss implications of VPA for safety and accessibility, with initial evidence suggesting that VPA may help users with physical impairments enjoy the benefits of exergaming.",0.8,0.8935877680778503,True,0.3318122278318339,0.6126999979548421,True
Storywell: Designing for Family Fitness App Motivation by Using Social Rewards and Reflection,"Physical activity (PA) is critical for reducing the risk of obesity, a prevalent health concern that burdens low-socioeconomic status (SES) households. While self-tracking apps can increase PA, encouraging app engagement remains a challenge, thus limiting the app's efficacy. To understand how to better support caregiver's motivation to use family health apps, we designed and evaluated Storywell?a mobile app for promoting family PA. Guided by Self-Determination Theory, Storywell provides social rewards (e.g., storybooks with interactive reflective questions) aimed at supporting relatedness and motivation. Our 3-month qualitative study with 18 families revealed satisfying moments that can affect caregiver's motivation. We contribute new knowledge on designing satisfying moments that heighten the motivation to use health apps, especially for low-SES families who face many barriers to using such systems.",1.0,0.8882794976234436,True,0.3775406687981454,0.6329100832107946,True
As We May Ink?: Learning from Everyday Analog Pen Use to Improve Digital Ink Experiences,"This paper sheds light on gaps and discrepancies between the experiences afforded by analog pens and their digital counterparts. Despite the long history (and recent renaissance) of digital pens, the literature still lacks a comprehensive survey of what types of marks people make and what motivates them to use ink-both analog and digital in daily life. To capture the diversity of inking behaviors and tease out the unique affordances of pen-and ink, we conducted a diary study with 26 participants from diverse backgrounds. From analysis of 493 diary entries we identified 8 analog pen-and-ink activities, and 9 affordances of pens. We contextualized and contrasted these findings using a survey with 1,633 respondents and a follow-up diary study with 30 participants, observing digital pens. Our analysis reveals gaps and research opportunities based on pen affordances not yet fully explored in the literature.",1.1,0.7238836288452148,True,0.401312339887548,0.5625979843663814,True
Designing in the Network of Relations for Species Conservation: The Playful Tingtibi Community Birdhouse,"This paper investigates connecting people in remote communities through nature in order to foster stewardship and conservation of endangered species. Global citizen science technologies have found success in urban, developed countries, but they typically rely on large distributed populations to gather or analyze data and do not suit sparsely populated and remote contexts. We undertook a long-term field study to iteratively co-design a tangible and playful nature engagement prototype in a remote World Heritage Area community. The prototype design fosters learning through ambient sounds as well as exploration and discovery of species through nature soundscape recordings. We found that the prototypes amplified locals' interest, became embedded in community relations and gradually led to placemaking of new engagement 'spaces' and of newer forms. We contribute lessons learned on how design can foster nature engagement and stewardship of endangered species by heeding Suchman's call for design to ""enter networks of relations that make technology possible"". We contribute design implications and new design foci HCI/Citizen science engagement for species conservation.",1.0,0.9898487329483032,True,0.3775406687981454,0.6836947008732244,True
Has Instagram Fundamentally Altered the 'Family Snapshot'?,"This paper considers how parents use the social media platform Instagram to facilitate the capture, curation and sharing of 'family snapshots'. Our work draws upon established cross-disciplinary literature relating to film photography and the composition of family albums in order to establish whether social media has changed the way parents visually present their families. We conducted a qualitative visual analysis of a sample of 4,000 photographs collected from Instagram using hashtags relating to children and parenting. We show that the style and composition of snapshots featuring children remains fundamentally unchanged and continues to be dominated by rather bland and idealised images of the happy family and the cute child. In addition, we find that the frequent taking and sharing of photographs via Instagram has inevitably resulted in a more mundane visual catalogue of daily life. We note a tension in the desire to use social media as a means to evidence good parenting, while trying to effectively manage the social identity of the child and finally, we note the reluctance of parents to use their own snapshots to portray family tension or disharmony, but their willingness to use externally generated content for this purpose.",1.3,0.8365793228149414,True,0.45016600268752216,0.6433726627512317,True
Recipes for Programmable Money,"This paper presents a qualitative study of the recent integration of a UK-based, digital-first mobile banking app - Monzo - with the web automation service IFTTT (If This Then That). Through analysis of 113 unique IFTTT 'recipes' shared by Monzo users on public community forums, we illustrate the potentially diverse functions of these recipes, and how they are achieved through different kinds of automation. Beyond achieving more convenient and efficient financial management, we note many playful and expressive applications of conditionality and automation that far extend traditional functions of banking applications and infrastructure. We use these findings to map opportunities, challenges and areas of future research in the development of 'programmable money' and related financial technologies. Specifically, we present design implications for the extension of native digital banking applications; novel uses of banking data; the applicability of blockchains and smart contracts; and future forms of financial autonomy.",1.0,0.8335875868797302,True,0.3775406687981454,0.6055641278389379,True
Everybody's Hacking: Participation and the Mainstreaming of Hackathons,"Hackathons have become a popular tool for bringing people together to imagine new possibilities for technology. Despite originating in technology communities, hackathons have now been widely adopted by a broad range of organisations. This mainstreaming of hackathons means they encompass a very different range of attendees and activities than they once did, to the extent that some events billed as hackathons may involve no coding at all. Given this shift away from production of code, they might instead be seen as an increasingly popular participatory design activity, from which designers and researchers in HCI can learn. Through fieldwork at six hackathons that targeted non-technical communities, we identify the types of activities and contributions that emerge through these events and the barriers and tensions that might exist. In doing so, we contribute a greater understanding of hackathons as a growing phenomenon and as a potential tool for participatory research.",1.0,0.724406361579895,True,0.3775406687981454,0.5509735151890203,True
Cyborg Assemblages: How autistic adults construct sociotechnical networks to support cognitive function,"Autism has become a popular context for accessible technology researchers, yet a majority of HCI projects for autism and ADHD do not engage in participatory methods or otherwise involve disabled stakeholders in the project and research design. Prior inquiry has identified executive function as a common difficulty for which technologies may provide novel benefits. In this study, we explore how autistic adults currently use technologies, broadly defined, to augment executive function and support themselves in day-to-day tasks. We collect qualitative data from narratives elicited during informal asynchronous interviews to conduct a digital ethnomethodology. Following from principles of Design Justice, crip technoscience, and cyborg assemblage theory, we investigate how autistic adults articulate their own sociotechnical environments into technologically mediated assemblages of executive function and interpersonal webs of care. These patterns of sociotechnical formation inform future work in research and design for tools that can mediate executive function for all users.",1.0,0.8298724293708801,True,0.3775406687981454,0.6037065490845128,True
LaserFactory: A Laser Cutter-based Electromechanical Assembly and Fabrication Platform to Make Functional Devices & Robots,"LaserFactory is an integrated fabrication process that augments a commercially available fabrication machine to support the manufacture of fully functioning devices without human intervention. In addition to creating 2D and 3D mechanical structures, LaserFactory creates conductive circuit traces with arbitrary geometries, picks-and-places electronic and electromechanical components, and solders them in place. To enable this functionality, we make four contributions. First, we build a hardware add-on to the laser cutter head that can deposit silver circuit traces and assemble components. Second, we develop a new method to cure dispensed silver using a CO2 laser. Third, we build a motion-based signaling method that allows our system to be readily integrated with commercial laser cutters. Finally, we provide a design and visualization tool for making functional devices with LaserFactory. Having described the LaserFactory system, we demonstrate how it is used to fabricate devices such as a fully functioning quadcopter and a sensor-equipped wristband. Our evaluation shows that LaserFactory can assemble a variety of differently sized components (up to 65g), that these can be connected by narrow traces (down to 0.75mm) that become highly conductive after laser soldering (3.2Ω/m), and that our acceleration-based sensing scheme works reliably (to 99.5% accuracy).",1.8,0.6275386214256287,True,0.574442516811659,0.6009905691186439,True
Can You Hear My Heartbeat?: Hearing an Expressive Biosignal Elicits Empathy,"Interfaces designed to elicit empathy provide an opportunity for HCI with important pro-social outcomes. Recent research has demonstrated that perceiving expressive biosignals can facilitate emotional understanding and connection with others, but this work has been largely limited to visual approaches. We propose that hearing these signals will also elicit empathy, and test this hypothesis with sounding heartbeats. In a lab-based within-subjects study, participants (N = 27) completed an emotion recognition task in different heartbeat conditions. We found that hearing heartbeats changed participants’ emotional perspective and increased their reported ability to “feel what the other was feeling.” From these results, we argue that auditory heartbeats are well-suited as an empathic intervention, and might be particularly useful for certain groups and use-contexts because of its musical and non-visual nature. This work establishes a baseline for empathic auditory interfaces, and offers a method to evaluate the effects of future designs.",1.1,0.7953150272369385,True,0.401312339887548,0.5983136835622432,True
(Dis)Appearables: A Concept and Method for Actuated Tangible UIs to Appear and Disappear based on Stages,"(Dis)Appearables is an approach for actuated Tangible User Interfaces (TUIs) to appear and disappear. This technique is supported by Stages: physical platforms inspired by theatrical stages. Self-propelled TUI’s autonomously move between front and back stage allowing them to dynamically appear and disappear from users’ attention. This platform opens up a novel interaction design space for expressive displays with dynamic physical affordances. We demonstrate and explore this approach based on a proof-of-concept implementation using two-wheeled robots, and multiple stage design examples. We have implemented a stage design pipeline which allows users to plan and design stages that are composed with front and back stages, and transition portals such as trap doors or lifts. The pipeline includes control of the robots, which guides them on and off stage. With this proof-of-concept prototype, we demonstrated a range of applications including interactive mobility simulation, self re-configuring desktops, remote hockey, and storytelling/gaming. Inspired by theatrical stage designs, this is a new take on ‘controlling the existence of matter’ for user experience design.",0.8,0.8697922229766846,True,0.3318122278318339,0.6008022254042592,True
Crowdsourcing vs Laboratory-Style Social Acceptability Studies?: Examining the Social Acceptability of Spatial User Interactions for Head-Worn Displays,"The use of crowdsourcing platforms for data collection in HCI research is attractive in their ability to provide rapid access to large and diverse participant samples. As a result, several researchers have conducted studies investigating the similarities and differences between data collected through crowdsourcing and more traditional, laboratory-style data collection. We add to this body of research by examining the feasibility of conducting social acceptability studies via crowdsourcing. Social acceptability can be a key determinant for the early adoption of emerging technologies, and as such, we focus our investigation on social acceptability for Head-Worn Display (HWD) input modalities. Our results indicate that data collected via a crowdsourced experiment and a laboratory-style setting did not differ at a statistically significant level. These results provide initial support for crowdsourcing platforms as viable options for conducting social acceptability research.",1.1,0.7515125274658203,True,0.401312339887548,0.5764124336766842,True
"People May Punish, But Not Blame Robots","As robots may take a greater part in our moral decision-making processes, whether people hold them accountable for moral harm becomes critical to explore. Blame and punishment signify moral accountability, often involving emotions. We quantitatively looked into people’s willingness to blame or punish an emotional vs. non-emotional robot that admits to its wrongdoing. Studies 1 and 2 (online video interaction) showed that people may punish a robot due to its lack of perceived emotional capacity than its perceived agency. Study 3 (in the lab) demonstrated that people were neither willing to blame nor punish the robot. Punishing non-emotional robots seems more likely than blaming them, yet punishment towards robots is more likely to arise online than offline. We reflect on if and why victimized humans (and those who care for them) may seek out retributive justice against robot scapegoats when there are no humans to hold accountable for moral harm.",1.0,0.859962522983551,True,0.3775406687981454,0.6187515958908483,True
Prioritizing Flexibility and Intangibles: Medical Crowdfunding for Stigmatized Individuals,"HCI research on crowdfunding has primarily focused on creative or organizational endeavors. Yet a majority of crowdfunding campaigns are conducted by individuals in need, often for healthcare. To better understand and improve this common crowdfunding experience, especially for those that inhabit a vulnerable social status, we conducted 20 interviews with transmen crowdfunding for top-surgery. Design choices that optimize site flexibility (e.g. control of personal information; enable cross-site communication) and foreground intangibles, such as political values and emotional support, are priorities for individuals from a stigmatized community. Findings differed from previous crowdfunding research and contribute to limited research on transgender identities in HCI. Overall they provide unique insights into how design choices can facilitate marginalized identity management in highly public online spaces.",1.0,0.7551535964012146,True,0.3775406687981454,0.5663471325996801,True
Hackathons as Participatory Design: Iterating Feminist Utopias,"Breastfeeding is not only a public health issue, but also a matter of economic and social justice. This paper presents an iteration of a participatory design process to create spaces for re-imagining products, services, systems, and policies that support breastfeeding in the United States. Our work contributes to a growing literature around making hackathons more inclusive and accessible, designing participatory processes that center marginalized voices, and incorporating systems- and relationship-based approaches to problem solving. By presenting an honest assessment of the successes and shortcomings of the first iteration of a hackathon, we explain how we re-structured the second ""Make the Breast Pump Not Suck"" hackathon in service of equity and systems design. Key to our re-imagining of conventional innovation structures is a focus on experience design, where joy and play serve as key strategies to help people and institutions build relationships across lines of difference. We conclude with a discussion of design principles applicable not only to designers of events, but to social movement researchers and HCI scholars trying to address oppression through the design of technologies and socio-technical systems.",1.0,0.9247323870658875,True,0.3775406687981454,0.6511365279320165,True
How Busy Are You?: Predicting the Interruptibility Intensity of Mobile Users,"Smartphones frequently notify users about newly available messages or other notifications. It can be very disruptive when these notifications interrupt users while they are busy. Our work here is based on the observation that people usually exhibit different levels of busyness at different contexts. This means that classifying users' interruptibility as a binary status, interruptible or not interruptible, is not sufficient to accurately measure their availability towards smartphone interruptions. In this paper, we propose, implement and evaluate a two-stage hierarchical model to predict people's interruptibility intensity. Our work is the first to introduce personality traits into interruptibility prediction model, and we found that personality data improves the prediction significantly. Our model bootstraps the prediction with similar people's data, and provides a good initial prediction for users whose individual models have not been trained on their own data yet. Overall prediction accuracy of our model can reach 66.1%.",1.1,0.8961061835289001,True,0.401312339887548,0.6487092617082241,True
O&O: A DIY toolkit for designing and rapid prototyping olfactory interfaces,"Constructing olfactory interfaces on demand requires significant design proficiency and engineering effort. The absence of powerful and convenient tools that reduced innovation complexity posed obstacles for future research in the area. To address this problem, we proposed O&O, a modular olfactory interface DIY toolkit. The toolkit consists of: (1) a scent generation kit, a set of electronics and accessories that supported three common scent vaporization techniques; (2) a module construction kit, a set of primitive cardboard modules for assembling permutable functional structures; (3) a design manual, a step-by-step design thinking framework that directs the decision-making and prototyping process. We organized a formal workshop with 19 participants and four solo DIY trials to evaluate the capability of the toolkit, the overall user engagement, the creations in both sessions, and the iterative suggestions. Finally, design implications and future opportunities were discussed for further research.",0.8,0.768193781375885,True,0.3318122278318339,0.5500030046038594,True
Can Anybody Help Me?: Using Community Help Desk Call Records to Examine the Impact of Digital Divides During a Global Pandemic,"The COVID-19 global pandemic has ignited lightning-fast adoption of digital tools in our communities, organizations, and systems of governance. It also inspired an unprecedented level of providing access to digital devices to communities and individuals lacking prior access. The situation and circumstances provide a unique opportunity to understand digital divides through a new lens. In this work, we contribute a contemporaneous understanding of digital divides beyond access by qualitatively analyzing over 300 calls made to a volunteer-based community IT help desk. We highlight the intertwined network of challenges leading to ecosystem digital divides and contribute new insights into how the complex socio-technical systems of practice, and the tools to support them, must adapt to bridge digital divides more effectively.",1.1,0.7985790967941284,True,0.401312339887548,0.5999457183408382,True
“Hartal (Strike) Happens Here Everyday”: Understanding Impact of Disruption on Education in Kashmir,"Sustainable Development Goal 4 promotes inclusive and equitable quality education and lifelong learning opportunities for all. However, regions with ongoing socio-political conflict suffer disruption to education and learning. We situate our work in Kashmir, India, affected by socio-political conflict for more than three decades. We did multiple field visits and conducted 21 semi-structured interviews with parents, teachers, students, and members of a non-government organization that runs Community Learning Centers in Kashmir. Our findings present the barriers in education caused by disruption and the role of community learning centers in overcoming the barriers within these contextual constraints. Further, we discuss engaging researchers and policymakers to leverage human infrastructure, embedding uncertainty into the design, infrastructuring trust, and content usability to develop solutions to make education more accessible. Despite significant research in HCI and Education, research in this particular context is under-explored, and our work contributes to filling this gap.",0.8,0.8291500210762024,True,0.3318122278318339,0.5804811244540181,True
Share and Share Alike?: Social Information and Interaction Style in Coordination of Shared Use,"Interfaces are commonly designed from the perspective of individual users, even though most of the systems we use in everyday life are in fact shared. We argue that more attention is needed for system sharing, especially because interfaces are known to influence coordination of shared use. In this work, we aim to deepen the understanding of this relation. To do so, we design three interfaces for a shared lighting system that vary in the type of social information they allow people to share with others and in their overall interaction style. We systematically compare longitudinal and real-life use of the interfaces, evaluating (1) people's appraisal of three types of social information and (2) the influence of an interaction style on coordination of shared use. The results disclose relations between the interface and the amount of verbal communication, consideration, and accountability. With this work, we urge the need for interaction designers to consider shared use.",1.1,0.7394434809684753,True,0.401312339887548,0.5703779104280117,True
Simulator Sickness in Augmented Reality Training Using the Microsoft HoloLens,"Augmented Reality is on the rise with consumer-grade smart glasses becoming available in recent years. Those interested in deploying these head-mounted displays need to understand better the effect technology has on the end user. One key aspect potentially hindering the use is motion sickness, a known problem inherited from virtual reality, which so far remains under-explored. In this paper we address this problem by conducting an experiment with 142 subjects in three different industries: aviation, medical, and space. We evaluate whether the Microsoft HoloLens, an augmented reality head-mounted display, causes simulator sickness and how different symptom groups contribute to it (nausea, oculomotor and disorientation). Our findings suggest that the Microsoft HoloLens causes across all participants only negligible symptoms of simulator sickness. Most consumers who use it will face no symptoms while only few experience minimal discomfort in the training environments we tested it in.",1.0,0.7699396014213562,True,0.3775406687981454,0.5737401351097509,True
"Keeping a Low Profile?: Technology, Risk and Privacy among Undocumented Immigrants","Undocumented immigrants in the United States face risks of discrimination, surveillance, and deportation. We investigate their technology use, risk perceptions, and protective strategies relating to their vulnerability. Through semi-structured interviews with Latinx undocumented immigrants, we find that while participants act to address offline threats, this vigilance does not translate to their online activities. Their technology use is shaped by needs and benefits rather than risk perceptions. While our participants are concerned about identity theft and privacy generally, and some raise concerns about online harassment, their understanding of government surveillance risks is vague and met with resignation. We identify tensions among self-expression, group privacy, and self-censorship related to their immigration status, as well as strong trust in service providers. Our findings have implications for digital literacy education, privacy and security interfaces, and technology design in general. Even minor design decisions can substantially affect exposure risks and well-being for such vulnerable communities.",1.1,0.727057933807373,True,0.401312339887548,0.5641851368474605,True
Self Harmony: Rethinking Hackathons to Design and Critique Digital Technologies for Those Affected by Self-Harm,"In this paper we explore the opportunities, challenges and best practices around designing technologies for those affected by self-harm. Our work contributes to a growing HCI literature on mental health and wellbeing, as well as understandings of how to imbue appropriate value-sensitivity within the digital design process in these contexts. The first phase of our study was centred upon a hackathon during which teams of designers were asked to conceptualise and prototype digital products or services for those affected by self-harm. We discuss how value-sensitive actions and activities, including engagements with those with lived experiences of self-harm, were used to scaffold the conventional hackathon format in such a challenging context. Our approach was then extended through a series of critical engagements with clinicians and charity workers who provided appraisal of the prototypes and designs. Through analysis of these engagements we expose a number of design challenges for future HCI work that considers self-harm; moreover we offer insight into the role of stakeholder critiques in extending and rethinking hackathons as a design method in sensitive contexts.",1.0,0.8644181489944458,True,0.3775406687981454,0.6209794088962957,True
P2PSTORY: Dataset of Children as Storytellers and Listeners in Peer-to-Peer Interactions,"Understanding social-emotional behaviors in storytelling interactions plays a critical role in the development of interactive educational technologies for children. A challenge when designing for such interactions using technology like social robots, virtual agents, and tablets is understanding the social-emotional behaviors pertinent to storytelling-especially when emulating a natural peer-to-peer relation between the child and the technology. We present P2PSTORY, a dataset of young children (5-6 years old) engaging in natural peer-to-peer storytelling interactions with fellow classmates. The dataset consists of rich social behaviors of children without adult supervision, with each participant demonstrating being a storyteller and a listener. The dataset contains 58 video recorded sessions along with a diverse set of behavioral annotations as well as developmental and demographic profiles of each child participant. We describe the main characteristics of the dataset in addition to findings that reveal perceptual differences between adults and children when evaluating the attentiveness of listeners.",1.0,0.8687009811401367,True,0.3775406687981454,0.6231208249691411,True
What Are You Talking To?: Understanding Children's Perceptions of Conversational Agents,"Conversational agents (CAs) available in smart phones or smart speakers play an increasingly important role in young children's technological landscapes and life worlds. While a handful of studies have documented children's natural interactions with CAs, little is known about children's perceptions of CAs. To fill this gap, we examined three- to six-year-olds' perceptions of CAs' animate/artifact domain membership and properties, as well as their justifications for these perceptions. We found that children sometimes take a more nuanced position and spontaneously attribute both artifact and animate properties to CAs or view them as neither artifacts nor animate objects. This study extends current research on children's perceptions of intelligent artifacts by adding CAs as a new genre of study and provides some underlying knowledge that may guide the development of CAs to support young children's cognitive and social development.",1.1,0.7114726901054382,True,0.401312339887548,0.5563925149964931,True
A novel interaction for competence assessment using micro-behaviors:: Extending CACHET to graphs and charts,"Competence Assessment by Chunk Hierarchy Evaluation with Transcription-tasks (CACHET) was proposed by Cheng [14]. It analyses micro-behaviors captured during cycles of stimulus viewing and copying in order to probe chunk structures in memory. This study extends CACHET by applying it to the domain of graphs and charts. Since drawing strategies are diverse, a new interactive stimulus presentation method is introduced: Transcription with Incremental Presentation of the Stimulus (TIPS). TIPS aims to reduce strategy variations that mask the chunking signal by giving users manual element-by-element control over the display of the stimulus. The potential of TIPS, is shown by the analysis of six participants transcriptions of stimuli of different levels of familiarity and complexity that reveal clear signals of chunking. To understand how the chunk size and individual differences drive TIPS measurements, a CPM-GOMS model was constructed to formalize the cognitive process involved in stimulus comprehension and chunk creation.",0.8,0.8101170659065247,True,0.3318122278318339,0.5709646468691792,True
Always On(line)?: User Experience of Smartwatches and their Role within Multi-Device Ecologies,"Users have access to a growing ecosystem of devices (desktop, mobile and wearable) that can deliver notifications and help people to stay in contact. Smartwatches are gaining popularity, yet little is known about the user experience and their impact on our increasingly always online culture. We report on a qualitative study with existing users on their everyday use of smartwatches to understand both the added value and the challenges of being constantly connected at the wrist. Our findings show that users see a large benefit in receiving notifications on their wrist, especially in terms of helping manage expectations of availability. Moreover, we find that response rates after viewing a notification on a smartwatch change based on the other devices available: laptops prompt quicker replies than smartphones. Finally, there are still many costs associated with using smartwatches, thus we make a series of design recommendations to improve the user experience of smartwatches.",1.9,0.7969010472297668,True,0.598687660112452,0.6977943536711094,True
"Research Fiction: Storytelling, Plot and Design","What kind of stories and plots do researchers of Human Computer Interaction draw on when they make fictions? This paper applies the ""basic plots"" identified in the study of literature to scenarios, speculative design and design fiction. Traditional HCI scenarios employ the plot of ""Overcoming the Monster"" where the monster is some problem to be solved. Much of the commentary on critical, speculative or adversarial design also draws on this plot as it attempts to overcome monsters like public apathy or a lack of debate. Design Fiction more frequently takes the form of a ""Voyage and Return"" or a ""Quest"". The paper argues that a better understanding of plot and storytelling could contribute to more reflective research fiction.",1.0,0.9307677745819092,True,0.3775406687981454,0.6541542216900273,True
What are you thinking?: Using CBT and Storytelling to Improve Mental Health Among College Students,"Depression and anxiety among college students have been on the rise globally. Cognitive Behavioural Therapy has emerged as an empirically reinforced and effective treatment. However, factors like cost, lack of resources, misguided prioritization and stigmatization of mental health issues in the Global South limit students’ access to psychotherapy. While technology can bridge this gap, research shows current self-guided mHealth apps for CBT are not always evidence-based and have limited efficacy compared to therapist-guided alternatives. In this paper, we explore whether interactive storytelling and other gamification mechanisms can increase the efficacy of a self-guided mHealth app, while drawing from empirically supported CBT protocols. We designed an mHealth application with contextualised storylines to help students learn psychological concepts and better identify the negative patterns in their thoughts. We present the results of a 3-arm randomized controlled trial conducted to assess the effect of this application compared to active and inactive control conditions.",2.1,0.8386396765708923,True,0.6456563062257954,0.7421479913983439,True
"Being (In)Visible: Privacy, Transparency, and Disclosure in the Self-Management of Bipolar Disorder","Research in personal informatics (PI) calls for systems to sup- port social forms of tracking, raising questions about how privacy can and should support intentionally sharing sensitive health information. We focus on the case of personal data related to the self-tracking of bipolar disorder (BD) in order to explore the ways in which disclosure activities intersect with other privacy experiences. While research in HCI of- ten discusses privacy as a disclosure activity, this does not reflect the ways in which privacy can be passively experienced. In this paper we broaden conceptions of privacy by defining transparency experiences and contributing factors in contrast to disclosure activities and preferences. Next, we ground this theoretical move in empirical analysis of personal narratives shared by people managing BD. We discuss the resulting emer- gent model of transparency in terms of implications for the design of socially-enabled PI systems. CAUTION: This paper contains references to experiences of mental illness, including self-harm, depression, suicidal ideation, etc.",0.8,0.8124233484268188,True,0.3318122278318339,0.5721177881293263,True
"""Tricky to get your head around"": Information Work of People Managing Chronic Kidney Disease in the UK","People diagnosed with a chronic health condition have many information needs which healthcare providers, patient groups, and resource designers seek to support. However, as a disease progresses, knowing when, how, and for what purposes patients want to interact with and construct personal meaning from health-related information is still unclear. This paper presents findings regarding the information work of chronic kidney disease patients. We conducted semi-structured interviews with 13 patients and 6 clinicians, and observations at 9 patient group events. We used the stages of the information journey - recognizing need, seeking, interpreting, and using information - to frame our data analysis. We identified two distinct but often overlapping information work phases, 'Learning' and 'Living With' a chronic condition to show how patient information work activities shift over time. We also describe social and individual factors influencing information work, and discuss technology design opportunities including customized education and collaboration tools.",1.0,0.9619523882865906,True,0.3775406687981454,0.669746528542368,True
"""Can you believe [1:21]?!"": Content and Time-Based Reference Patterns in Video Comments","As videos become increasingly ubiquitous, so is video-based commenting. To contextualize comments, people often reference specific audio/visual content within video. However, the literature falls short of explaining the types of video content people refer to, how they establish references and identify referents, how video characteristics (e.g., genre) impact referencing behaviors, and how references impact social engagement. We present a taxonomy for classifying video references by referent type and temporal specificity. Using our taxonomy, we analyzed 2.5K references with quotations and timestamps collected from public YouTube comments. We found: 1) people reference intervals of video more frequently than time-points, 2) visual entities are referenced more often than sounds, and 3) comments with quotes are more likely to receive replies but not more ""likes"". We discuss the need for in-situ dereferencing user interfaces, illustrate design concepts for typed referencing features, and provide a dataset for future studies.",1.6,0.9807553887367249,True,0.52497918747894,0.7528672881078324,True
What.Hack: Engaging Anti-Phishing Training Through a Role-playing Phishing Simulation Game,"Phishing attacks are a major problem, as evidenced by the DNC hackings during the 2016 US presidential election, in which staff were tricked into sharing passwords by fake Google security emails, granting access to confidential information. Vulnerabilities such as these are due in part to insufficient and tiresome user training in cybersecurity. Ideally, we would have more engaging training methods that teach cybersecurity in an active and entertaining way. To address this need, we introduce the game What.Hack, which not only teaches phishing concepts but also simulates actual phishing attacks in a role-playing game to encourage the player to practice defending themselves. Our user study shows that our game design is more engaging and effective in improving performance than a standard form of training and a competing training game design (which does not simulate phishing attempts through role-playing).",1.0,0.8872820734977722,True,0.3775406687981454,0.6324113711479589,True
Slacktivists or Activists?: Identity Work in the Virtual Disability March,"Protests are important social forms of activism, but can be inaccessible to people with disabilities. Online activism, like the 2017 Disability March, has provided alternative venues for involvement in accessible protesting and social movements. In this study, we use identity theory as a lens to understand why and how disabled activists engaged in an online movement, and its impact on their self-concepts. We interviewed 18 disabled activists about their experiences with online protesting during the Disability March. Respondents' identities (as both disabled individuals and as activists) led them to organize or join the March, evolved alongside the group's actions, and were reprioritized or strained as a result of their involvement. Our findings describe the values and limitations of this activism to our respondents, highlight the tensions they perceived about their activist identities, and present opportunities to support further accessibility and identity changes by integrating technology into their activist experiences.",1.1,0.9471900463104248,True,0.401312339887548,0.6742511930989864,True
"Tips, Tricks, and Training: Supporting Anti-Phishing Awareness among Mid-Career Office Workers Based on Employees’ Current Practices","Preventing workplace phishing depends on the actions of every employee, regardless of cybersecurity expertise. Based on 24 semi-structured interviews with mid-career office workers (70.8% women, averaging 44 years old) at two U.S. universities, we found that less than 21% of our participants had any formal anti-phishing training. Much of what our participants know about phishing comes from informal sources that emphasize “tips” and ""tricks"" like those found in conversations with friends, news stories, newsletters, social media, and podcasts. These informal channels provide opportunities for IT professionals wishing to enhance employees’ anti-phishing awareness by better aligning the delivery of expert advice with employees’ current practices and desires. We provide four recommendations designed to embrace ""guerrilla learning"" by distributing anti-phishing educational resources across the workplace and workday in part to encourage the delivery of more accurate information in more informal and incidental ways, and greater dialogue between anti-phishing training instructors and learners.",1.0,0.7938677668571472,True,0.3775406687981454,0.5857042178276464,True
What Moves Players?: Visual Data Exploration of Twitter and Gameplay Data,"In recent years, microblogging platforms have not only become an important communication channel for the game industry to generate and uphold audience interest but also a rich resource for gauging player opinion. In this paper we use data gathered from Twitter to examine which topics matter to players and to identify influential members of a game's community. By triangulating in-game data with Twitter activity we explore how tweets can provide contextual information for understanding fluctuations in in-game activity. To facilitate analysis of the data we introduce a visual data exploration tool and use it to analyze tweets related to the game Destiny. In total, we collected over one million tweets from about 250,000 users over a 14-month period and gameplay data from roughly 3,500 players over a six-month period.",1.1,0.8150237798690796,True,0.401312339887548,0.6081680598783138,True
Will the Crowd Game the Algorithm?: Using Layperson Judgments to Combat Misinformation on Social Media by Downranking Distrusted Sources,"How can social media platforms fight the spread of misinformation? One possibility is to use newsfeed algorithms to downrank content from sources that users rate as untrustworthy. But will laypeople be handicapped by motivated reasoning or lack of expertise, and thus unable to identify misinformation sites? And will they ""game"" this crowdsourcing mechanism in order to promote content that aligns with their partisan agendas? We conducted a survey experiment in which =984 Americans indicated their trust in numerous news sites. To study the tendency of people to game the system, half of the participants were told their responses would inform social media ranking algorithms. Participants trusted mainstream sources much more than hyper-partisan or fake news sources, and their ratings were highly correlated with professional fact-checker judgments. Critically, informing participants that their responses would influence ranking algorithms did not diminish these results, despite the manipulation increasing the political polarization of trust ratings.",1.1,0.9756487011909485,True,0.401312339887548,0.6884805205392482,True
A Place to Play: The (Dis)Abled Embodied Experience for Autistic Children in Online Spaces,"Play is the work of children-but access to play is not equal from child to child. Having access to a place to play is a challenge for marginalized children, such as children with disabilities. For autistic children, playing with other children in the physical world may be uncomfortable or even painful. Yet, having practice in the social skills play provides is essential for childhood development. In this ethnographic work, I explore how one community uses the sense of place and the digital embodied experience in a virtual world specifically to give autistic children access to play with their peers. The contribution of this work is twofold. First, I demonstrate how various physical and virtual spaces work together to make play possible. Second, I demonstrate these spaces, though some of them are digital, are no more or less ""real"" than the physical spaces making up a schoolyard or playground.",0.8,0.9745686054229736,True,0.3318122278318339,0.6531904166274037,True
"“It’s Complicated”: Negotiating Accessibility and (Mis)Representation in Image Descriptions of Race, Gender, and Disability","Content creators are instructed to write textual descriptions of visual content to make it accessible; yet existing guidelines lack specifics on how to write about people’s appearance, particularly while remaining mindful of consequences of (mis)representation. In this paper, we report on interviews with screen reader users who were also Black, Indigenous, People of Color, Non-binary, and/or Transgender on their current image description practices and preferences, and experiences negotiating theirs and others’ appearances non-visually. We discuss these perspectives, and the ethics of humans and AI describing appearance characteristics that may convey the race, gender, and disabilities of those photographed. In turn, we share considerations for more carefully describing appearance, and contexts in which such information is perceived salient. Finally, we offer tensions and questions for accessibility research to equitably consider politics and ecosystems in which technologies will embed, such as potential risks of human and AI biases amplifying through image descriptions.",0.8,0.9067941904067993,True,0.3318122278318339,0.6193032091193166,True
Transforming Game Difficulty Curves using Function Composition,"Player engagement within a game is often influenced by its difficulty curve: the pace at which in-game challenges become harder. Thus, finding an optimal difficulty curve is important. In this paper, we present a flexible and formal approach to transforming game difficulty curves by leveraging function composition. This allows us to describe changes to difficulty curves, such as making them ""smoother"", in a more precise way. In an experiment with 400 players, we used function composition to modify the existing difficulty curve of the puzzle game Paradox to generate new curves. We found that transforming difficulty curves in this way impacted player engagement, including the number of levels completed and the estimated skill needed to complete those levels, as well as perceived competence. Further, we found some transformed curves dominated others with respect to engagement, indicating that different design goals can be traded-off by considering a subset of curves.",1.0,0.8686848282814026,True,0.3775406687981454,0.623112748539774,True
I Need Your Encouragement!: Requesting Supportive Comments on Social Media Reduces Test Anxiety,"Many students underperform on exams due to experiencing high test anxiety. We report on a study comparing a novel intervention of seeking support from one's social network to the more common approaches of expressive writing and studying task-relevant materials for simulated open-ended test questions. We measured in-the-moment (state) anxiety before and after each intervention, and correctness of the solutions. We also surveyed students to learn about their perceptions of the interventions. Our results showed that social support decreased the anxiety of high test-anxious students by 21% with the reduction in anxiety correlating with the number of messages received. Social support also allowed high test-anxious students to score at the level of low test-anxious students. Expressive writing showed a similar effect, but increased the anxiety of low test-anxious students by 61%. Studying task materials had no effect on anxiety and high test-anxious students performed worse than low test-anxious students. Despite benefiting from social support, we found that students were uncomfortable soliciting support from their online social network. Realizing the benefits of this approach may therefore require different formulations of social support in practice.",1.3,0.7515474557876587,True,0.45016600268752216,0.6008567292375904,True
FamilyStories: Asynchronous Audio Storytelling for Family Members Across Time Zones,"Family members who are separated across time zones can easily miss out on feeling connected. We designed and studied the usage of an asynchronous storytelling system, called FamilyStories, to explore the use of audio-based sharing. FamilyStories allows family members to share activities and experiences over distance in different time zones using three different devices that contain different contextual features. To evaluate the design, we conducted a five-week long field study with two family member pairs. Our results show the value of slow, flexible, and non-suggestive interfaces for asynchronous audio communication. We also found ephemerality helped in the sharing of 'instant' feelings, while large time zone differences could be 'synchronized' with time delayed messages. We raise these as design opportunities for asynchronous audio storytelling systems.",1.0,0.7248735427856445,True,0.3775406687981454,0.551207105791895,True
"Hey Alexa, Who Am I Talking to?: Analyzing Users’ Perception and Awareness Regarding Third-party Alexa Skills","The Amazon Alexa voice assistant provides convenience through automation and control of smart home appliances using voice commands. Amazon allows third-party applications known as skills to run on top of Alexa to further extend Alexa’s capability. However, as multiple skills can share the same invocation phrase and request access to sensitive user data, growing security and privacy concerns surround third-party skills. In this paper, we study the availability and effectiveness of existing security indicators or a lack thereof to help users properly comprehend the risk of interacting with different types of skills. We conduct an interactive user study (inviting active users of Amazon Alexa) where participants listen to and interact with real-world skills using the official Alexa app. We find that most participants fail to identify the skill developer correctly (i.e., they assume Amazon also develops the third-party skills) and cannot correctly determine which skills will be automatically activated through the voice interface. We also propose and evaluate a few voice-based skill type indicators, showcasing how users would benefit from such voice-based indicators.",1.1,0.8764193058013916,True,0.401312339887548,0.6388658228444698,True
Contextualizing Privacy Decisions for Better Prediction (and Protection),"Modern mobile operating systems implement an ask-on-first-use policy to regulate applications' access to private user data: the user is prompted to allow or deny access to a sensitive resource the first time an app attempts to use it. Prior research shows that this model may not adequately capture user privacy preferences because subsequent requests may occur under varying contexts. To address this shortcoming, we implemented a novel privacy management system in Android, in which we use contextual signals to build a classifier that predicts user privacy preferences under various scenarios. We performed a 37-person field study to evaluate this new permission model under normal device usage. From our exit interviews and collection of over 5 million data points from participants, we show that this new permission model reduces the error rate by 75% (i.e., fewer privacy violations), while preserving usability. We offer guidelines for how platforms can better support user privacy decision making.",0.8,0.7965078949928284,True,0.3318122278318339,0.5641600614123311,True
Is it Happy?: Behavioural and Narrative Frame Complexity Impact Perceptions of a Simple Furry Robot's Emotions,"Critical to social human-robot interaction is a robot's emotional richness, expressed within the parameters of its physical display. While emotion arousal is straightforward to convey, human valence (positivity) evaluations are famously ambiguous, whether we are assessing other humans or a robot. Imagine someone breathing raggedly: are they nervous, or excited? To assess the premise that irregular breathing connotes low valence (emotion negativity), we implemented different levels of breathing variability and complexity in simple furry robots. We asked 10 participants to watch and feel the behaviors, rate their valence, and explain their impressions. While a quantitative exploration of new and previous data showed correlation between multi-scale entropy and valence, the rich narratives revealed by thematic analysis of participant explanations call into question whether a single motion can, alone, be unambiguously valenced. Based on this evidence that people perceive robots as having inner lives, we recommend ways to build up narrative contexts over multiple interactions.",1.1,0.7535836696624756,True,0.401312339887548,0.5774480047750118,True
You’re Making Me Sick: A Systematic Review of How Virtual Reality Research Considers Gender & Cybersickness,"While multiple studies suggest that female-identified participants are more likely to experience cybersickness in virtual reality (VR), our systematic review of 71 eligible VR publications (59 studies and 12 surveys) pertaining to gender and cybersickness reveals a number of confounding factors in study design (e.g., a variety of technical specifications, tasks, content), a lack of demographic data, and a bias in participant recruitment. Our review shows an ongoing need within VR research to more consistently include and report on women’s experiences in VR to better understand the gendered possibility of cybersickness. Based on the gaps identified in our systematic review, we contribute study design recommendations for future work, arguing that gender considerations are necessary at every stage of VR study design, even when the study is not ‘about’ gender.",0.8,0.9075815081596375,True,0.3318122278318339,0.6196968679957356,True
"Is Two Enough?: ! Studying Benefits, Barriers, and Biases of Multi-Tablet Use for Collaborative Visualization","A sizable part of HCI research on cross-device interaction is driven by the vision of users conducting complex knowledge work seamlessly across multiple mobile devices. This is based on the Weiserian assumption that people will be inclined to distribute their work across multiple ``pads' if such are available. We observed that this is not the reality today, even when devices were in abundance. We present a study with 24 participants in 12 dyads completing a collaborative visualization task with up to six tablets. They could choose between three different visualization types to answer questions about economic data. Tasks were designed to afford simultaneous use of tablets, either with linked or independent views. We found that users typically utilized only one tablet per user. A quantitative and qualitative analysis revealed a ``legacy bias' that introduced barriers for using more tablets and reduced the overall benefit of multi-device visualization.",1.6,0.8565653562545776,True,0.52497918747894,0.6907722718667588,True
What Do We Mean by “Accessibility Research”?: A Literature Survey of Accessibility Papers in CHI and ASSETS from 1994 to 2019,"Accessibility research has grown substantially in the past few decades, yet there has been no literature review of the field. To understand current and historical trends, we created and analyzed a dataset of accessibility papers appearing at CHI and ASSETS since ASSETS’ founding in 1994. We qualitatively coded areas of focus and methodological decisions for the past 10 years (2010-2019, N=506 papers), and analyzed paper counts and keywords over the full 26 years (N=836 papers). Our findings highlight areas that have received disproportionate attention and those that are underserved—for example, over 43% of papers in the past 10 years are on accessibility for blind and low vision people. We also capture common study characteristics, such as the roles of disabled and nondisabled participants as well as sample sizes (e.g., a median of 13 for participant groups with disabilities and older adults). We close by critically reflecting on gaps in the literature and offering guidance for future work in the field.",1.1,0.7748656272888184,True,0.401312339887548,0.5880889835881832,True
Notable: On-the-fly Assistant for Data Storytelling in Computational Notebooks,"Computational notebooks are widely used for data analysis. Their interleaved displays of code and execution results (e.g., visualizations) are welcomed since they enable iterative analysis and preserve the exploration process. However, the communication of data findings remains challenging in computational notebooks. Users have to carefully identify useful findings from useless ones, document them with texts and visual embellishments, and then organize them in different tools. Such workflow greatly increases their workload, according to our interviews with practitioners. To address the challenge, we designed Notable to offer on-the-fly assistance for data storytelling in computational notebooks. It provides intelligent support to minimize the work of documenting and organizing data findings and diminishes the cost of switching between data exploration and storytelling. To evaluate Notable, we conducted a user study with 12 data workers. The feedback from user study participants verifies its effectiveness and usability.",1.0,0.8942816853523254,True,0.3775406687981454,0.6359111770752355,True
Revisiting Gendered Web Forms: An Evaluation of Gender Inputs with (Non-)Binary People,"Gender input forms act as gates to accessing information, websites, and services online. Non-binary people regularly have to interact with them, though many do not offer non-binary gender options. This results in non-binary individuals having to either choose an incorrect gender category or refrain from using a site or service—which is occasionally infeasible (e.g., when accessing health services). We tested five different forms through a survey with binary and non-binary participants (n = 350) in three contexts—a digital health form, a social media website, and a dating app. Our results indicate that the majority of participants found binary “male or female” forms exclusive and uncomfortable to fill out across all contexts. We conclude with design considerations for improving gender input forms and consequently their underlying gender model in databases. Our work aims to sensitize designers of (online) gender web forms to the needs and desires of non-binary people.",0.8,0.808551549911499,True,0.3318122278318339,0.5701818888716664,True
StoryChat: Designing a Narrative-Based Viewer Participation Tool for Live Streaming Chatrooms,"Live streaming platforms and existing viewer participation tools enable users to interact and engage with an online community, but the anonymity and scale of chat usually result in the spread of negative comments. However, only a few existing moderation tools investigate the influence of proactive moderation on viewers’ engagement and prosocial behavior. To address this, we developed StoryChat, a narrative-based viewer participation tool that utilizes a dynamic graphical plot to reflect chatroom negativity. We crafted the narrative through a viewer-centered (N=65) iterative design process and evaluated the tool with 48 experienced viewers in a deployment study. We discovered that StoryChat encouraged viewers to contribute prosocial comments, increased viewer engagement, and fostered viewers’ sense of community. Viewers reported a closer connection between streamers and other viewers because of the narrative design, suggesting that narrative-based viewer engagement tools have the potential to encourage community engagement and prosocial behaviors.",1.0,0.8045249581336975,True,0.3775406687981454,0.5910328134659215,True
Cognitive Load Estimation in the Wild,"Cognitive load has been shown, over hundreds of validated studies, to be an important variable for understanding human performance. However, establishing practical, non-contact approaches for automated estimation of cognitive load under real-world conditions is far from a solved problem. Toward the goal of designing such a system, we propose two novel vision-based methods for cognitive load estimation, and evaluate them on a large-scale dataset collected under real-world driving conditions. Cognitive load is defined by which of 3 levels of a validated reference task the observed subject was performing. On this 3-class problem, our best proposed method of using 3D convolutional neural networks achieves 86.1% accuracy at predicting task-induced cognitive load in a sample of 92 subjects from video alone. This work uses the driving context as a training and evaluation dataset, but the trained network is not constrained to the driving environment as it requires no calibration and makes no assumptions about the subject's visual appearance, activity, head pose, scale, and perspective.",1.0,0.769957959651947,True,0.3775406687981454,0.5737493142250463,True
Does It Feel Real?: Using Tangibles with Different Fidelities to Build and Explore Scenes in Virtual Reality,"Professionals in domains like film, theater, or architecture often rely on physical models to visualize spaces. With virtual reality (VR) new tools are available providing immersive experiences with correct perceptions of depth and scale. However, these lack the tangibility of physical models. Using tangible objects in VR can close this gap but creates the challenges of producing suitable objects and interacting with them with only the virtual objects visible. This work addresses these challenges by evaluating tangibles with three haptic fidelities: equal disc-shaped tangibles for all virtual objects, Lego-built tangibles, and 3D-printed tangibles resembling the virtual shapes. We present results from a comparative study on immersion, performance, and intuitive interaction and interviews with domain experts. The results show that 3D-printed objects perform best, but Lego offers a good trade-off between fast creation of tangibles and sufficient fidelity. The experts rate our approach as useful and would use all three versions.",1.1,0.7065515518188477,True,0.401312339887548,0.5539319458531978,True
"Trade-offs for Substituting a Human with an Agent in a Pair Programming Context: The Good, the Bad, and the Ugly","Pair programming has a documented history of benefits, such as increased code quality, productivity, self-efficacy, knowledge transfer, and reduced gender gap. Research uncovered problems with pair programming related to scheduling, collocating, role imbalance, and power dynamics. We investigated the trade-offs of substituting a human with an agent to simultaneously provide benefits and alleviate obstacles in pair programming. We conducted gender-balanced studies with human-human pairs in a remote lab with 18 programmers and Wizard-of-Oz studies with 14 programmers, then analyzed results quantitatively and qualitatively. Our comparative analysis of the two studies showed no significant differences in productivity, code quality, and self-efficacy. Further, agents facilitated knowledge transfer; however, unlike humans, agents were unable to provide logical explanations or discussions. Human partners trusted and showed humility towards agents. Our results demonstrate that agents can act as effective pair programming partners and open the way towards new research on conversational agents for programming.",1.8,0.7849710583686829,True,0.574442516811659,0.679706787590171,True
"The Annoying, the Disturbing, and the Weird: Challenges with Phone Numbers as Identifiers and Phone Number Recycling","Phone numbers are intimately connected to our digital lives. People are increasingly required to disclose their phone number in digital spaces, both commercial and personal. While convenient for companies, the pervasive use of phone numbers as user identifiers also poses privacy, security, and access risks for individuals. In order to understand these risks, we present findings from a qualitative online elicitation study with 195 participants about their negative experiences with phone numbers, the consequences they faced, and how those consequences impacted their behavior. Our participants frequently reported experiencing phone number recycling, unwanted exposure, and temporary loss of access to a phone number. Resulting consequences they faced included harassment, account access problems, and privacy invasions. Based on our findings, we discuss service providers’ faulty assumptions in the use of phone numbers as user identifiers, problems arising from phone number recycling, and provide design and public policy recommendations for mitigating these issues with phone numbers.",1.0,0.7338769435882568,True,0.3775406687981454,0.5557088061932012,True
EdiPulse: Investigating a Playful Approach to Self-monitoring through 3D Printed Chocolate Treats,"Self-monitoring offers benefits in facilitating awareness about physical exercise, but such data-centric activity may not always lead to an enjoyable experience. We introduce EdiPulse a novel system that creates activity treats to offer playful reflections on everyday physical activity through the appealing medium of chocolate. EdiPulse translates self-monitored data from physical activity into small 3D printed chocolate treats. These treats (< 20 grams of chocolate in total) embody four forms: Graph, Flower, Slogan and Emoji. We deployed our system across 7 households and studied its use with 13 participants for 2 weeks per household. The field study revealed positive aspects of our approach along with some open challenges, which we disseminate across five themes: Reflection, Positivity, Determination, Affection, and Co-experience. We conclude by highlighting key implications of our work for future playful food-based technology design in supporting the experience of being physically active",1.0,0.9899805784225464,True,0.3775406687981454,0.683760623610346,True
I (Don't) See What You Typed There! Shoulder-surfing Resistant Password Entry on Gamepads,"Using gamepad-driven devices like games consoles is an activity frequently shared with others. Thus, shoulder-surfing is a serious threat. To address this threat, we present the first investigation of shoulder-surfing resistant text password entry on gamepads by (1) identifying the requirements of this context; (2) assessing whether shoulder-surfing resistant authentication schemes proposed in non-gamepad contexts can be viably adapted to meet these requirements; (3) proposing ""Colorwheels"", a novel shoulder-surfing resistant authentication scheme specifically geared towards this context; (4) using two different methodologies proposed in the literature for evaluating shoulder-surfing resistance to compare ""Colorwheels"", on-screen keyboards (the de facto standard in this context), and an existing shoulder-surfing resistant scheme which we identified during our assessment and adapted for the gamepad context; (5) evaluating all three schemes regarding their usability. Having applied different methodologies to measure shoulder-surfing resistance, we discuss their strengths and pitfalls and derive recommendations for future research.",1.3,0.9622815847396851,True,0.45016600268752216,0.7062237937136036,True
Functional Destruction: Utilizing Sustainable Materials’ Physical Transiency for Electronics Applications,"Today’s electronics are manufactured to provide stable functionality and fixed physical forms optimized for reliable operation over long periods and repeated use. However, even when applications don’t call for such robustness, the permanency of these electronics comes with environmental consequences. In this paper, we describe an alternative approach that utilizes sustainable transient electronics whose method of destruction is also key to their functionality. We create these electronics through three different methods: 1) by inkjet printing conductive silver traces on poly(vinyl alcohol) (PVA) substrates to create water-soluble sensors; 2) by mixing a conductive beeswax material configured as a meltable sensor; and 3) by fabricating edible electronics with 3D printed chocolate and culinary gold leaf. To enable practical applications of these devices, we implement a fully transient and sustainable chipless RF detection system.",1.0,0.7226973176002502,True,0.3775406687981454,0.5501189931991979,True
"Random, Messy, Funny, Raw: Finstas as Intimate Reconfigurations of Social Media","Among many young people, the creation of a finsta-a portmanteau of ""fake"" and ""Instagram"" which describes secondary Instagram accounts-provides an outlet to share emotional, low-quality, or indecorous content with their close friends. To study why people create and maintain finstas, we conducted a qualitative study through interviews with finsta users and content analysis of video bloggers exposing their finsta on YouTube. We found that one way that young people deal with mounting social pressures is by reconfiguring online platforms and changing their purposes, norms, expectations, and currencies. Carving out smaller spaces accessible only to close friends allows users the opportunity for a more unguarded, vulnerable, and unserious performance. Drawing on feminist theory, we term this process intimate reconfiguration. Through this reconfiguration finsta users repurpose an existing and widely-used social platform to create opportunities for more meaningful and reciprocal forms of social support.",2.0,0.9945070147514343,True,0.6224593312018546,0.8084831729766444,True
Persuading the Driver (Poster presentation): A Literature Review to Identify Blind Spots,,0.8,0.8074159026145935,True,0.3318122278318339,0.5696140652232137,True
To Repeat or Not to Repeat?: Redesigning Repeating Auditory Alarms Based on EEG Analysis,"Auditory alarms that repeatedly interrupt users until they react are common, especially in the context of alarms. However, when an alarm repeats, our brains habituate to it and perceive it less and less, with reductions in both perception and attention-shifting: a phenomenon known as the repetition-suppression effect (RS). To retain users' perception and attention, this paper proposes and tests the use of pitch- and intensity-modulated alarms. Its experimental findings suggest that the proposed modulated alarms can reduce RS, albeit in different patterns, depending on whether pitch or intensity is the focus of the modulation. Specifically, pitch-modulated alarms were found to reduce RS more when the number of repetitions was small, while intensity-modulated alarms reduced it more as the number of repetitions increased. Based on these results, we make several recommendations for the design of improved repeating alarms, based on which modulation approach should be adopted in various situations.",1.1,0.7369839549064636,True,0.401312339887548,0.5691481473970058,True
How to Design a Digital Storytelling Authoring Tool for Developing Pre-Reading and Pre-Writing Skills,"In the paper we describe an exploration into the design of an authoring tool to support the creation of multimedia stories. We explicitly targeted children with no reading or writing skills and their educators. Children in this age group often enjoy reading and creating stories together with adults and in so doing develop important pre-literacy skills. Literature suggests that when children play an active role in these activities, with a high level of engagement and interaction, there is a significant increase in their vocabulary acquisition and an improvement in their communication skills. Thus, we investigated these issues by conducting an explorative study in a pre-school class with fifteen children and three teachers. Here, we describe the emerging challenges and provide design directions for an authoring system to support the co-creation of stories for pre-literate children.",1.0,0.7391592860221863,True,0.3775406687981454,0.5583499774101659,True
Interdependent Wearables (for Play): A Strong Concept for Design,"Typically wearable devices are conceived of and constructed as stand-alone, individually based technologies. However, in practice wearables become part of the social context and ecology of overall device use. We present a strong concept for design: Interdependent Wearables (for play): wearables designed to require shared attention and mutual awareness, with interdependent functionality that encourages and rewards collocated interaction. The concept arose through design, development, and public exhibition of Hotaru, a collocated social game that uses wearables as game controllers. Hotaru has been shown in festivals and also formally playtested with 62 individuals. To more fully articulate the Interdependent Wearables strong concept, we compared this system's design with wearable and embodied systems for play and other purposes, and drew upon relevant HCI theory. The work is of benefit to those in the HCI/UX community focused on the design and development of social wearable technologies, especially those interested in supporting collocated interaction.",0.8,0.9761195778846741,True,0.3318122278318339,0.653965902858254,True
From in the Class or in the Wild?: Peers Provide Better Design Feedback Than External Crowds,"As demand for design education increases, instructors are struggling to provide timely, personalized feedback for student projects. Gathering feedback from classroom peers and external crowds offer scalable approaches, but there is little evidence of how they compare. We report on a study in which students (n=127) created early- and late-stage prototypes as part of nine-week projects. At each stage, students received feedback from peers and external crowds: their own social networks, online communities, and a task market. We measured the quality, quantity and valence of the feedback and the actions taken on it, and categorized its content using a taxonomy of critique discourse. The study found that peers produced feedback that was of higher perceived quality, acted upon more, and longer compared to the crowds. However, crowd feedback was found to be a viable supplement to peer feedback and students preferred it for projects targeting specialized audiences. Feedback from all sources spanned only a subset of the critique categories. Instructors may fill this gap by further scaffolding feedback generation. The study contributes insights for how to best utilize different feedback sources in project-based courses.",2.1,0.8558856248855591,True,0.6456563062257954,0.7507709655556772,True
ActiveInk: (Th)Inking with Data,"During sensemaking, people annotate insights: underlining sentences in a document or circling regions on a map. They jot down their hypotheses: drawing correlation lines on scatterplots or creating personal legends to track patterns. We present ActiveInk, a system enabling people to seamlessly transition between exploring data and externalizing their thoughts using pen and touch. ActiveInk enables the natural use of pen for active reading behaviors, while supporting analytic actions by activating any of these ink strokes. Through a qualitative study with eight participants, we contribute observations of active reading behaviors during data exploration and design principles to support sensemaking.",0.8,0.8056455254554749,True,0.3318122278318339,0.5687288766436543,True
Supporting Communication between Grandparents and Grandchildren through Tangible Storytelling Systems,"Grandparents and grandchildren that live apart often rely on communication technologies, such as messengers, video conferencing, and phone calls for maintaining relationships. While some of these systems are challenging for grandparents, others are less engaging for children. To facilitate communication, we developed StoryBox, a tangible device that allows sharing photos, tangible artifacts, and audio recordings of everyday life. We conducted a preliminary study with two families to identify design issues, and further refine the prototype. Subsequently, we conducted a field study with four families for up to four weeks to better understand real-world use and examine inter-generational connectedness. We found that StoryBox was accessible, simple, and helped bridge the technological gap between grandparents and grandchildren. Children communicated asynchronously in a playful and idiosyncratic manner, and grandparents shared past family memories. We provide insights on how to ease communication between different generations, engage them in sharing activities, and strengthen family relationships.",1.0,0.7823022603988647,True,0.3775406687981454,0.5799214645985051,True
"Supporting Cultures of Making: Technology, Policy, Visions, and Myths","Recent HCI research has linked social policy to design, e.g., in issues such as public safety, privacy, and social justice. One area where policy, technology, and design intersect is in the vision of the creative economy. In that vision, creativity, distinct local/regional cultural practices, technology, and entrepreneurship synergistically produce social innovation on a scale sufficient to drive economies. Culture and creative industries (CCI) policy specifies how governments intervene to support such clusters. Maker cultures are seen as central to this vision, but comparatively little is known about how makers produce culture. We offer a critical analysis of several encounters between CCI policy in Taiwan and its maker scene. These encounters reveal misalignments that undercut efforts intended to support making. We propose that supporting any creative culture, including making, entails a serious commitment to understanding its culture, including its cultural contents and their means of production. We further argue that scholarly rigor in cultivating cultural appreciation is just as fundamental as scholarly rigor in empirically representing cultural practices when it comes to pursuing such a cultural understanding.",1.0,0.7333200573921204,True,0.3775406687981454,0.5554303630951329,True
Online Proctoring: Privacy Invasion or Study Alleviation?: Discovering Acceptability Using Contextual Integrity,"Detecting fraud during online exams using proctoring software comes with substantial privacy challenges. Previous work argues students experience heightened anxiety and have privacy concerns. However, little is known about which specific aspects of online proctoring cause these concerns. This study contributes such insights by using the Contextual Integrity (CI) framework to discover how students (N = 456) rate the acceptability of 1064 proctoring information flows with varying information types, recipients, and transmission principles. We find that the acceptability varies considerably depending on the context. Besides exposing obvious privacy violations, we find that, under certain conditions, students consider it acceptable to share data with teachers - despite their lack of involvement in proctoring. Also, the acceptability of sharing highly sensitive information - which should under no circumstances be shared - sometimes increases. We discuss the implications of these and other findings and provide concrete recommendations for educational institutions using online proctoring.",1.1,0.7110272645950317,True,0.401312339887548,0.5561698022412899,True
Rethinking Creative Labor: A Sociotechnical Examination of Creativity & Creative Work on TikTok,"Social media platform success relies on users to consume, create, and share creative content. While some creatives aspire to become influencers, this is not the goal of all creatives, particularly those with smaller audiences. Through an interview study of 15 creatives on TikTok, we explore the often overlapping intentions for creating and sharing videos, as well as the challenges to maintaining these creative intentions and routines as they are shaped by platform logic. We find platforms introduce impediments which disrupt people’s creative routines and alienate people from their overlapping creative intentions; introducing challenges which alienate people from their sense of self, and their audiences. We construct a broader definition of creative labor - the work of professionalizing and monetizing a creative product shared on social media - reflecting on how the routine enactment of creative labor is impacted by infrastructural elements of technology.",0.8,0.8034497499465942,True,0.3318122278318339,0.567630988889214,True
OScH in the Wild: Dissemination of Open Science Hardware and Implications for HCI,"Open Science Hardware (OScH) refers to open-source alternatives for proprietary scientific equipment. While the OScH movement aims to reduce barriers for scientific experimentation both in and beyond professional labs, disseminating OScH for widespread adoption proves to be challenging in practice. To this end, we examined real-world practices related to the dissemination of OScH through a two-part study. First, we developed an open science hardware, a DIY incubator, and disseminated it through the Instructables website and maker workshops. In parallel, we interviewed eight open science hardware practitioners from different parts of the world. Insights from interviews together with our own self-reflections revealed how different OScH dissemination modalities serve unique purposes. Our findings also reveal several challenges for widespread adoption of OScH and the importance of collaborations between OScH developers. We conclude by discussing the opportunities for HCI to lower barriers for customization, support internationalization of OScH, and scaffold proactive distributed collaborations between developers and users.",1.0,0.7686555981636047,True,0.3775406687981454,0.5730981334808751,True
Do You Feel Like Passing Through Walls?: Effect of Self-Avatar Appearance on Facilitating Realistic Behavior in Virtual Environments,"Preventing users from walking through virtual boundaries (e.g., walls) is an important issue to be addressed in room-scale virtual environments (VEs), considering the safety and design limitations. Sensory feedback from wall collisions has been shown to be effective; however, it can disrupt the immersion. We assumed that a greater sense of presence would discourage users from walking through walls and conducted a two-factor between-subjects experiment (N = 92) that controls the anthropomorphism (realistic or abstract) and visibility (full-body or hand-only) of self-avatars. We analyzed the participants' behaviors and the moment they first penetrated the wall in game-like VEs that gradually instigated participants to penetrate the walls. The results showed that the realistic full-body self-avatar was the most effective for discouraging the participants from penetrating the walls. Furthermore, the participants with lower presence tended to walk through the walls sooner. This study can contribute to applications that require realistic user responses in VEs.",1.1,0.9181095957756042,True,0.401312339887548,0.6597109678315761,True
“Finding the Magic Sauce”: Exploring Perspectives of Recruiters and Job Seekers on Recruitment Bias and Automated Tools,"Automated recruitment tools are proliferating. While having the promise of improving efficiency, various risks, including bias, challenges the potential of these tools. An in-depth understanding of the perceived risk factors and needs from the perspective of both recruiters and job seekers is needed. We address this through an interview study in the high-tech industry to compare and contrast the concerns of these two roles. We found that the importance of clarifying position requirements and assessing candidates as “whole individuals” are commonly discussed by both recruiters and job seekers. In contrast, while recruiters tended to be more aware of cognitive bias and desired more tool support during interviews, job seekers voiced more desire towards a healthy candidate-company relationship. Additionally, both roles considered the uncertainty of the current technology capability and reduced human contact as concerns for using automated tools. Based on these results, we provided design implications for automated recruitment tools and related decision-support technologies.",1.0,0.7841271758079529,True,0.3775406687981454,0.5808339223030492,True
MagicFace: Stepping into Character through an Augmented Reality Mirror,"Augmented Reality (AR) is coming of age and appearing in various smartphone apps. One emerging AR type uses the front-facing camera and overlays a user's face with digital features that transform the physical appearance, making the user look like someone else, such as a popstar or a historical character. However, little is known about how people react to such stepping into character and how convincing they perceive it to be. We developed an app with two Egyptian looks, MagicFace, which was situated both in an opera house and a museum. In the first setting, people were invited to use the app, while in the second setting they came across it on their own when visiting the exhibition. Our findings show marked differences in how people approach and experience the MagicFace in these different contexts. We discuss how realistic and compelling this kind of AR technology is, as well as its implications for educational and cultural settings.",1.0,0.957072913646698,True,0.3775406687981454,0.6673067912224218,True
(Re)discovering the Physical Body Online: Strategies and Challenges to Approach Non-Cisgender Identity in Social Virtual Reality,"The contemporary understanding of gender continues to highlight the complexity and variety of gender identities beyond a binary dichotomy regarding one’s biological sex assigned at birth. The emergence and popularity of various online social spaces also makes the digital presentation of gender even more sophisticated. In this paper, we use non-cisgender as an umbrella term to describe diverse gender identities that do not match people’s sex assigned at birth, including Transgender, Genderfluid, and Non-binary. We especially explore non-cisgender individuals’ identity practices and their challenges in novel social Virtual Reality (VR) spaces where they can present, express, and experiment their identity in ways that traditional online social spaces cannot provide. We provide one of the first empirical evidence of how social VR platforms may introduce new and novel phenomena and practices of approaching diverse gender identities online. We also contribute to re-conceptualizing technology-supported identity practices by highlighting the role of (re)discovering the physical body online and informing the design of the emerging metaverse for supporting diverse gender identities in the future.",0.8,0.8452774286270142,True,0.3318122278318339,0.588544828229424,True
"CLAW: A Multifunctional Handheld Haptic Controller for Grasping, Touching, and Triggering in Virtual Reality","CLAW is a handheld virtual reality controller that augments the typical controller functionality with force feedback and actuated movement to the index finger. Our controller enables three distinct interactions (grasping virtual object, touching virtual surfaces, and triggering) and changes its corresponding haptic rendering by sensing the differences in the user's grasp. A servo motor coupled with a force sensor renders controllable forces to the index finger during grasping and touching. Using position tracking, a voice coil actuator at the index fingertip generates vibrations for various textures synchronized with finger movement. CLAW also supports a haptic force feedback in the trigger mode when the user holds a gun. We describe the design considerations for CLAW and evaluate its performance through two user studies. The first study obtained qualitative user feedback on the naturalness, effectiveness, and comfort when using the device. The second study investigated the ease of the transition between grasping and touching when using our device.",1.0,0.7692263126373291,True,0.3775406687981454,0.5733834907177373,True
`I make up a silly name': Understanding Children's Perception of Privacy Risks Online,"Children under 11 are often regarded as too young to comprehend the implications of online privacy. Perhaps as a result, little research has focused on younger kids' risk recognition and coping. Such knowledge is, however, critical for designing efficient safeguarding mechanisms for this age group. Through 12 focus group studies with 29 children aged 6-10 from UK schools, we examined how children described privacy risks related to their use of tablet computers and what information was used by them to identify threats. We found that children could identify and articulate certain privacy risks well, such as information oversharing or revealing real identities online; however, they had less awareness with respect to other risks, such as online tracking or game promotions. Our findings offer promising directions for supporting children's awareness of cyber risks and the ability to protect themselves online.",1.0,0.8788622617721558,True,0.3775406687981454,0.6282014652851506,True
"Multi-moji: Combining Thermal, Vibrotactile & Visual Stimuli to Expand the Affective Range of Feedback","This paper explores the combination of multiple concurrent modalities for conveying emotional information in HCI: temperature, vibration and abstract visual displays. Each modality has been studied individually, but can only convey a limited range of emotions within two-dimensional valence-arousal space. This paper is the first to systematically combine multiple modalities to expand the available affective range. Three studies were conducted: Study 1 measured the emotionality of vibrotactile feedback by itself; Study 2 measured the perceived emotional content of three bimodal combinations: vibrotactile + thermal, vibrotactile + visual and visual + thermal. Study 3 then combined all three modalities. Results show that combining modalities increases the available range of emotional states, particularly in the problematic top-right and bottom-left quadrants of the dimensional model. We also provide a novel lookup resource for designers to identify stimuli to convey a range of emotions",0.8,0.9731631278991699,True,0.3318122278318339,0.6524876778655019,True
On Hackathons: A Multidisciplinary Literature Review,"The number of hackathon events worldwide has nearly quadrupled in the last five years. Despite exponential growth across diverse industries and increasing interest across academic disciplines, our integrated understanding of the phenomena of hackathons is limited. We conduct the first multidisciplinary literature review of publications from 1999 to 2022 to understand the conceptualization of the phenomena over time. We find that hackathon research can be categorized into 4 core areas (purpose, format, processes, and outcomes). Research was first driven by a purpose (innovation, learning, and collaboration), followed by an examination of how formats adjust to purpose to influence what happens (processes) and what is produced (outcomes), and critical reviews of the hackathon phenomena. We contribute a unifying framework with these four core areas to inform future directions of hackathon research and practice, as well as a discussion of the need for longitudinal and multidisciplinary research of hackathons.",1.0,0.9361310601234436,True,0.3775406687981454,0.6568358644607946,True
Becoming a Speleologist: Design Implications for Coordination in Wild Outdoor Environments,"Learning outdoor sports entails acquiring physical skills, managing gear, and coordinating with others. We investigated how speleologists are trained to explore underground caves. We interviewed 15 instructors and 10 trainees to understand the main problems that may occur during training cave trips. Our findings show that stressful situations are linked to beginners’ difficulties applying new gestures and procedures - on which their progression and safety depend - and coordinating with others when they are out of sight. It emerged that group awareness and communication are pivotal for their tranquility. Yet, the underground environment makes communicating very hard. This study led to the elaboration of design implications for technology supporting awareness, communication, and coordination in speleology training, which draw from and enrich previous literature on coordination in the wild, as it may happen while performing outdoor sports or during search-and-rescue operations.",1.0,0.7969510555267334,True,0.3775406687981454,0.5872458621624395,True
"Where is the Digital Divide?: A Survey of Security, Privacy, and Socioeconomics","The behavior of the least-secure user can influence security and privacy outcomes for everyone else. Thus, it is important to understand the factors that influence the security and privacy of a broad variety of people. Prior work has suggested that users with differing socioeconomic status (SES) may behave differently; however, no research has examined how SES, advice sources, and resources relate to the security and privacy incidents users report. To address this question, we analyze a 3,000 respondent, census-representative telephone survey. We find that, contrary to prior assumptions, people with lower educational attainment report equal or fewer incidents as more educated people, and that users' experiences are significantly correlated with their advice sources, regardless of SES or resources.",1.1,0.7231110334396362,True,0.401312339887548,0.5622116866635921,True
“It Would Be Cool to Get Stampeded by Dinosaurs”: Analyzing Children's Conceptual Model of AR Headsets Through Co-Design,"Children are being presented with augmented reality (AR) in different contexts, such as education and gaming. However, little is known about how children conceptualize AR, especially AR headsets. Prior work has shown that children's interaction behaviors and expectations of technological devices can be quite different from adults’. It is important to understand children's mental models of AR headsets to design more effective experiences for them. To elicit children's perceptions, we conducted four participatory design sessions with ten children on designing content for imaginary AR headsets. We found that children expect AR systems to be highly intelligent and to recognize and virtually transform surroundings to create immersive environments. Also, children are in favor of using these devices for difficult tasks but prefer to work on their own for easy tasks. Our work contributes new understanding on how children comprehend AR headsets and provides recommendations for designing future headsets for children.",1.0,0.9716625213623047,True,0.3775406687981454,0.6746015950802251,True
Design Goals for Playful Technology to Support Physical Activity Among Wheelchair Users,"Playful technology has the potential to support physical activity (PA) among wheelchair users, but little is known about design considerations for this audience, who experience significant access barriers. In this paper, we lever-age the Integrated Behavioural Model (IBM) to understand wheelchair users' perspectives on PA, technology, and play.First, we present findings from an interview study with eight physically active wheelchair users. Second, we build on the interviews in a survey that received 44 responses from a broader group of wheelchair users. Results show that the anticipation of positive experiences was the strongest predictor of engagement with PA, and that accessibility concerns act as barriers both in terms of PA participation and technology use. We present four design goals - emphasizing enjoyment,involving others, building knowledge and enabling flexibility - to make our findings actionable for researchers and designers wishing to create accessible playful technology to support PA.",1.0,0.980072021484375,True,0.3775406687981454,0.6788063451412603,True
Storyboard-Based Empirical Modeling of Touch Interface Performance,"Touch interactions are now ubiquitous, but few tools are available to help designers quickly prototype touch interfaces and predict their performance. For rapid prototyping, most applications only support visual design. For predictive modelling, tools such as CogTool generate performance predictions but do not represent touch actions natively and do not allow exploration of different usage contexts. To combine the benefits of rapid visual design tools with underlying predictive models, we developed the Storyboard Empirical Modelling tool (StEM) for exploring and predicting user performance with touch interfaces. StEM provides performance models for mainstream touch actions, based on a large corpus of realistic data. We evaluated StEM in an experiment and compared its predictions to empirical times for several scenarios. The study showed that our predictions are accurate (within 7% of empirical values on average), and that StEM correctly predicted differences between alternative designs. Our tool provides new capabilities for exploring and predicting touch performance, even in the early stages of design.",1.0,0.7348055243492126,True,0.3775406687981454,0.5561730965736791,True
Touch&Fold: A Foldable Haptic Actuator for Rendering Touch in Mixed Reality,"We propose a nail-mounted foldable haptic device that provides tactile feedback to mixed reality (MR) environments by pressing against the user's fingerpad when a user touches a virtual object. What is novel in our device is that it quickly tucks away when the user interacts with real-world objects. Its design allows it to fold back on top of the user's nail when not in use, keeping the user's fingerpad free to, for instance, manipulate handheld tools and other objects while in MR. To achieve this, we engineered a wireless and self-contained haptic device, which measures 24×24×41 mm and weighs 9.5 g. Furthermore, our foldable end-effector also features a linear resonant actuator, allowing it to render not only touch contacts (i.e., pressure) but also textures (i.e., vibrations). We demonstrate how our device renders contacts with MR surfaces, buttons, low- and high-frequency textures. In our first user study, we found that participants perceived our device to be more realistic than a previous haptic device that also leaves the fingerpad free (i.e., fingernail vibration). In our second user study, we investigated the participants’ experience while using our device in a real-world task that involved physical objects. We found that our device allowed participants to use the same finger to manipulate handheld tools, small objects, and even feel textures and liquids, without much hindrance to their dexterity, while feeling haptic feedback when touching MR interfaces.",0.8,0.854326605796814,True,0.3318122278318339,0.5930694168143239,True
"Seekers, Providers, Welcomers, and Storytellers: Modeling Social Roles in Online Health Communities","Participants in online communities often enact different roles when participating in their communities. For example, some in cancer support communities specialize in providing disease-related information or socializing new members. This work clusters the behavioral patterns of users of a cancer support community into specific functional roles. Based on a series of quantitative and qualitative evaluations, this research identified eleven roles that members occupy, such as welcomer and story sharer. We investigated role dynamics, including how roles change over members' lifecycles, and how roles predict long-term participation in the community. We found that members frequently change roles over their history, from ones that seek resources to ones offering help, while the distribution of roles is stable over the community's history. Adopting certain roles early on predicts members' continued participation in the community. Our methodology will be useful for facilitating better use of members' skills and interests in support of community-building efforts.",1.0,0.803370475769043,True,0.3775406687981454,0.5904555722835942,True
Political Hashtags & the Lost Art of Democratic Discourse,"In this work, we investigate whether and how the presence of political hashtags in social media news articles influences the way people discuss news content. Specifically, we examine how political hashtags in news posts act as a design characteristic that affects the quality of online discourse. We use a randomized control experiment to assess how the presence versus absence of political hashtags (particularly the most prevalently used #MeToo and #BlackLivesMatter) in social media news posts shapes discourse across a general audience (n=3205). Key findings show differences in topical focus, emotional tone of discourse, and rhetorical styles between commenters who were shown news posts with political hashtags versus those shown news posts without the hashtags. Compared to the control group, those shown hashtagged news posts heavily focus on the politics of the hashtag, use more words associated with fear, anger, and disgust in their comments, and exhibit black-and-white rhetoric and less emotionally temperate expressions in their arguments.",0.8,0.8736860752105713,True,0.3318122278318339,0.6027491515212026,True
"Tap, Dwell or Gesture?: Exploring Head-Based Text Entry Techniques for HMDs","Despite the increasing popularity of head mounted displays (HMDs), development of efficient text entry methods on these devices has remained under explored. In this paper, we investigate the feasibility of head-based text entry for HMDs, by which, the user controls a pointer on a virtual keyboard using head rotation. Specifically, we investigate three techniques: TapType, DwellType, and GestureType. Users of TapType select a letter by pointing to it and tapping a button. Users of DwellType select a letter by pointing to it and dwelling over it for a period of time. Users of GestureType perform word-level input using a gesture typing style. Two lab studies were conducted. In the first study, users typed 10.59 WPM, 15.58 WPM, and 19.04 WPM with DwellType, TapType, and GestureType, respectively. Users subjectively felt that all three of the techniques were easy to learn and considered the induced fatigue to be acceptable. In the second study, we further investigated GestureType. We improved its gesture-word recognition algorithm by incorporating the head movement pattern obtained from the first study. This resulted in users reaching 24.73 WPM after 60 minutes of training. Based on these results, we argue that head-based text entry is feasible and practical on HMDs, and deserves more attention.",1.1,0.9093146920204163,True,0.401312339887548,0.6553135159539821,True
Introducing Transient Gestures to Improve Pan and Zoom on Touch Surfaces,"Despite the ubiquity of touch-based input and the availability of increasingly computationally powerful touchscreen devices, there has been comparatively little work on enhancing basic canonical gestures such as swipe-to-pan and pinch-to-zoom. In this paper, we introduce transient pan and zoom, i.e. pan and zoom manipulation gestures that temporarily alter the view and can be rapidly undone. Leveraging typical touchscreen support for additional contact points, we design our transient gestures such that they co-exist with traditional pan and zoom interaction. We show that our transient pan-and-zoom reduces repetition in multi-level navigation and facilitates rapid movement between document states. We conclude with a discussion of user feedback, and directions for future research.",1.0,0.830949604511261,True,0.3775406687981454,0.6042451366547033,True
Disagree? You Must be a Bot! How Beliefs Shape Twitter Profile Perceptions,"In this paper, we investigate the human ability to distinguish political social bots from humans on Twitter. Following motivated reasoning theory from social and cognitive psychology, our central hypothesis is that especially those accounts which are opinion-incongruent are perceived as social bot accounts when the account is ambiguous about its nature. We also hypothesize that credibility ratings mediate this relationship. We asked N = 151 participants to evaluate 24 Twitter accounts and decide whether the accounts were humans or social bots. Findings support our motivated reasoning hypothesis for a sub-group of Twitter users (those who are more familiar with Twitter): Accounts that are opinion-incongruent are evaluated as relatively more bot-like than accounts that are opinion-congruent. Moreover, it does not matter whether the account is clearly social bot or human or ambiguous about its nature. This was mediated by perceived credibility in the sense that congruent profiles were evaluated to be more credible resulting in lower perceptions as bots.",0.8,0.9636039137840271,True,0.3318122278318339,0.6477080708079305,True
CurveBoards: Integrating Breadboards into Physical Objects to Prototype Function in the Context of Form,"CurveBoards are breadboards integrated into physical objects. In contrast to traditional breadboards, CurveBoards better preserve the object's look and feel while maintaining high circuit fluidity, which enables designers to exchange and reposition components during design iteration. Since CurveBoards are fully functional, i.e., the screens are displaying content and the buttons take user input, designers can test interactive scenarios and log interaction data on the physical prototype while still being able to make changes to the component layout and circuit design as needed. We present an interactive editor that enables users to convert 3D models into CurveBoards and discuss our fabrication technique for making CurveBoard prototypes. We also provide a technical evaluation of CurveBoard's conductivity and durability and summarize informal user feedback.",1.0,0.7828012704849243,True,0.3775406687981454,0.5801709696415349,True
Bots & (Main)Frames: Exploring the Impact of Tangible Blocks and Collaborative Play in an Educational Programming Game,"While recent work has begun to evaluate the efficacy of educational programming games, many common design decisions in these games (e.g., single player gameplay using touchpad or mouse) have not been explored for learning outcomes. For instance, alternative design approaches such as collaborative play and embodied interaction with tangibles may also provide important benefits to learners. To better understand how these design decisions impact learning and related factors, we created an educational programming game that allows for systematically varying input method and mode of play. In this paper, we describe design rationale for mouse and tangible versions of our game, and report a 2x2 factorial experiment comparing efficacy of mouse and tangible input methods with individual and collaborative modes of play. Results indicate tangibles have a greater positive impact on learning, situational interest, enjoyment, and programming self-beliefs. We also found collaborative play helps further reduce programming anxiety over individual play.",0.8,0.9483712911605835,True,0.3318122278318339,0.6400917594962087,True
Seeing with New Eyes: Designing for In-the-Wild Museum Gifting,"This paper presents the GIFT smartphone app, an artist-led Research through Design project benefitting from a three-day in-the-wild deployment. The app takes as its premise the generative potential of combining the contexts of gifting and museum visits. Visitors explore the museum, searching for objects that would most appeal to the gift-receiver they have in mind, then photographing those objects and adding audio messages for their receivers describing the motivation for their choices. This paper charts the designers' key aim of creating a new frame of mind using voice, and the most striking findings discovered during in-the-wild deployment in a museum -- 'seeing with new eyes' and fostering personal connections. We discuss empathy, motivation, and bottom-up personalisation in the productive space revealed by this combination of contexts. We suggest that this work reveals opportunities for designers of gifting services as well as those working in cultural heritage.",1.0,0.8838456273078918,True,0.3775406687981454,0.6306931480530187,True
(Re-)Distributional Food Justice: Negotiating conflicting views of fairness within a local grassroots community,"Sustainable HCI and Human-Food-Interaction research have developing interest in preventing food waste through food sharing. Sustainability requires attention to both the opportunities and challenges associated with the building of food sharing groups engaged in the redistribution of food but also in developing a wider agenda which includes, for instance, the local production of food resources. In this paper, we argue for a better understanding of the different conceptions of ‘fairness’ which inform volunteer and guest practice and in turn mediate community-building efforts. We examine the practices surrounding ‘SharingEvent’ and challenges faced to sustainability by the heterogenous, and sometimes contested, commitments of the people involved. We further consider how ICT provided opportunities for explicit examination of ideological differences concerning what ‘sharing’ might mean. Our findings show that community building is dependent on the negotiation of different values and purposes identified. We derive recommendations for action-oriented researchers ultimately concerned with systemic transformation.",0.8,0.8981359004974365,True,0.3318122278318339,0.6149740641646352,True
Participatory Media: Creating Spaces for Storytelling in Neighbourhood Planning,"Neighbourhood planning devolves power to communities to create their own planning policy but traditional forms of participation are still relied upon. And despite the ubiquitous nature of technology in society, digital participation methods are rarely used. In this paper, we outline fieldwork with two neighbourhood planning groups who used participatory media technology to improve engagement though the art of storytelling. We focus on the configuration of participatory media as a way to widen participation and enable story creation and sharing amongst citizens. We highlight that storytelling using media technology can provide a model of and a model for the way we ""do"" neighbourhood planning whilst emphasising the challenges of ensuring processes are linked to tangible actions and encouraging the multiplicity of stories.",1.0,0.7952094674110413,True,0.3775406687981454,0.5863750681045934,True
How to Trick AI: Users' Strategies for Protecting Themselves from Automatic Personality Assessment,"Psychological targeting tries to influence and manipulate users' behaviour. We investigated whether users can protect themselves from being profiled by a chatbot, which automatically assesses users' personality. Participants interacted twice with the chatbot: (1) They chatted for 45 minutes in customer service scenarios and received their actual profile (baseline). (2) They then were asked to repeat the interaction and to disguise their personality by strategically tricking the chatbot into calculating a falsified profile. In interviews, participants mentioned 41 different strategies but could only apply a subset of them in the interaction. They were able to manipulate all Big Five personality dimensions by nearly 10%. Participants regarded personality as very sensitive data. As they found tricking the AI too exhaustive for everyday use, we reflect on opportunities for privacy protective designs in the context of personality-aware systems.",1.0,0.858373761177063,True,0.3775406687981454,0.6179572149876043,True
Sticky Goals: Understanding Goal Commitments for Behavioral Changes in the Wild,"A commitment device, an attempt to bind oneself for a successful goal achievement, has been used as an effective strategy to promote behavior change. However, little is known about how commitment devices are used in the wild, and what aspects of commitment devices are related to goal achievements. In this paper, we explore a large-scale dataset from stickK, an online behavior change support system that provides both financial and social commitments. We characterize the patterns of behavior change goals (e.g., topics and commitment setting) and then perform a series of multilevel regression analyses on goal achievements. Our results reveal that successful goal achievements are largely dependent on the configuration of financial and social commitment devices, and a mixed commitment setting is considered beneficial. We discuss how our findings could inform the design of effective commitment devices, and how large-scale data can be leveraged to support data-driven goal elicitation and customization.",1.0,0.7365004420280457,True,0.3775406687981454,0.5570205554130956,True
Playful Reflection: Impact of Gamification on a Virtual Reality Simulation of Breastfeeding,"Gamification is a popular technique to improve task engagement, and has broadly been deployed in health and education to a point where many users now expect gameful experiences in these settings. However, gamification has been criticised for being a potential obstacle to the experience of reflection. Motivated by this tension, our work examines how the addition of gamification to a Virtual Reality simulation of breastfeeding impacts player experience and reflection. Using a within-subjects design, we invited 34 participants to take part in a mixed-methods evaluation of a gamified and non-gamified variant of the simulation that included questionnaires and semi-structured interviews. Results show that gamification improved player experience and encouraged players to reflect on goal achievement and performance. However, it also diverted players’ attention from nuances within the act of nursing. Drawing on our findings, we contribute considerations for the application of gamification in personal and sensitive settings such as breastfeeding.",1.0,0.9909499287605286,True,0.3775406687981454,0.684245298779337,True
A World Full of Privacy and Security (Mis)conceptions? Findings of a Representative Survey in 12 Countries,"Misconceptions about digital security and privacy topics in the general public frequently lead to insecure behavior. However, little is known about the prevalence and extent of such misconceptions in a global context. In this work, we present the results of the first large-scale survey of a global population on misconceptions: We conducted an online survey with n = 12, 351 participants in 12 countries on four continents. By investigating influencing factors of misconceptions around eight common security and privacy topics (including E2EE, Wi-Fi, VPN, and malware), we find the country of residence to be the strongest estimate for holding misconceptions. We also identify differences between non-Western and Western countries, demonstrating the need for region-specific research on user security knowledge, perceptions, and behavior. While we did not observe many outright misconceptions, we did identify a lack of understanding and uncertainty about several fundamental privacy and security topics.",1.1,0.7835084199905396,True,0.401312339887548,0.5924103799390438,True
MapUncover: Fostering Spatial Exploration through Gamification in Mobile Map Apps,"Getting from A to B has never been easier. Mobile navigation systems allow universal access to spatial information. However, following detailed route instructions leads to a decrease in spatial exploration behaviour and therefore a reduction of spatial knowledge acquisition. Facilitating spatial exploration has the potential to counteract this negative effect. This paper investigates how we can support people in re-discovering their surroundings. We designed and evaluated a mobile application to promote spatial exploration through gamification. The app requires active exploration behaviour to uncover a map. Gamification elements such as quests, statistics, and social competition are used to encourage exploration. We conducted an exploratory field study (n = 22). Our results show a significant increase in familiarity with the environment and a variety of exploration patterns. Based on our findings, we propose modifications to current mapping applications by limiting the visible cartographic elements and alternating routes to improve spatial knowledge acquisition.",1.0,0.9636589884757996,True,0.3775406687981454,0.6705998286369725,True
StoryCoder: Teaching Computational Thinking Concepts Through Storytelling in a Voice-Guided App for Children,"Computational thinking (CT) education reaches only a fraction of young children, in part because CT learning tools often require expensive hardware or fluent literacy. Informed by needfinding interviews, we developed a voice-guided smartphone application leveraging storytelling as a creative activity by which to teach CT concepts to 5- to 8-year-old children. The app includes two storytelling games where users create and listen to stories as well as four CT games where users then modify those stories to learn about sequences, loops, events, and variables. We improved upon the app design through wizard-of-oz testing (N = 28) and iterative design testing (N = 22) before conducting an evaluation study (N = 22). Children were successfully able to navigate the app, effectively learn about the target computing concepts, and, after using the app, children demonstrated above-chance performance on a near transfer CT concept recognition task.",1.0,0.8122553825378418,True,0.3775406687981454,0.5948980256679937,True
DuoRhythmo: Design and remote user experience evaluation (UXE) of a collaborative accessible digital musical interface (CADMI) for people with ALS (PALS),"We present DuoRhythmo, a collaborative accessible digital musical interface (CADMI) that gives people living with Amyotrophic Lateral Sclerosis (PALS) the experience of remotely and collaboratively creating music in real-time. We designed DuoRhythmo specifically to be utilized for eye tracking and optimized it for head- and computer mouse interaction, as well using a user-centered design approach. Together with five PALS, we completed a mixed-methods evaluation to assess the accessibility of DuoRhythmo. Participants described the CADMI using the Microsoft Desirability Toolkit (MDT) as fun, empowering, accessible, easy to use, engaging, and stimulating and gave an average System Usability Scale (SUS) score of 79.5. We suggest further research on remote collaboration within the field of accessible digital musical instruments (ADMIs) using the term CADMI to explore the positive effects of collaborative music-making on the quality of life of PALS.",0.8,0.916674792766571,True,0.3318122278318339,0.6242435102992024,True
Design for Collaborative Survival: An Inquiry into Human-Fungi Relationships,"In response to recent calls for HCI to address ongoing environmental crises and existential threats, this paper introduces the concept of collaborative survival and examines how it shapes the design of interactive artifacts. Collaborative survival describes how our (human) ability to persist as a species is deeply entangled with and dependent upon the health of a multitude of other species. We explore collaborative survival within the context of designing tools for mushroom foraging and reflect on how interactive products can open new pathways for noticing and joining-with these entanglements towards preferable futures. In addition to highlighting three tactics-engagement, attunement and expansion-that can guide designs towards multispecies flourishing, our prototypes illustrate the potential for wearable technology to extend the body into the environment.",1.0,0.7954668998718262,True,0.3775406687981454,0.5865037843349858,True
"""Protection on that Erection?"": Discourses of Accountability & Compromising Participation in Digital Sexual Health","This paper analyses sexual health workers' 'talk' around their introduction of a digital platform to enhance a regionally managed condom distribution scheme for young people. In examining the discursive resources workers used in framing the sexual health service, their service users and digital technology, we argue that problematic ideologies around young people and sexuality were exercised and reproduced. Workers positioned themselves as the gatekeepers of young people's sexual health, who were in turn constructed as 'mischievous' and 'misguided', with technology having a corruptive role over what was considered to be 'healthy' and 'normal' sexual relationships. We suggest our findings indicate severe challenges in developing community-commissioned platforms alongside service providers, and questions how plausible user participation can be in attempting to conduct collaborative, participatory and engaged work in this context.",1.1,0.9016789197921753,True,0.401312339887548,0.6514956298398616,True
Let's Play!: Digital and Analog Play between Preschoolers and Parents,"Play is an enjoyable and developmentally useful part of early childhood, and parent-child play is a highly productive mechanism by which children learn to participate in the world. We conducted an observational lab study to examine how 15 parent-child pairs (children age 4-6) respond to and play with tablet apps as compared to analog toys. We found that parents and children were less likely to engage with each other or to respond to each other's bids for attention during play sessions with tab-lets versus play sessions with toys. We also observed that specific design features of tablet devices and children's apps-such as one-sided interfaces, game paradigms that demand continual attention, and lack of support for parallel interaction-are the primary mechanism shaping these differences. We provide guidance suggesting how children's apps might be re-designed to preserve the ad-vantages of digital play experiences while also evolving to build in the advantages of traditional toys.",1.3,0.9881632328033447,True,0.45016600268752216,0.7191646177454334,True
"Tools, Tricks, and Hacks: Exploring Novel Digital Fabrication Workflows on #PlotterTwitter","As digital fabrication machines become widespread, online communities have provided space for diverse practitioners to share their work, troubleshoot, and socialize. These communities pioneer increasingly novel fabrication workflows, and it is critical that we understand and conceptualize these workflows beyond traditional manufacturing models. To this end, we conduct a qualitative study of #PlotterTwitter, an online community developing custom hardware and software tools to create artwork with computer-controlled drawing machines known as plotters. We documented and analyzed emergent themes where the traditional interpretation of digital fabrication workflows fails to capture important nuances and nascent directions. We find that #PlotterTwitter makers champion creative exploration of interwoven digital and physical materials over a predictable series of steps. We discuss how this challenges long-running views of digital fabrication and propose design implications for future frameworks and toolkits to account for this breadth of practice.",2.0,0.9501785039901733,True,0.6224593312018546,0.7863189175960139,True
"""We Don't Do That Here"": How Collaborative Editing with Mentors Improves Engagement in Social Q&A Communities","Online question-and-answer (Q&A) communities like Stack Overflow have norms that are not obvious to novice users. Novices create and post programming questions without feedback, and the community enforces site norms through public downvoting and commenting. This can leave novices discouraged from further participation. We deployed a month long, just-in-time mentorship program to Stack Overflow in which we redirected novices in the process of asking a question to an on-site Help Room. There, novices received feedback on their question drafts from experienced Stack Overflow mentors. We present examples and discussion of various question improvements including: question context, code formatting, and wording that adheres to on-site cultural norms. We find that mentored questions are substantially improved over non-mentored questions, with average scores increasing by 50%. We provide design implications that challenge how socio-technical communities onboard novices across domains.",0.8,0.7958647608757019,True,0.3318122278318339,0.5638384943537679,True
Drone & Wo: Cultural Influences on Human-Drone Interaction Techniques,"As drones become ubiquitous, it is important to understand how cultural differences impact human-drone interaction. A previous elicitation study performed in the USA illustrated how users would intuitively interact with drones. We replicated this study in China to gain insight into how these user-defined interactions vary across the two cultures. We found that as per the US study, Chinese participants chose to interact primarily using gesture. However, Chinese participants used multi-modal interactions more than their US counterparts. Agreement for many proposed interactions was high within each culture. Across cultures, there were notable differences despite similarities in interaction modality preferences. For instance, culturally-specific gestures emerged in China, such as a T-shape gesture for stopping the drone. Participants from both cultures anthropomorphized the drone, and welcomed it into their personal space. We describe the implications of these findings on designing culturally-aware and intuitive human-drone interaction.",0.8,0.8432525396347046,True,0.3318122278318339,0.5875323837332692,True
Light-In-Light-Out (Li-Lo) Displays: Harvesting and Manipulating Light to Provide Novel Forms of Communication,"Many of us daily encounter shadow and reflected light patterns alongside macro-level changes in ambient light levels. These are caused by elements—opaque objects, glass, mirrors, even clouds—in our environment interfacing with sunlight or artificial indoor lighting. Inspired by these phenomena, we explored ways of creating digitally-supported displays that use light, shade and reflection for output and harness the energy they need to operate from the sun or indoor ambient light. Through a set of design workshops we developed exemplar devices: SolarPix, ShadMo and GlowBoard. We detail their function and implementation, as well as evidencing their technical viability. The designs were informed by material understandings from the Global North and Global South and demonstrated in a cross-cultural workshop run in parallel in India and South Africa where community co-designers reflected on their uses and value given lived experience of their communication practices and unreliable energy networks.",0.8,0.8804990649223328,True,0.3318122278318339,0.6061556463770833,True
What Can We Learn from Augmented Reality (AR)?: Benefits and Drawbacks of AR for Inquiry-based Learning of Physics,"Emerging technologies such as Augmented Reality (AR), have the potential to radically transform education by making challenging concepts visible and accessible to novices. In this project, we have designed a Hololens-based system in which collaborators are exposed to an unstructured learning activity in which they learned about the invisible physics involved in audio speakers. They learned topics ranging from spatial knowledge, such as shape of magnetic fields, to abstract conceptual knowledge, such as relationships between electricity and magnetism. We compared participants' learning, attitudes and collaboration with a tangible interface through multiple experimental conditions containing varying layers of AR information. We found that educational AR representations were beneficial for learning specific knowledge and increasing participants' self-efficacy (i.e., their ability to learn concepts in physics). However, we also found that participants in conditions that did not contain AR educational content, learned some concepts better than other groups and became more curious about physics. We discuss learning and collaboration differences, as well as benefits and detriments of implementing augmented reality for unstructured learning activities.",1.9,0.7869075536727905,True,0.598687660112452,0.6927976068926213,True
From Data to Insights: A Layered Storytelling Approach for Multimodal Learning Analytics,"Significant progress to integrate and analyse multimodal data has been carried out in the last years. Yet, little research has tackled the challenge of visualising and supporting the sensemaking of multimodal data to inform teaching and learning. It is naïve to expect that simply by rendering multiple data streams visually, a teacher or learner will be able to make sense of them. This paper introduces an approach to unravel the complexity of multimodal data by organising it into meaningful layers that explain critical insights to teachers and students. The approach is illustrated through the design of two data storytelling prototypes in the context of nursing simulation. Two authentic studies with educators and students identified the potential of the approach to create learning analytics interfaces that communicate insights on team performance, as well as concerns in terms of accountability and automated insights discovery.",1.0,0.773245632648468,True,0.3775406687981454,0.5753931507233068,True
What Can HCI Learn from Sexual Consent?: A Feminist Process of Embodied Consent for Interactions with Emerging Technologies,"Sexual consent has undergone a transformation toward an “enthusiastic” feminist model that emphasizes consent as an ongoing and voluntary process of negotiation and affirmation. This paper considers how such a model can advance understandings of consent in HCI research and design in relation to embodied interactions with emerging technologies that also occur outside of sexual interactions. We apply the popular “FRIES” model of sexual consent (Freely given, Reversible, Informed, Enthusiastic and Specific) to three areas of embodied interaction: 1) bodily-play interactions, 2) persuasive interactions with smart technologies, and 3) intimate interactions with anthropomorphized devices. Based on erotic play practices, we contribute a “TEASE” process guideline (Traffic lights, Establish ongoing dialogue, Aftercare, Safewords, and Explicate soft/hard limits) to advance consensual practice in HCI and develop implementation scenarios.",1.1,0.8774242997169495,True,0.401312339887548,0.6393683198022487,True
Wanting To Live Here: Design After Anthropocentric Functionalism,"Design research has recently turned to theoretical perspectives, including care ethics and posthumanism, to counter the industrial processes that have led to climate crisis. As design theorists and ethnographers of interaction, we researched experimental eco-farming in a community that shared many of these theoretical and ideological commitments. Our goal was not to offer an account of use and provide design implications in support of it. Instead, we chose to identify concrete practices and artifacts that embody the sorts of industrial transformations that we are seeking—even if they are manifest in an imperfect or partial form. We encountered practices focused on community building, local resilience to climate disruptions, experiments in eco-farming, economic survival, and attracting the next generation. One interlocutor translated these concerns into a simple binary, asking, “do we want to live here?” This paper contributes to a design research agenda that might (eventually) provide an affirmative answer.",1.0,0.8017676472663879,True,0.3775406687981454,0.5896541580322667,True
MR.Brick: Designing A Remote Mixed-reality Educational Game System for Promoting Children’s Social & Collaborative Skills,"Children are one of the groups most influenced by COVID-19-related social distancing, and a lack of contact with peers can limit their opportunities to develop social and collaborative skills. However, remote socialization and collaboration as an alternative approach is still a great challenge for children. This paper presents MR.Brick, a Mixed Reality (MR) educational game system that helps children adapt to remote collaboration. A controlled experimental study involving 24 children aged six to ten was conducted to compare MR.Brick with the traditional video game by measuring their social and collaborative skills and analyzing their multi-modal playing behaviours. The results showed that MR.Brick was more conducive to children’s remote collaboration experience than the traditional video game. Given the lack of training systems designed for children to collaborate remotely, this study may inspire interaction design and educational research in related fields.",0.8,0.8408782482147217,True,0.3318122278318339,0.5863452380232778,True
"My Telepresence, My Culture?: An Intercultural Investigation of Telepresence Robot Operators' Interpersonal Distance Behaviors","Interpersonal distance behaviors can vary significantly across countries and impact human social interaction. Do these cross-cultural differences play out when one of the interaction partners participates through a teleoperated robot? Emerging research shows that when being approached by a robot, people tend to hold similar cultural preferences as they would for an approaching human. However, no work yet has investigated this question from a robot teleoperator's perspective. Toward answering this, we conducted an online study (N = 774) using a novel simulation paradigm across two countries (U.S. and India). Results show that in the role of a telepresence robot operator, participants exhibited cross-cultural differences in interpersonal distance behavior in line with human-human proxemic research, indicating that culture-specific distance behavior can manifest in the way a robot operator controls a robot. We discuss implications for designers who seek to automate path planning and navigation for teleoperated robots.",1.1,0.8782210946083069,True,0.401312339887548,0.6397667172479274,True
StoryBuddy: A Human-AI Collaborative Chatbot for Parent-Child Interactive Storytelling with Flexible Parental Involvement,"Despite its benefits for children’s skill development and parent-child bonding, many parents do not often engage in interactive storytelling by having story-related dialogues with their child due to limited availability or challenges in coming up with appropriate questions. While recent advances made AI generation of questions from stories possible, the fully-automated approach excludes parent involvement, disregards educational goals, and underoptimizes for child engagement. Informed by need-finding interviews and participatory design (PD) results, we developed StoryBuddy, an AI-enabled system for parents to create interactive storytelling experiences. StoryBuddy’s design highlighted the need for accommodating dynamic user needs between the desire for parent involvement and parent-child bonding and the goal of minimizing parent intervention when busy. The PD revealed varied assessment and educational goals of parents, which StoryBuddy addressed by supporting configuring question types and tracking child progress. A user study validated StoryBuddy’s usability and suggested design insights for future parent-AI collaboration systems.",1.0,0.8521357178688049,True,0.3775406687981454,0.6148381933334752,True
HeatCraft: Designing Playful Experiences with Ingestible Sensors via Localized Thermal Stimuli,"Ingestible sensors are pill-like sensors that people swallow mainly for medical purposes. We propose that ingestible sensors also offer unique opportunities to facilitate intriguing bodily experiences in a playful manner. To explore this, we present ""HeatCraft"", a two-player system that translates the user's body temperature measured by an ingestible sensor to localized thermal stimuli delivered through a waist belt equipped with heating pads. We conducted a study with 16 participants. The study revealed three design themes (Integration of body and technology, Integration of internal body and outside world, and Integration of play and life) along with some open challenges. In summary, this work contributes knowledge to the future design of playful experiences with ingestible sensors.",1.0,0.9908223748207092,True,0.3775406687981454,0.6841815218094274,True
(Re)Politicizing Digital Well-Being: Beyond User Engagements,"The psychological costs of the attention economy are often considered through the binary of harmful design and healthy use, with digital well-being chiefly characterised as a matter of personal responsibility. This article adopts an interdisciplinary approach to highlight the empirical, ideological, and political limits of embedding this individualised perspective in computational discourses and designs of digital well-being measurement. We will reveal well-being to be a culturally specific and environmentally conditioned concept and will problematize user engagement as a universal proxy for well-being. Instead, the contributing factors of user well-being will be located in environing social, cultural, and political conditions far beyond the control of individual users alone. In doing so, we hope to reinvigorate the issue of digital well-being measurement as a nexus point of political concern, through which multiple disciplines can study experiences of digital ill as symptomatic of wider social inequalities and (capitalist) relations of power.",0.8,0.9145128726959229,True,0.3318122278318339,0.6231625502638783,True
'I Just Want to Hack Myself to Not Get Distracted': Evaluating Design Interventions for Self-Control on Facebook,"Beyond being the world's largest social network, Facebook is for many also one of its greatest sources of digital distraction. For students, problematic use has been associated with negative effects on academic achievement and general wellbeing. To understand what strategies could help users regain control, we investigated how simple interventions to the Facebook UI affect behaviour and perceived control. We assigned 58 university students to one of three interventions: goal reminders, removed newsfeed, or white background (control). We logged use for 6 weeks, applied interventions in the middle weeks, and administered fortnightly surveys. Both goal reminders and removed newsfeed helped participants stay on task and avoid distraction. However, goal reminders were often annoying, and removing the newsfeed made some fear missing out on information. Our findings point to future interventions such as controls for adjusting types and amount of available information, and flexible blocking which matches individual definitions of 'distraction'.",1.0,0.7226980924606323,True,0.3775406687981454,0.5501193806293889,True
Misleading Beyond Visual Tricks: How People Actually Lie with Charts,"Data visualizations can empower an audience to make informed decisions. At the same time, deceptive representations of data can lead to inaccurate interpretations while still providing an illusion of data-driven insights. Existing research on misleading visualizations primarily focuses on examples of charts and techniques previously reported to be deceptive. These approaches do not necessarily describe how charts mislead the general population in practice. We instead present an analysis of data visualizations found in a real-world discourse of a significant global event—Twitter posts with visualizations related to the COVID-19 pandemic. Our work shows that, contrary to conventional wisdom, violations of visualization design guidelines are not the dominant way people mislead with charts. Specifically, they do not disproportionately lead to reasoning errors in posters’ arguments. Through a series of examples, we present common reasoning errors and discuss how even faithfully plotted data visualizations can be used to support misinformation.",1.0,0.8252707719802856,True,0.3775406687981454,0.6014057203892156,True
Me vs. Super(wo)man: Effects of Customization and Identification in a VR Exergame,"Customised avatars are a powerful tool to increase identification, engagement and intrinsic motivation in digital games. We investigated the effects of customisation in a self-competitive VR exergame by modelling players and their previous performance in the game with customised avatars. In a first study we found that, similar to non-exertion games, customisation significantly increased identification and intrinsic motivation, as well as physical performance in the exergame. In a second study we identified a more complex relationship with the customisation style: idealised avatars increased wishful identification but decreased exergame performance compared to realistic avatars. In a third study, we found that 'enhancing' realistic avatars with idealised characteristics increased wishful identification, but did not have any adverse effects. We discuss the findings based on feedforward and self-determination theory, proposing notions of intrinsic identification (fostering a sense of self) and extrinsic identification (drawing away from the self) to explain the results.",0.8,0.9332496523857117,True,0.3318122278318339,0.6325309401087728,True
Utilizing Narrative Grounding to Design Storytelling Gamesfor Creative Foreign Language Production,"Foreign language students must learn to use language creatively to overcome knowledge gaps and keep readers or listeners interested. However, few tools exist to support practicing this skill. Therefore, we set out to explore design of storytelling games for practicing creative language use. Through an iterative design process, we identified narrative grounding (establishing common ground for collaborative narrative) as key to student engagement and learning. However, designing games for narrative grounding while keeping the game flexible enough to easily accommodate teacher goals is challenging. Considering this challenge, we designed a collaborative storytelling game where students help scaffold the narrative and teachers can easily integrate language goals with ""language cards"". In an in-classroom evaluation with 36 students, we show the importance of narrative grounding for learning. Qualitative evidence also suggests narrative grounding makes the game more engaging for players. We conclude with discussion of design implications for digital language learning tools.",1.0,0.9087169170379639,True,0.3775406687981454,0.6431287929180547,True
"AutoML in The Wild: Obstacles, Workarounds, and Expectations","Automated machine learning (AutoML) is envisioned to make ML techniques accessible to ordinary users. Recent work has investigated the role of humans in enhancing AutoML functionality throughout a standard ML workflow. However, it is also critical to understand how users adopt existing AutoML solutions in complex, real-world settings from a holistic perspective. To fill this gap, this study conducted semi-structured interviews of AutoML users (N = 19) focusing on understanding (1) the limitations of AutoML encountered by users in their real-world practices, (2) the strategies users adopt to cope with such limitations, and (3) how the limitations and workarounds impact their use of AutoML. Our findings reveal that users actively exercise user agency to overcome three major challenges arising from customizability, transparency, and privacy. Furthermore, users make cautious decisions about whether and how to apply AutoML on a case-by-case basis. Finally, we derive design implications for developing future AutoML solutions.",1.0,0.7312451004981995,True,0.3775406687981454,0.5543928846481725,True
"Hacking, Switching, Combining: Understanding and Supporting DIY Assistive Technology Design by Blind People","Existing assistive technologies (AT) often fail to support the unique needs of blind and visually impaired (BVI) people. Thus, BVI people have become domain experts in customizing and ‘hacking’ AT, creatively suiting their needs. We aim to understand this behavior in depth, and how BVI people envision creating future DIY personalized AT. We conducted a multi-part qualitative study with 12 blind participants: an interview on unique uses of AT, a two-week diary study to log use cases, and a scenario-based design session to imagine creating future technologies. We found that participants work to design new AT both implicitly through creative use cases, and explicitly through regular ideation and development. Participants envisioned creating a variety of new technologies, and we summarize expected benefits and concerns of using a DIY technology approach. From our results, we present design considerations for future DIY technology systems to support existing customization and ‘hacking’ behaviors.",1.0,0.9609047770500183,True,0.3775406687981454,0.6692227229240819,True
“Oops...”: Mobile Message Deletion in Conversation Error and Regret Remediation,"Message deletion in mobile messaging apps allows people to “unsay” things they have said. This paper explores how and why people use (or do not use) this feature within remediation strategies after a communication error is identified. We present findings from a multi-stage survey designed to explore people’s general experiences of the message deletion feature (N = 401), peoples’ experiences of using this feature during the remediation of an error (N = 70), and receivers’ perceptions around recent message deletions (N = 68). While people are typically aware of the deletion feature, it is infrequently used. When used, it is primarily done so to improve conversations by reducing confusion between conversation partners. We found people being aware of message deletions creating information-gaps which can provoke curiosity in recipients, causing them to develop narratives to help address the uncertainty. We found concerns amongst senders that these narratives would be of a negative nature, having an undesirable impact on how others perceive them. We use our findings to suggest ways in which mobile messaging apps could improve conversational experiences around erroneous and regrettable messages.",1.0,0.814556360244751,True,0.3775406687981454,0.5960485145214482,True
"How Space is Told: Linking Trajectory, Narrative, and Intent in Augmented Reality Storytelling for Cultural Heritage Sites","We report on a qualitative study in which 22 participants created Augmented Reality (AR) stories for outdoor cultural heritage sites. As storytelling is a crucial strategy for AR content aimed at providing meaningful experiences, the emphasis has been on what storytelling does, rather than how it is done, the end user’s needs prioritized over the author’s. To address this imbalance, we identify how recurring patterns in the spatial trajectories and narrative compositions of AR stories for cultural heritage sites are linked to the author’s intent and creative process: While authors tend to bind story arcs tightly to confined trajectories for narrative delivery, the need for spatial exploration results in thematic content mapped loosely onto encompassing trajectories. Based on our analysis, we present design recommendations for site-specific AR storytelling tools that can support authors in delivering their intent while leveraging the placeness of cultural heritage sites as a creative resource.",1.0,0.7619466185569763,True,0.3775406687981454,0.5697436436775609,True
StoryDrawer: A Child–AI Collaborative Drawing System to Support Children's Creative Visual Storytelling,"Visual storytelling is a new approach to creative expression based on verbal and figural creativity. The keys to visual storytelling are narrating and drawing over a period of time, which can be beneficial but also demanding on creativity for children. Informed by need-finding investigations, we developed StoryDrawer, a co-creative system that supports visual storytelling for children aged 6–10 years through collaborative drawing between children and artificial intelligence (AI). The system includes a context-based voice agent and two AI-driven collaborative strategies: the real-time transformation of children's telling into drawings, and the generation of abstract sketches with semantic similarity to existing story content. We conducted a 2 × 2 study with 64 children to evaluate the efficacy of StoryDrawer by varying the two strategies in four conditions. The results suggest that StoryDrawer provoked participants’ creative and elaborate ideas and contributed to their creative outcomes during an engaging visual storytelling experience.",1.0,0.7878808975219727,True,0.3775406687981454,0.5827107831600591,True
Magical Brush: A Symbol-Based Modern Chinese Painting System for Novices,"Modern Chinese painting is a new type of painting inherited from ancient Chinese painting. Drawing modern Chinese painting is time-consuming and laborious, which is difficult for novices to start. Symbols are fundamental components of Chinese cultural works both materially and mentally. We introduce a symbol-based modern Chinese painting system termed Magical Brush. Magical Brush combines symbolic cultural factors with AI generative models, with the attempt to help novices create a complete modern Chinese painting, learn basic ideas of Chinese paintings and obtain co-creation engagement. In user study, we compare Magical Brush to other AI and non-AI digital painting tools. Results indicate that by combining cultural factors, Magical Brush can help novices easily create modern Chinese paintings and experience the cultural connotations in the process.",1.0,0.8616479635238647,True,0.3775406687981454,0.6195943161610051,True
Scaling Creative Inspiration with Fine-Grained Functional Aspects of Ideas,"Large repositories of products, patents and scientific papers offer an opportunity for building systems that scour millions of ideas and help users discover inspirations. However, idea descriptions are typically in the form of unstructured text, lacking key structure that is required for supporting creative innovation interactions. Prior work has explored idea representations that were either limited in expressivity, required significant manual effort from users, or dependent on curated knowledge bases with poor coverage. We explore a novel representation that automatically breaks up products into fine-grained functional aspects capturing the purposes and mechanisms of ideas, and use it to support important creative innovation interactions: functional search for ideas, and exploration of the design space around a focal problem by viewing related problem perspectives pooled from across many products. In user studies, our approach boosts the quality of creative search and inspirations, substantially outperforming strong baselines by 50-60%.",1.0,0.8273249268531799,True,0.3775406687981454,0.6024327978256627,True
"Design, Mould, Grow!: A Fabrication Pipeline for Growing 3D Designs Using Myco-Materials","There is a growing interest in sustainable fabrication approaches, including the exploration of material conservation and utilisation of waste materials. Particularly, recent work has applied organic myco-materials, made from fungi, to develop tangible, interactive devices. However, a systematic approach for 3D fabrication using myco-materials is under-explored. In this paper, we present a parametric design tool and a fabrication pipeline to grow 3D designs using the mycelia of edible fungi species, such as Reishi or Oyster mushrooms. The proposed tool is designed based on empirical results from a series of technical evaluations of the geometric and material qualities of 3D-grown myco-objects. Furthermore, the paper introduces an easy-to-replicate fabrication process that can recycle different organic waste material combinations such as sawdust and coffee grounds to grow mycelia. Through a series of demonstration applications, we identify the challenges and opportunities for working with myco-materials in the HCI context.",1.3,0.8816701769828796,True,0.45016600268752216,0.6659180898352008,True
FlatMagic: Improving Flat Colorization through AI-driven Design for Digital Comic Professionals,"Creating digital comics involves multiple stages, some creative and some menial. For example, coloring a comic requires a labor-intensive stage known as ‘flatting,’ or masking segments of continuous color, as well as creative shading, lighting, and stylization stages. The use of AI can automate the colorization process, but early efforts have revealed limitations—technical and UX—to full automation. Via a formative study of professionals, we identify flatting as a bottleneck and key target of opportunity for human-guided AI-driven automation. Based on this insight, we built FlatMagic, an interactive, AI-driven flat colorization support tool for Photoshop. Our user studies found that using FlatMagic significantly reduced professionals’ real and perceived effort versus their current practice. While participants effectively used FlatMagic, we also identified potential constraints in interactions with AI and partially automated workflows. We reflect on implications for comic-focused tools and the benefits and pitfalls of intermediate representations and partial automation in designing human-AI collaboration tools for professionals.",1.0,0.940300464630127,True,0.3775406687981454,0.6589205667141362,True
Fair&Share: Fast and Fair Multi-Criteria Selections,"Traditional multi-criteria selection methods are the leading approach for selecting a set of candidates when multiple criteria determine selection relevancy. For instance, hiring platforms combine candidates' proximity, skills, and years of experience to build shortlists for recruiters. While these methods succeed in efficiently selecting candidates, their chosen set may unfairly affect marginalized candidate groups (e.g., race or gender). Bridging the gap between traditional fairness-unaware multi-criteria selection and contemporary fairness interventions, we characterize the open problem of fair multi-criteria selection. We design Fair&Share the first efficient fairness-tunable multi-criteria selection method. Fair&Share supports several fair representation notions. The key to Fair&Share is the design of its group-aware utility objective. Fair&Share uses a novel fairness calibration component to provide a user-friendly tuning mechanism for controlling the balance between selection relevancy (utility) and representation fairness. Our fairness-focused selection policy iteratively builds the result set by prioritizing candidates as aiding either the fair representation or the shared overall utility goals. We prove the optimality of Fair&Share, meaning that Fair&Share selects the best possible candidates such that the desired fair representation is achieved. Our experimental study demonstrates that Fair&Share achieves the best fairness and utility performance of state-of-the-art alternatives adapted to this new problem while taking a fraction of the time.",0.8,0.8093132376670837,True,0.3318122278318339,0.5705627327494588,True
Info-Wild: Knowledge Extraction and Management for Wildlife Conservation,"Our primary objective is to explore and enhance AI's role for wildlife conservation, in brief, Nature Through the Lens of AI. It seeks to address crucial challenges related to data heterogeneity, scale integration, data privacy, mitigating biases, and decision-making under uncertainty. This workshop is centred around leveraging AI's prowess in deciphering complex spatio-temporal data patterns for wildlife conservation, thereby contributing significantly to the broader canvas of AI for social good. The workshop intends to create an interdisciplinary platform bringing together computer scientists, data scientists, geospatial experts, ecologists, and conservation practitioners, fostering collaboration and driving real-world impact. The program will include keynote speeches, panel discussions, and interactive sessions focusing on efficient knowledge extraction and management, remote sensing technologies, predictive modeling, species distribution modeling, habitat quality assessment, and human-wildlife conflict mitigation. With an em- phasis on CIKM's primary interests, our aim is not only to enrich understanding of AI's symbiotic potential with ecology but also to utilize it to address pressing societal and environmental challenges.",1.0,0.7368178367614746,True,0.3775406687981454,0.5571792527798101,True
QALink: Enriching Text Documents with Relevant Q&A Site Contents,"With rapid development of Q&A sites such as Quora and StackExchange, high quality question-answer pairs have been produced by users. These Q&A contents cover a wide range of topics, and they are useful for users to resolve queries and obtain new knowledge. Meanwhile, when people are reading digital documents, they may encounter reading problems such as lack of background information and unclear illustration of concepts. We believe that Q&A sites offer high-quality contents which can serve as rich supplements to digital documents. In this paper, we devise a rigorous formulation of the novel text enrichment problem, and design an end-to-end system named QALink which assigns the most relevant Q&A contents to the corresponding section of the document. We first present a new segmentation approach to model each document with a hierarchical structure. Based on the hierarchy, queries are constructed to retrieve and rank related question-answer pairs. Both syntactical and semantic features are adopted in our system. The empirical evaluation results indicate that QALink is able to effectively enrich text documents with relevant Q&A contents to help people better understand the documents.",0.8,0.8470406532287598,True,0.3318122278318339,0.5894264405302968,True
Beast: Scalable Exploratory Analytics on Spatio-temporal Data,"This paper introduces the open-source Beast system for scalable exploratory data science on big spatio-temporal data. Beast is based on well-established research and has been released to assist the research community with analyzing big spatio-temporal data. Beast provides a set of extensible components that naturally integrate with Spark to build exploratory data science pipelines. Beast can install in less than a minute on an existing Spark cluster and provides a wide array of features including loading vector and raster data represented in standard file formats, synthetic data generation for benchmarking, load-balanced spatial partitioning, data summarization, interactive visualization, and more. Beast builds on several research projects; its goal is to make all this research widely available to researchers in one integrative and coherent system.",1.0,0.9529408812522888,True,0.3775406687981454,0.6652407750252172,True
What Can History Tell Us?,"Recommendation systems have been widely applied to many E-commerce and online social media platforms. Recently, sequential item recommendation, especially session-based recommendation, has aroused wide research interests. However, existing sequential recommendation approaches either ignore the historical sessions or consider all historical sessions without any distinction that whether the historical sessions are relevant or not to the current session, which motivates us to distinguish the effect of each historical session and identify relevant historical sessions for recommendation. In light of this, we propose a novel deep learning based sequential recommender framework for session-based recommendation, which takes Nonlocal Neural Network and Recurrent Neural Network as the main building blocks. Specifically, we design a two-layer nonlocal architecture to identify historical sessions that are relevant to the current session and learn the long-term user preferences mostly from these relevant sessions. Besides, we also design a gated recurrent unit (GRU) enhanced by the nonlocal structure to learn the short-term user preferences from the current session. Finally, we propose a novel approach to integrate both long-term and short-term user preferences in a unified way to facilitate training the whole recommender model in an end-to-end manner. We conduct extensive experiments on two widely used real-world datasets, and the experimental results show that our model achieves significant improvements over the state-of-the-art methods.",1.3,0.6544170379638672,True,0.45016600268752216,0.5522915203256946,True
Stop&Hop: Early Classification of Irregular Time Series,"Early classification algorithms help users react faster to their machine learning model's predictions. Early warning systems in hospitals, for example, let clinicians improve their patients' outcomes by accurately predicting infections. While early classification systems are advancing rapidly, a major gap remains: existing systems do not consider irregular time series, which have uneven and often-long gaps between their observations. Such series are notoriously pervasive in impactful domains like healthcare. We bridge this gap and study early classification of irregular time series, a new setting for early classifiers that opens doors to more real-world problems. Our solution, Stop&Hop, uses a continuous-time recurrent network to model ongoing irregular time series in real time, while an irregularity-aware halting policy, trained with reinforcement learning, predicts when to stop and classify the streaming series. By taking real-valued step sizes, the halting policy flexibly decides exactly when to stop ongoing series in real time. This way, Stop&Hop seamlessly integrates information contained in the timing of observations, a new and vital source for early classification in this setting, with the time series values to provide early classifications for irregular time series. Using four synthetic and three real-world datasets, we demonstrate that Stop&Hop consistently makes earlier and more-accurate predictions than state-of-the-art alternatives adapted to this new problem. Our code is publicly available at https://github.com/thartvigsen/StopAndHop.",0.8,0.9360439777374268,True,0.3318122278318339,0.6339281027846303,True
Learn Basic Skills and Reuse: Modularized Adaptive Neural Architecture Search (MANAS),"Human intelligence is able to first learn some basic skills for solving basic problems and then assemble such basic skills into complex skills for solving complex or new problems. For example, the basic skills ""dig hole,'' ""put tree,'' ""backfill'' and ""watering'' compose a complex skill ""plant a tree''. Besides, some basic skills can be reused for solving other problems. For example, the basic skill ""dig hole'' not only can be used for planting a tree, but also can be used for mining treasures, building a drain, or landfilling. The ability to learn basic skills and reuse them for various tasks is very important for humans because it helps to avoid learning too many skills for solving each individual task, and makes it possible to solve a compositional number of tasks by learning just a few number of basic skills, which saves a considerable amount of memory and computational power in the human brain. We believe that machine intelligence should also capture the ability of learning basic skills and reusing them by composing into complex skills. In computer science language, each basic skill is a ""module'', which is a reusable network that has a concrete meaning and performs a concrete basic operation. The modules are assembled into a bigger ""model'' for doing a more complex task. The assembling procedure is adaptive to the input or task, i.e., for a given task, the modules should be assembled into the most suitable model for solving the given task. As a result, different inputs/tasks could have different assembled models. In this work, we take recommender system as an example and propose Modularized Adaptive Neural Architecture Search (MANAS) to demonstrate the above idea. Neural Architecture Search (NAS) has shown its power in discovering superior neural architectures. However, existing NAS mostly focus on searching for a global architecture regardless of the specific input, i.e., the architecture is not adaptive to the input. In this work, we borrow the idea from modularized neural logic reasoning and consider three basic logical operation modules: AND, OR, NOT. Meanwhile, making recommendations for each user is considered as a task. MANAS automatically assembles the logical operation modules into a network architecture tailored for the given user. As a result, a personalized neural architecture is assembled for each user to make recommendations for the user, which means that the resulting neural architecture is adaptive to the model's input (i.e., the user's past behaviors). Experiments on different datasets show that the adaptive architecture assembled by MANAS outperforms static global architectures. Further experiments and empirical analysis provide insights to the effectiveness of MANAS. The code is open-source at https://github.com/TalonCB/MANAS.",0.8,0.824293315410614,True,0.3318122278318339,0.5780527716212239,True
Personalizing Task-oriented Dialog Systems via Zero-shot Generalizable Reward Function,"Task-oriented dialog systems enable users to accomplish tasks using natural language. State-of-the-art systems respond to users in the same way regardless of their personalities, although personalizing dialogues can lead to higher levels of adoption and better user experiences. Building personalized dialog systems is an important, yet challenging endeavor, and only a handful of works took on the challenge. Most existing works rely on supervised learning approaches and require laborious and expensive labeled training data for each user profile. Additionally, collecting and labeling data for each user profile is virtually impossible. In this work, we propose a novel framework, P-ToD, to personalize task-oriented dialog systems capable of adapting to a wide range of user profiles in an unsupervised fashion using a zero-shot generalizable reward function. P-ToD uses a pre-trained GPT-2 as a backbone model and works in three phases. Phase one performs task-specific training. Phase two kicks off unsupervised personalization by leveraging the proximal policy optimization algorithm that performs policy gradients guided by the zero-shot generalizable reward function. Our novel reward function can quantify the quality of the generated responses even for unseen profiles. The optional final phase fine-tunes the personalized model using a few labeled training examples. We conduct extensive experimental analysis using the personalized bAbI dialogue benchmark for five tasks and up to 180 diverse user profiles. The experimental results demonstrate that P-ToD, even when it had access to zero labeled examples, outperforms state-of-the-art supervised personalization models and achieves competitive performance on BLEU and ROUGE metrics when compared to a strong fully-supervised GPT-2 baseline.",1.0,0.7830357551574707,True,0.3775406687981454,0.5802882119778081,True
Multi-subspace Implicit Alignment for Cross-modal Retrieval on Cooking Recipes and Food Images,"Cross-modal retrieval technology can help people quickly achieve mutual information between cooking recipes and food images. Both the embeddings of the image and the recipe consist of multiple representation subspaces. We argue that multiple aspects in the recipe are related to multiple regions in the food image. It is challenging to improve the cross-modal retrieval quality by making full use of the implicit connection between multiple subspaces of recipes and images. In this paper, we propose a multi-subspace implicit alignment cross-modal retrieval framework of recipes and images. Our framework learns multi-subspace information about cooking recipes and food images with multi-head attention networks; the implicit alignment at the subspace level promotes narrowing the semantic gap between recipe embeddings and food image embeddings; triple loss and adversarial loss are combined to help our framework for cross-modal learning. The experimental results show that our framework significantly outperforms to state-of-the-art methods in terms of MedR and R@K on Recipe 1M.",1.0,0.8445479869842529,True,0.3775406687981454,0.6110443278911992,True
Creative Storytelling with Language Models and Knowledge Graphs,"Automated story generation is a popular and well-recognized task in the field of natural language processing. The emergence of pre-trained language models based on large Transformer architectures shows the great capability of text generation. However, language models are limited when the generation requires explicit clues within the context. In this research, we study how to combine knowledge graphs with language models, and build a creative story generation system named DICE. DICE uses external knowledge graphs to provide context clues and implicit knowledge to generate coherent and creative stories. The evaluation shows that our approach can effectively inject the knowledge from knowledge graphs into the stories automatically generated by the language model.",1.0,0.9779882431030273,True,0.3775406687981454,0.6777644559505864,True
A Quantum Many-body Wave Function Inspired Language Modeling Approach,"The recently proposed quantum language model (QLM) aimed at a principled approach to modeling term dependency by applying the quantum probability theory. The latest development for a more effective QLM has adopted word embeddings as a kind of global dependency information and integrated the quantum-inspired idea in a neural network architecture. While these quantum-inspired LMs are theoretically more general and also practically effective, they have two major limitations. First, they have not taken into account the interaction among words with multiple meanings, which is common and important in understanding natural language text. Second, the integration of the quantum-inspired LM with the neural network was mainly for effective training of parameters, yet lacking a theoretical foundation accounting for such integration. To address these two issues, in this paper, we propose a Quantum Many-body Wave Function (QMWF) inspired language modeling approach. The QMWF inspired LM can adopt the tensor product to model the aforesaid interaction among words. It also enables us to reveal the inherent necessity of using Convolutional Neural Network (CNN) in QMWF language modeling. Furthermore, our approach delivers a simple algorithm to represent and match text/sentence pairs. Systematic evaluation shows the effectiveness of the proposed QMWF-LM algorithm, in comparison with the state of the art quantum-inspired LMs and a couple of CNN-based methods, on three typical Question Answering (QA) datasets.",1.0,0.7488898038864136,True,0.3775406687981454,0.5632152363422795,True
IWILDS'20: The 1st International Workshop on Investigating Learning during Web Search,"Web search is one of the most ubiquitous online activities and often used for learning purposes, i.e., to extend one's knowledge or skills about certain topics or procedures. The importance of learning as an outcome of Web search has been recognized in research at the intersection of information retrieval, human-computer interaction, psychology, and educational sciences. Search as Learning (SAL) research examines relationships between querying, navigation, and reading behavior during Web search and the resulting learning outcomes, and how they can be measured, predicted, and supported. IWILDS aims to provide a platform to the interdisciplinary SAL community, with the objective to bring together interested researchers, provide room for presentation and discussion of novel research insights, and to inspire future directions of SAL research.",1.0,0.8440316319465637,True,0.3775406687981454,0.6107861503723546,True
Recipe Popularity Prediction with Deep Visual-Semantic Fusion,"Predicting the popularity of user-created recipes has great potential to be adopted in several applications on recipe-sharing websites. To ensure timely prediction when a recipe is uploaded, a prediction model needs to be trained based on the recipe's content features (i.e., its visual and semantic features). This paper presents a novel approach to predicting recipe popularity using deep visual-semantic fusion. We first pre-train a deep model that predicts the popularity of recipes based on each single modality. We insert additional layers to the two models and concatenate their activations. Finally, we train a network comprising fully connected (FC) layers on the fused features to learn more powerful features, which are used for training a regressor. Based on experiments conducted on more than 150K recipes collected from the Cookpad website, we present a comprehensive comparison with several baselines to verify the effectiveness of our method. The best practice for the proposed method is also described.",1.0,0.7539438605308533,True,0.3775406687981454,0.5657422646644994,True
Tabular Functional Block Detection with Embedding-based Agglomerative Cell Clustering,"Tables are a widely-used format for data curation. The diversity of domains, layouts, and content of tables makes knowledge extraction challenging. Understanding table layouts is an important step for automatically harvesting knowledge from tabular data. Since table cells are spatially organized into regions, correctly identifying such regions and inferring their functional roles, referred to as functional block detection, is a critical part of understanding table layouts. Earlier functional block detection approaches fail to leverage spatial relationships and higher-level structure, either depending on cell-level predictions or relying on data types as signals for identifying blocks. In this paper, we introduce a flexible functional block detection method by applying agglomerative clustering techniques which merge smaller blocks into larger blocks using two merging strategies. Our proposed method uses cell embeddings with a customized dissimilarity function which utilizes local and margin distances, as well as block coherence metrics to capture cell, block, and table scoped features. Given the diversity of tables in real-world corpora, we also introduce a sampling-based approach for automatically tuning distance thresholds for each table. Experimental results show that our method improves over the earlier state-of-the-art method in terms of several evaluation metrics.",1.0,0.7914572358131409,True,0.3775406687981454,0.5844989523056432,True
Weave&Rec: A Word Embedding based 3-D Convolutional Network for News Recommendation,"An effective news recommendation system should harness the historical information of the user based on her interactions as well as the content of the articles. In this paper we propose a novel deep learning model for news recommendation which utilizes the content of the news articles as well as the sequence in which the articles were read by the user. To model both of these information, which are essentially of different types, we propose a simple yet effective architecture which utilizes a 3-dimensional Convolutional Neural Network which takes the word embeddings of the articles present in the user history as its input. Using such a method endows the model with the capability to automatically learn spatial (features of a particular article) as well as temporal features (features across articles read by a user) which signify the interest of the user. At test time, we use this in combination with a 2-dimensional Convolutional Neural Network for recommending articles to users. On a real-world dataset our method outperformed strong baselines which also model the news recommendation problem using neural networks.",0.8,0.7991847395896912,True,0.3318122278318339,0.5654984837107625,True
THECOG 2022 - Transforms In Behavioral And Affective Computing (Revisited),"Human decision making is central in many functions across a broad spectrum of fields such as marketing, investment, smart contract formulations, political campaigns, and organizational strategic management. Behavioral economics seeks to study the psychological, cultural, and social factors contributing to decision making along reasoning. It should be highlighted here that behavioral economics do not negate classical economic theory but rather extend it in two distinct directions. First, a finer granularity can be obtained by studying the decision making process not of massive populations but instead of individuals and groups with signal estimation or deep learning techniques based on a wide array of attributes ranging from social media posts to physiological signs. Second, time becomes a critical parameter and changes to the disposition towards alternative decisions can be tracked with input-output or state space models. The primary findings so far are concepts like bounded rationality and perceived risk, while results include optimal strategies for various levels of information awareness and action strategies based on perceived loss aversion principles. From the above it follows that behavioral economics relies on deep learning, signal processing, control theory, social media analysis, affective computing, natural language processing, and gamification to name only a few fields. Therefore, it is directly tied to computer science in many ways. THECOG will be a central meeting point for researchers of various backgrounds in order to generate new interdisciplinary and groundbreaking results.",0.8,0.8268778324127197,True,0.3318122278318339,0.5793450301222768,True
ARGH!: Automated Rumor Generation Hub,"It is still challenging to effectively identify rumors due to rapid changes in people's interests and perceptions. To enhance rumor detectors, we first need to better understand which rumors are effective (in terms of bypassing detection) and their characteristics. In this paper, we introduce ARGH, a novel framework to automatically generate rumors using recent advancements in natural language processing, customized to target and generate specific topics. To show the effectiveness of ARGH, we conducted a user study with 212 participants and analyzed how well humans can detect the rumors generated by ARGH, and we also tested its performance against the state-of-the-art rumor detection model PLAN [17]. Surprisingly, the experimental results demonstrate that the generated rumors are significantly harder to identify as rumors than hand-written rumors, degrading the detection accuracy by both humans and machines by 18.87% and 17.62%, respectively. We believe that ARGH will be a useful tool to obtain high quality and evasive rumor datasets quickly, which is often a tedious and time consuming task. Further, our analysis results provide valuable insight into how to characterize evasive rumors and how they can be generated, which will help to enhance the existing rumor detection techniques.",1.3,0.8328388929367065,True,0.45016600268752216,0.6415024478121143,True
Toward an Effective Black-Box Adversarial Attack on Functional JavaScript Malware against Commercial Anti-Virus,"Machine learning has been a rising technique in signatureless malware detection and is popular in the anti-virus industry. Despite the powerful ability of machine learning, it is known to be vulnerable to attack by injecting specially crafted input noise (adversarial example). In this paper, we develop a systematic attack method that is effective, general and also efficient which automatically generates functional malware. Experiment results showed that such adversarial malware could deceive commercial anti-virus and completely defeat learning-based malware detector provided by a well-known anti-virus vendor. We further examine the effectiveness of our approach on multiple anti-virus engines on VirusTotal and investigate the transferability of our proposed method between different features and classification algorithms. Finally, we show how our attack could resist JavaScript de-obfuscation techniques.",1.0,0.8315247893333435,True,0.3775406687981454,0.6045327290657445,True
The 5th International Workshop on Mining Actionable Insights from Social Networks (MAISoN 2020): Special Edition on Dis/Misinformation Mining from Social media,"For the fifth edition of the workshop on Mining Actionable Insights from Social Networks (MAISoN), we organized a special edition with focus on dis/misinformation mining from social media, co-located with CIKM 2020. This topic has attracted a lot of interest from the community since the Coronavirus (COVID-19) epidemic has given rise to an increase of misinformation on social media. The aim of this edition was to bring together researchers from different disciplines interested in mining dis/misinformation on social media. In particular, the distinguishing focus of this special edition was its emphasis on techniques that use social media data for building diagnostic, predictive and prescriptive analysis models related to misinformation. This means that there is rigorous attention for techniques that can be used to understand how and why dis/misinformation is created and spread, to uncover hidden and unexpected aspects of dis/misinformation content, and to recommend insightful countermeasures to restrict the circulation of dis/misinformation and alleviate their negative effects.",0.8,0.8000038862228394,True,0.3318122278318339,0.5659080570273366,True
How to Find It Better?: Cross-Learning for WeChat Mini Programs,"WeChat Mini Program is a lightweight app relying on the WeChat client, which can be accessed directly from the search list without downloading and installing. Retrieval and ranking for the Mini Programs differ from traditional web search in two sides. On the one hand, as the search queries are often short and most Mini Programs contain few useful textual information, it is hard to retrieve when the user input is inaccurate. On the other hand, without user scoring and rating system like App Store and Google Play, it is hard to rank relatively better results in a more advanced position. In this paper, we propose a Cross-Learning strategy to improve the search experience, where the semantics of queries and Mini Programs are represented not by itself, but by each other. We treat the search task as an extreme multi-label classification problem where the queries are inputs and the Mini Programs are labels. We propose a N-Gram self-attention query encoder to capture the search intention behind these short queries, and carefully design the label selection strategy based on user behavior to rank higher quality Mini Programs in higher positions. Our model outperforms some state-of-the-art baselines in the offline environment, and brought improvement to our actual business in the online A/B Test, which proves the practical significance of our work.",1.1,0.7200257182121277,True,0.401312339887548,0.5606690290498378,True
Storyfinder: Personalized Knowledge Base Construction and Management by Browsing the Web,"This paper presents Storyfinder, an application which consists of a browser plugin and a web server backend with the goal to highlight and manage the information contained in web pages by combining techniques from natural language processing and visual analytics. Webpages are analyzed while visiting them by means of natural language processing components, and metadata in the form of named entities and keywords are extracted and stored for further reference. The extracted information is instantaneously highlighted in the web page and stored in a graph of entities and relations. The graph can be inspected and modified. The investigational scope can be set to a single web page, multiple web pages, or the complete set of analyzed web pages in a user's history. The graph view is designed to adhere to standards of visual analytics and information visualization. Storyfinder is available as an open source application. Its benefit for information access is evaluated in a small user study.",1.0,0.7750338912010193,True,0.3775406687981454,0.5762872799995824,True
Now You See Me (CME): Concept-based Model Extraction,"Deep Neural Networks (DNNs) have achieved remarkable performance on a range of tasks. A key step to further empowering DNN-based approaches is improving their explainability. In this work we present CME: a concept-based model extraction framework, used for analysing DNN models via concept-based extracted models. Using two case studies (dSprites, and Caltech UCSD Birds), we demonstrate how CME can be used to (i) analyse the concept information learned by a DNN model (ii) analyse how a DNN uses this concept information when predicting output labels (iii) identify key concept information that can further improve DNN predictive performance (for one of the case studies, we showed how model accuracy can be improved by over 14%, using only 30% of the available concepts).",0.8,0.7751524448394775,True,0.3318122278318339,0.5534823363356557,True
Does That Mean You're Happy?: RNN-based Modeling of User Interaction Sequences to Detect Good Abandonment,"Queries for which there are no clicks are known as abandoned queries. Differentiating between good and bad abandonment queries has become an important task in search engine evaluation since it allows for better measurement of search engine features that do not require users to click. Examples of these features include answers on the SERP and detailed Web result snippets. In this paper, we investigate how sequences of user interactions on the SERP differ between good and bad abandonment. To do this, we study the behavior patterns on a labeled dataset of abandoned queries and find that they differ in several ways, such as in the number of user interactions and the nature of those interactions. Based on this insight, we frame good abandonment detection as a sequence classification problem. We use a Long Short-Term Memory (LSTM) Recurrent Neural Network (RNN) to model the sequence of user interactions and show that it performs significantly better than other baselines when detecting good abandonment, achieving 71% accuracy. Our findings have implications for search engine evaluation.",1.1,0.8652533888816833,True,0.401312339887548,0.6332828643846157,True
gFOV: A Full-Stack SPARQL Query Optimizer & Plan Visualizer,"SPARQL is the standard query language for RDF data. A SPARQL query consists of basic graph patterns (BGPs), which are matched onto the data graph, and graph pattern operators, which specify how to merge the matched results. Despite the prevalence of graph pattern operators in real-world SPARQL workloads, the optimization of SPARQL queries with graph pattern operators has scarcely been studied. We hence propose gFOV, a full-stack SPARQL query optimizer and plan visualizer targeting both BGPs and graph pattern operators. As its basis, we propose a novel BGP-based evaluation tree (BE-tree) plan representation for SPARQL queries that integrates the physical plan for BGPs, which directly accesses the RDF store, and the logical plan for graph pattern operators, which operates on existent results in memory. On top of it, we devise a full-stack cost-based optimization scheme, combining logical and physical plan optimization, that outperforms the state-of-the-art. In the demonstration, we present an interactive interface that explains our optimization scheme and shows its efficiency by visualizing changes in the query plan and allowing the audience to inspect and execute alternative plans.",0.8,0.848288357257843,True,0.3318122278318339,0.5900502925448384,True
How Safe is Your (Taxi) Driver?,"For an auto insurer, understanding the risk of individual drivers is a critical factor in building a healthy and profitable portfolio. For decades, assessing the risk of drivers has relied on demographic information which allows the insurer to segment the market in several risk groups priced with an appropriate premium. In the recent years, however, some insurers started experimenting with so called Usage-Based Insurance (UBI) in which the insurer monitors a number of additional variables (mostly related to the location) and uses them to better assess the risk of the drivers. While several studies have reported results on the UBI trials these studies keep the studied data confidential (for obvious privacy and business concerns) which inevitably limits their reproducibility and interest by the data-mining community. In this paper we discuss a methodology for studying driver risk assessment using a public dataset of 173M taxi rides in NYC with over 40K drivers. Our approach for risk assessment utilizes not only the location data (which is significantly sparser than what is normally exploited in UBI) but also the revenue, tips and overall activity of the drivers (as proxies of their behavioral traits) and obtain risk scoring accuracy on par with the reported results on non-professional driver cohorts in spite of sparser location data and no demographic information about the drivers.",1.1,0.8764037489891052,True,0.401312339887548,0.6388580444383266,True
tHoops: A Multi-Aspect Analytical Framework for Spatio-Temporal Basketball Data,"During the past few years advancements in sports information systems and technology has allowed the collection of a number of detailed spatio-temporal data that capture various aspects of basketball. For example, shot charts, that is, maps capturing locations of (made or missed) shots, and spatio-temporal trajectories for the players on the court can capture information about the offensive and defensive tendencies, as well as, schemes used by a team. Characterization of these processes is important for player and team comparisons, scouting, game preparation etc. Team and player tendencies have traditionally been compared in a heuristic manner, which inevitably can lead to subtle but crucial information being ignored. Recently automated ways for these comparisons have appeared in the sports analytics literature. However, these approaches are almost exclusively focused on the spatial distribution of the underlying actions (usually shots taken), ignoring a multitude of other parameters that can affect the action studied. In this study, we propose a framework based on tensor decomposition for obtaining a set of prototype spatio-temporal patterns based on the core spatio-temporal information and contextual meta-data. At the epicenter of our work is a 3D tensor $\tensor$, whose dimensions represent the entity under consideration (team, player, possession etc.), the location on the court and time. We make use of the PARAFAC decomposition and we decompose the tensor into several interpretable patterns, that can be thought of as prototype patterns of the process examined (e.g., shot selection, offensive schemes etc.). We also introduce an approach for choosing the number of components to be considered. Using the tensor components, we can then express every entity as a weighted combination of these components. Finally, the framework introduced in this paper has applications that go beyond purely pattern analysis. In particular, it can facilitate a variety of tasks in the work-flow of a franchise's basketball operations as well as in the sports analytics research community.",1.0,0.9174823760986328,True,0.3775406687981454,0.6475115224483892,True
Who is Delivering My Food?: Detecting Food Delivery Abusers using Variational Reward Inference Networks,"The recent paramount success of the gig economy has introduced new business opportunities in different areas such as food delivery service. However, there are food delivery ride abusers who break the company rule by driving unauthorized vehicles that are not stated in the contract. These abusers are particularly problematic because they break the transportation regulations and unfairly take more orders. However, detecting these abusers are challenging because of lack of labeled datasets and these anomalous abusers do not frequently occur compared to normal riders. Furthermore, sequential patterns of abusing behaviors are not easy to model. In this work, we aim to detect food delivery abusers using unauthorized vehicles, by formulating this problem as a novelty detection over sequential data. We propose the Variational Reward Inference based Novelty Detector (VRIND) using sequential novelty detection using inverse reinforcement learning with variational inference, in which the reward function can learn the behavioral intention of decision-making experts. The reward function is represented by a neural network that is capable of approximating reward distributions by variational reward inference. Using a commercial food delivery trajectory dataset from our company, we demonstrate that our model significantly outperforms over the other baseline methods in identifying novelty (abusers) in sequential data, which can ensure regulatory compliance and provide the fair opportunity to more than 100 thousand delivery riders, serving more than 1.5 million daily transactions in our Baemin food delivery system.",1.1,0.7758681774139404,True,0.401312339887548,0.5885902586507442,True
Generating Persuasive Visual Storylines for Promotional Videos,"Video contents have become a critical tool for promoting products in E-commerce. However, the lack of automatic promotional video generation solutions makes large-scale video-based promotion campaigns infeasible. The first step of automatically producing promotional videos is to generate visual storylines, which is to select the building block footage and place them in an appropriate order. This task is related to the subjective viewing experience. It is hitherto performed by human experts and thus, hard to scale. To address this problem, we propose WundtBackpack, an algorithmic approach to generate storylines based on available visual materials, which can be video clips or images. It consists of two main parts, 1) the Learnable Wundt Curve to evaluate the perceived persuasiveness based on the stimulus intensity of a sequence of visual materials, which only requires a small volume of data to train; and 2) a clustering-based backpacking algorithm to generate persuasive sequences of visual materials while considering video length constraints. In this way, the proposed approach provides a dynamic structure to empower artificial intelligence (AI) to organize video footage in order to construct a sequence of visual stimuli with persuasive power. Extensive real-world experiments show that our approach achieves close to 10% higher perceived persuasiveness scores by human testers, and 12.5% higher expected revenue compared to the best performing state-of-the-art approach.",1.0,0.7765344977378845,True,0.3775406687981454,0.577037583268015,True
Every Word has its History: Interactive Exploration and Visualization of Word Sense Evolution,"Human language constantly evolves due to the changing world and the need for easier forms of expression and communication. Our knowledge of language evolution is however still fragmentary despite significant interest of both researchers as well as wider public in the evolution of language. In this paper, we present an interactive framework that permits users study the evolution of words and concepts. The system we propose offers a rich online interface allowing arbitrary queries and complex analytics over large scale historical textual data, letting users investigate changes in meaning, context and word relationships across time.",1.0,0.7456244826316833,True,0.3775406687981454,0.5615825757149144,True
"Can We Have Both Fish and Bear's Paw?: Improving Performance, Reliability, and both of them for Relation Extraction under Label Shift","Neural Relation Extraction (RE) models need large amounts of labeled data for effective training, which mainly comes from automatically labeling by Distant Supervision (DS). Though fast and easy, the label shift problem inevitably happens, i.e., the label distribution of DS-generated training set is quite different from that of the real world (i.e. test set). According to our observations, label shift not only leads to performance diminishment, but also hinders the reliability of DS-RE models by causing bad confidence estimation. In this paper, we make contributions by answering the following three questions: 1) How to improve performance of DS-RE models under label shift? 2) How to make sure their reliability under label shift? 3) How to improve both performance and reliability for DS-RE models under label shift? To the best of our knowledge, this is the first paper to study the performance as well as reliability of DS-RE models under label shift. Experiment results show significant improvements on two real-world datasets and six popular neural RE models, making a step further towards high-performance and reliable RE system under real-world label-shift conditions.",1.1,0.9278789758682251,True,0.401312339887548,0.6645956578778865,True
A Multi-Interest Evolution Story: Applying Psychology in Query-based Recommendation for Inferring Customer Intention,"The query-based recommendation now is becoming a basic research topic in the e-commerce scenario. Generally, given a query that a user typed, it aims to provide a set of items that the user may be interested in. In this task, the customer intention (i.e., browsing or purchase) is an important factor to configure the corresponding recommendation strategy for better shopping experiences (i.e., providing diverse items when the user prefers to browse or recommending specific items when detecting the user is willing to purchase). Though necessary, this is usually overlooked in previous works. In addition, the diversity and evolution of user interests also bring challenges to inferring user intentions correctly. In this paper, we propose a predecessor task to infer two important customer intentions, which are purchasing and browsing respectively, and we introduce a novel Psychological Intention Prediction Model (PIPM for short) to address this issue. Inspired by cognitive psychology, we first devise a multi-interest extraction module to adaptively extract interests from the user-item interaction sequence. After this, we design an interest evolution layer to model the evolution of the mined multiple interests. Finally, we aggregate all evolved multiple interests to infer users' intentions in his/her next visit. Extensive experiments are conducted on a large-scale Taobao industrial dataset. The results demonstrate that PIPM gains a significant improvement on AUC and GAUC than state-of-the-art baselines. Notably, PIPM has been deployed on the Taobao e-commerce platform and obtained over 10% improvement on PCTR.",1.0,0.8472035527229309,True,0.3775406687981454,0.6123721107605382,True
Discovering Urban Functions of High-Definition Zoning with Continuous Human Traces,"Identifying the dynamic functions of different urban zones enables a variety of smart city applications, such as intelligent urban planning, real-time traffic scheduling, and community precision management. Traditional urban function research using government administrative zoning systems is often conducted in a coarse resolution with fixed split, and ignore the reshaping of zones by city growth. To solve this problem, we propose a two-stage framework in order to represent the high-definition distribution of urban function across the city, by analyzing continuous human traces extracted from the dense, widespread, and full-time cellular data. At the representation stage, we embed the locations of base stations by modeling the user movements with staying and transfer events, along with the consideration of dynamic trip purposes in continuous human traces. At the annotation stage, we first divide the city into the finest unit zones and each covers at least one base station. By clustering the base stations, we further group the unit zones into functional zones. Last, we annotate functional zones based on the local point-of-interest (POI) information. In experiments, we evaluate the proposed high-definition function study in two tasks: (i) in-zone crowd flow prediction, and (ii) zone-enhanced POI recommendation. The results demonstrate the advantage of the proposed method with both the effectiveness of city split and the high-quality function annotation.",1.0,0.7690553069114685,True,0.3775406687981454,0.573297987854807,True
Is It Enough Just Looking at the Title?: Leveraging Body Text To Enrich Title Words Towards Accurate News Recommendation,"In a news recommender system, a user tends to click on a news article if she is interested in its topic understood by looking at its title. Such a behavior is possible since, when viewing the title, humans naturally think of the contextual meaning of each title word by leveraging their own background knowledge. Motivated by this, we propose a novel personalized news recommendation framework CAST (Context-aware Attention network with a Selection module for Title word representation), which is capable of enriching title words by leveraging body text that fully provides the whole content of a given article as the context. Through extensive experiments, we demonstrate (1) the effectiveness of core modules in CAST, (2) the superiority of CAST over 9 state-of-the-art news recommendation methods, and (3) the interpretability with CAST.",1.1,0.7661977410316467,True,0.401312339887548,0.5837550404595974,True
"Characteristic Functions on Graphs: Birds of a Feather, from Statistical Descriptors to Parametric Models","In this paper, we propose a flexible notion of characteristic functions defined on graph vertices to describe the distribution of vertex features at multiple scales. We introduce FEATHER, a computationally efficient algorithm to calculate a specific variant of these characteristic functions where the probability weights of the characteristic function are defined as the transition probabilities of random walks. We argue that features extracted by this procedure are useful for node level machine learning tasks. We discuss the pooling of these node representations, resulting in compact descriptors of graphs that can serve as features for graph classification algorithms. We analytically prove that FEATHER describes isomorphic graphs with the same representation and exhibits robustness to data corruption. Using the node feature characteristic functions we define parametric models where evaluation points of the functions are learned parameters of supervised classifiers. Experiments on real world large datasets show that our proposed algorithm creates high quality representations, performs transfer learning efficiently, exhibits robustness to hyperparameter changes and scales linearly with the input size.",1.0,0.9249390959739685,True,0.3775406687981454,0.651239882386057,True
Modeling Menu Bundle Designs of Crowdfunding Projects,"Offering products in the forms of menu bundles is a common practice in marketing to attract customers and maximize revenues. In crowdfunding platforms such as Kickstarter, rewards also play an important part in influencing project success. Designing rewards consisting of the appropriate items is a challenging yet crucial task for the project creators. However, prior research has not considered the strategies project creators take to offer and bundle the rewards, making it hard to study the impact of reward designs on project success. In this paper, we raise a novel research question: understanding project creators' decisions of reward designs to level their chance to succeed. We approach this by modeling the design behavior of project creators, and identifying the behaviors that lead to project success. We propose a probabilistic generative model, Menu-Offering-Bundle (MOB) model, to capture the offering and bundling decisions of project creators based on collected data of 14K crowdfunding projects and their 149K reward bundles across a half-year period. Our proposed model is shown to capture the offering and bundling topics, outperform the baselines in predicting reward designs. We also find that the learned offering and bundling topics carry distinguishable meanings and provide insights of key factors on project success.",1.0,0.8191874027252197,True,0.3775406687981454,0.5983640357616826,True
#StayHome or #Marathon?: Social Media Enhanced Pandemic Surveillance on Spatial-temporal Dynamic Graphs,"COVID-19 has caused lasting damage to almost every domain in public health, society, and economy. To monitor the pandemic trend, existing studies rely on the aggregation of traditional statistical models and epidemic spread theory. In other words, historical statistics of COVID-19, as well as the population mobility data, become the essential knowledge for monitoring the pandemic trend. However, these solutions can barely provide precise prediction and satisfactory explanations on the long-term disease surveillance while the ubiquitous social media resources can be the key enabler for solving this problem. For example, serious discussions may occur on social media before and after some breaking events take place. To take advantage of the social media data, we propose a novel framework, Social Media enhAnced pandemic suRveillance Technique (SMART), which is composed of two modules: (i) information extraction module to construct heterogeneous knowledge graphs based on the extracted events and relationships among them; (ii) time series prediction module to provide both short-term and long-term forecasts of the confirmed cases and fatality at the state-level in the United States and to discover risk factors for COVID-19 interventions. Extensive experiments show that our method largely outperforms the state-of-the-art baselines by 7.3% and 7.4% in confirmed case/fatality prediction, respectively.",1.1,0.9308065176010132,True,0.401312339887548,0.6660594287442806,True
Cautiously Optimistic Policy Optimization and Exploration with Linear Function Approximation,"Policy optimization methods are popular reinforcement learning algorithms, because their incremental and on-policy nature makes them more stable than the value-based counterparts. However, the same properties also make them slow to converge and sample inefficient, as the on-policy requirement precludes data reuse and the incremental updates couple large iteration complexity into the sample complexity. These characteristics have been observed in experiments as well as in theory in the recent work of Agarwal et al. (2020a), which provides a policy optimization method PC-PG that can robustly find near optimal polices for approximately linear Markov decision processes but suffers from an extremely poor sample complexity compared with value-based techniques. In this paper, we propose a new algorithm, COPOE, that overcomes the sample complexity issue of PC-PG while retaining its robustness to model misspecification. Compared with PC-PG, COPOE makes several important algorithmic enhancements, such as enabling data reuse, and uses more refined analysis techniques, which we expect to be more broadly applicable to designing new reinforcement learning algorithms. The result is an improvement in sample complexity from Õ(1/ǫ) for PC-PG to Õ(1/ǫ) for COPOE, nearly bridging the gap with value-based techniques.",1.0,0.7536896467208862,True,0.3775406687981454,0.5656151577595159,True
An $\widetilde\mathcalO(m/\varepsilon^3.5)$-Cost Algorithm for Semidefinite Programs with Diagonal Constraints,"We study semidefinite programs with diagonal constraints. This problem class appears in combinatorial optimization and has a wide range of engineering applications such as in circuit design, channel assignment in wireless networks, phase recovery, covariance matrix estimation, and low-order controller design. 
In this paper, we give an algorithm to solve this problem to $\varepsilon$-accuracy, with a run time of $\widetilde{\mathcal{O}}(m/\varepsilon^{3.5})$, where $m$ is the number of non-zero entries in the cost matrix. We improve upon the previous best run time of $\widetilde{\mathcal{O}}(m/\varepsilon^{4.5})$ by Arora and Kale. As a corollary of our result, given an instance of the Max-Cut problem with $n$ vertices and $m \gg n$ edges, our algorithm when applied to the standard SDP relaxation of Max-Cut returns a $(1 - \varepsilon)\alpha_{GW}$ cut in time $\widetilde{\mathcal{O}}(m/\varepsilon^{3.5})$, where $\alpha_{GW} \approx 0.878567$ is the Goemans-Williamson approximation ratio. We obtain this run time via the stochastic variance reduction framework applied to the Arora-Kale algorithm, by constructing a constant-accuracy estimator to maintain the primal iterates.",0.8,0.784776508808136,True,0.3318122278318339,0.5582943683199849,True
Breaking the Lower Bound with (Little) Structure: Acceleration in Non-Convex Stochastic Optimization with Heavy-Tailed Noise,"We consider the stochastic optimization problem with smooth but not necessarily convex objectives in the heavy-tailed noise regime, where the stochastic gradient's noise is assumed to have bounded $p$th moment ($p\in(1,2]$). Zhang et al. (2020) is the first to prove the $\Omega(T^{\frac{1-p}{3p-2}})$ lower bound for convergence (in expectation) and provides a simple clipping algorithm that matches this optimal rate. Cutkosky and Mehta (2021) proposes another algorithm, which is shown to achieve the nearly optimal high-probability convergence guarantee $O(\log(T/\delta)T^{\frac{1-p}{3p-2}})$, where $\delta$ is the probability of failure. However, this desirable guarantee is only established under the additional assumption that the stochastic gradient itself is bounded in $p$th moment, which fails to hold even for quadratic objectives and centered Gaussian noise. In this work, we first improve the analysis of the algorithm in Cutkosky and Mehta (2021) to obtain the same nearly optimal high-probability convergence rate $O(\log(T/\delta)T^{\frac{1-p}{3p-2}})$, without the above-mentioned restrictive assumption. Next, and curiously, we show that one can achieve a faster rate than that dictated by the lower bound $\Omega(T^{\frac{1-p}{3p-2}})$ with only a tiny bit of structure, i.e., when the objective function $F(x)$ is assumed to be in the form of $\mathbb{E}_{\Xi\sim\mathcal{D}}[f(x,\Xi)]$, arguably the most widely applicable class of stochastic optimization problems. For this class of problems, we propose the first variance-reduced accelerated algorithm and establish that it guarantees a high-probability convergence rate of $O(\log(T/\delta)T^{\frac{1-p}{2p-1}})$ under a mild condition, which is faster than $\Omega(T^{\frac{1-p}{3p-2}})$. Notably, even when specialized to the finite-variance case, our result yields the (near-)optimal high-probability rate $O(\log(T/\delta)T^{-1/3})$.",0.8,0.7942827343940735,True,0.3318122278318339,0.5630474811129537,True
The merged-staircase property: a necessary and nearly sufficient condition for SGD learning of sparse functions on two-layer neural networks,"It is currently known how to characterize functions that neural networks can learn with SGD for two extremal parameterizations: neural networks in the linear regime, and neural networks with no structural constraints. However, for the main parametrization of interest (non-linear but regular networks) no tight characterization has yet been achieved, despite significant developments. We take a step in this direction by considering depth-2 neural networks trained by SGD in the mean-field regime. We consider functions on binary inputs that depend on a latent low-dimensional subspace (i.e., small number of coordinates). This regime is of interest since it is poorly understood how neural networks routinely tackle high-dimensional datasets and adapt to latent low-dimensional structure without suffering from the curse of dimensionality. Accordingly, we study SGD-learnability with $O(d)$ sample complexity in a large ambient dimension $d$. Our main results characterize a hierarchical property, the""merged-staircase property"", that is both necessary and nearly sufficient for learning in this setting. We further show that non-linear training is necessary: for this class of functions, linear methods on any feature map (e.g., the NTK) are not capable of learning efficiently. The key tools are a new""dimension-free""dynamics approximation result that applies to functions defined on a latent space of low-dimension, a proof of global convergence based on polynomial identity testing, and an improvement of lower bounds against linear methods for non-almost orthogonal functions.",1.0,0.7749585509300232,True,0.3775406687981454,0.5762496098640844,True
Exponential Hardness of Reinforcement Learning with Linear Function Approximation,"A fundamental question in reinforcement learning theory is: suppose the optimal value functions are linear in given features, can we learn them efficiently? This problem's counterpart in supervised learning, linear regression, can be solved both statistically and computationally efficiently. Therefore, it was quite surprising when a recent work \cite{kane2022computational} showed a computational-statistical gap for linear reinforcement learning: even though there are polynomial sample-complexity algorithms, unless NP = RP, there are no polynomial time algorithms for this setting. In this work, we build on their result to show a computational lower bound, which is exponential in feature dimension and horizon, for linear reinforcement learning under the Randomized Exponential Time Hypothesis. To prove this we build a round-based game where in each round the learner is searching for an unknown vector in a unit hypercube. The rewards in this game are chosen such that if the learner achieves large reward, then the learner's actions can be used to simulate solving a variant of 3-SAT, where (a) each variable shows up in a bounded number of clauses (b) if an instance has no solutions then it also has no solutions that satisfy more than (1-$\epsilon$)-fraction of clauses. We use standard reductions to show this 3-SAT variant is approximately as hard as 3-SAT. Finally, we also show a lower bound optimized for horizon dependence that almost matches the best known upper bound of $\exp(\sqrt{H})$.",1.0,0.7720125317573547,True,0.3775406687981454,0.5747766002777501,True
How do infinite width bounded norm networks look in function space?,"We consider the question of what functions can be captured by ReLU networks with an unbounded number of units (infinite width), but where the overall network Euclidean norm (sum of squares of all weights in the system, except for an unregularized bias term for each unit) is bounded; or equivalently what is the minimal norm required to approximate a given function. For functions $f : \mathbb R \rightarrow \mathbb R$ and a single hidden layer, we show that the minimal network norm for representing $f$ is $\max(\int |f''(x)| dx, |f'(-\infty) + f'(+\infty)|)$, and hence the minimal norm fit for a sample is given by a linear spline interpolation.",1.3,0.8402668237686157,True,0.45016600268752216,0.6452164132280689,True
"Contextual Bandits with Continuous Actions: Smoothing, Zooming, and Adapting","We study contextual bandit learning with an abstract policy class and continuous action space. We obtain two qualitatively different regret bounds: one competes with a smoothed version of the policy class under no continuity assumptions, while the other requires standard Lipschitz assumptions. Both bounds exhibit data-dependent ""zooming"" behavior and, with no tuning, yield improved guarantees for benign problems. We also study adapting to unknown smoothness parameters, establishing a price-of-adaptivity and deriving optimal adaptive algorithms that require no additional information.",1.0,0.9710720777511597,True,0.3775406687981454,0.6743063732746526,True
"Open problem: log(n) factor in ""Local Glivenko-Cantelli","Can the log( n ) factor in the upper bound of Cohen and Kontorovich (COLT, 2023) be removed? Introduction. Cohen and Kontorovich (2023) considered the following problem. Let Y j , j ∈ N be a sequence of independent Binomial( n, p j ) random variables, where n ∈ N and p j ↓ 0 as j → ∞ . Since E Y j = np j , let us consider the centered, normalized process ¯ Y j := n − 1 Y j − p j . Finally, we define ∆ n to be the expected uniform absolute deviation:",0.8,0.7858896851539612,True,0.3318122278318339,0.5588509564928975,True
An $\widetilde\mathcal{O}(m/\varepsilon^3.5)$-Cost Algorithm for Semidefinite Programs with Diagonal Constraints,,0.8,0.8101781606674194,True,0.3318122278318339,0.5709951942496266,True
Best of both worlds: Stochastic & adversarial best-arm identification,"We study bandit best-arm identification with arbitrary and potentially adversarial rewards. A simple random uniform learner obtains the optimal rate of error in the adversarial scenario. However, this type of strategy is suboptimal when the rewards are sampled stochastically. Therefore, we ask: Can we design a learner that performs optimally in both the stochastic and adversarial problems while not being aware of the nature of the rewards? First, we show that designing such a learner is impossible in general. In particular, to be robust to adversarial rewards, we can only guarantee optimal rates of error on a subset of the stochastic problems. We give a lower bound that characterizes the optimal rate in stochastic problems if the strategy is constrained to be robust to adversarial rewards. Finally, we design a simple parameter-free algorithm and show that its probability of error matches (up to log factors) the lower bound in stochastic problems, and it is also robust to adversarial ones.",0.8,0.9460996985435486,True,0.3318122278318339,0.6389559631876912,True
Is your function low dimensional?,"We study the problem of testing if a function depends on a small number of linear directions of its input data. We call a function $f$ a linear $k$-junta if it is completely determined by some $k$-dimensional subspace of the input space. In this paper, we study the problem of testing whether a given $n$ variable function $f : \mathbb{R}^n \to \{0,1\}$, is a linear $k$-junta or $\epsilon$-far from all linear $k$-juntas, where the closeness is measured with respect to the Gaussian measure on $\mathbb{R}^n$. Linear $k$-juntas are a common generalization of two fundamental classes from Boolean function analysis (both of which have been studied in property testing) $\textbf{1.}$ $k$- juntas which are functions on the Boolean cube which depend on at most k of the variables and $\textbf{2.}$ intersection of $k$ halfspaces, a fundamental geometric concept class. 
We show that the class of linear $k$-juntas is not testable, but adding a surface area constraint makes it testable: we give a $\mathsf{poly}(k \cdot s/\epsilon)$-query non-adaptive tester for linear $k$-juntas with surface area at most $s$. We show that the polynomial dependence on $s$ is necessary. Moreover, we show that if the function is a linear $k$-junta with surface area at most $s$, we give a $(s \cdot k)^{O(k)}$-query non-adaptive algorithm to learn the function up to a rotation of the basis. In particular, this implies that we can test the class of intersections of $k$ halfspaces in $\mathbb{R}^n$ with query complexity independent of $n$.",1.3,0.6531492471694946,True,0.45016600268752216,0.5516576249285083,True
Stochastic Approximation of Smooth and Strongly Convex Functions: Beyond the O(1/T) Convergence Rate,"Stochastic approximation (SA) is a classical approach for stochastic convex optimization. Previous studies have demonstrated that the convergence rate of SA can be improved by introducing either smoothness or strong convexity condition. In this paper, we make use of smoothness and strong convexity simultaneously to boost the convergence rate. Let $\lambda$ be the modulus of strong convexity, $\kappa$ be the condition number, $F_*$ be the minimal risk, and $\alpha>1$ be some small constant. First, we demonstrate that, in expectation, an $O(1/[\lambda T^\alpha] + \kappa F_*/T)$ risk bound is attainable when $T = \Omega(\kappa^\alpha)$. Thus, when $F_*$ is small, the convergence rate could be faster than $O(1/[\lambda T])$ and approaches $O(1/[\lambda T^\alpha])$ in the ideal case. Second, to further benefit from small risk, we show that, in expectation, an $O(1/2^{T/\kappa}+F_*)$ risk bound is achievable. Thus, the excess risk reduces exponentially until reaching $O(F_*)$, and if $F_*=0$, we obtain a global linear convergence. Finally, we emphasize that our proof is constructive and each risk bound is equipped with an efficient stochastic algorithm attaining that bound.",1.8,0.6778176426887512,True,0.574442516811659,0.6261300797502052,True
Chasing Convex Bodies and Functions with Black-Box Advice,"We consider the problem of convex function chasing with black-box advice, where an online decision-maker aims to minimize the total cost of making and switching between decisions in a normed vector space, aided by black-box advice such as the decisions of a machine-learned algorithm. The decision-maker seeks cost comparable to the advice when it performs well, known as $\textit{consistency}$, while also ensuring worst-case $\textit{robustness}$ even when the advice is adversarial. We first consider the common paradigm of algorithms that switch between the decisions of the advice and a competitive algorithm, showing that no algorithm in this class can improve upon 3-consistency while staying robust. We then propose two novel algorithms that bypass this limitation by exploiting the problem's convexity. The first, INTERP, achieves $(\sqrt{2}+\epsilon)$-consistency and $\mathcal{O}(\frac{C}{\epsilon^2})$-robustness for any $\epsilon>0$, where $C$ is the competitive ratio of an algorithm for convex function chasing or a subclass thereof. The second, BDINTERP, achieves $(1+\epsilon)$-consistency and $\mathcal{O}(\frac{CD}{\epsilon})$-robustness when the problem has bounded diameter $D$. Further, we show that BDINTERP achieves near-optimal consistency-robustness trade-off for the special case where cost functions are $\alpha$-polyhedral.",1.0,0.7613584399223328,True,0.3775406687981454,0.5694495543602391,True
Dimension-Free Bounds on Chasing Convex Functions,"We consider the problem of chasing convex functions, where functions arrive over time. The player takes actions after seeing the function, and the goal is to achieve a small function cost for these actions, as well as a small cost for moving between actions. While the general problem requires a polynomial dependence on the dimension, we show how to get dimension-independent bounds for well-behaved functions. In particular, we consider the case where the convex functions are $\kappa$-well-conditioned, and give an algorithm that achieves an $O(\sqrt \kappa)$-competitiveness. Moreover, when the functions are supported on $k$-dimensional affine subspaces--e.g., when the function are the indicators of some affine subspaces--we get $O(\min(k, \sqrt{k \log T}))$-competitive algorithms for request sequences of length $T$. We also show some lower bounds, that well-conditioned functions require $\Omega(\kappa^{1/3})$-competitiveness, and $k$-dimensional functions require $\Omega(\sqrt{k})$-competitiveness.",1.0,0.7603979706764221,True,0.3775406687981454,0.5689693197372838,True
"Amplifying the Security of Functional Encryption, Unconditionally",,1.0,0.8838696479797363,True,0.3775406687981454,0.6307051583889409,True
All-But-Many Lossy Trapdoor Functions and Selective Opening Chosen-Ciphertext Security from LWE,"Selective opening (SO) security refers to adversaries that receive a number of ciphertexts and, after having corrupted a subset of the senders (thus obtaining the plaintexts and the senders' random coins), aim at breaking the security of remaining ciphertexts. So far, very few public-key encryption schemes are known to provide simulation-based selective opening (SIM-SO-CCA2) security under chosen-ciphertext attacks and most of them encrypt messages bit-wise. The only exceptions to date rely on all-but-many lossy trapdoor functions (as introduced by Hofheinz; Eurocrypt'12) and the Composite Residuosity assumption. In this paper, we describe the first all-but-many lossy trapdoor function with security relying on the presumed hardness of the Learning-With-Errors problem (LWE) with standard parameters. Our construction exploits homomorphic computations on lattice trapdoors for lossy LWE matrices. By carefully embedding a lattice trapdoor in lossy public keys, we are able to prove SIM-SO-CCA2 security under the LWE assumption. As a result of independent interest, we describe a variant of our scheme whose multi-challenge CCA2 security tightly relates to the hardness of LWE and the security of a pseudo-random function.",1.0,0.8455238938331604,True,0.3775406687981454,0.611532281315653,True
New Design Techniques for Efficient Arithmetization-Oriented Hash Functions: ttAnemoi Permutations and ttJive Compression Mode,,1.0,0.9645593166351318,True,0.3775406687981454,0.6710499927166387,True
Alzette: A 64-Bit ARX-box - (Feat. CRAX and TRAX),", Abstract. S-boxes are the only source of non-linearity in many symmetric primitives. While they are often deﬁned as being functions operating on a small space, some recent designs propose the use of much larger ones (e.g., 32 bits). In this context, an S-box is then deﬁned as a subfunction whose cryptographic properties can be estimated precisely. We present a 64-bit ARX-based S-box called Alzette , which can be evaluated in constant time using only 12 instructions on modern CPUs. Its parallel application can also leverage vector (SIMD) instructions. One iteration of Alzette has diﬀerential and linear properties comparable to those of the AES S-box, and two are at least as secure as the AES super S-box. As the state size is much larger than the typical 4 or 8 bits, the study of the relevant cryptographic properties of Alzette is not trivial. We further discuss how such wide S-boxes could be used to construct round functions of 64-, 128- and 256-bit (tweakable) block ciphers with good cryptographic properties that are guaranteed even in the related-tweak setting. We use these structures to design a very lightweight 64-bit block cipher ( Crax ) which outperforms SPECK-64/128 for short messages on micro-controllers, and a 256-bit tweakable block cipher ( Trax ) which can be used to obtain strong security guarantees against powerful adversaries (nonce misuse, quantum attacks).",0.8,0.8484683632850647,True,0.3318122278318339,0.5901402955584493,True
Compressed E-protocol Theory and Practical Applications to Plug & Play Algorithms,,0.8,0.9712634086608887,True,0.3318122278318339,0.6515378182463613,True
Superposition Meet-in-the-Middle Attacks: Updates on Fundamental Security of AES-like Hashing,,1.0,0.8368903398513794,True,0.3775406687981454,0.6072155043247625,True
Puncturable Pseudorandom Sets and Private Information Retrieval with Near-Optimal Online Bandwidth and Time,"Imagine one or more non-colluding servers each holding a large public database, e.g., the repository of DNS entries. Clients would like to access entries in this database without disclosing their queries to the servers. Classical private information retrieval (PIR) schemes achieve polylogarithmic bandwidth per query, but require the server to perform linear computation per query, which is a significant barrier towards deployment.",1.0,0.9314084053039551,True,0.3775406687981454,0.6544745370510503,True
"Parallel Repetition of (k1, đots , kμ )-Special-Sound Multi-round Interactive Proofs","In many occasions, the knowledge error κ of an interactive proof is not small enough, and thus needs to be reduced. This can be done generically by repeating the interactive proof in parallel. While there have been many works studying the effect of parallel repetition on the soundness error of interactive proofs and arguments, the effect of parallel repetition on the knowledge error has largely remained unstudied. Only recently it was shown that the t-fold parallel repetition of any interactive protocol reduces the knowledge error from κ down to κ t + ν for any nonnegligible term ν. This generic result is suboptimal in that it does not give the knowledge error κ t that one would expect for typical protocols, and, worse, the knowledge error remains non-negligible. In this work we show that indeed the t-fold parallel repetition of any (k1, . . . , kµ)-special-sound multi-round public-coin interactive proof optimally reduces the knowledge error from κ down to κ t . At the core of our results is an alternative, in some sense more fine-grained, measure of quality of a dishonest prover than its success probability, for which we show that it characterizes when knowledge extraction is possible. This new measure then turns out to be very convenient when it comes to analyzing the parallel repetition of such interactive proofs. While parallel repetition reduces the knowledge error, it is easily seen to increase the completeness error. For this reason, we generalize our result to the case of s-out-of-t threshold parallel repetition, where the verifier accepts if s out of t of the parallel instances are accepting. An appropriately chosen threshold s allows both the knowledge error and completeness error to be reduced simultaneously.",0.8,0.9155744314193726,True,0.3318122278318339,0.6236933296256032,True
英語で読み解くホワイトペーパー 今回のホワイトペーパー BitTorrent(ビットトレント),,0.8,0.8076251745223999,True,0.3318122278318339,0.5697187011771169,True
CSI -Otter: Isogeny-Based (Partially) Blind Signatures from the Class Group Action with a Twist,,0.8,0.9807835817337036,True,0.3318122278318339,0.6562979047827687,True
Correlation of Quadratic Boolean Functions: Cryptanalysis of All Versions of Full \mathsf MORUS,"We show that the correlation of any quadratic Boolean function can be read out from its so-called disjoint quadratic form. We further propose a polynomial-time algorithm that can transform an arbitrary quadratic Boolean function into its disjoint quadratic form. With this algorithm, the exact correlation of quadratic Boolean functions can be computed efficiently.",1.0,0.8030473589897156,True,0.3775406687981454,0.5902940138939305,True
Lattice-Based Succinct Arguments from Vanishing Polynomials - (Extended Abstract),,0.8,0.7756762504577637,True,0.3318122278318339,0.5537442391447988,True
All-But-Many Lossy Trapdoor Functions from Lattices and Applications,"All-but-many lossy trapdoor functions"" (ABM-LTF) are a powerful cryptographic primitive studied by Hofheinz (Eurocrypt 2012). ABM-LTFs are parametrised with tags: a lossy tag makes the function lossy; an injective tag makes the function injective, and invertible with a trapdoor. Existing ABM-LTFs rely on non-standard assumptions. Our first result is an ABM-LTF construction from lattices, based on the learning-with-errors (LWE) problem. Unlike the previous schemes which behaved as ""encrypted signatures"", the core of our construction is an ""encrypted, homomorphic-evaluation-friendly, weak pseudorandom function"". The weak pseudorandom function outputs matrices, where the lossy tags are preimages of the zero matrix, and the injective tags are preimages of random full-rank matrices. Our second result is a public-key system tightly secure against ""selective opening"" attacks, where an attacker gets many challenges and can ask to see the random bits of any of them. Following the steps of Hemenway et al. (Asiacrypt 2011)  and Hofheinz (Eurocrypt 2012), our ABM-LTF gives the first lattice-based, compact public-key encryption (PKE) scheme that has indistinguishability against adaptive chosen-ciphertext and selective opening attacks (IND-SO-CCA2), with tight security, and whose public-key size and security reduction are independent of the number of decryption queries and ciphertext challenges. Meanwhile, this result provides an alternative solution to the problem of building pairing-free IND-CCA2 PKE schemes with tight security in the multi-challenge setting, which was firstly answered by Gay et al. (Eurocrypt 2016). Additionally, our ABM-LTF answers the open question of constructing (non-necessarily lossy) all-but-many trapdoor functions from lattices, first asked by Alperin-Sheriff and Peikert (PKC 2012).",1.0,0.7334364056587219,True,0.3775406687981454,0.5554885372284337,True
Compressed $\varSigma $-Protocol Theory and Practical Application to Plug & Play Secure Algorithmics,"Σ-Protocols provide a well-understood basis for secure algorithmics. Recently, Bulletproofs (Bootle et al., EUROCRYPT 2016, and Bünz et al., S&P 2018)  have been proposed as a drop-in replacement in case of zero-knowledge (ZK) for arithmetic circuits, achieving logarithmic communication instead of linear. Its pivot is an ingenious, logarithmic-size proof of knowledge BP for certain quadratic relations. However, reducing ZK for general relations to it forces a somewhat cumbersome ""reinvention"" of cryptographic protocol theory. We take a rather different viewpoint and reconcile Bulletproofs with Σ-Protocol Theory such that (a) simpler circuit ZK is developed within established theory, while (b) achieving exactly the same logarithmic communication. The natural key here is linearization. First, we repurpose BPs as a blackbox compression mechanism for standard Σ-Protocols handling ZK proofs of general linear relations (on compactly committed secret vectors); our pivot. Second, we reduce the case of general nonlinear relations to blackbox applications of our pivot via a novel variation on arithmetic secret sharing based techniques for Σ-Protocols (Cramer et  al., ICITS 2012). Orthogonally, we enhance versatility by enabling scenarios not previously addressed, e.g., when a secret input is dispersed across several commitments. Standard implementation platforms leading to logarithmic communication follow from a Discrete-Log assumption or a generalized Strong-RSA assumption. Also, under a Knowledge-of-Exponent Assumption (KEA) communication drops to constant, as in ZK-SNARKS. All in all, our theory should more generally be useful for modular (""plug & play"") design of practical cryptographic protocols; this is further evidenced by our separate work (2020) on proofs of partial knowledge.",0.8,0.9722641706466675,True,0.3318122278318339,0.6520381992392507,True
One-Way Functions and the Hardness of (Probabilistic) Time-Bounded Kolmogorov Complexity w.r.t. Samplable Distributions,,1.8,0.7197808623313904,True,0.574442516811659,0.6471116895715248,True
急成長中のSTO業界を追っていく。(第4回)2020年はさらなる躍進を!抑えておくべきたった3つのポイント,,1.3,0.7765369415283203,True,0.45016600268752216,0.6133514721079212,True
"Zoom to Learn, Learn to Zoom","This paper shows that when applying machine learning to digital zoom, it is beneficial to operate on real, RAW sensor data. Existing learning-based super-resolution methods do not use real sensor data, instead operating on processed RGB images. We show that these approaches forfeit detail and accuracy that can be gained by operating on raw data, particularly when zooming in on distant objects. The key barrier to using real sensor data for training is that ground-truth high-resolution imagery is missing. We show how to obtain such ground-truth data via optical zoom and contribute a dataset, SR-RAW, for real-world computational zoom. We use SR-RAW to train a deep network with a novel contextual bilateral loss that is robust to mild misalignment between input and outputs images. The trained network achieves state-of-the-art performance in 4X and 8X computational zoom. We also show that synthesizing sensor data by resampling high-resolution RGB images is an oversimplified approximation of real sensor data and noise, resulting in worse image quality.",1.0,0.8864681720733643,True,0.3775406687981454,0.6320044204357549,True
CNN-Generated Images Are Surprisingly Easy to Spot… for Now,"In this work we ask whether it is possible to create a ""universal"" detector for telling apart real images from these generated by a CNN, regardless of architecture or dataset used. To test this, we collect a dataset consisting of fake images generated by 11 different CNN-based image generator models, chosen to span the space of commonly used architectures today (ProGAN, StyleGAN, BigGAN, CycleGAN, StarGAN, GauGAN, DeepFakes, cascaded refinement networks, implicit maximum likelihood estimation, second-order attention super-resolution, seeing-in-the-dark). We demonstrate that, with careful pre- and post-processing and data augmentation, a standard image classifier trained on only one specific CNN generator (ProGAN) is able to generalize surprisingly well to unseen architectures, datasets, and training methods (including the just released StyleGAN2). Our findings suggest the intriguing possibility that today's CNN-generated images share some common systematic flaws, preventing them from achieving realistic image synthesis.",1.0,0.7630186080932617,True,0.3775406687981454,0.5702796384457036,True
Knockoff Nets: Stealing Functionality of Black-Box Models,"Machine Learning (ML) models are increasingly deployed in the wild to perform a wide range of tasks. In this work, we ask to what extent can an adversary steal functionality of such ``victim'' models based solely on blackbox interactions: image in, predictions out. In contrast to prior work, we study complex victim blackbox models, and an adversary lacking knowledge of train/test data used by the model, its internals, and semantics over model outputs. We formulate model functionality stealing as a two-step approach: (i) querying a set of input images to the blackbox model to obtain predictions; and (ii) training a ``knockoff'' with queried image-prediction pairs. We make multiple remarkable observations: (a) querying random images from a different distribution than that of the blackbox training data results in a well-performing knockoff; (b) this is possible even when the knockoff is represented using a different architecture; and (c) our reinforcement learning approach additionally improves query sample efficiency in certain settings and provides performance gains. We validate model functionality stealing on a range of datasets and tasks, as well as show that a reasonable knockoff of an image analysis API could be created for as little as $30.",1.0,0.9435837268829346,True,0.3775406687981454,0.66056219784054,True
JAWS: Just A Wild Shot for Cinematic Transfer in Neural Radiance Fields,"This paper presents JAWS, an optimization-driven approach that achieves the robust transfer of visual cinematic features from a reference in-the-wild video clip to a newly generated clip. To this end, we rely on an implicit-neural-representation (INR) in a way to compute a clip that shares the same cinematic features as the reference clip. We propose a general formulation of a camera optimization problem in an INR that computes extrinsic and intrinsic camera parameters as well as timing. By leveraging the differentiability of neural representations, we can back-propagate our designed cinematic losses measured on proxy estimators through a NeRF network to the proposed cinematic parameters directly. We also introduce specific enhancements such as guidance maps to improve the overall quality and efficiency. Results display the capacity of our system to replicate well known camera sequences from movies, adapting the framing, camera parameters and timing of the generated video clip to maximize the similarity with the reference clip.",1.0,0.9949555993080139,True,0.3775406687981454,0.6862481340530797,True
Real-time Multi-person Eyeblink Detection in the Wild for Untrimmed Video,"Real-time eyeblink detection in the wild can widely serve for fatigue detection, face anti-spoofing, emotion analysis, etc. The existing research efforts generally focus on single-person cases towards trimmed video. However, multi-person scenario within untrimmed videos is also important for practical applications, which has not been well concerned yet. To address this, we shed light on this research field for the first time with essential contributions on dataset, theory, and practices. In particular, a large-scale dataset termed MPEblink that involves 686 untrimmed videos with 8748 eyeblink events is proposed under multi-person conditions. The samples are captured from uncon-strainedfilms to reveal “in the wild“ characteristics. Meanwhile, a real-time multi-person eyeblink detection method is also proposed. Being different from the existing counter-parts, our proposition runs in a one-stage spatio-temporal way with end-to-end learning capacity. Specifically, it simultaneously addresses the sub-tasks of face detection, face tracking, and human instance-level eyeblink detection. This paradigm holds 2 main advantages: (1) eyeblink features can be facilitated via the face's global context (e.g., head pose and illumination condition) with joint optimization and interaction, and (2) addressing these sub-tasks in parallel instead of sequential manner can save time remarkably to meet the real-time running requirement. Experiments on MPEblink verify the essential challenges of real-time multi-person eyeblink detection in the wild for untrimmed video. Our method also outperforms existing approaches by large margins and with a high inference speed.",1.0,0.8138731718063354,True,0.3775406687981454,0.5957069203022405,True
Revamping Cross-Modal Recipe Retrieval with Hierarchical Transformers and Self-supervised Learning,"Cross-modal recipe retrieval has recently gained substantial attention due to the importance of food in people’s lives, as well as the availability of vast amounts of digital cooking recipes and food images to train machine learning models. In this work, we revisit existing approaches for cross-modal recipe retrieval and propose a simplified end-to-end model based on well established and high performing encoders for text and images. We introduce a hierarchical recipe Transformer which attentively encodes individual recipe components (titles, ingredients and instructions). Further, we propose a self-supervised loss function computed on top of pairs of individual recipe components, which is able to leverage semantic relationships within recipes, and enables training using both image-recipe and recipe-only samples. We conduct a thorough analysis and ablation studies to validate our design choices. As a result, our proposed method achieves state-of-the-art performance in the cross-modal recipe retrieval task on the Recipe1M dataset. We make code and models publicly available 1.",1.0,0.7738770246505737,True,0.3775406687981454,0.5757088467243596,True
Learning to Recommend Frame for Interactive Video Object Segmentation in the Wild,"This paper proposes a framework for the interactive video object segmentation (VOS) in the wild where users can choose some frames for annotations iteratively. Then, based on the user annotations, a segmentation algorithm refines the masks. The previous interactive VOS paradigm selects the frame with some worst evaluation metric, and the ground truth is required for calculating the evaluation metric, which is impractical in the testing phase. In contrast, in this paper, we advocate that the frame with the worst evaluation metric may not be exactly the most valuable frame that leads to the most performance improvement across the video. Thus, we formulate the frame selection problem in the interactive VOS as a Markov Decision Process, where an agent is learned to recommend the frame under a deep reinforcement learning framework. The learned agent can automatically determine the most valuable frame, making the interactive setting more practical in the wild. Experimental results on the public datasets show the effectiveness of our learned agent without any changes to the underlying VOS algorithms. Our data, code, and models are available at https://github.com/svip-lab/IVOS-W.",1.0,0.8047680258750916,True,0.3775406687981454,0.5911543473366185,True
3D Shape Generation with Grid-based Implicit Functions,"Previous approaches to generate shapes in a 3D setting train a GAN on the latent space of an autoencoder (AE). Even though this produces convincing results, it has two major shortcomings. As the GAN is limited to reproduce the dataset the AE was trained on, we cannot reuse a trained AE for novel data. Furthermore, it is difficult to add spatial supervision into the generation process, as the AE only gives us a global representation. To remedy these issues, we propose to train the GAN on grids (i.e. each cell covers a part of a shape). In this representation each cell is equipped with a latent vector provided by an AE. This localized representation enables more expressiveness (since the cell-based latent vectors can be combined in novel ways) as well as spatial control of the generation process (e.g. via bounding boxes). Our method outperforms the current state of the art on all established evaluation measures, proposed for quantitatively evaluating the generative capabilities of GANs. We show limitations of these measures and propose the adaptation of a robust criterion from statistical analysis as an alternative.",1.0,0.7422865033149719,True,0.3775406687981454,0.5599135860565587,True
3D Video Loops from Asynchronous Input,"Looping videos are short video clips that can be looped endlessly without visible seams or artifacts. They provide a very attractive way to capture the dynamism of natural scenes. Existing methods have been mostly limited to 2D representations. In this paper, we take a step forward and propose a practical solution that enables an immersive experience on dynamic 3D looping scenes. The key challenge is to consider the per-view looping conditions from asynchronous input while maintaining view consistency for the 3D representation. We propose a novel sparse 3D video representation, namely Multi-Tile Video (MTV), which not only provides a view-consistent prior, but also greatly reduces memory usage, making the optimization of a 4D volume tractable. Then, we introduce a two-stage pipeline to construct the 3D looping MTV from completely asynchronous multi-view videos with no time overlap. A novel looping loss based on video temporal retargeting algorithms is adopted during the optimization to loop the 3D scene. Experiments of our framework have shown promise in successfully generating and rendering photorealistic 3D looping videos in real time even on mobile devices. The code, dataset, and live demos are available in https://limacv.github.io/VideoLoop3D_web/.",1.0,0.8136554956436157,True,0.3775406687981454,0.5955980822208806,True
Zoom-In-To-Check: Boosting Video Interpolation via Instance-Level Discrimination,"We propose a light-weight video frame interpolation algorithm. Our key innovation is an instance-level supervision that allows information to be learned from the high-resolution version of similar objects. Our experiment shows that the proposed method can generate state-of-the-art results across different datasets, with fractional computation resources (time and memory) of competing methods. Given two image frames, a cascade network creates an intermediate frame with 1) a flow-warping module that computes coarse bi-directional optical flow and creates an interpolated image via flow-based warping, followed by 2) an image synthesis module to make fine-scale corrections. In the learning stage, object detection proposals are generated on the interpolated image. Lower resolution objects are zoomed into, and the learning algorithms using an adversarial loss trained on high-resolution objects to guide the system towards the instance-level refinement corrects details of object shape and boundaries.",1.0,0.8205575942993164,True,0.3775406687981454,0.599049131548731,True
Projection & Probability-Driven Black-Box Attack,"Generating adversarial examples in a black-box setting retains a significant challenge with vast practical application prospects. In particular, existing black-box attacks suffer from the need for excessive queries, as it is non-trivial to find an appropriate direction to optimize in the high-dimensional space. In this paper, we propose Projection & Probability-driven Black-box Attack (PPBA) to tackle this problem by reducing the solution space and providing better optimization. For reducing the solution space, we first model the adversarial perturbation optimization problem as a process of recovering frequency-sparse perturbations with compressed sensing, under the setting that random noise in the low-frequency space is more likely to be adversarial. We then propose a simple method to construct a low-frequency constrained sensing matrix, which works as a plug-and-play projection matrix to reduce the dimensionality. Such a sensing matrix is shown to be flexible enough to be integrated into existing methods like NES and BanditsTD. For better optimization, we perform a random walk with a probability-driven strategy, which utilizes all queries over the whole progress to make full use of the sensing matrix for a less query budget. Extensive experiments show that our method requires at most 24% fewer queries with a higher attack success rate compared with state-of-the-art approaches. Finally, the attack method is evaluated on the real-world online service, i.e., Google Cloud Vision API, which further demonstrates our practical potentials.",0.8,0.9540128707885742,True,0.3318122278318339,0.642912549310204,True
Event Probability Mask (EPM) and Event Denoising Convolutional Neural Network (EDnCNN) for Neuromorphic Cameras,"This paper presents a novel method for labeling real-world neuromorphic camera sensor data by calculating the likelihood of generating an event at each pixel within a short time window, which we refer to as “event probability mask” or EPM. Its applications include (i) objective benchmarking of event denoising performance, (ii) training convolutional neural networks for noise removal called “event denoising convolutional neural network” (EDnCNN), and (iii) estimating internal neuromorphic camera parameters. We provide the first dataset (DVSNOISE20) of real-world labeled neuromorphic camera events for noise removal.",0.8,0.7700700163841248,True,0.3318122278318339,0.5509411221079793,True
Meta-Tuning Loss Functions and Data Augmentation for Few-Shot Object Detection,"Few-shot object detection, the problem of modelling novel object detection categories with few training instances, is an emerging topic in the area of few-shot learning and object detection. Contemporary techniques can be divided into two groups: fine-tuning based and meta-learning based approaches. While meta-learning approaches aim to learn dedicated meta-models for mapping samples to novel class models, fine-tuning approaches tackle few-shot detection in a simpler manner, by adapting the detection model to novel classes through gradient based optimization. Despite their simplicity, fine-tuning based approaches typically yield competitive detection results. Based on this observation, we focus on the role of loss functions and augmentations as the force driving the fine-tuning process, and propose to tune their dynamics through meta-learning principles. The proposed training scheme, therefore, allows learning inductive biases that can boost few-shot detection, while keeping the advantages of fine-tuning based approaches. In addition, the proposed approach yields interpretable loss functions, as opposed to highly parametric and complex few-shot meta-models. The experimental results highlight the merits of the proposed scheme, with significant improvements over the strong fine-tuning based few-shot detection baselines on benchmark Pascal VOC and MS-COCO datasets, in terms of both standard and generalized few-shot performance metrics.",1.0,0.7464219331741333,True,0.3775406687981454,0.5619813009861394,True
Tracking Through Containers and Occluders in the Wild,"Tracking objects with persistence in cluttered and dynamic environments remains a difficult challenge for computer vision systems. In this paper, we introduce TCOW, a new benchmark and model for visual tracking through heavy occlusion and containment. We set up a task where the goal is to, given a video sequence, segment both the projected extent of the target object, as well as the surrounding container or occluder whenever one exists. To study this task, we create a mixture of synthetic and annotated real datasets to support both supervised learning and structured evaluation of model performance under various forms of task variation, such as moving or nested containment. We evaluate two recent transformer-based video models and find that while they can be surprisingly capable of tracking targets under certain settings of task variation, there remains a considerable performance gap before we can claim a tracking model to have acquired a true notion of object permanence.",1.0,0.8914154171943665,True,0.3775406687981454,0.634478042996256,True
Learning to Restore 3D Face from In-the-Wild Degraded Images,"In-the-wild 3D face modelling is a challenging problem as the predicted facial geometry and texture suffer from a lack of reliable clues or priors, when the input images are degraded. To address such a problem, in this paper we propose a novel Learning to Restore (L2R) 3D face framework for unsupervised high-quality face reconstruction from low-resolution images. Rather than directly refining 2D image appearance, L2R learns to recover fine-grained 3D details on the proxy against degradation via extracting generative facial priors. Concretely, L2R proposes a novel albedo restoration network to model high-quality 3D facial texture, in which the diverse guidance from the pre-trained Generative Adversarial Networks (GANs) is leveraged to complement the lack of input facial clues. With the finer details of the restored 3D texture, L2R then learns displacement maps from scratch to enhance the significant facial structure and geometry. Both of the procedures are mutually optimized with a novel 3D-aware adversarial loss, which further improves the modelling performance and suppresses the potential uncertainty. Extensive experiments on benchmarks show that L2R outperforms state-of-the-art methods under the condition of low-quality inputs, and obtains superior performances than 2D pre-processed modelling approaches with limited 3D proxy.",1.0,0.7496010661125183,True,0.3775406687981454,0.5635708674553319,True
Hallucinated Neural Radiance Fields in the Wild,"Neural Radiance Fields (NeRF) has recently gained popularity for its impressive novel view synthesis ability. This paper studies the problem of hallucinated NeRF: i.e., recovering a realistic NeRF at a different time of day from a group of tourism images. Existing solutions adopt NeRF with a controllable appearance embedding to render novel views under various conditions, but they cannot render view-consistent images with an unseen appearance. To solve this problem, we present an end-to-end framework for constructing a hallucinated NeRF, dubbed as Ha-NeRF. Specifically, we propose an appearance hallucination module to handle time-varying appearances and transfer them to novel views. Considering the complex occlusions of tourism images, we introduce an anti-occlusion module to decompose the static subjects for visibility accurately. Experimental results on synthetic data and real tourism photo collections demonstrate that our method can hallucinate the desired appearances and render occlusion-free images from different views. The project and supplementary materials are available at https://rover-xingyu.github.io/Ha-NeRF/.",1.0,0.8645171523094177,True,0.3775406687981454,0.6210289105537816,True
Unsupervised Face Normalization With Extreme Pose and Expression in the Wild,"Face recognition achieves great success thanks to the emergence of deep learning. However, many contemporary face recognition models still have limited invariance to strong intra-personal variations such as large pose changes. Face normalization provides an effective and cheap way to distil face identity and dispel face variances for recognition. We focus on face generation in the wild with unpaired data. To this end, we propose a Face Normalization Model (FNM) to generate a frontal, neutral expression, photorealistic face image for face recognition. FNM is a well-designed Generative Adversarial Network (GAN) with three distinct novelties. First, a face expert network is introduced to construct generator and provide the ability of retaining face identity. Second, with the reconstruction of normal face, pixel-wise loss is applied to stabilize optimization process. Third, we present a series of face attention discriminators to refine local textures. FNM could recover canonical-view, expression-free image and directly improve the performance of face recognition model. Extensive qualitative and quantitative experiments on both controlled and in-the-wild databases demonstrate the superiority of our face normalization method.",1.0,0.8132955431938171,True,0.3775406687981454,0.5954181059959813,True
Learning Multi-View Aggregation In the Wild for Large-Scale 3D Semantic Segmentation,"Recent works on 3D semantic segmentation propose to exploit the synergy between images and point clouds by processing each modality with a dedicated network and projecting learned 2D features onto 3D points. Merging large-scale point clouds and images raises several challenges, such as constructing a mapping between points and pixels, and aggregating features between multiple views. Current methods require mesh reconstruction or specialized sensors to recover occlusions, and use heuristics to select and aggregate available images. In contrast, we propose an end-to-end trainable multi-view aggregation model leveraging the viewing conditions of 3D points to merge features from images taken at arbitrary positions. Our method can combine standard 2D and 3D networks and outperforms both 3D models operating on colorized point clouds and hybrid 2D/3D networks without requiring colorization, meshing, or true depth maps. We set a new state-of-the-art for large-scale indoor/outdoor semantic segmentation on S3DIS (74.7 mIoU 6-Fold) and on KITTI-360 (58.3 mIoU). Our full pipeline is accessible at https://github.com/drprojects/DeepViewAgg, and only requires raw 3D scans and a set of images and poses.",1.0,0.8600451946258545,True,0.3775406687981454,0.618792931712,True
Learning to Align Sequential Actions in the Wild,"State-of-the-art methods for self-supervised sequential action alignment rely on deep networks that find correspondences across videos in time. They either learn frame-to-frame mapping across sequences, which does not leverage temporal information, or assume monotonic alignment between each video pair, which ignores variations in the order of actions. As such, these methods are not able to deal with common real-world scenarios that involve background frames or videos that contain non-monotonic sequence of actions. In this paper, we propose an approach to align sequential actions in the wild that involve diverse temporal variations. To this end, we propose an approach to enforce temporal priors on the optimal transport matrix, which leverages temporal consistency, while allowing for variations in the order of actions. Our model accounts for both monotonic and non-monotonic sequences and handles background frames that should not be aligned. We demonstrate that our approach consistently outperforms the state-of-the-art in self-supervised sequential action representation learning on four different benchmark datasets. Code is publicly available at https://github.com/weizheliu/VAVA.",1.0,0.8223965167999268,True,0.3775406687981454,0.5999685927990361,True
Oops! Predicting Unintentional Action in Video,"From just a short glance at a video, we can often tell whether a person's action is intentional or not. Can we train a model to recognize this? We introduce a dataset of in-the-wild videos of unintentional action, as well as a suite of tasks for recognizing, localizing, and anticipating its onset. We train a supervised neural network as a baseline and analyze its performance compared to human consistency on the tasks. We also investigate self-supervised representations that leverage natural signals in our dataset, and show the effectiveness of an approach that uses the intrinsic speed of video to perform competitively with highly-supervised pretraining. However, a significant gap between machine and human performance remains.",1.5,0.9135477542877197,True,0.5,0.7067738771438599,True
Imagic: Text-Based Real Image Editing with Diffusion Models,"Text-conditioned image editing has recently attracted considerable interest. However, most methods are currently limited to one of the following: specific editing types (e.g., object overlay, style transfer), synthetically generated images, or requiring multiple input images of a common object. In this paper we demonstrate, for the very first time, the ability to apply complex (e.g., non-rigid) text-based semantic edits to a single real image. For example, we can change the posture and composition of one or multiple objects inside an image, while preserving its original characteristics. Our method can make a standing dog sit down, cause a bird to spread its wings, etc. – each within its single high-resolution user-provided natural image. Contrary to previous work, our proposed method requires only a single input image and a target text (the desired edit). It operates on real images, and does not require any additional inputs (such as image masks or additional views of the object). Our method, called Imagic, leverages a pre-trained text-to-image diffusion model for this task. It produces a text embedding that aligns with both the input image and the target text, while fine-tuning the diffusion model to capture the image-specific appearance. We demonstrate the quality and versatility of Imagic on numerous inputs from various domains, showcasing a plethora of high quality complex semantic image edits, all within a single unified framework. To better assess performance, we introduce TEdBench, a highly challenging image editing benchmark. We conduct a user study, whose findings show that human raters prefer Imagic to previous leading editing methods on TEdBench.",1.0,0.8186501860618591,True,0.3775406687981454,0.5980954274300023,True
"3D Face Morphable Models ""In-the-Wild""","3D Morphable Models (3DMMs) are powerful statistical models of 3D facial shape and texture, and among the state-of-the-art methods for reconstructing facial shape from single images. With the advent of new 3D sensors, many 3D facial datasets have been collected containing both neutral as well as expressive faces. However, all datasets are captured under controlled conditions. Thus, even though powerful 3D facial shape models can be learnt from such data, it is difficult to build statistical texture models that are sufficient to reconstruct faces captured in unconstrained conditions (in-the-wild). In this paper, we propose the first, to the best of our knowledge, in-the-wild 3DMM by combining a powerful statistical model of facial shape, which describes both identity and expression, with an in-the-wild texture model. We show that the employment of such an in-the-wild texture model greatly simplifies the fitting procedure, because there is no need to optimise with regards to the illumination parameters. Furthermore, we propose a new fast algorithm for fitting the 3DMM in arbitrary images. Finally, we have captured the first 3D facial database with relatively unconstrained conditions and report quantitative evaluations with state-of-the-art performance. Complementary qualitative reconstruction results are demonstrated on standard in-the-wild facial databases.",1.0,0.8459003567695618,True,0.3775406687981454,0.6117205127838536,True
Pose-Guided Human Animation from a Single Image in the Wild,"We present a new pose transfer method for synthesizing a human animation from a single image of a person controlled by a sequence of body poses. Existing pose transfer methods exhibit significant visual artifacts when applying to a novel scene, resulting in temporal inconsistency and failures in preserving the identity and textures of the person. To address these limitations, we design a compositional neural network that predicts the silhouette, garment labels, and textures. Each modular network is explicitly dedicated to a subtask that can be learned from the synthetic data. At the inference time, we utilize the trained network to produce a unified representation of appearance and its labels in UV coordinates, which remains constant across poses. The unified representation provides an incomplete yet strong guidance to generating the appearance in response to the pose change. We use the trained network to complete the appearance and render it with the background. With these strategies, we are able to synthesize human animations that can preserve the identity and appearance of the person in a temporally coherent way without any fine-tuning of the network on the testing scene. Experiments show that our method outperforms the state-of-the-arts in terms of synthesis quality, temporal coherence, and generalization ability.",1.0,0.8380293250083923,True,0.3775406687981454,0.6077849969032689,True
3D human tongue reconstruction from single “in-the-wild” images,"3D face reconstruction from a single image is a task that has garnered increased interest in the Computer Vision community, especially due to its broad use in a number of applications such as realistic 3D avatar creation, pose invariant face recognition and face hallucination. Since the introduction of the 3D Morphable Model in the late 90's, we witnessed an explosion of research aiming at particularly tackling this task. Nevertheless, despite the increasing level of detail in the 3D face reconstructions from single images mainly attributed to deep learning advances, finer and highly deformable components of the face such as the tongue are still absent from all 3D face models in the literature, although being very important for the realness of the 3D avatar representations. In this work we present the first, to the best of our knowledge, end-to-end trainable pipeline that accurately reconstructs the 3D face together with the tongue. Moreover, we make this pipeline robust in “in-the-wild” images by introducing a novel GAN method tailored for 3D tongue surface generation. Finally, we make publicly available to the community the first diverse tongue dataset, consisting of 1,800 raw scans of 700 individuals varying in gender, age, and ethnicity backgrounds**Project url: www.github.com/steliosploumpis/tongue. As we demonstrate in an extensive series of quantitative as well as qualitative experiments, our model proves to be robust and realistically captures the 3D tongue structure, even in adverse “in-the- wild” conditions.",1.0,0.8068506717681885,True,0.3775406687981454,0.592195670283167,True
"Monocular Total Capture: Posing Face, Body, and Hands in the Wild","We present the first method to capture the 3D total motion of a target person from a monocular view input. Given an image or a monocular video, our method reconstructs the motion from body, face, and fingers represented by a 3D deformable mesh model. We use an efficient representation called 3D Part Orientation Fields (POFs), to encode the 3D orientations of all body parts in the common 2D image space. POFs are predicted by a Fully Convolutional Network, along with the joint confidence maps. To train our network, we collect a new 3D human motion dataset capturing diverse total body motion of 40 subjects in a multiview system. We leverage a 3D deformable human model to reconstruct total body pose from the CNN outputs with the aid of the pose and shape prior in the model. We also present a texture-based tracking method to obtain temporally coherent motion capture output. We perform thorough quantitative evaluations including comparison with the existing body-specific and hand-specific methods, and performance analysis on camera viewpoint and human pose changes. Finally, we demonstrate the results of our total body motion capture on various challenging in-the-wild videos.",1.0,0.7556533217430115,True,0.3775406687981454,0.5665969952705785,True
clDice - a Novel Topology-Preserving Loss Function for Tubular Structure Segmentation,"Accurate segmentation of tubular, network-like structures, such as vessels, neurons, or roads, is relevant to many fields of research. For such structures, the topology is their most important characteristic; particularly preserving connectedness: in the case of vascular networks, missing a connected vessel entirely alters the blood-flow dynamics. We introduce a novel similarity measure termed centerlineDice (short clDice), which is calculated on the inter-section of the segmentation masks and their (morphological) skeleta. We theoretically prove that clDice guarantees topology preservation up to homotopy equivalence for binary 2D and 3D segmentation. Extending this, we pro-pose a computationally efficient, differentiable loss function (soft-clDice) for training arbitrary neural segmentation networks. We benchmark the soft-clDice loss on five public datasets, including vessels, roads and neurons (2D and 3D). Training on soft-clDice leads to segmentation with more accurate connectivity information, higher graph similarity, and better volumetric scores.",1.0,0.7467962503433228,True,0.3775406687981454,0.5621684595707341,True
Shading Annotations in the Wild,"Understanding shading effects in images is critical for a variety of vision and graphics problems, including intrinsic image decomposition, shadow removal, image relighting, and inverse rendering. As is the case with other vision tasks, machine learning is a promising approach to understanding shading - but there is little ground truth shading data available for real-world images. We introduce Shading Annotations in the Wild (SAW), a new large-scale, public dataset of shading annotations in indoor scenes, comprised of multiple forms of shading judgments obtained via crowdsourcing, along with shading annotations automatically generated from RGB-D imagery. We use this data to train a convolutional neural network to predict per-pixel shading information in an image. We demonstrate the value of our data and network in an application to intrinsic images, where we can reduce decomposition artifacts produced by existing algorithms. Our database is available at http://opensurfaces.cs.cornell.edu/saw.",1.0,0.9066230058670044,True,0.3775406687981454,0.642081837332575,True
E2(GO)MOTION: Motion Augmented Event Stream for Egocentric Action Recognition,"Event cameras are novel bio-inspired sensors, which asynchronously capture pixel-level intensity changes in the form of “events”. Due to their sensing mechanism, event cameras have little to no motion blur, a very high temporal resolution and require significantly less power and memory than traditional frame-based cameras. These characteristics make them a perfect fit to several real-world applications such as egocentric action recognition on wearable devices, where fast camera motion and limited power challenge traditional vision sensors. However, the ever-growing field of event-based vision has, to date, overlooked the potential of event cameras in such applications. In this paper, we show that event data is a very valuable modality for egocentric action recognition. To do so, we introduce N-EPIC-Kitchens, the first event-based camera extension of the large-scale EPIC-Kitchens dataset. In this context, we propose two strategies: (i) directly processing event-camera data with traditional video-processing architectures (E2(GO)) and (ii) using event-data to distill optical flow information (E2(GO)MO). On our proposed benchmark, we show that event data provides a comparable performance to RGB and optical flow, yet without any additional flow computation at deploy time, and an improved performance of up to 4% with respect to RGB only information. The N-EPIC-Kitchens dataset is available at https://github.com/EgocentricVision/N-EPIC-Kitchens.",0.8,0.7884043455123901,True,0.3318122278318339,0.560108286672112,True
Why Discard if You can Recycle?: A Recycling Max Pooling Module for 3D Point Cloud Analysis,"In recent years, most 3D point cloud analysis models have focused on developing either new network architectures or more efficient modules for aggregating point features from a local neighborhood. Regardless of the network architecture or the methodology used for improved feature learning, these models share one thing, which is the use of max-pooling in the end to obtain permutation invariant features. We first show that this traditional approach causes only a fraction of 3D points contribute to the permutation-invariant features, and discards the rest of the points. In order to address this issue and improve the performance of any baseline 3D point classification or segmentation model, we propose a new module, referred to as the Recycling Max-Pooling (RMP) module, to recycle and utilize the features of some of the discarded points. We incorporate a refinement loss that uses the recycled features to refine the prediction loss obtained from the features kept by traditional max-pooling. To the best of our knowledge, this is the first work that explores recycling of still useful points that are traditionally discarded by max-pooling. We demonstrate the effectiveness of the proposed RMP module by incorporating it into several milestone baselines and state-of-the-art networks for point cloud classification and indoor semantic segmentation tasks. We show that RPM, without any bells and whistles, consistently improves the performance of all the tested networks by using the same base network implementation and hyper-parameters. The code is provided in the supplementary material.",1.1,0.790925920009613,True,0.401312339887548,0.5961191299485805,True
Detecting Adversarial Samples Using Influence Functions and Nearest Neighbors,"Deep neural networks (DNNs) are notorious for their vulnerability to adversarial attacks, which are small perturbations added to their input images to mislead their prediction. Detection of adversarial examples is, therefore, a fundamental requirement for robust classification frameworks. In this work, we present a method for detecting such adversarial attacks, which is suitable for any pre-trained neural network classifier. We use influence functions to measure the impact of every training sample on the validation set data. From the influence scores, we find the most supportive training samples for any given validation example. A k-nearest neighbor (k-NN) model fitted on the DNN's activation layers is employed to search for the ranking of these supporting training samples. We observe that these samples are highly correlated with the nearest neighbors of the normal inputs, while this correlation is much weaker for adversarial inputs. We train an adversarial detector using the k-NN ranks and distances and show that it successfully distinguishes adversarial examples, getting state-of-the-art results on six attack methods with three datasets. Code is available at https://github.com/giladcohen/NNIF_adv_defense.",1.0,0.8081139922142029,True,0.3775406687981454,0.5928273305061742,True
Learning to Zoom and Unzoom,"Many perception systems in mobile computing, autonomous navigation, and AR/VR face strict compute constraints that are particularly challenging for high-resolution input images. Previous works propose nonuniform downsamplers that “learn to zoom” on salient image regions, reducing compute while retaining task-relevant image information. However, for tasks with spatial labels (such as 2D/3D object detection and semantic segmentation), such distortions may harm performance. In this work (LZU), we “learn to zoom” in on the input image, compute spatial features, and then “unzoom” to revert any deformations. To enable efficient and differentiable unzooming, we approximate the zooming warp with a piecewise bilinear mapping that is invertible. LZU can be applied to any task with 2D spatial input and any model with 2D spatial features, and we demonstrate this versatility by evaluating on a variety of tasks and datasets: object detection on Argoverse-HD, semantic segmentation on Cityscapes, and monocular 3D object detection on nuScenes. Interestingly, we observe boosts in performance even when high-resolution sensor data is unavailable, implying that LZU can be used to “learn to upsample” as well. Code and additional visuals are available at https://tchittesh.github.io/lzu/.",1.0,0.9574170708656311,True,0.3775406687981454,0.6674788698318883,True
Learning When and Where to Zoom With Deep Reinforcement Learning,"While high resolution images contain semantically more useful information than their lower resolution counterparts, processing them is computationally more expensive, and in some applications, e.g. remote sensing, they can be much more expensive to acquire. For these reasons, it is desirable to develop an automatic method to selectively use high resolution data when necessary while maintaining accuracy and reducing acquisition/run-time cost. In this direction, we propose PatchDrop a reinforcement learning approach to dynamically identify when and where to use/acquire high resolution data conditioned on the paired, cheap, low resolution images. We conduct experiments on CIFAR10, CIFAR100, ImageNet and fMoW datasets where we use significantly less high resolution data while maintaining similar accuracy to models which use full high resolution images.",1.0,0.762962281703949,True,0.3775406687981454,0.5702514752510472,True
Adversarial Normalization: I Can visualize Everything (ICE),"Vision transformers use [CLS] tokens to predict image classes. Their explainability visualization has been studied using relevant information from [CLS] tokens or focusing on attention scores during self-attention. Such visualization, however, is challenging because of the dependence of the structure of a vision transformer on skip connections and attention operators, the instability of non-linearities in the learning process, and the limited reflection of self-attention scores on relevance. We argue that the output vectors for each input patch token in a vision transformer retain the image information of each patch location, which can facilitate the prediction of an image class. In this paper, we propose ICE (Adversarial Normalization: I Can visualize Everything), a novel method that enables a model to directly predict a class for each patch in an image; thus, advancing the effective visualization of the explainability of a vision transformer. Our method distinguishes background from foreground regions by predicting background classes for patches that do not determine image classes. We used the DeiT-S model, the most representative model employed in studies, on the explainability visualization of vision transformers. On the ImageNet-Segmentation dataset, ICE outperformed all explainability visualization methods for four cases depending on the model size. We also conducted quantitative and qualitative analyses on the tasks of weakly-supervised object localization and unsupervised object discovery. On the CUB-200-2011 and PASCALVOC07/12 datasets, ICE achieved comparable performance to the state-of-the-art methods. We incorporated ICE into the encoder of DeiT-S and improved efficiency by 44.01% on the ImageNet dataset over that achieved by the original DeiT-S model. We showed performance on the accuracy and efficiency comparable to EViT, the state-of-the-art pruning model, demonstrating the effectiveness of ICE. The code is available at https://github.com/Hanyang-HCC-Lab/ICE.",0.8,0.7853666543960571,True,0.3318122278318339,0.5585894411139455,True
De-rendering 3D Objects in the Wild,"With increasing focus on augmented and virtual reality (XR) applications comes the demand for algorithms that can lift objects from images into representations that are suitable for a wide variety of related 3D tasks. Large-scale deployment of XR devices and applications means that we cannot solely rely on supervised learning, as collecting and annotating data for the unlimited variety of objects in the real world is infeasible. We present a weakly supervised method that is able to decompose a single image of an object into shape (depth and normals), material (albedo, reflectivity and shininess) and global lighting parameters. For training, the method only relies on a rough initial shape estimate of the training objects to bootstrap the learning process. This shape supervision can come for example from a pretrained depth network or-more generically-from a traditional structure-from-motion pipeline. In our experiments, we show that the method can successfully de-render 2D images into a decomposed 3D representation and generalizes to unseen object categories. Since in-the-wild evaluation is difficult due to the lack of ground truth data, we also introduce a photo-realistic synthetic test set that allows for quantitative evaluation. Please find our project page at: https://github.com/Brummi/derender3d",1.0,0.8184858560562134,True,0.3775406687981454,0.5980132624271794,True
WildLight: In-the-wild Inverse Rendering with a Flashlight,"This paper proposes a practical photometric solution for the challenging problem of in-the-wild inverse rendering under unknown ambient lighting. Our system recovers scene geometry and reflectance using only multi-view images captured by a smartphone. The key idea is to exploit smartphone's built-in flashlight as a minimally controlled light source, and decompose image intensities into two photometric components – a static appearance corresponds to ambient flux, plus a dynamic reflection induced by the moving flashlight. Our method does not require flash/non-flash images to be captured in pairs. Building on the success of neural light fields, we use an off-the-shelf method to capture the ambient reflections, while the flashlight component enables physically accurate photometric constraints to decouple reflectance and illumination. Compared to existing inverse rendering methods, our setup is applicable to non-darkroom environments yet sidesteps the inherent difficulties of explicit solving ambient reflections. We demonstrate by extensive experiments that our method is easy to implement, casual to set up, and consistently outperforms existing in-the-wild inverse rendering techniques. Finally, our neural reconstruction can be easily exported to PBR textured triangle mesh ready for industrial renderers. Our source code and data are released to https://github.com/za-cheng/WildLight.",1.0,0.9293655753135681,True,0.3775406687981454,0.6534531220558568,True
Local Implicit Ray Function for Generalizable Radiance Field Representation,"We propose LIRF (Local Implicit Ray Function), a generalizable neural rendering approach for novel view rendering. Current generalizable neural radiance fields (NeRF) methods sample a scene with a single ray per pixel and may therefore render blurred or aliased views when the input views and rendered views capture scene content with different resolutions. To solve this problem, we propose LIRF to aggregate the information from conical frustums to construct a ray. Given 3D positions within conical frustums, LIRF takes 3D coordinates and the features of conical frustums as inputs and predicts a local volumetric radiance field. Since the coordinates are continuous, LIRF renders high-quality novel views at a continuously-valued scale via volume rendering. Besides, we predict the visible weights for each input view via transformer-based feature matching to improve the performance in occluded areas. Experimental results on real-world scenes validate that our method outperforms state-of-the-art methods on novel view rendering of unseen scenes at arbitrary scales.",1.0,0.7280591130256653,True,0.3775406687981454,0.5527998909119054,True
Exploiting Temporal Context for 3D Human Pose Estimation in the Wild,"We present a bundle-adjustment-based algorithm for recovering accurate 3D human pose and meshes from monocular videos. Unlike previous algorithms which operate on single frames, we show that reconstructing a person over an entire sequence gives extra constraints that can resolve ambiguities. This is because videos often give multiple views of a person, yet the overall body shape does not change and 3D positions vary slowly. Our method improves not only on standard mocap-based datasets like Human 3.6M -- where we show quantitative improvements -- but also on challenging in-the-wild datasets such as Kinetics. Building upon our algorithm, we present a new dataset of more than 3 million frames of YouTube videos from Kinetics with automatically generated 3D poses and meshes. We show that retraining a single-frame 3D pose estimator on this data improves accuracy on both real-world and mocap data by evaluating on the 3DPW and HumanEVA datasets.",1.0,0.9059552550315857,True,0.3775406687981454,0.6417479619148656,True
Graph-Structured Referring Expression Reasoning in the Wild,"Grounding referring expressions aims to locate in an image an object referred to by a natural language expression. The linguistic structure of a referring expression provides a layout of reasoning over the visual contents, and it is often crucial to align and jointly understand the image and the referring expression. In this paper, we propose a scene graph guided modular network (SGMN), which performs reasoning over a semantic graph and a scene graph with neural modules under the guidance of the linguistic structure of the expression. In particular, we model the image as a structured semantic graph, and parse the expression into a language scene graph. The language scene graph not only decodes the linguistic structure of the expression, but also has a consistent representation with the image semantic graph. In addition to exploring structured solutions to grounding referring expressions, we also propose Ref-Reasoning, a large-scale real-world dataset for structured referring expression reasoning. We automatically generate referring expressions over the scene graphs of images using diverse expression templates and functional programs. This dataset is equipped with real-world visual contents as well as semantically rich expressions with different reasoning layouts. Experimental results show that our SGMN not only significantly outperforms existing state-of-the-art algorithms on the new Ref-Reasoning dataset, but also surpasses state-of-the-art structured methods on commonly used benchmark datasets. It can also provide interpretable visual evidences of reasoning.",1.0,0.8219055533409119,True,0.3775406687981454,0.5997231110695287,True
Make-A-Story: Visual Memory Conditioned Consistent Story Generation,"There has been a recent explosion of impressive generative models that can produce high quality images (or videos) conditioned on text descriptions. However, all such approaches rely on conditional sentences that contain un-ambiguous descriptions of scenes and main actors in them. Therefore employing such models for more complex task of story visualization, where naturally references and co-references exist, and one requires to reason about when to maintain consistency of actors and backgrounds across frames/scenes, and when not to, based on story progression, remains a challenge. In this work, we address the aforementioned challenges and propose a novel autoregressive diffusion-based framework with a visual memory module that implicitly captures the actor and background context across the generated frames. Sentence-conditioned soft attention over the memories enables effective reference resolution and learns to maintain scene and actor consistency when needed. To validate the effectiveness of our approach, we extend the MUGEN dataset [19] and introduce additional characters, backgrounds and referencing in multi-sentence storylines. Our experiments for story generation on the MUGEN, the PororoSV [30] and the FlintstonesSV [16] dataset show that our method not only outperforms prior state-of-the-art in generating frames with high visual quality, which are consistent with the story, but also models appropriate correspondences between the characters and the background.",1.0,0.882867157459259,True,0.3775406687981454,0.6302039131287023,True
In the Wild Human Pose Estimation Using Explicit 2D Features and Intermediate 3D Representations,"Convolutional Neural Network based approaches for monocular 3D human pose estimation usually require a large amount of training images with 3D pose annotations. While it is feasible to provide 2D joint annotations for large corpora of in-the-wild images with humans, providing accurate 3D annotations to such in-the-wild corpora is hardly feasible in practice. Most existing 3D labelled data sets are either synthetically created or feature in-studio images. 3D pose estimation algorithms trained on such data often have limited ability to generalize to real world scene diversity. We therefore propose a new deep learning based method for monocular 3D human pose estimation that shows high accuracy and generalizes better to in-the-wild scenes. It has a network architecture that comprises a new disentangled hidden space encoding of explicit 2D and 3D features, and uses supervision by a new learned projection model from predicted 3D pose. Our algorithm can be jointly trained on image data with 3D labels and image data with only 2D labels. It achieves state-of-the-art accuracy on challenging in-the-wild data.",1.0,0.7979477047920227,True,0.3775406687981454,0.5877441867950841,True
"Super-Fibonacci Spirals: Fast, Low-Discrepancy Sampling of SO(3)","Super-Fibonacci spirals are an extension of Fibonacci spirals, enabling fast generation of an arbitrary but fixed number of 3D orientations. The algorithm is simple and fast. A comprehensive evaluation comparing to other meth-ods shows that the generated sets of orientations have low discrepancy, minimal spurious components in the power spectrum, and almost identical Voronoi volumes. This makes them useful for a variety of applications, in partic-ular Monte Carlo sampling.",0.8,0.8279886841773987,True,0.3318122278318339,0.5799004560046163,True
Gotta Adapt 'Em All: Joint Pixel and Feature-Level Domain Adaptation for Recognition in the Wild,"Recent developments in deep domain adaptation have allowed knowledge transfer from a labeled source domain to an unlabeled target domain at the level of intermediate features or input pixels. We propose that advantages may be derived by combining them, in the form of different insights that lead to a novel design and complementary properties that result in better performance. At the feature level, inspired by insights from semi-supervised learning, we propose a classification-aware domain adversarial neural network that brings target examples into more classifiable regions of source domain. Next, we posit that computer vision insights are more amenable to injection at the pixel level. In particular, we use 3D geometry and image synthesis based on a generalized appearance flow to preserve identity across pose transformations, while using an attribute-conditioned CycleGAN to translate a single source into multiple target images that differ in lower-level properties such as lighting. Besides standard UDA benchmark, we validate on a novel and apt problem of car recognition in unlabeled surveillance images using labeled images from the web, handling explicitly specified, nameable factors of variation through pixel-level and implicit, unspecified factors through feature-level adaptation.",1.0,0.9030004143714905,True,0.3775406687981454,0.640270541584818,True
Few-Shot Head Swapping in the Wild,"The head swapping task aims at flawlessly placing a source head onto a target body, which is of great importance to various entertainment scenarios. While face swapping has drawn much attention, the task of head swapping has rarely been explored, particularly under the few-shot setting. It is inherently challenging due to its unique needs in head modeling and background blending. In this paper, we present the Head Swapper (HeSer), which achieves few-shot head swapping in the wild through two delicately de-signed modules. Firstly, a Head2Head Aligner is devised to holistically migrate pose and expression information from the target to the source head by examining multi-scale in-formation. Secondly, to tackle the challenges of skin color variations and head-background mismatches in the swapping procedure, a Head2Scene Blender is introduced to si-multaneously modify facial skin color and fill mismatched gaps on the background around the head. Particularly, seamless blending is achieved with the help of a Semantic-Guided Color Reference Creation procedure and a Blending UNet. Extensive experiments demonstrate that the proposed method produces superior head swapping results on a variety of scenes.",1.0,0.97788405418396,True,0.3775406687981454,0.6777123614910527,True
DeepFaceFlow: In-the-Wild Dense 3D Facial Motion Estimation,"Dense 3D facial motion capture from only monocular in-the-wild pairs of RGB images is a highly challenging problem with numerous applications, ranging from facial expression recognition to facial reenactment. In this work, we propose DeepFaceFlow, a robust, fast, and highly-accurate framework for the dense estimation of 3D non-rigid facial flow between pairs of monocular images. Our DeepFaceFlow framework was trained and tested on two very large-scale facial video datasets, one of them of our own collection and annotation, with the aid of occlusion-aware and 3D-based loss function. We conduct comprehensive experiments probing different aspects of our approach and demonstrating its improved performance against state-of-the-art flow and 3D reconstruction methods. Furthermore, we incorporate our framework in a full-head state-of-the-art facial video synthesis method and demonstrate the ability of our method in better representing and capturing the facial dynamics, resulting in a highly-realistic facial video synthesis. Given registered pairs of images, our framework generates 3D flow maps at 60 fps.",1.0,0.8474393486976624,True,0.3775406687981454,0.6124900087479039,True
Learning to Estimate Robust 3D Human Mesh from In-the-Wild Crowded Scenes,"We consider the problem of recovering a single person's 3D human mesh from in-the-wild crowded scenes. While much progress has been in 3D human mesh estimation, existing methods struggle when test input has crowded scenes. The first reason for the failure is a domain gap between training and testing data. A motion capture dataset, which provides accurate 3D labels for training, lacks crowd data and impedes a network from learning crowded scene-robust image features of a target person. The second reason is a feature processing that spatially averages the feature map of a localized bounding box containing multiple people. Averaging the whole feature map makes a target person's feature indistinguishable from others. We present 3DCrowdNet that firstly explicitly targets in-the-wild crowded scenes and estimates a robust 3D human mesh by addressing the above issues. First, we leverage 2D human pose estimation that does not require a motion capture dataset with 3D labels for training and does not suffer from the domain gap. Second, we propose a joint-based regressor that distinguishes a target person's feature from others. Our joint-based regressor preserves the spatial activation of a target by sampling features from the target's joint locations and regresses human model parameters. As a result, 3DCrowdNet learns target-focused features and effectively excludes the irrelevant features of nearby persons. We conduct experiments on various benchmarks and prove the robustness of 3D CrowdNet to the in-the-wild crowded scenes both quantitatively and qualitatively. Codes are available here 11https://github.com/hongsukchoi/3DCrowdNet_RELEASE.",1.0,0.8089579343795776,True,0.3775406687981454,0.5932493015888616,True
Ensemble Generative Cleaning With Feedback Loops for Defending Adversarial Attacks,"Effective defense of deep neural networks against adversarial attacks remains a challenging problem, especially under powerful white-box attacks. In this paper, we develop a new method called ensemble generative cleaning with feedback loops (EGC-FL) for effective defense of deep neural networks. The proposed EGC-FL method is based on two central ideas. First, we introduce a transformed deadzone layer into the defense network, which consists of an orthonormal transform and a deadzone-based activation function, to destroy the sophisticated noise pattern of adversarial attacks. Second, by constructing a generative cleaning network with a feedback loop, we are able to generate an ensemble of diverse estimations of the original clean image. We then learn a network to fuse this set of diverse estimations together to restore the original image. Our extensive experimental results demonstrate that our approach improves the state-of-art by large margins in both white-box and black-box attacks. It significantly improves the classification accuracy for white-box PGD attacks upon the second best method by more than 29% on the SVHN dataset and more than 39% on the challenging CIFAR-10 dataset.",1.0,0.8317571878433228,True,0.3775406687981454,0.6046489283207341,True
Strike (With) a Pose: Neural Networks Are Easily Fooled by Strange Poses of Familiar Objects,"Despite excellent performance on stationary test sets, deep neural networks (DNNs) can fail to generalize to out-of-distribution (OoD) inputs, including natural, non-adversarial ones, which are common in real-world settings. In this paper, we present a framework for discovering DNN failures that harnesses 3D renderers and 3D models. That is, we estimate the parameters of a 3D renderer that cause a target DNN to misbehave in response to the rendered image. Using our framework and a self-assembled dataset of 3D objects, we investigate the vulnerability of DNNs to OoD poses of well-known objects in ImageNet. For objects that are readily recognized by DNNs in their canonical poses, DNNs incorrectly classify 97% of their pose space. In addition, DNNs are highly sensitive to slight pose perturbations. Importantly, adversarial poses transfer across models and datasets. We find that 99.9% and 99.4% of the poses misclassified by Inception-v3 also transfer to the AlexNet and ResNet-50 image classifiers trained on the same ImageNet dataset, respectively, and 75.5% transfer to the YOLOv3 object detector trained on MS COCO.",0.8,0.906868040561676,True,0.3318122278318339,0.6193401341967549,True
OASIS: A Large-Scale Dataset for Single Image 3D in the Wild,"Single-view 3D is the task of recovering 3D properties such as depth and surface normals from a single image. We hypothesize that a major obstacle to single-image 3D is data. We address this issue by presenting Open Annotations of Single Image Surfaces (OASIS), a dataset for single-image 3D in the wild consisting of annotations of detailed 3D geometry for 140,000 images. We train and evaluate leading models on a variety of single-image 3D tasks. We expect OASIS to be a useful resource for 3D vision research. Project site: https://pvl.cs.princeton.edu/OASIS.",1.0,0.7519319653511047,True,0.3775406687981454,0.5647363170746251,True
Face Forensics in the Wild,"On existing public benchmarks, face forgery detection techniques have achieved great success. However, when used in multi-person videos, which often contain many people active in the scene with only a small subset having been manipulated, their performance remains far from being satisfactory. To take face forgery detection to a new level, we construct a novel large-scale dataset, called FFIW10K, which comprises 10,000 high-quality forgery videos, with an average of three human faces in each frame. The manipulation procedure is fully automatic, controlled by a domain-adversarial quality assessment network, making our dataset highly scalable with low human cost. In addition, we propose a novel algorithm to tackle the task of multi-person face forgery detection. Supervised by only video-level label, the algorithm explores multiple instance learning and learns to automatically attend to tampered faces. Our algorithm outperforms representative approaches for both forgery classification and localization on FFIW10K, and also shows high generalization ability on existing benchmarks. We hope that our dataset and study will help the community to explore this new field in more depth.",1.0,0.7919828295707703,True,0.3775406687981454,0.5847617491844579,True
Transitional Adaptation of Pretrained Models for Visual Storytelling,"Previous models for vision-to-language generation tasks usually pretrain a visual encoder and a language generator in the respective domains and jointly finetune them with the target task. However, this direct transfer practice may suffer from the discord between visual specificity and language fluency since they are often separately trained from large corpora of visual and text data with no common ground. In this work, we claim that a transitional adaptation task is required between pretraining and finetuning to harmonize the visual encoder and the language model for challenging downstream target tasks like visual storytelling. We propose a novel approach named Transitional Adaptation of Pre-trained Model (TAPM) that adapts the multi-modal modules to each other with a simpler alignment task between visual inputs only with no need for text labels. Through extensive experiments, we show that the adaptation step significantly improves the performance of multiple language models for sequential video and image captioning tasks. We achieve new state-of-the-art performance on both language metrics and human evaluation in the multi-sentence description task of LSMDC 2019 [50] and the image storytelling task of VIST [18]. Our experiments reveal that this improvement in caption quality does not depend on the specific choice of language models.",1.0,0.7314330339431763,True,0.3775406687981454,0.5544868513706609,True
3PSDF: Three-Pole Signed Distance Function for Learning Surfaces with Arbitrary Topologies,"Recent advances in learning 3D shapes using neural implicit functions have achieved impressive results by breaking the previous barrier of resolution and diversity for varying topologies. However, most of such approaches are limited to closed surfaces as they require the space to be divided into inside and outside. More recent works based on unsigned distance function have been proposed to handle complex geometry containing both the open and closed surfaces. Nonetheless, as their direct outputs are point clouds, robustly obtaining high-quality meshing results from discrete points remains an open question. We present a novel learnable implicit representation, called three-pole signed distance function (3PSDF), that can represent non-watertight 3D shapes with arbitrary topologies while supporting easy field-to-mesh conversion using the classic Marching Cubes algorithm. The key to our method is the introduction of a new sign, the NULL sign, in addition to the conventional in and out labels. The existence of the null sign could stop the formation of a closed isosurface derived from the bisector of the in/out regions. Further, we propose a dedicated learning framework to effectively learn 3PSDF without worrying about the vanishing gradient due to the null labels. Experimental results show that our approach outperforms the previous state-of-the-art methods in a wide range of benchmarks both quantitatively and qualitatively.",1.0,0.7482502460479736,True,0.3775406687981454,0.5628954574230596,True
Mask-Guided Matting in the Wild,"Mask-guided matting has shown great practicality compared to traditional trimap-based methods. The mask-guided approach takes an easily-obtainable coarse mask as guidance and produces an accurate alpha matte. To extend the success toward practical usage, we tackle mask-guided matting in the wild, which covers a wide range of categories in their complex context robustly. To this end, we propose a simple yet effective learning framework based on two core insights: 1) learning a generalized matting model that can better understand the given mask guidance and 2) leveraging weak supervision datasets (e.g., instance segmentation dataset) to alleviate the limited diversity and scale of existing matting datasets. Extensive experimental results on multiple benchmarks, consisting of a newly proposed synthetic benchmark (Composition-Wild) and existing natural datasets, demonstrate the superiority of the proposed method. Moreover, we provide appealing results on new practical applications (e.g., panoptic matting and mask-guided video matting), showing the great generality and potential of our model.",1.0,0.9520420432090759,True,0.3775406687981454,0.6647913560036107,True
Learning Student Networks in the Wild,"Data-free learning for student networks is a new paradigm for solving users’ anxiety caused by the privacy problem of using original training data. Since the architectures of modern convolutional neural networks (CNNs) are compact and sophisticated, the alternative images or meta-data generated from the teacher network are often broken. Thus, the student network cannot achieve the comparable performance to that of the pre-trained teacher network especially on the large-scale image dataset. Different to previous works, we present to maximally utilize the massive available unlabeled data in the wild. Specifically, we first thoroughly analyze the output differences between teacher and student network on the original data and develop a data collection method. Then, a noisy knowledge distillation algorithm is proposed for achieving the performance of the student network. In practice, an adaptation matrix is learned with the student network for correcting the label noise produced by the teacher network on the collected unlabeled images. The effectiveness of our DFND (Data-Free Noisy Distillation) method is then verified on several benchmarks to demonstrate its superiority over state-of-the-art data-free distillation methods. Experiments on various datasets demonstrate that the student networks learned by the proposed method can achieve comparable performance with those using the original dataset. Code is available at https://github.com/huawei-noah/Data-Efficient-Model-Compression",1.0,0.8195832967758179,True,0.3775406687981454,0.5985619827869817,True
Fast Sinkhorn Filters: Using Matrix Scaling for Non-Rigid Shape Correspondence with Functional Maps,"In this paper, we provide a theoretical foundation for pointwise map recovery from functional maps and highlight its relation to a range of shape correspondence methods based on spectral alignment. With this analysis in hand, we develop a novel spectral registration technique: Fast Sinkhorn Filters, which allows for the recovery of accurate and bijective pointwise correspondences with a superior time and memory complexity in comparison to existing approaches. Our method combines the simple and concise representation of correspondence using functional maps with the matrix scaling schemes from computational optimal transport. By exploiting the sparse structure of the kernel matrices involved in the transport map computation, we provide an efficient trade-off between acceptable accuracy and complexity for the problem of dense shape correspondence, while promoting bijectivity.1",1.0,0.7518168091773987,True,0.3775406687981454,0.5646787389877721,True
From Patches to Pictures (PaQ-2-PiQ): Mapping the Perceptual Space of Picture Quality,"Blind or no-reference (NR) perceptual picture quality prediction is a difficult, unsolved problem of great consequence to the social and streaming media industries that impacts billions of viewers daily. Unfortunately, popular NR prediction models perform poorly on real-world distorted pictures. To advance progress on this problem, we introduce the largest (by far) subjective picture quality database, containing about 40, 000 real-world distorted pictures and 120, 000 patches, on which we collected about 4M human judgments of picture quality. Using these picture and patch quality labels, we built deep region-based architectures that learn to produce state-of-the-art global picture quality predictions as well as useful local picture quality maps. Our innovations include picture quality prediction architectures that produce global-to-local inferences as well as local-to-global inferences (via feedback). The dataset and source code are available at https: //live.ece.utexas.edu/research.php.",0.8,0.894934356212616,True,0.3318122278318339,0.6133732920222249,True
It's About Time: Analog Clock Reading in the Wild,"In this paper, we present a framework for reading analog clocks in natural images or videos. Specifically, we make the following contributions: First, we create a scalable pipeline for generating synthetic clocks, significantly reducing the requirements for the labour-intensive annotations; Second, we introduce a clock recognition architecture based on spatial transformer networks (STN), which is trained end-to-end for clock alignment and recognition. We show that the model trained on the proposed synthetic dataset generalises towards real clocks with good accuracy, advocating a Sim2Real training regime; Third, to further reduce the gap between simulation and real data, we leverage the special property of “time”, i.e. uniformity, to generate reliable pseudo-labels on real unlabelled clock videos, and show that training on these videos offers further improvements while still requiring zero manual annotations. Lastly, we introduce three benchmark datasets based on COCO, Open Images, and The Clock movie, with full annotations for time, accurate to the minute.",1.0,0.7600408792495728,True,0.3775406687981454,0.5687907740238591,True
Bringing Inputs to Shared Domains for 3D Interacting Hands Recovery in the Wild,"Despite recent achievements, existing 3D interacting hands recovery methods have shown results mainly on motion capture (MoCap) environments, not on in-the-wild (ITW) ones. This is because collecting 3D interacting hands data in the wild is extremely challenging, even for the 2D data. We present InterWild, which brings MoCap and ITW samples to shared domains for robust 3D interacting hands recovery in the wild with a limited amount of ITW 2D/3D interacting hands data. 3D interacting hands recovery consists of two sub-problems: 1) 3D recovery of each hand and 2) 3D relative translation recovery between two hands. For the first sub-problem, we bring MoCap and ITW samples to a shared 2D scale space. Although ITW datasets provide a limited amount of 2D/3D interacting hands, they contain large-scale 2D single hand data. Motivated by this, we use a single hand image as an input for the first sub-problem regardless of whether two hands are interacting. Hence, interacting hands of MoCap datasets are brought to the 2D scale space of single hands of ITW datasets. For the second sub-problem, we bring MoCap and ITW samples to a shared appearance-invariant space. Unlike the first sub-problem, 2D labels of ITW datasets are not helpful for the second sub-problem due to the 3D translation's ambiguity. Hence, instead of relying on ITW samples, we amplify the generalizability of MoCap samples by taking only a geometric feature without an image as an input for the second sub-problem. As the geometric feature is invariant to appearances, MoCap and ITW samples do not suffer from a huge appearance gap between the two datasets. The code is publicly available11https://github.com/facebookresearch/InterWild.",1.0,0.7735035419464111,True,0.3775406687981454,0.5755221053722783,True
HOP: History-and-Order Aware Pretraining for Vision-and-Language Navigation,"Pretraining has been adopted in a few of recent works for Vision-and-Language Navigation (VLN). However, pre-vious pre-training methods for VLN either lack the ability to predict future actions or ignore the trajectory contexts, which are essential for a greedy navigation process. In this work, to promote the learning of spatio-temporal visual-textual correspondence as well as the agent's capability of decision making, we propose a novel history-and-order aware pre-training paradigm (HOP) with VLN-specific objectives that exploit the past observations and support future action prediction. Specifically, in addition to the commonly used Masked Language Modeling (MLM) and Trajectory-Instruction Matching (TIM), we design two proxy tasks to model temporal order information: Trajectory Order Modeling (TOM) and Group Order Modeling (GOM). Moreover, our navigation action prediction is also enhanced by intro-ducing the task of Action Prediction with History (APH), which takes into account the history visual perceptions. Extensive experimental results on four downstream VLN tasks (R2R, REVERIE, NDH, RxR) demonstrate the effectiveness of our proposed method compared against several state-of-the-art agents.",1.0,0.9272775650024414,True,0.3775406687981454,0.6524091169002935,True
Thermal Spread Functions (TSF): Physics-Guided Material Classification,"Robust and non-destructive material classification is a challenging but crucial first-step in numerous vision applications. We propose a physics-guided material classification framework that relies on thermal properties of the object. Our key observation is that the rate of heating and cooling of an object depends on the unique intrinsic properties of the material, namely the emissivity and diffusivity. We leverage this observation by gently heating the objects in the scene with a low-power laser for a fixed duration and then turning it off, while a thermal camera captures measurements during the heating and cooling process. We then take this spatial and temporal “thermal spread function” (TSF) to solve an inverse heat equation using the finite-differences approach, resulting in a spatially varying estimate of diffusivity and emissivity. These tuples are then used to train a classifier that produces a fine-grained material label at each spatial pixel. Our approach is extremely simple requiring only a small light source (low power laser) and a thermal camera, and produces robust classification results with 86% accuracy over 16 classes11Code: https://github.com/aniketdashpute/TSF.",1.8,0.5340203642845154,False,0.574442516811659,0.5542314405480873,True
Deep Animation Video Interpolation in the Wild,"In the animation industry, cartoon videos are usually produced at low frame rate since hand drawing of such frames is costly and time-consuming. Therefore, it is desirable to develop computational models that can automatically interpolate the in-between animation frames. However, existing video interpolation methods fail to produce satisfying results on animation data. Compared to natural videos, animation videos possess two unique characteristics that make frame interpolation difficult: 1) cartoons comprise lines and smooth color pieces. The smooth areas lack textures and make it difficult to estimate accurate motions on animation videos. 2) cartoons express stories via exaggeration. Some of the motions are non-linear and extremely large. In this work, we formally define and study the animation video interpolation problem for the first time. To address the aforementioned challenges, we propose an effective framework, AnimeInterp, with two dedicated modules in a coarse-to-fine manner. Specifically, 1) Segment-Guided Matching resolves the ""lack of textures"" challenge by exploiting global matching among color pieces that are piece-wise coherent. 2) Recurrent Flow Refinement resolves the ""non-linear and extremely large motion"" challenge by recur-rent predictions using a transformer-like architecture. To facilitate comprehensive training and evaluations, we build a large-scale animation triplet dataset, ATD-12K, which comprises 12,000 triplets with rich annotations. Extensive experiments demonstrate that our approach outperforms existing state-of-the-art interpolation methods for animation videos. Notably, AnimeInterp shows favorable perceptual quality and robustness for animation scenarios in the wild. The proposed dataset and code are available at https://github.com/lisiyao21/AnimeInterp/.",1.0,0.8742042183876038,True,0.3775406687981454,0.6258724435928746,True
3D Semantic Segmentation in the Wild: Learning Generalized Models for Adverse-Condition Point Clouds,"Robust point cloud parsing under all-weather conditions is crucial to level-5 autonomy in autonomous driving. However, how to learn a universal 3D semantic segmentation (3DSS) model is largely neglected as most existing benchmarks are dominated by point clouds captured under normal weather. We introduce SemanticSTF, an adverse-weather point cloud dataset that provides dense point-level annotations and allows to study 3DSS under various adverse weather conditions. We study all-weather 3DSS modeling under two setups: 1) domain adaptive 3DSS that adapts from normal-weather data to adverse-weather data; 2) domain generalizable 3DSS that learns all-weather 3DSS models from normal-weather data. Our studies reveal the challenge while existing 3DSS methods encounter adverse-weather data, showing the great value of SemanticSTF in steering the future endeavor along this very meaningful research direction. In addition, we design a domain randomization technique that alternatively randomizes the geometry styles of point clouds and aggregates their embeddings, ultimately leading to a generalizable model that can improve 3DSS under various adverse weather effectively. The SemanticSTF and related codes are available at https://github.com/xiaoaoran/SemanticSTF.",1.0,0.7924361228942871,True,0.3775406687981454,0.5849883958462163,True
BTS: A Bi-lingual Benchmark for Text Segmentation in the Wild,"As a prerequisite of many text-related tasks such as text erasing and text style transfer, text segmentation arouses more and more attention recently. Current researches mainly focus on only English characters and digits, while few work studies Chinese characters due to the lack of pub-lic large-scale and high-quality Chinese datasets, which limits the practical application scenarios of text segmentation. Different from English which has a limited alphabet of letters, Chinese has much more basic characters with com-plex structures, making the problem more difficult to deal with. To better analyze this problem, we propose the Bi-lingual Text Segmentation (BTS) dataset, a benchmark that covers various common Chinese scenes including 14,250 diverse and fine-annotated text images. BTS mainly focuses on Chinese characters, and also contains English words and digits. We also introduce Prior Guided Text Segmen-tation Network (PGTSNet), the first baseline to handle bi-lingual and complex-structured text segmentation. A plug-in text region highlighting module and a text perceptual dis-criminator are proposed in PGTSNet to supervise the model with text prior, and guide for more stable and finer text seg-mentation. A variation loss is also employed for suppressing background noise under complex scene. Extensive ex-periments are conducted not only to demonstrate the neces-sity and superiority of the proposed dataset BTS, but also to show the effectiveness of the proposed PGTSNet compared with a variety of state-of-the-art text segmentation methods.",1.0,0.8081796765327454,True,0.3775406687981454,0.5928601726654454,True
MagicPony: Learning Articulated 3D Animals in the Wild,"We consider the problem of predicting the 3D shape, articulation, viewpoint, texture, and lighting of an articulated animal like a horse given a single test image as input. We present a new method, dubbed MagicPony, that learns this predictor purely from in-the-wild single-view images of the object category, with minimal assumptions about the topology of deformation. At its core is an implicit-explicit representation of articulated shape and appearance, combining the strengths of neural fields and meshes. In order to help the model understand an object's shape and pose, we distil the knowledge captured by an off-the-shelf self-supervised vision transformer and fuse it into the 3D model. To overcome local optima in viewpoint estimation, we further introduce a new viewpoint sampling scheme that comes at no additional training cost. MagicPony outperforms prior work on this challenging task and demonstrates excellent generalisation in reconstructing art, despite the fact that it is only trained on real images. The code can be found on the project page at https://3dmagicpony.github.io/",2.0,0.9600518941879272,True,0.6224593312018546,0.7912556126948909,True
MagicNet: Semi-Supervised Multi-Organ Segmentation via Magic-Cube Partition and Recovery,"We propose a novel teacher-student model for semi-supervised multi-organ segmentation. In teacher-student model, data augmentation is usually adopted on unlabeled data to regularize the consistent training between teacher and student. We start from a key perspective that fixed relative locationsand variable sizes of different organs can provide distribution information where a multi-organ CT scan is drawn. Thus, we treat the prior anatomy as a strong tool to guide the data augmentation and reduce the mismatch between labeled and unlabeled images for semi-supervised learning. More specifically, we propose a data augmentation strategy based on partition-and-recovery N3 cubes cross-and within-labeled and unlabeled images. Our strategy encourages unlabeled images to learn organ semantics in relative locations from the labeled images (cross-branch) and enhances the learning ability for small organs (within-branch). For within-branch, we further propose to refine the quality of pseudo labels by blending the learned representations from small cubes to incorporate local attributes. Our method is termed as MagicNet, since it treats the CT volume as a magic-cube and N3-cube partition-and-recovery process matches with the rule of playing a magic-cube. Extensive experiments on two public CT multi-organ datasets demonstrate the effectiveness of MagicNet, and noticeably outperforms state-of-the-art semi-supervised medical image segmentation approaches, with + 7% DSC improvement on MACT dataset with 10% labeled images. Code is avaiable at https://github.com/DeepMed-Lab-ECNU/MagicNet.",1.0,0.7699518203735352,True,0.3775406687981454,0.5737462445858403,True
Zero Experience Required: Plug & Play Modular Transfer Learning for Semantic Visual Navigation,"In reinforcement learning for visual navigation, it is common to develop a model for each new task, and train that model from scratch with task-specific interactions in 3D environments. However, this process is expensive; mas-sive amounts of interactions are needed for the model to generalize well. Moreover, this process is repeated when-ever there is a change in the task type or the goal modality. We present a unified approach to visual navigation using a novel modular transfer learning model. Our model can ef-fectively leverage its experience from one source task and apply it to multiple target tasks (e.g., ObjectNav, Room-Nav, Vi ewNav) with various goal modalities (e.g., image, sketch, audio, label). Furthermore, our model enables zero-shot experience learning, whereby it can solve the target tasks without receiving any task-specific interactive training. Our experiments on multiple photorealistic datasets and challenging tasks show that our approach learns faster, generalizes better, and outperforms SoTA models by a sig-nificant margin. Project page: https://vision.cs.utexas.edu/projects/zsel/",0.8,0.9570540189743042,True,0.3318122278318339,0.644433123403069,True
"Pretrain, Self-train, Distill: A simple recipe for Supersizing 3D Reconstruction","Our work learns a unified model for single-view 3D reconstruction of objects from hundreds of semantic categories. As a scalable alternative to direct 3D supervision, our work relies on segmented image collections for learning 3D of generic categories. Unlike prior works that use similar supervision but learn independent category-specific models from scratch, our approach of learning a unified model simplifies the training process while also allowing the model to benefit from the common structure across categories. Using image collections from standard recognition datasets, we show that our approach allows learning 3D inference for over 150 object categories. We evaluate using two datasets and qualitatively and quantitatively show that our unified reconstruction approach improves over prior category-specific reconstruction baselines. Our final 3D reconstruction model is also capable of zero-shot inference on images from unseen object categories and we empirically show that increasing the number of training categories improves the reconstruction quality.",1.0,0.9384233951568604,True,0.3775406687981454,0.6579820319775029,True
Magic Layouts: Structural Prior for Component Detection in User Interface Designs,"We present Magic Layouts; a method for parsing screen-shots or hand-drawn sketches of user interface (UI) layouts. Our core contribution is to extend existing detectors to exploit a learned structural prior for UI designs, enabling robust detection of UI components; buttons, text boxes and similar. Specifically we learn a prior over mobile UI layouts, encoding common spatial co-occurrence relationships between different UI components. Conditioning region proposals using this prior leads to performance gains on UI layout parsing for both hand-drawn UIs and app screen-shots, which we demonstrate within the context an interactive application for rapidly acquiring digital prototypes of user experience (UX) designs.",1.0,0.9076692461967468,True,0.3775406687981454,0.6426049574974462,True
Can't Steal? Cont-Steal! Contrastive Stealing Attacks Against Image Encoders,"Self-supervised representation learning techniques have been developing rapidly to make full use of unlabeled images. They encode images into rich features that are oblivious to downstream tasks. Behind their revolutionary representation power, the requirements for dedicated model designs and a massive amount of computation resources expose image encoders to the risks of potential model stealing attacks - a cheap way to mimic the well-trained encoder performance while circumventing the demanding requirements. Yet conventional attacks only target supervised classifiers given their predicted labels and/or posteriors, which leaves the vulnerability of unsupervised encoders unexplored. In this paper, we first instantiate the conventional stealing attacks against encoders and demonstrate their severer vulnerability compared with downstream classifiers. To better leverage the rich representation of encoders, we further propose Cont-Steal, a contrastive-learning-based attack, and validate its improved stealing effectiveness in various experiment settings. As a takeaway, we appeal to our community's attention to the intellectual property protection of representation learning techniques, especially to the defenses against encoder stealing attacks like ours.11See our code in https://github.com/zeyangsha/Cont-Steal.",0.8,0.979577898979187,True,0.3318122278318339,0.6556950634055104,True
Troubleshooting Blind Image Quality Models in the Wild,"Recently, the group maximum differentiation competition (gMAD) has been used to improve blind image quality assessment (BIQA) models, with the help of full-reference metrics. When applying this type of approach to troubleshoot ""best-performing"" BIQA models in the wild, we are faced with a practical challenge: it is highly nontrivial to obtain stronger competing models for efficient failure-spotting. Inspired by recent findings that difficult samples of deep models may be exposed through network pruning, we construct a set of ""self-competitors,"" as random ensembles of pruned versions of the target model to be improved. Diverse failures can then be efficiently identified via self-gMAD competition. Next, we fine-tune both the target and its pruned variants on the human-rated gMAD set. This allows all models to learn from their respective failures, preparing themselves for the next round of self-gMAD competition. Experimental results demonstrate that our method efficiently troubleshoots BIQA models in the wild with improved generalizability.",1.0,0.7448729872703552,True,0.3775406687981454,0.5612068280342504,True
AvatarMe: Realistically Renderable 3D Facial Reconstruction “In-the-Wild”,"Over the last years, with the advent of Generative Adversarial Networks (GANs), many face analysis tasks have accomplished astounding performance, with applications including, but not limited to, face generation and 3D face reconstruction from a single ""in-the-wild"" image. Nevertheless, to the best of our knowledge, there is no method which can produce high-resolution photorealistic 3D faces from ""in-the-wild"" images and this can be attributed to the: (a) scarcity of available data for training, and (b) lack of robust methodologies that can successfully be applied on very high-resolution data. In this paper, we introduce AvatarMe, the first method that is able to reconstruct photorealistic 3D faces from a single ""in-the-wild"" image with an increasing level of detail. To achieve this, we capture a large dataset of facial shape and reflectance and build on a state-of-the-art 3D texture and shape reconstruction method and successively refine its results, while generating the per-pixel diffuse and specular components that are required for realistic rendering. As we demonstrate in a series of qualitative and quantitative experiments, AvatarMe outperforms the existing arts by a significant margin and reconstructs authentic, 4K by 6K-resolution 3D faces from a single low-resolution image that, for the first time, bridges the uncanny valley.",1.0,0.8959115147590637,True,0.3775406687981454,0.6367260917786046,True
"Zero-Shot Learning — The Good, the Bad and the Ugly","Due to the importance of zero-shot learning, the number of proposed approaches has increased steadily recently. We argue that it is time to take a step back and to analyze the status quo of the area. The purpose of this paper is three-fold. First, given the fact that there is no agreed upon zero-shot learning benchmark, we first define a new benchmark by unifying both the evaluation protocols and data splits. This is an important contribution as published results are often not comparable and sometimes even flawed due to, e.g. pre-training on zero-shot test classes. Second, we compare and analyze a significant number of the state-of-the-art methods in depth, both in the classic zero-shot setting but also in the more realistic generalized zero-shot setting. Finally, we discuss limitations of the current status of the area which can be taken as a basis for advancing it.",1.8,0.7266506552696228,True,0.574442516811659,0.650546586040641,True
Counting Out Time: Class Agnostic Video Repetition Counting in the Wild,"We present an approach for estimating the period with which an action is repeated in a video. The crux of the approach lies in constraining the period prediction module to use temporal self-similarity as an intermediate representation bottleneck that allows generalization to unseen repetitions in videos in the wild. We train this model, called RepNet, with a synthetic dataset that is generated from a large unlabeled video collection by sampling short clips of varying lengths and repeating them with different periods and counts. This combination of synthetic data and a powerful yet constrained model, allows us to predict periods in a class-agnostic fashion. Our model substantially exceeds the state of the art performance on existing periodicity (PERTUBE) and repetition counting (QUVA) benchmarks. We also collect a new challenging dataset called Countix (~90 times larger than existing datasets) which captures the challenges of repetition counting in real-world videos. Project webpage: https://sites.google.com/view/repnet .",1.0,0.9005175828933716,True,0.3775406687981454,0.6390291258457585,True
Gait Recognition in the Wild with Dense 3D Representations and A Benchmark,"Existing studies for gait recognition are dominated by 2D representations like the silhouette or skeleton of the human body in constrained scenes. However, humans live and walk in the unconstrained 3D space, so projecting the 3D human body onto the 2D plane will discard a lot of crucial information like the viewpoint, shape, and dynamics for gait recognition. Therefore, this paper aims to explore dense 3D representations for gait recognition in the wild, which is a practical yet neglected problem. In particular, we propose a novel framework to explore the 3D Skinned Multi-Person Linear (SMPL) model of the human body for gait recognition, named SMPLGait. Our framework has two elaborately-designed branches of which one extracts appearance features from silhouettes, the other learns knowledge of 3D viewpoints and shapes from the 3D SMPL model. In addition, due to the lack of suitable datasets, we build the first large-scale 3D representation-based gait recognition dataset, named Gait3D. It contains 4,000 subjects and over 25,000 sequences extracted from 39 cameras in an unconstrained indoor scene. More importantly, it provides 3D SMPL models recovered from video frames which can provide dense 3D information of body shape, viewpoint, and dynamics. Based on Gait3D, we comprehensively compare our method with existing gait recognition approaches, which reflects the superior performance of our framework and the potential of 3D representations for gait recognition in the wild. The code and dataset are available at: https://gait3d.github.io.",1.0,0.7863479852676392,True,0.3775406687981454,0.5819443270328923,True
Shelf-Supervised Mesh Prediction in the Wild,"We aim to infer 3D shape and pose of object from a single image and propose a learning-based approach that can train from unstructured image collections, supervised by only segmentation outputs from off-the-shelf recognition systems (i.e. ‘shelf-supervised’). We first infer a volumetric representation in a canonical frame, along with the camera pose. We enforce the representation geometrically consistent with both appearance and masks, and also that the synthesized novel views are indistinguishable from image collections. The coarse volumetric prediction is then converted to a mesh-based representation, which is further refined in the predicted camera frame. These two steps allow both shape-pose factorization from image collections and per-instance reconstruction in finer details. We examine the method on both synthetic and the real-world datasets and demonstrate its scalability on 50 categories in the wild, an order of magnitude more classes than existing works.",1.0,0.7572997808456421,True,0.3775406687981454,0.5674202248218938,True
Learning to Predict Visual Attributes in the Wild,"Visual attributes constitute a large portion of information contained in a scene. Objects can be described using a wide variety of attributes which portray their visual appearance (color, texture), geometry (shape, size, posture), and other intrinsic properties (state, action). Existing work is mostly limited to study of attribute prediction in specific domains. In this paper, we introduce a large-scale in-the-wild visual attribute prediction dataset consisting of over 927K attribute annotations for over 260K object instances. Formally, object attribute prediction is a multi-label classification problem where all attributes that apply to an object must be predicted. Our dataset poses significant challenges to existing methods due to large number of attributes, label sparsity, data imbalance, and object occlusion. To this end, we propose several techniques that systematically tackle these challenges, including a base model that utilizes both low- and high-level CNN features with multi-hop attention, reweighting and resampling techniques, a novel negative label expansion scheme, and a novel supervised attribute-aware contrastive learning algorithm. Using these techniques, we achieve near 3.7 mAP and 5.7 overall F1 points improvement over the current state of the art. Further details about the VAW dataset can be found at https://vawdataset.com/",1.0,0.7656694650650024,True,0.3775406687981454,0.571605066931574,True
DeepFlux for Skeletons in the Wild,"Computing object skeletons in natural images is challenging, owing to large variations in object appearance and scale, and the complexity of handling background clutter. Many recent methods frame object skeleton detection as a binary pixel classification problem, which is similar in spirit to learning-based edge detection, as well as to semantic segmentation methods. In the present article, we depart from this strategy by training a CNN to predict a two-dimensional vector field, which maps each scene point to a candidate skeleton pixel, in the spirit of flux-based skeletonization algorithms. This ``image context flux'' representation has two major advantages over previous approaches. First, it explicitly encodes the relative position of skeletal pixels to semantically meaningful entities, such as the image points in their spatial context, and hence also the implied object boundaries. Second, since the skeleton detection context is a region-based vector field, it is better able to cope with object parts of large width. We evaluate the proposed method on three benchmark datasets for skeleton detection and two for symmetry detection, achieving consistently superior performance over state-of-the-art methods.",1.0,0.9394892454147339,True,0.3775406687981454,0.6585149571064397,True
Global Texture Enhancement for Fake Face Detection in the Wild,"Generative Adversarial Networks (GANs) can generate realistic fake face images that can easily fool human beings. On the contrary, a common Convolutional Neural Network(CNN) discriminator can achieve more than99.9%accuracyin discerning fake/real images. In this paper, we conduct an empirical study on fake/real faces, and have two important observations: firstly, the texture of fake faces is substantially different from real ones; secondly, global texture statistics are more robust to image editing and transferable to fake faces from different GANs and datasets. Motivated by the above observations, we propose a new architecture coined as Gram-Net, which leverages global image texture representations for robust fake image detection. Experimental results on several datasets demonstrate that our Gram-Netoutperforms existing approaches. Especially, our Gram-Netis more robust to image editings, e.g. down-sampling, JPEGcompression, blur, and noise. More importantly, our Gram-Net generalizes significantly better in detecting fake faces from GAN models not seen in the training phase and can perform decently in detecting fake natural images",1.0,0.8996592164039612,True,0.3775406687981454,0.6385999426010533,True
Q: How to Specialize Large Vision-Language Models to Data-Scarce VQA Tasks? A: Self-Train on Unlabeled Images!,"Finetuning a large vision language model (VLM) on a target dataset after large scale pretraining is a dominant paradigm in visual question answering (VQA). Datasets for specialized tasks such as knowledge-based VQA or VQA in non natural-image domains are orders of magnitude smaller than those for general-purpose VQA. While collecting additional labels for specialized tasks or domains can be challenging, unlabeled images are often available. We introduce SelTDA (Self-Taught Data Augmentation), a strategy for finetuning large VLMs on small-scale VQA datasets. SelTDA uses the VLM and target dataset to build a teacher model that can generate question-answer pseudolabels directly conditioned on an image alone, allowing us to pseudolabel unlabeled images. SelTDA then finetunes the initial VLM on the original dataset augmented with freshly pseudolabeled images. We describe a series of experiments showing that our self-taught data augmentation increases robustness to adversarially searched questions, counterfactual examples and rephrasings, improves domain generalization, and results in greater retention of numerical reasoning skills. The proposed strategy requires no additional annotations or architectural modifications, and is compatible with any modern encoder-decoder multimodal transformer. Code available at https://github.com/codezakh/SelTDA.",0.8,0.9590913653373718,True,0.3318122278318339,0.6454517965846028,True
Detecting Masked Faces in the Wild with LLE-CNNs,"Detecting faces with occlusions is a challenging task due to two main reasons: 1) the absence of large datasets of masked faces, and 2) the absence of facial cues from the masked regions. To address these two issues, this paper first introduces a dataset, denoted as MAFA, with 30, 811 Internet images and 35, 806 masked faces. Faces in the dataset have various orientations and occlusion degrees, while at least one part of each face is occluded by mask. Based on this dataset, we further propose LLE-CNNs for masked face detection, which consist of three major modules. The Proposal module first combines two pre-trained CNNs to extract candidate facial regions from the input image and represent them with high dimensional descriptors. After that, the Embedding module is incorporated to turn such descriptors into a similarity-based descriptor by using locally linear embedding (LLE) algorithm and the dictionaries trained on a large pool of synthesized normal faces, masked faces and non-faces. In this manner, many missing facial cues can be largely recovered and the influences of noisy cues introduced by diversified masks can be greatly alleviated. Finally, the Verification module is incorporated to identify candidate facial regions and refine their positions by jointly performing the classification and regression tasks within a unified CNN. Experimental results on the MAFA dataset show that the proposed approach remarkably outperforms 6 state-of-the-arts by at least 15.6%.",1.0,0.8241536021232605,True,0.3775406687981454,0.600847135460703,True
Learning Augmentation Network via Influence Functions,"Data augmentation can impact the generalization performance of an image classification model in a significant way. However, it is currently conducted on the basis of trial and error, and its impact on the generalization performance cannot be predicted during training. This paper considers an influence function that predicts how generalization performance, in terms of validation loss, is affected by a particular augmented training sample. The influence function provides an approximation of the change in validation loss without actually comparing the performances that include and exclude the sample in the training process. Based on this function, a differentiable augmentation network is learned to augment an input training sample to reduce validation loss. The augmented sample is fed into the classification network, and its influence is approximated as a function of the parameters of the last fully-connected layer of the classification network. By backpropagating the influence to the augmentation network, the augmentation network parameters are learned. Experimental results on CIFAR-10, CIFAR-100, and ImageNet show that the proposed method provides better generalization performance than conventional data augmentation methods do.",1.0,0.7853038311004639,True,0.3775406687981454,0.5814222499493047,True
Variational Autoencoders Pursue PCA Directions (by Accident),"The Variational Autoencoder (VAE) is a powerful architecture capable of representation learning and generative modeling. When it comes to learning interpretable (disentangled) representations, VAE and its variants show unparalleled performance. However, the reasons for this are unclear, since a very particular alignment of the latent embedding is needed but the design of the VAE does not encourage it in any explicit way. We address this matter and offer the following explanation: the diagonal approximation in the encoder together with the inherent stochasticity force local orthogonality of the decoder. The local behavior of promoting both reconstruction and orthogonality matches closely how the PCA embedding is chosen. Alongside providing an intuitive understanding, we justify the statement with full theoretical analysis as well as with experiments.",0.8,0.9273926615715027,True,0.3318122278318339,0.6296024447016683,True
Critical Regularizations for Neural Surface Reconstruction in the Wild,"Neural implicit functions have recently shown promising results on surface reconstructions from multiple views. However, current methods still suffer from excessive time complexity and poor robustness when reconstructing unbounded or complex scenes. In this paper, we present RegSDF, which shows that proper point cloud supervisions and geometry regularizations are sufficient to produce high-quality and robust reconstruction results. Specifically, RegSDF takes an additional oriented point cloud as input, and optimizes a signed distance field and a surface light field within a differentiable rendering framework. We also introduce the two critical regularizations for this optimization. The first one is the Hessian regularization that smoothly diffuses the signed distance values to the entire distance field given noisy and incomplete input. And the second one is the minimal surface regularization that compactly interpolates and extrapolates the missing geometry. Extensive experiments are conducted on DTU, Blended-MVS, and Tanks and Temples datasets. Compared with recent neural surface reconstruction approaches, RegSDF is able to reconstruct surfaces with fine details even for open scenes with complex topologies and unstructured camera trajectories.",1.0,0.7955730557441711,True,0.3775406687981454,0.5865568622711583,True
Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution,"In this paper, we explore the space-time video super-resolution task, which aims to generate a high-resolution (HR) slow-motion video from a low frame rate (LFR), low-resolution (LR) video. A simple solution is to split it into two sub-tasks: video frame interpolation (VFI) and video super-resolution (VSR). However, temporal interpolation and spatial super-resolution are intra-related in this task. Two-stage methods cannot fully take advantage of the natural property. In addition, state-of-the-art VFI or VSR networks require a large frame-synthesis or reconstruction module for predicting high-quality video frames, which makes the two-stage methods have large model sizes and thus be time-consuming. To overcome the problems, we propose a one-stage space-time video super-resolution framework, which directly synthesizes an HR slow-motion video from an LFR, LR video. Rather than synthesizing missing LR video frames as VFI networks do, we firstly temporally interpolate LR frame features in missing LR video frames capturing local temporal contexts by the proposed feature temporal interpolation network. Then, we propose a deformable ConvLSTM to align and aggregate temporal information simultaneously for better leveraging global temporal contexts. Finally, a deep reconstruction network is adopted to predict HR slow-motion video frames. Extensive experiments on benchmark datasets demonstrate that the proposed method not only achieves better quantitative and qualitative performance but also is more than three times faster than recent two-stage state-of-the-art methods, e.g., DAIN+EDVR and DAIN+RBPN.",1.0,0.845116138458252,True,0.3775406687981454,0.6113284036281987,True
PhraseCut: Language-Based Image Segmentation in the Wild,"We consider the problem of segmenting image regions given a natural language phrase, and study it on a novel dataset of 77,262 images and 345,486 phrase-region pairs. Our dataset is collected on top of the Visual Genome dataset and uses the existing annotations to generate a challenging set of referring phrases for which the corresponding regions are manually annotated. Phrases in our dataset correspond to multiple regions and describe a large number of object and stuff categories as well as their attributes such as color, shape, parts, and relationships with other entities in the image. Our experiments show that the scale and diversity of concepts in our dataset poses significant challenges to the existing state-of-the-art. We systematically handle the long-tail nature of these concepts and present a modular approach to combine category, attribute, and relationship cues that outperforms existing approaches.",1.0,0.8880860209465027,True,0.3775406687981454,0.6328133448723241,True
Multi-View Reconstruction Using Signed Ray Distance Functions (SRDF),"In this paper, we investigate a new optimization framework for multi-view 3D shape reconstructions. Recent differentiable rendering approaches have provided breakthrough performances with implicit shape representations though they can still lack precision in the estimated geometries. On the other hand multi-view stereo methods can yield pixel wise geometric accuracy with local depth predictions along viewing rays. Our approach bridges the gap between the two strategies with a novel volumetric shape representation that is implicit but parameterized with pixel depths to better materialize the shape surface with consistent signed distances along viewing rays. The approach retains pixel-accuracy while benefiting from volumetric integration in the optimization. To this aim, depths are optimized by evaluating, at each 3D location within the volumetric discretization, the agreement between the depth prediction consistency and the photometric consistency for the corresponding pixels. The optimization is agnostic to the associated photo-consistency term which can vary from a median-based baseline to more elaborate criteria, e.g. learned functions. Our experiments demonstrate the benefit of the volumetric integration with depth predictions. They also show that our approach outperforms existing approaches over standard 3D benchmarks with better geometry estimations.",1.8,0.6622017025947571,True,0.574442516811659,0.6183221097032081,True
"Face Normals ""In-the-Wild"" Using Fully Convolutional Networks","In this work we pursue a data-driven approach to the problem of estimating surface normals from a single intensity image, focusing in particular on human faces. We introduce new methods to exploit the currently available facial databases for dataset construction and tailor a deep convolutional neural network to the task of estimating facial surface normals in-the-wild. We train a fully convolutional network that can accurately recover facial normals from images including a challenging variety of expressions and facial poses. We compare against state-of-the-art face Shape-from-Shading and 3D reconstruction techniques and show that the proposed network can recover substantially more accurate and realistic normals. Furthermore, in contrast to other existing face-specific surface recovery methods, we do not require the solving of an explicit alignment step due to the fully convolutional nature of our network.",1.0,0.8453693389892578,True,0.3775406687981454,0.6114550038937017,True
Learning Neural Proto-Face Field for Disentangled 3D Face Modeling in the Wild,"Generative models show good potential for recovering 3D faces beyond limited shape assumptions. While plausible details and resolutions are achieved, these models easily fail under extreme conditions of pose, shadow or appearance, due to the entangled fitting or lack of multi-view priors. To address this problem, this paper presents a novel Neural Proto-face Field (NPF) for unsupervised robust 3D face modeling. Instead of using constrained images as Neural Radiance Field (NeRF), NPF disentangles the common/specific facial cues, i.e., ID, expression and scene-specific details from in-the-wild photo collections. Specifically, NPF learns a face prototype to aggregate 3D-consistent identity via uncertainty modeling, extracting multi-image priors from a photo collection. NPF then learns to deform the prototype with the appropriate facial expressions, constrained by a loss of expression consistency and personal idiosyncrasies. Finally, NPF is optimized to fit a target image in the collection, recovering specific details of appearance and geometry. In this way, the generative model benefits from multi-image priors and meaningful facial structures. Extensive experiments on benchmarks show that NPF recovers superior or competitive facial shapes and textures, compared to state-of-the-art methods.",1.0,0.7491559386253357,True,0.3775406687981454,0.5633483037117406,True
Modeling Entities as Semantic Points for Visual Information Extraction in the Wild,"Recently, Visual Information Extraction (VIE) has been becoming increasingly important in both the academia and industry, due to the wide range of real-world applications. Previously, numerous works have been proposed to tackle this problem. However, the benchmarks used to assess these methods are relatively plain, i.e., scenarios with real-world complexity are not fully represented in these benchmarks. As the first contribution of this work, we curate and release a new dataset for VIE, in which the document images are much more challenging in that they are taken from real applications, and difficulties such as blur, partial occlusion, and printing shift are quite common. All these factors may lead to failures in information extraction. Therefore, as the second contribution, we explore an alternative approach to precisely and robustly extract key information from document images under such tough conditions. Specifically, in contrast to previous methods, which usually either incorporate visual information into a multi-modal architecture or train text spotting and information extraction in an end-to-end fashion, we explicitly model entities as semantic points, i.e., center points of entities are enriched with semantic information describing the attributes and relationships of different entities, which could largely benefit entity labeling and linking. Extensive experiments on standard benchmarks in this field as well as the proposed dataset demonstrate that the proposed method can achieve significantly enhanced performance on entity labeling and linking, compared with previous state-of-the-art models. Dataset is available at https://www.modelscope.cn/datasets/damo/SIBR/summary.",1.0,0.7690005898475647,True,0.3775406687981454,0.5732706293228551,True
Depth from Defocus in the Wild,"We consider the problem of two-frame depth from defocus in conditions unsuitable for existing methods yet typical of everyday photography: a handheld cellphone camera, a small aperture, a non-stationary scene and sparse surface texture. Our approach combines a global analysis of image content&#x2014;3D surfaces, deformations, figure-ground relations, textures&#x2014;with local estimation of joint depth-flow likelihoods in tiny patches. To enable local estimation we (1) derive novel defocus-equalization filters that induce brightness constancy across frames and (2) impose a tight upper bound on defocus blur&#x2014;just three pixels in radius&#x2014;through an appropriate choice of the second frame. For global analysis we use a novel piecewise-spline scene representation that can propagate depth and flow across large irregularly-shaped regions. Our experiments show that this combination preserves sharp boundaries and yields good depth and flow maps in the face of significant noise, uncertainty, non-rigidity, and data sparsity.",1.0,0.7909027934074402,True,0.3775406687981454,0.5842217311027929,True
Lipstick ain’t enough: Beyond Color Matching for In-the-Wild Makeup Transfer,"Makeup transfer is the task of applying on a source face the makeup style from a reference image. Real-life makeups are diverse and wild, which cover not only color-changing but also patterns, such as stickers, blushes, and jewelries. However, existing works overlooked the latter components and confined makeup transfer to color manipulation, focusing only on light makeup styles. In this work, we propose a holistic makeup transfer framework that can handle all the mentioned makeup components. It consists of an improved color transfer branch and a novel pattern transfer branch to learn all makeup properties, including color, shape, texture, and location. To train and evaluate such a system, we also introduce new makeup datasets for real and synthetic extreme makeup. Experimental results show that our framework achieves the state of the art performance on both light and extreme makeup styles. Code is available at https://github.com/VinAIResearch/CPM.",1.0,0.9360268115997314,True,0.3775406687981454,0.6567837401989385,True
Video Magnification in the Wild Using Fractional Anisotropy in Temporal Distribution,"Video magnification methods can magnify and reveal subtle changes invisible to the naked eye. However, in such subtle changes, meaningful ones caused by physical and natural phenomena are mixed with non-meaningful ones caused by photographic noise. Therefore, current methods often produce noisy and misleading magnification outputs due to the non-meaningful subtle changes. For detecting only meaningful subtle changes, several methods have been proposed but require human manipulations, additional resources, or input video scene limitations. In this paper, we present a novel method using fractional anisotropy (FA) to detect only meaningful subtle changes without the aforementioned requirements. FA has been used in neuroscience to evaluate anisotropic diffusion of water molecules in the body. On the basis of our observation that temporal distribution of meaningful subtle changes more clearly indicates anisotropic diffusion than that of non-meaningful ones, we used FA to design a fractional anisotropic filter that passes only meaningful subtle changes. Using the filter enables our method to obtain better and more impressive magnification results than those obtained with state-of-the-art methods.",1.0,0.8155211806297302,True,0.3775406687981454,0.5965309247139379,True
Shapes and Context: In-The-Wild Image Synthesis & Manipulation,"We introduce a data-driven model for interactively synthesizing in-the-wild images from semantic label input masks. Our approach is dramatically different from recent work in this space, in that we make use of no learning. Instead, our approach uses simple but classic tools for matching scene context, shapes, and parts to a stored library of exemplars. Though simple, this approach has several notable advantages over recent work: (1) because nothing is learned, it is not limited to specific training data distributions (such as cityscapes, facades, or faces); (2) it can synthesize arbitrarily high-resolution images, limited only by the resolution of the exemplar library; (3) by appropriately composing shapes and parts, it can generate an exponentially large set of viable candidate output images (that can say, be interactively searched by a user). We present results on the diverse COCO dataset, significantly outperforming learning-based approaches on standard image synthesis metrics. Finally, we explore user-interaction and user-controllability, demonstrating that our system can be used as a platform for user-driven content creation.",1.8,0.9306396842002869,True,0.574442516811659,0.752541100505973,True
GINA-3D: Learning to Generate Implicit Neural Assets in the Wild,"Modeling the 3D world from sensor data for simulation is a scalable way of developing testing and validation environments for robotic learning problems such as autonomous driving. However, manually creating or recreating real-world-like environments is difficult, expensive, and not scalable. Recent generative model techniques have shown promising progress to address such challenges by learning 3D assets using only plentiful 2D images - but still suffer limitations as they leverage either human-curated image datasets or renderings from manually-created synthetic 3D environments. In this paper, we introduce GINA-3D, a generative model that uses real-world driving data from camera and LiDAR sensors to create realistic 3D implicit neural assets of diverse vehicles and pedestrians. Compared to the existing image datasets, the real-world driving setting poses new challenges due to occlusions, lighting-variations and longtail distributions. GINA-3D tackles these challenges by decoupling representation learning and generative modeling into two stages with a learned triplane latent structure, inspired by recent advances in generative modeling of images. To evaluate our approach, we construct a large-scale object-centric dataset containing over 520K images of vehicles and pedestrians from the Waymo Open Dataset, and a new set of 80K images of longtail instances such as construction equipment, garbage trucks, and cable cars. We compare our model with existing approaches and demonstrate that it achieves state-of-the-art performance in quality and diversity for both generated images and geometries.",1.0,0.7889074683189392,True,0.3775406687981454,0.5832240685585424,True
Whose Hands are These? Hand Detection and Hand-Body Association in the Wild,"We study a new problem of detecting hands and finding the location of the corresponding person for each detected hand. This task is helpful for many downstream tasks such as hand tracking and hand contact estimation. Associating hands with people is challenging in unconstrained conditions since multiple people can be present in the scene with varying overlaps and occlusions. We propose a novel end-to-end trainable convolutional network that can Jointly detect hands and the body location for the corresponding person. Our method first detects a set of hands and bodies and uses a novel Hand-Body Association Network to predict association scores between them. We use these association scores to find the body location for each detected hand. We also introduce a new challenging dataset called BodyHands containing uncon-strained images with hand and their corresponding body locations annotations. We conduct extensive experiments on BodyHands and another public dataset to show the effectiveness of our method. Finally, we demonstrate the benefits of hand-body association in two critical applications: hand tracking and hand contact estimation. Our experiments show that hand tracking and hand contact estimation methods can be improved significantly by reasoning about the hand-body association. Code and data can be found at http://vision.cs.stonybrook.edu/~supreeth/BodyHands/.",1.3,0.8511168360710144,True,0.45016600268752216,0.6506414193792682,True
Blindly Assess Image Quality in the Wild Guided by a Self-Adaptive Hyper Network,"Blind image quality assessment (BIQA) for authentically distorted images has always been a challenging problem, since images captured in the wild include varies contents and diverse types of distortions. The vast majority of prior BIQA methods focus on how to predict synthetic image quality, but fail when applied to real-world distorted images. To deal with the challenge, we propose a self-adaptive hyper network architecture to blind assess image quality in the wild. We separate the IQA procedure into three stages including content understanding, perception rule learning and quality predicting. After extracting image semantics, perception rule is established adaptively by a hyper network, and then adopted by a quality prediction network. In our model, image quality can be estimated in a self-adaptive manner, thus generalizes well on diverse images captured in the wild. Experimental results verify that our approach not only outperforms the state-of-the-art methods on challenging authentic image databases but also achieves competing performances on synthetic image databases, though it is not explicitly designed for the synthetic task.",1.0,0.7536945939064026,True,0.3775406687981454,0.565617631352274,True
Large-Scale Object Detection in the Wild From Imbalanced Multi-Labels,"Training with more data has always been the most stable and effective way of improving performance in deep learn-ing era. As the largest object detection dataset so far, OpenImages brings great opportunities and challenges for object detection in general and sophisticated scenarios. However, owing to its semi-automatic collecting and labeling pipeline to deal with the huge data scale, Open Images dataset suffers from label-related problems that objects may explicitly or implicitly have multiple labels and the label distribution is extremely imbalanced. In this work, we quantitatively analyze these label problems and provide a simple but effective solution. We design a concurrent softmax to handle the multi-label problems in object detection and propose a soft-sampling methods with hybrid training scheduler to deal with the label imbalance. Overall, our method yields a dramatic improvement of 3.34 points, leading to the best single model with 60.90 mAP on the public object detection test set of Open Images. And our ensembling result achieves 67.17mAP, which is 4.29 points higher than the first place method last year.",1.0,0.7828693985939026,True,0.3775406687981454,0.580205033696024,True
Progressive Attention Memory Network for Movie Story Question Answering,"This paper proposes the progressive attention memory network (PAMN) for movie story question answering (QA). Movie story QA is challenging compared to VQA in two aspects: (1) pinpointing the temporal parts relevant to answer the question is difficult as the movies are typically longer than an hour, (2) it has both video and subtitle where different questions require different modality to infer the answer. To overcome these challenges, PAMN involves three main features: (1) progressive attention mechanism that utilizes cues from both question and answer to progressively prune out irrelevant temporal parts in memory, (2) dynamic modality fusion that adaptively determines the contribution of each modality for answering the current question, and (3) belief correction answering scheme that successively corrects the prediction score on each candidate answer. Experiments on publicly available benchmark datasets, MovieQA and TVQA, demonstrate that each feature contributes to our movie story QA architecture, PAMN, and improves performance to achieve the state-of-the-art result. Qualitative analysis by visualizing the inference mechanism of PAMN is also provided.",1.0,0.8117343783378601,True,0.3775406687981454,0.5946375235680028,True
Feature-Level Frankenstein: Eliminating Variations for Discriminative Recognition,"Recent successes of deep learning-based recognition rely on maintaining the content related to the main-task label. However, how to explicitly dispel the noisy signals for better generalization remains an open issue. We systematically summarize the detrimental factors as task-relevant/irrelevant semantic variations and unspecified latent variation. In this paper, we cast these problems as an adversarial minimax game in the latent space. Specifically, we propose equipping an end-to-end conditional adversarial network with the ability to decompose an input sample into three complementary parts. The discriminative representation inherits the desired invariance property guided by prior knowledge of the task, which is marginally independent to the task-relevant/irrelevant semantic and latent variations. Our proposed framework achieves top performance on a serial of tasks, including digits recognition, lighting, makeup, disguise-tolerant face recognition, and facial attributes recognition.",1.0,0.8962611556053162,True,0.3775406687981454,0.6369009122017308,True
Zoom In and Out: A Mixed-scale Triplet Network for Camouflaged Object Detection,"The recently proposed camouflaged object detection (COD) attempts to segment objects that are visually blended into their surroundings, which is extremely complex and difficult in real-world scenarios. Apart from high intrinsic similarity between the camouflaged objects and their background, the objects are usually diverse in scale, fuzzy in appearance, and even severely occluded. To deal with these problems, we propose a mixed-scale triplet network, Zoom- Net, which mimics the behavior of humans when observing vague images, i.e., zooming in and out. Specifically, our ZoomNet employs the zoom strategy to learn the discriminative mixed-scale semantics by the designed scale integration unit and hierarchical mixed-scale unit, which fully explores imperceptible clues between the candidate objects and background surroundings. Moreover, considering the uncertainty and ambiguity derived from indistinguishable textures, we construct a simple yet effective regularization constraint, uncertainty-aware loss, to promote the model to accurately produce predictions with higher confidence in candidate regions. Without bells and whistles, our proposed highly task-friendly model consistently surpasses the existing 23 state-of-the-art methods on four public datasets. Besides, the superior performance over the recent cutting-edge models on the SOD task also verifies the effectiveness and generality of our model. The code will be available at https://github.com/lartpang/ZoomNet.",1.0,0.8460742235183716,True,0.3775406687981454,0.6118074461582585,True
Vid2Avatar: 3D Avatar Reconstruction from Videos in the Wild via Self-supervised Scene Decomposition,"We present Vid2Avatar, a method to learn human avatars from monocular in-the-wild videos. Reconstructing humans that move naturally from monocular in-the-wild videos is difficult. Solving it requires accurately separating humans from arbitrary backgrounds. Moreover, it requires reconstructing detailed 3D surface from short video sequences, making it even more challenging. Despite these challenges, our method does not require any groundtruth supervision or priors extracted from large datasets of clothed human scans, nor do we rely on any external segmentation modules. Instead, it solves the tasks of scene decomposition and surface reconstruction directly in 3D by modeling both the human and the background in the scene jointly, parameterized via two separate neural fields. Specifically, we define a temporally consistent human representation in canonical space and formulate a global optimization over the background model, the canonical human shape and texture, and per-frame human pose parameters. A coarse-to-fine sampling strategy for volume rendering and novel objectives are introduced for a clean separation of dynamic human and static background, yielding detailed and robust 3D human reconstructions. The evaluation of our method shows improvements over prior art on publicly available datasets.",1.0,0.7291480302810669,True,0.3775406687981454,0.5533443495396062,True
Spatiotemporal Self-Supervised Learning for Point Clouds in the Wild,"Self-supervised learning (SSL) has the potential to benefit many applications, particularly those where manually annotating data is cumbersome. One such situation is the semantic segmentation of point clouds. In this context, existing methods employ contrastive learning strategies and define positive pairs by performing various augmentation of point clusters in a single frame. As such, these methods do not exploit the temporal nature of LiDAR data. In this paper, we introduce an SSL strategy that leverages positive pairs in both the spatial and temporal domain. To this end, we design (i) a point-to-cluster learning strategy that aggregates spatial information to distinguish objects; and (ii) a cluster-to-cluster learning strategy based on unsupervised object tracking that exploits temporal correspondences. We demonstrate the benefits of our approach via extensive experiments performed by self-supervised training on two large-scale LiDAR datasets and transferring the resulting models to other point cloud segmentation benchmarks. Our results evidence that our method outperforms the state-of-the-art point cloud SSL methods.11Our code and pretrained models will be found at https://github.com/YanhaoWu/STSSL. Correspondence to Ke Wei.",1.0,0.8282448053359985,True,0.3775406687981454,0.602892737067072,True
Distilling Self-Supervised Vision Transformers for Weakly-Supervised Few-Shot Classification & Segmentation,"We address the task of weakly-supervised few-shot image classification and segmentation, by leveraging a Vision Transformer (ViT) pretrained with self-supervision. Our proposed method takes token representations from the self-supervised ViT and leverages their correlations, via selfattention, to produce classification and segmentation predictions through separate task heads. Our model is able to effectively learn to perform classification and segmentation in the absence of pixel-level labels during training, using only image-level labels. To do this it uses attention maps, created from tokens generated by the self-supervised ViT backbone, as pixel-level pseudo-labels. We also explore a practical setup with “mixed” supervision, where a small number of training images contains ground-truth pixel-level labels and the remaining images have only image-level labels. For this mixed setup, we propose to improve the pseudo-labels using a pseudo-label enhancer that was trained using the available ground-truth pixel-level labels. Experiments on Pascal-5i and COCO-20i demonstrate significant performance gains in a variety of supervision settings, and in particular when little-to-no pixel-level labels are available.",0.8,0.8006893992424011,True,0.3318122278318339,0.5662508135371175,True
Magic3D: High-Resolution Text-to-3D Content Creation,"DreamFusion [31] has recently demonstrated the utility of a pretrained text-to-image diffusion model to optimize Neural Radiance Fields (NeRF) [23], achieving remarkable text-to-3D synthesis results. However, the method has two inherent limitations: (a) extremely slow optimization of NeRF and (b) low-resolution image space supervision on NeRF, leading to low-quality 3D models with a long processing time. In this paper, we address these limitations by utilizing a two-stage optimization framework. First, we obtain a coarse model using a low-resolution diffusion prior and accelerate with a sparse 3D hash grid structure. Using the coarse representation as the initialization, we further optimize a textured 3D mesh model with an efficient differentiable renderer interacting with a high-resolution latent diffusion model. Our method, dubbed Magic3D, can create high quality 3D mesh models in 40 minutes, which is 2× faster than DreamFusion (reportedly taking 1.5 hours on average), while also achieving higher resolution. User studies show 61.7% raters to prefer our approach over DreamFusion. Together with the image-conditioned generation capabilities, we provide users with new ways to control 3D synthesis, opening up new avenues to various creative applications.",1.0,0.8411878347396851,True,0.3775406687981454,0.6093642517689153,True
Robust Partial Matching for Person Search in the Wild,"Various factors like occlusions, backgrounds, etc., would lead to misaligned detected bounding boxes , e.g., ones covering only portions of human body. This issue is common but overlooked by previous person search works. To alleviate this issue, this paper proposes an Align-to-Part Network (APNet) for person detection and re-Identification (reID). APNet refines detected bounding boxes to cover the estimated holistic body regions, from which discriminative part features can be extracted and aligned. Aligned part features naturally formulate reID as a partial feature matching procedure, where valid part features are selected for similarity computation, while part features on occluded or noisy regions are discarded. This design enhances the robustness of person search to real-world challenges with marginal computation overhead. This paper also contributes a Large-Scale dataset for Person Search in the wild (LSPS), which is by far the largest and the most challenging dataset for person search. Experiments show that APNet brings considerable performance improvement on LSPS. Meanwhile, it achieves competitive performance on existing person search benchmarks like CUHK-SYSU and PRW.",1.0,0.7671653628349304,True,0.3775406687981454,0.572353015816538,True
Dual Attention Guided Gaze Target Detection in the Wild,"Gaze target detection aims to infer where each person in a scene is looking. Existing works focus on 2D gaze and 2D saliency, but fail to exploit 3D contexts. In this work, we propose a three-stage method to simulate the human gaze inference behavior in 3D space. In the first stage, we introduce a coarse-to-fine strategy to robustly estimate a 3D gaze orientation from the head. The predicted gaze is decomposed into a planar gaze on the image plane and a depth-channel gaze. In the second stage, we develop a Dual Attention Module (DAM), which takes the planar gaze to produce the filed of view and masks interfering objects regulated by depth information according to the depth-channel gaze. In the third stage, we use the generated dual attention as guidance to perform two sub-tasks: (1) identifying whether the gaze target is inside or out of the image; (2) locating the target if inside. Extensive experiments demonstrate that our approach performs favorably against state-of-the-art methods on GazeFollow and VideoAttentionTarget datasets.",1.0,0.8434069156646729,True,0.3775406687981454,0.6104737922314092,True
On Aliased Resizing and Surprising Subtleties in GAN Evaluation,"Metrics for evaluating generative models aim to measure the discrepancy between real and generated images. The often-used Fréchet Inception Distance (FID) metric, for example, extracts “high-level” features using a deep network from the two sets. However, we find that the differences in “low-level” preprocessing, specifically image resizing and compression, can induce large variations and have unforeseen consequences. For instance, when resizing an image, e.g., with a bilinear or bicubic kernel, signal processing principles mandate adjusting prefilter width depending on the downsampling factor, to antialias to the appropriate bandwidth. However, commonly-used implementations use a fixed-width prefilter, resulting in aliasing artifacts. Such aliasing leads to corruptions in the feature extraction down-stream. Next, lossy compression, such as JPEG, is commonly used to reduce the file size of an image. Although designed to minimally degrade the perceptual quality of an image, the operation also produces variations downstream. Furthermore, we show that if compression is used on real training images, FID can actually improve if the generated images are also subsequently compressed. This paper shows that choices in low-level image processing have been an under-appreciated aspect of generative modeling. We identify and characterize variations in generative modeling development pipelines, provide recommendations based on signal processing principles, and release a reference implementation to facilitate future comparisons.",1.0,0.9197512865066528,True,0.3775406687981454,0.6486459776523992,True
Curls & Whey: Boosting Black-Box Adversarial Attacks,"Image classifiers based on deep neural networks suffer from harassment caused by adversarial examples. Two defects exist in black-box iterative attacks that generate adversarial examples by incrementally adjusting the noise-adding direction for each step. On the one hand, existing iterative attacks add noises monotonically along the direction of gradient ascent, resulting in a lack of diversity and adaptability of the generated iterative trajectories. On the other hand, it is trivial to perform adversarial attack by adding excessive noises, but currently there is no refinement mechanism to squeeze redundant noises. In this work, we propose Curls \& Whey black-box attack to fix the above two defects. During Curls iteration, by combining gradient ascent and descent, we `curl' up iterative trajectories to integrate more diversity and transferability into adversarial examples. Curls iteration also alleviates the diminishing marginal effect in existing iterative attacks. The Whey optimization further squeezes the `whey' of noises by exploiting the robustness of adversarial perturbation. Extensive experiments on Imagenet and Tiny-Imagenet demonstrate that our approach achieves impressive decrease on noise magnitude in l2 norm. Curls & Whey attack also shows promising transferability against ensemble models as well as adversarially trained models. In addition, we extend our attack to the targeted misclassification, effectively reducing the difficulty of targeted attacks under black-box condition.",0.8,0.9754326939582825,True,0.3318122278318339,0.6536224608950582,True
Neural Rerendering in the Wild,"We explore total scene capture --- recording, modeling, and rerendering a scene under varying appearance such as season and time of day. Starting from Internet photos of a tourist landmark, we apply traditional 3D reconstruction to register the photos and approximate the scene as a point cloud. For each photo, we render the scene points into a deep framebuffer, and train a deep neural network to learn the mapping of these initial renderings to the actual photos. This rerendering network also takes as input a latent appearance vector and a semantic mask indicating the location of transient objects like pedestrians. The model is evaluated on several datasets of publicly available images spanning a broad range of illumination conditions. We create short videos that demonstrate realistic manipulation of the image viewpoint, appearance, and semantic labels. We also compare results to prior work on scene reconstruction from Internet photos.",1.0,0.82242351770401,True,0.3775406687981454,0.5999820932510778,True
VindLU: A Recipe for Effective Video-and-Language Pretraining,"The last several years have witnessed remarkable progress in video-and-language (VidL) understanding. However, most modern VidL approaches use complex and specialized model architectures and sophisticated pretraining protocols, making the reproducibility, analysis and comparisons of these frameworks difficult. Hence, instead of proposing yet another new VidL model, this paper conducts a thorough empirical study demystifying the most important factors in the VidL model design. Among the factors that we investigate are (i) the spatiotemporal architecture design, (ii) the multimodal fusion schemes, (iii) the pretraining objectives, (iv) the choice of pretraining data, (v) pretraining and finetuning protocols, and (vi) dataset and model scaling. Our empirical study reveals that the most important design factors include: temporal modeling, video-to-text multimodal fusion, masked modeling objectives, and joint training on images and videos. Using these empirical insights, we then develop a step-by-step recipe, dubbed VindLU, for effective VidL pretraining. Our final model trained using our recipe achieves comparable or better than state-of-the-art results on several VidL tasks without relying on external CLIP pretraining. In particular, on the text-to-video retrieval task, our approach obtains 61.2% on DiDeMo, and 55.0% on ActivityNet, outperforming current SOTA by 7.8% and 6.1% respectively. Furthermore, our model also obtains state-of-the-art video question-answering results on ActivityNet-QA, MSRVTT-QA, MSRVTT-MC and TVQA. Our code and pretrained models are publicly available at: https://github.com/klauscc/VindLU.",1.0,0.7520173788070679,True,0.3775406687981454,0.5647790238026067,True
More than Words: In-the-Wild Visually-Driven Prosody for Text-to-Speech,"In this paper we present VDTTS, a Visually-Driven Text-to-Speech model. Motivated by dubbing, VDTTS takes ad-vantage of video frames as an additional input alongside text, and generates speech that matches the video signal. We demonstrate how this allows VDTTS to, unlike plain TTS models, generate speech that not only has prosodic variations like natural pauses and pitch, but is also synchronized to the input video. Experimentally, we show our model produces well-synchronized outputs, approaching the video-speech synchronization quality of the ground-truth, on several challenging benchmarks including “in-the-wild” content from VoxCeleb2. Supplementary demo videos demonstrating video-speech synchronization, robustness to speaker ID swapping, and prosody, presented at the project page.11Project page: http://google-research.github.io/lingvo-lab/vdtts",1.0,0.9105913043022156,True,0.3775406687981454,0.6440659865501805,True
Cooling-Shrinking Attack: Blinding the Tracker With Imperceptible Noises,"Adversarial attack of CNN aims at deceiving models to misbehave by adding imperceptible perturbations to images. This feature facilitates to understand neural networks deeply and to improve the robustness of deep learning models. Although several works have focused on attacking image classifiers and object detectors, an effective and efficient method for attacking single object trackers of any target in a model-free way remains lacking. In this paper, a cooling-shrinking attack method is proposed to deceive state-of-the-art SiameseRPN-based trackers. An effective and efficient perturbation generator is trained with a carefully designed adversarial loss, which can simultaneously cool hot regions where the target exists on the heatmaps and force the predicted bounding box to shrink, making the tracked target invisible to trackers. Numerous experiments on OTB100, VOT2018, and LaSOT datasets show that our method can effectively fool the state-of-the-art SiameseRPN++ tracker by adding small perturbations to the template or the search regions. Besides, our method has good transferability and is able to deceive other top-performance trackers such as DaSiamRPN, DaSiamRPN-UpdateNet, and DiMP. The source codes are available at https://github.com/MasterBin-IIAU/CSA.",1.0,0.776742696762085,True,0.3775406687981454,0.5771416827801152,True
"Analyzing Computer Vision Data — The Good, the Bad and the Ugly","In recent years, a great number of datasets were published to train and evaluate computer vision (CV) algorithms. These valuable contributions helped to push CV solutions to a level where they can be used for safety-relevant applications, such as autonomous driving. However, major questions concerning quality and usefulness of test data for CV evaluation are still unanswered. Researchers and engineers try to cover all test cases by using as much test data as possible. In this paper, we propose a different solution for this challenge. We introduce a method for dataset analysis which builds upon an improved version of the CV-HAZOP checklist, a list of potential hazards within the CV domain. Picking stereo vision as an example, we provide an extensive survey of 28 datasets covering the last two decades. We create a tailored checklist and apply it to the datasets Middlebury, KITTI, Sintel, Freiburg, and HCI to present a thorough characterization and quantitative comparison. We confirm the usability of our checklist for identification of challenging stereo situations by applying nine state-of-the-art stereo matching algorithms on the analyzed datasets, showing that hazard frames correlate with difficult frames. We show that challenging datasets still allow a meaningful algorithm evaluation even for small subsets. Finally, we provide a list of missing test cases that are still not covered by current datasets as inspiration for researchers who want to participate in future dataset creation.",1.8,0.6536650657653809,True,0.574442516811659,0.61405379128852,True
Dressing in the Wild by Watching Dance Videos,"While significant progress has been made in garment transfer, one of the most applicable directions of human-centric image generation, existing works overlook the in-the-wild imagery, presenting severe garment-person mis-alignment as well as noticeable degradation in fine texture details. This paper, therefore, attends to virtual try-on in real-world scenes and brings essential improvements in authenticity and naturalness especially for loose garment (e.g., skirts, formal dresses), challenging poses (e.g., cross arms, bent legs), and cluttered backgrounds. Specifically, we find that the pixel flow excels at handling loose gar-ments whereas the vertex flow is preferred for hard poses, and by combining their advantages we propose a novel generative network called wFlow that can effectively push up garment transfer to in-the-wild context. Moreover, former approaches require paired images for training. Instead, we cut down the laboriousness by working on a newly constructed large-scale video dataset named Dance50k with self-supervised cross-frame training and an online cycle op-timization. The proposed Dance50k can boost real-world virtual dressing by covering a wide variety of garments under dancing poses. Extensive experiments demonstrate the superiority of our w Flow in generating realistic garment transfer results for in-the-wild images without resorting to expensive paired datasets. 11Xiaodan Liang is the corresponding author. The project page of wFlow is https://awesome-wflow.github.io.",1.0,0.9668548703193665,True,0.3775406687981454,0.672197769558756,True
Dynamic Class Queue for Large Scale Face Recognition In the Wild,"Learning discriminative representation using large-scale face datasets in the wild is crucial for real-world applications, yet it remains challenging. The difficulties lie in many aspects and this work focus on computing resource constraint and long-tailed class distribution. Recently, classification-based representation learning with deep neural networks and well-designed losses have demonstrated good recognition performance. However, the computing and memory cost linearly scales up to the number of identities (classes) in the training set, and the learning process suffers from unbalanced classes. In this work, we propose a dynamic class queue (DCQ) to tackle these two problems. Specifically, for each iteration during training, a subset of classes for recognition are dynamically selected and their class weights are dynamically generated on-the-fly which are stored in a queue. Since only a subset of classes is selected for each iteration, the computing requirement is reduced. By using a single server without model parallel, we empirically verify in large-scale datasets that 10% of classes are sufficient to achieve similar performance as using all classes. Moreover, the class weights are dynamically generated in a few-shot manner and therefore suitable for tail classes with only a few instances. We show clear improvement over a strong baseline in the largest public dataset Megaface Challenge2 (MF2) which has 672K identities and over 88% of them have less than 10 instances. Code is available at https://github.com/bilylee/DCQ",1.0,0.8843453526496887,True,0.3775406687981454,0.6309430107239171,True
Soft Biometric Attributes in the Wild: Case Study on Gender Classification,,1.0,0.8811483383178711,True,0.3775406687981454,0.6293445035580083,True
Multi-Object Manipulation via Object-Centric Neural Scattering Functions,"Learned visual dynamics models have proven effective for robotic manipulation tasks. Yet, it remains unclear how best to represent scenes involving multi-object interactions. Current methods decompose a scene into discrete objects, but they struggle with precise modeling and manipulation amid challenging lighting conditions as they only encode appearance tied with specific illuminations. In this work, we propose using object-centric neural scattering functions (OSFs) as object representations in a model-predictive control framework. OSFs model per-object light transport, enabling compositional scene re-rendering under object rearrangement and varying lighting conditions. By combining this approach with inverse parameter estimation and graph-based neural dynamics models, we demonstrate improved model-predictive control performance and generalization in compositional multi-object environments, even in previously unseen scenarios and harsh lighting conditions.",1.0,0.8432843685150146,True,0.3775406687981454,0.6104125186565801,True
Marching-Primitives: Shape Abstraction from Signed Distance Function,"Representing complex objects with basic geometric primitives has long been a topic in computer vision. Primitive-based representations have the merits of compactness and computational efficiency in higher-level tasks such as physics simulation, collision checking, and robotic manipulation. Unlike previous works which extract polygonal meshes from a signed distance function (SDF), in this paper, we present a novel method, named Marching-Primitives, to obtain a primitive-based abstraction directly from an SDF. Our method grows geometric primitives (such as superquadrics) iteratively by analyzing the connectivity of voxels while marching at different levels of signed distance. For each valid connected volume of interest, we march on the scope of voxels from which a primitive is able to be extracted in a probabilistic sense and simultaneously solve for the parameters of the primitive to capture the underlying local geometry. We evaluate the performance of our method on both synthetic and real-world datasets. The results show that the proposed method out-performs the state-of-the-art in terms of accuracy, and is directly generalizable among different categories and scales. The code is open-sourced at https://github.com/ChirikjianLab/Marching-Primitives.git.",1.0,0.8167048692703247,True,0.3775406687981454,0.5971227690342351,True
R²GAN: Cross-Modal Recipe Retrieval With Generative Adversarial Network,"Representing procedure text such as recipe for crossmodal retrieval is inherently a difficult problem, not mentioning to generate image from recipe for visualization. This paper studies a new version of GAN, named Recipe Retrieval Generative Adversarial Network (R2GAN), to explore the feasibility of generating image from procedure text for retrieval problem. The motivation of using GAN is twofold: learning compatible cross-modal features in an adversarial way, and explanation of search results by showing the images generated from recipes. The novelty of R2GAN comes from architecture design, specifically a GAN with one generator and dual discriminators is used, which makes the generation of image from recipe a feasible idea. Furthermore, empowered by the generated images, a two-level ranking loss in both embedding and image spaces are considered. These add-ons not only result in excellent retrieval performance, but also generate close-to-realistic food images useful for explaining ranking of recipes. On recipe1M dataset, R2GAN demonstrates high scalability to data size, outperforms all the existing approaches, and generates images intuitive for human to interpret the search results.",1.0,0.7594724297523499,True,0.3775406687981454,0.5685065492752477,True
WildNet: Learning Domain Generalized Semantic Segmentation from the Wild,"We present a new domain generalized semantic segmentation network named WildNet, which learns domain-generalized features by leveraging a variety of contents and styles from the wild. In domain generalization, the low generalization ability for unseen target domains is clearly due to overfitting to the source domain. To address this problem, previous works have focused on generalizing the domain by removing or diversifying the styles of the source domain. These alleviated overfitting to the source-style but overlooked overfitting to the source-content. In this paper, we propose to diversify both the content and style of the source domain with the help of the wild. Our main idea is for networks to naturally learn domain-generalized semantic information from the wild. To this end, we diversify styles by augmenting source features to resemble wild styles and enable networks to adapt to a variety of styles. Further-more, we encourage networks to learn class-discriminant features by providing semantic variations borrowed from the wild to source contents in the feature space. Finally, we regularize networks to capture consistent semantic information even when both the content and style of the source domain are extended to the wild. Extensive experiments on five different datasets validate the effectiveness of our WildNet, and we significantly outperform state-of-the-art methods. The source code and model are available online: https://github.com/suhyeonlee/WildNet.",1.0,0.8710394501686096,True,0.3775406687981454,0.6242900594833776,True
Re-IQA: Unsupervised Learning for Image Quality Assessment in the Wild,"Automatic Perceptual Image Quality Assessment is a challenging problem that impacts billions of internet, and social media users daily. To advance research in this field, we propose a Mixture of Experts approach to train two separate encoders to learn high-level content and low-level image quality features in an unsupervised setting. The unique novelty of our approach is its ability to generate low-level representations of image quality that are complementary to high-level features representing image content. We refer to the framework used to train the two encoders as Re-IQA. For Image Quality Assessment in the Wild, we deploy the complementary low and high-level image representations obtained from the Re-IQA framework to train a linear regression model, which is used to map the image representations to the ground truth quality scores, refer Figure 1. Our method achieves state-of-the-art performance on multiple large-scale image quality assessment databases containing both real and synthetic distortions, demonstrating how deep neural networks can be trained in an unsupervised setting to produce perceptually relevant representations. We conclude from our experiments that the low and high-level features obtained are indeed complementary and positively impact the performance of the linear regressor. A public release of all the codes associated with this work will be made available on GitHub.",1.0,0.8606553077697754,True,0.3775406687981454,0.6190979882839605,True
Unsupervised Learning of 3D Object Categories from Videos in the Wild,"Our goal is to learn a deep network that, given a small number of images of an object of a given category, reconstructs it in 3D. While several recent works have obtained analogous results using synthetic data or assuming the avail-ability of 2D primitives such as keypoints, we are interested in working with challenging real data and with no manual annotations. We thus focus on learning a model from multiple views of a large collection of object instances. We contribute with a new large dataset of object centric videos suitable for training and benchmarking this class of models. We show that existing techniques leveraging meshes, voxels, or implicit surfaces, which work well for reconstructing isolated objects, fail on this challenging data. Finally, we propose a new neural network design, called warp-conditioned ray embedding (WCR), which significantly improves reconstruction while obtaining a detailed implicit representation of the object surface and texture, also compensating for the noise in the initial SfM reconstruction that bootstrapped the learning process. Our evaluation demonstrates performance improvements over several deep monocular reconstruction baselines on existing benchmarks and on our novel dataset. For additional material please visit: https://henzler.github.io/publication/unsupervised_videos/.",1.0,0.8002294301986694,True,0.3775406687981454,0.5888850494984075,True
Multi-scale FCN with Cascaded Instance Aware Segmentation for Arbitrary Oriented Word Spotting in the Wild,"Scene text detection has attracted great attention these years. Text potentially exist in a wide variety of images or videos and play an important role in understanding the scene. In this paper, we present a novel text detection algorithm which is composed of two cascaded steps: (1) a multi-scale fully convolutional neural network (FCN) is proposed to extract text block regions, (2) a novel instance (word or line) aware segmentation is designed to further remove false positives and obtain word instances. The proposed algorithm can accurately localize word or text line in arbitrary orientations, including curved text lines which cannot be handled in a lot of other frameworks. Our algorithm achieved state-of-the-art performance in ICDAR 2013 (IC13), ICDAR 2015 (IC15) and CUTE80 and Street View Text (SVT) benchmark datasets.",1.0,0.9186962246894836,True,0.3775406687981454,0.6481184467438146,True
Achieving Robustness in the Wild via Adversarial Mixing With Disentangled Representations,"Recent research has made the surprising finding that state-of-the-art deep learning models sometimes fail to generalize to small variations of the input. Adversarial training has been shown to be an effective approach to overcome this problem. However, its application has been limited to enforcing invariance to analytically defined transformations like lp-norm bounded perturbations. Such perturbations do not necessarily cover plausible real-world variations that preserve the semantics of the input (such as a change in lighting conditions). In this paper, we propose a novel approach to express and formalize robustness to these kinds of real-world transformations of the input. The two key ideas underlying our formulation are (1) leveraging disentangled representations of the input to define different factors of variations, and (2) generating new input images by adversarially composing the representations of different images. We use a StyleGAN model to demonstrate the efficacy of this framework. Specifically, we leverage the disentangled latent representations computed by a StyleGAN model to generate perturbations of an image that are similar to real-world variations (like adding make-up, or changing the skin-tone of a person) and train models to be invariant to these perturbations. Extensive experiments show that our method improves generalization and reduces the effect of spurious correlations (reducing the error rate of a ""smile"" detector by 21% for example).",1.0,0.9385975003242493,True,0.3775406687981454,0.6580690845611974,True
NeuralLift-360: Lifting an in-the-Wild 2D Photo to A 3D Object with 360° Views,"Virtual reality and augmented reality (XR) bring increasing demand for 3D content generation. However, creating high-quality 3D content requires tedious work from a human expert. In this work, we study the challenging task of lifting a single image to a 3D object and, for the first time, demonstrate the ability to generate a plausible 3D object with 360° views that corresponds well with the given reference image. By conditioning on the reference image, our model can fulfill the everlasting curiosity for synthesizing novel views of objects from images. Our technique sheds light on a promising direction of easing the workflows for 3D artists and XR designers. We propose a novel framework, dubbed NeuralLift-360, that utilizes a depth-aware neural radiance representation (NeRF) and learns to craft the scene guided by denoising diffusion models. By introducing a ranking loss, our NeuralLift-360 can be guided with rough depth estimation in the wild. We also adopt a CLIP-guided sampling strategy for the diffusion prior to provide coherent guidance. Extensive experiments demonstrate that our NeuralLift-360 significantly outperforms existing state-of-the-art baselines. Project page: https://vita-group.github.io/NeuralLift-360/",1.0,0.7766488790512085,True,0.3775406687981454,0.577094773924677,True
Learning to Aggregate and Personalize 3D Face from In-the-Wild Photo Collection,"Non-parametric face modeling aims to reconstruct 3D face only from images without shape assumptions. While plausible facial details are predicted, the models tend to over-depend on local color appearance and suffer from ambiguous noise. To address such problem, this paper presents a novel Learning to Aggregate and Personalize (LAP) framework for unsupervised robust 3D face modeling. Instead of using controlled environment, the proposed method implicitly disentangles ID-consistent and scene-specific face from unconstrained photo set. Specifically, to learn ID-consistent face, LAP adaptively aggregates intrinsic face factors of an identity based on a novel curriculum learning approach with relaxed consistency loss. To adapt the face for a personalized scene, we propose a novel attribute-refining network to modify ID-consistent face with target attribute and details. Based on the proposed method, we make unsupervised 3D face modeling benefit from meaningful image facial structure and possibly higher resolutions. Extensive experiments on benchmarks show LAP recovers superior or competitive face shape and texture, compared with state-of-the-art (SOTA) methods with or without prior and supervision.",1.0,0.8467131853103638,True,0.3775406687981454,0.6121269270542546,True
Shape from Polarization for Complex Scenes in the Wild,"We present a new data-driven approach with physics based priors to scene-level normal estimation from a single polarization image. Existing shape from polarization (SfP) works mainly focus on estimating the normal of a single object rather than complex scenes in the wild. A key barrier to high-quality scene-level SfP is the lack of real-world SfP data in complex scenes. Hence, we contribute the first real world scene-level SfP dataset with paired input polarization images and ground-truth normal maps. Then we propose a learning-based framework with a multi-head self-attention module and viewing encoding, which is designed to handle increasing polarization ambiguities caused by complex materials and non-orthographic projection in scene-level SfP. Our trained model can be generalized to far-field outdoor scenes as the relationship between polarized light and surface normals is not affected by distance. Experimental results demonstrate that our approach significantly outperforms existing SfP models on two datasets. Our dataset and source code will be publicly available at https://github.com/ChenyangLEI/sfp-wild.",1.0,0.7793404459953308,True,0.3775406687981454,0.5784405573967382,True
"Forward Propagation, Backward Regression, and Pose Association for Hand Tracking in the Wild","We propose HandLer, a novel convolutional architecture that can jointly detect and track hands online in unconstrained videos. HandLer is based on Cascade-RCNN with additional three novel stages. The first stage is Forward Propagation, where the features from frame t −1 are propagated to frame t based on previously detected hands and their estimated motion. The second stage is the Detection and Backward Regression, which uses outputs from the forward propagation to detect hands for frame t and their relative offset in frame t −1. The third stage uses an off-the-shelf human pose method to link any fragmented hand tracklets. We train the forward propagation and backward regression and detection stages end-to-end together with the other Cascade-RCNN components. To train and evaluate HandLer, we also contribute YouTube-Hand, the first challenging large-scale dataset of unconstrained videos annotated with hand locations and their trajectories. Experiments on this dataset and other benchmarks show that HandLer outperforms the existing state-of-the-art tracking algorithms by a large margin. Code and data are available at https://vision.cs.stonybrook.edu/~mingzhen/handler/.",1.0,0.8259981274604797,True,0.3775406687981454,0.6017693981293126,True
Robust Design of Deep Neural Networks Against Adversarial Attacks Based on Lyapunov Theory,"Deep neural networks (DNNs) are vulnerable to subtle adversarial perturbations applied to the input. These adversarial perturbations, though imperceptible, can easily mislead the DNN. In this work, we take a control theoretic approach to the problem of robustness in DNNs. We treat each individual layer of the DNN as a nonlinear system and use Lyapunov theory to prove stability and robustness locally. We then proceed to prove stability and robustness globally for the entire DNN. We develop empirically tight bounds on the response of the output layer, or any hidden layer, to adversarial perturbations added to the input, or the input of hidden layers. Recent works have proposed spectral norm regularization as a solution for improving robustness against l2 adversarial attacks. Our results give new insights into how spectral norm regularization can mitigate the adversarial effects. Finally, we evaluate the power of our approach on a variety of data sets and network architectures and against some of the well-known adversarial attacks.",1.0,0.8005592823028564,True,0.3775406687981454,0.589049975550501,True
HoloPose: Holistic 3D Human Reconstruction In-The-Wild,"We introduce HoloPose, a method for holistic monocular 3D human body reconstruction. We first introduce a part-based model for 3D model parameter regression that allows our method to operate in-the-wild, gracefully handling severe occlusions and large pose variation. We further train a multi-task network comprising 2D, 3D and Dense Pose estimation to drive the 3D reconstruction task. For this we introduce an iterative refinement method that aligns the model-based 3D estimates of 2D/3D joint positions and DensePose with their image-based counterparts delivered by CNNs, achieving both model-based, global consistency and high spatial accuracy thanks to the bottom-up CNN processing. We validate our contributions on challenging benchmarks, showing that our method allows us to get both accurate joint and 3D surface estimates while operating at more than 10fps in-the-wild. More information about our approach, including videos and demos is available at http://arielai.com/holopose.",1.0,0.9024320840835571,True,0.3775406687981454,0.6399863764408513,True
Learning Cross-Modal Embeddings With Adversarial Networks for Cooking Recipes and Food Images,"Food computing is playing an increasingly important role in human daily life, and has found tremendous applications in guiding human behavior towards smart food consumption and healthy lifestyle. An important task under the food-computing umbrella is retrieval, which is particularly helpful for health related applications, where we are interested in retrieving important information about food (e.g., ingredients, nutrition, etc.). In this paper, we investigate an open research task of cross-modal retrieval between cooking recipes and food images, and propose a novel framework Adversarial Cross-Modal Embedding (ACME) to resolve the cross-modal retrieval task in food domains. Specifically, the goal is to learn a common embedding feature space between the two modalities, in which our approach consists of several novel ideas: (i) learning by using a new triplet loss scheme together with an effective sampling strategy, (ii) imposing modality alignment using an adversarial learning strategy, and (iii) imposing cross-modal translation consistency such that the embedding of one modality is able to recover some important information of corresponding instances in the other modality. ACME achieves the state-of-the-art performance on the benchmark Recipe1M dataset, validating the efficacy of the proposed technique.",1.0,0.9263423681259155,True,0.3775406687981454,0.6519415184620305,True
UnsupervisedR&R: Unsupervised Point Cloud Registration via Differentiable Rendering,"Aligning partial views of a scene into a single whole is essential to understanding one’s environment and is a key component of numerous robotics tasks such as SLAM and SfM. Recent approaches have proposed end-to-end systems that can outperform traditional methods by leveraging pose supervision. However, with the rising prevalence of cameras with depth sensors, we can expect a new stream of raw RGB-D data without the annotations needed for supervision. We propose UnsupervisedR&R: an end-to-end unsupervised approach to learning point cloud registration from raw RGB-D video. The key idea is to leverage differentiable alignment and rendering to enforce photometric and geometric consistency between frames. We evaluate our approach on indoor scene datasets and find that we out-perform existing traditional approaches with classical and learned descriptors while being competitive with supervised geometric point cloud registration approaches.",0.8,0.8074374198913574,True,0.3318122278318339,0.5696248238615956,True
Unite and Conquer: Plug & Play Multi-Modal Synthesis Using Diffusion Models,"Generating photos satisfying multiple constraints finds broad utility in the content creation industry. A key hurdle to accomplishing this task is the need for paired data consisting of all modalities (i.e., constraints) and their corresponding output. Moreover, existing methods need retraining using paired data across all modalities to introduce a new condition. This paper proposes a solution to this problem based on denoising diffusion probabilistic models (DDPMs). Our motivation for choosing diffusion models over other generative models comes from the flexible internal structure of diffusion models. Since each sampling step in the DDPM follows a Gaussian distribution, we show that there exists a closed-form solution for generating an image given various constraints. Our method can unite multiple diffusion models trained on multiple sub-tasks and conquer the combined task through our proposed sampling strategy. We also introduce a novel reliability parameter that allows using different off-the-shelf diffusion models trained across various datasets during sampling time alone to guide it to the desired outcome satisfying multiple constraints. We perform experiments on various standard multimodal tasks to demonstrate the effectiveness of our approach. More details can be found at: https://nithin-gk.github.io/projectpages/Multidiff",0.8,0.9735055565834045,True,0.3318122278318339,0.6526588922076192,True
3D Hand Shape and Pose From Images in the Wild,"We present in this work the first end-to-end deep learning based method that predicts both 3D hand shape and pose from RGB images in the wild. Our network consists of the concatenation of a deep convolutional encoder, and a fixed model-based decoder. Given an input image, and optionally 2D joint detections obtained from an independent CNN, the encoder predicts a set of hand and view parameters. The decoder has two components: A pre-computed articulated mesh deformation hand model that generates a 3D mesh from the hand parameters, and a re-projection module controlled by the view parameters that projects the generated hand into the image domain. We show that using the shape and pose prior knowledge encoded in the hand model within a deep learning framework yields state-of-the-art performance in 3D pose prediction from images on standard benchmarks, and produces geometrically valid and plausible 3D reconstructions. Additionally, we show that training with weak supervision in the form of 2D joint annotations on datasets of images in the wild, in conjunction with full supervision in the form of 3D joint annotations on limited available datasets allows for good generalization to 3D shape and pose predictions on images in the wild.",1.0,0.9001375436782837,True,0.3775406687981454,0.6388391062382146,True
Polarized Reflection Removal With Perfect Alignment in the Wild,"We present a novel formulation to removing reflection from polarized images in the wild. We first identify the misalignment issues of existing reflection removal datasets where the collected reflection-free images are not perfectly aligned with input mixed images due to glass refraction. Then we build a new dataset with more than 100 types of glass in which obtained transmission images are perfectly aligned with input mixed images. Second, capitalizing on the special relationship between reflection and polarized light, we propose a polarized reflection removal model with a two-stage architecture. In addition, we design a novel perceptual NCC loss that can improve the performance of reflection removal and general image decomposition tasks. We conduct extensive experiments, and results suggest that our model outperforms state-of-the-art methods on reflection removal.",1.0,0.8496671915054321,True,0.3775406687981454,0.6136039301517888,True
Composing Text and Image for Image Retrieval - an Empirical Odyssey,"In this paper, we study the task of image retrieval, where the input query is specified in the form of an image plus some text that describes desired modifications to the input image. For example, we may present an image of the Eiffel tower, and ask the system to find images which are visually similar, but are modified in small ways, such as being taken at nighttime instead of during the day. o tackle this task, we embed the query (reference image plus modification text) and the target (images). The encoding function of the image text query learns a representation, such that the similarity with the target image representation is high iff it is a ``positive match''. We propose a new way to combine image and text through residual connection, that is designed for this retrieval task. We show this outperforms existing approaches on 3 different datasets, namely Fashion-200k, MIT-States and a new synthetic dataset we create based on CLEVR. We also show that our approach can be used to perform image classification with compositionally novel labels, and we outperform previous methods on MIT-States on this task.",1.0,0.7870491743087769,True,0.3775406687981454,0.5822949215534612,True
Learning Cross-Modal Embeddings for Cooking Recipes and Food Images,"In this paper, we introduce Recipe1M, a new large-scale, structured corpus of over 1m cooking recipes and 800k food images. As the largest publicly available collection of recipe data, Recipe1M affords the ability to train high-capacity models on aligned, multi-modal data. Using these data, we train a neural network to find a joint embedding of recipes and images that yields impressive results on an image-recipe retrieval task. Additionally, we demonstrate that regularization via the addition of a high-level classification objective both improves retrieval performance to rival that of humans and enables semantic vector arithmetic. We postulate that these embeddings will provide a basis for further exploration of the Recipe1M dataset and food and cooking in general. Code, data and models are publicly available",1.0,0.7452985644340515,True,0.3775406687981454,0.5614196166160985,True
Generating Diverse Story Continuations with Controllable Semantics,"We propose a simple and effective modeling framework for controlled generation of multiple, diverse outputs. We focus on the setting of generating the next sentence of a story given its context. As controllable dimensions, we consider several sentence attributes, including sentiment, length, predicates, frames, and automatically-induced clusters. Our empirical results demonstrate: (1) our framework is accurate in terms of generating outputs that match the target control values; (2) our model yields increased maximum metric scores compared to standard n-best list generation via beam search; (3) controlling generation with semantic frames leads to a stronger combination of diversity and quality than other control variables as measured by automatic metrics. We also conduct a human evaluation to assess the utility of providing multiple suggestions for creative writing, demonstrating promising results for the potential of controllable, diverse generation in a collaborative writing system.",1.0,0.8058175444602966,True,0.3775406687981454,0.5916791066292211,True
Learning VAE-LDA Models with Rounded Reparameterization Trick,"The introduction of VAE provides an efficient framework for the learning of generative models, including generative topic models. However, when the topic model is a Latent Dirichlet Allocation (LDA) model, a central technique of VAE, the reparameterization trick, fails to be applicable. This is because no reparameterization form of Dirichlet distributions is known to date that allows the use of the reparameterization trick. In this work, we propose a new method, which we call Rounded Reparameterization Trick (RRT), to reparameterize Dirichlet distributions for the learning of VAE-LDA models. This method, when applied to a VAE-LDA model, is shown experimentally to outperform the existing neural topic models on several benchmark datasets and on a synthetic dataset.",1.0,0.81216961145401,True,0.3775406687981454,0.5948551401260778,True
Birds Have Four Legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-trained Language Models,"Recent works show that pre-trained language models (PTLMs), such as BERT, possess certain commonsense and factual knowledge. They suggest that it is promising to use PTLMs as ""neural knowledge bases"" via predicting masked words. Surprisingly, we find that this may not work for numerical commonsense knowledge (e.g., a bird usually has two legs). In this paper, we investigate whether and to what extent we can induce numerical commonsense knowledge from PTLMs as well as the robustness of this process. To study this, we introduce a novel probing task with a diagnostic dataset, NumerSense, containing 13.6k masked-word-prediction probes (10.5k for fine-tuning and 3.1k for testing). Our analysis reveals that: (1) BERT and its stronger variant RoBERTa perform poorly on the diagnostic dataset prior to any fine-tuning; (2) fine-tuning with distant supervision brings some improvement; (3) the best supervised model still performs poorly as compared to human performance (54.06% vs 96.3% in accuracy).",1.6,0.9237661957740784,True,0.52497918747894,0.7243726916265092,True
Interpreting and Exploiting Functional Specialization in Multi-Head Attention under Multi-task Learning,"Transformer-based models, even though achieving super-human performance on several downstream tasks, are often regarded as a black box and used as a whole. It is still unclear what mechanisms they have learned, especially their core module: multi-head attention. Inspired by functional specialization in the human brain, which helps to efficiently handle multiple tasks, this work attempts to figure out whether the multi-head attention module will evolve similar function separation under multi-tasking training. If it is, can this mechanism further improve the model performance? To investigate these questions, we introduce an interpreting method to quantify the degree of functional specialization in multi-head attention. We further propose a simple multi-task training method to increase functional specialization and mitigate negative information transfer in multi-task learning. Experimental results on seven pre-trained transformer models have demonstrated that multi-head attention does evolve functional specialization phenomenon after multi-task training which is affected by the similarity of tasks. Moreover, the multi-task training strategy based on functional specialization boosts performance in both multi-task learning and transfer learning without adding any parameters.",1.0,0.7808651328086853,True,0.3775406687981454,0.5792029008034154,True
Learning Label Modular Prompts for Text Classification in the Wild,"Machine learning models usually assume i.i.d data during training and testing, but data and tasks in real world often change over time. To emulate the transient nature of real world, we propose a challenging but practical task: text classification in-the-wild, which introduces different non-stationary training/testing stages. Decomposing a complex task into modular components can enable robust generalisation under such non-stationary environment. However, current modular approaches in NLP do not take advantage of recent advances in parameter efficient tuning of pretrained language models. To close this gap, we propose ModularPrompt, a label-modular prompt tuning framework for text classification tasks. In ModularPrompt, the input prompt consists of a sequence of soft label prompts, each encoding modular knowledge related to the corresponding class label. In two of most formidable settings, ModularPrompt outperforms relevant baselines by a large margin demonstrating strong generalisation ability. We also conduct comprehensive analysis to validate whether the learned prompts satisfy properties of a modular representation.",1.0,0.8218017220497131,True,0.3775406687981454,0.5996711954239293,True
A Simpler and More Generalizable Story Detector using Verb and Character Features,"Story detection is the task of determining whether or not a unit of text contains a story. Prior approaches achieved a maximum performance of 0.66 F1, and did not generalize well across different corpora. We present a new state-of-the-art detector that achieves a maximum performance of 0.75 F1 (a 14% improvement), with significantly greater generalizability than previous work. In particular, our detector achieves performance above 0.70 F1 across a variety of combinations of lexically different corpora for training and testing, as well as dramatic improvements (up to 4,000%) in performance when trained on a small, disfluent data set. The new detector uses two basic types of features–ones related to events, and ones related to characters–totaling 283 specific features overall; previous detectors used tens of thousands of features, and so this detector represents a significant simplification along with increased performance.",1.0,0.7518039345741272,True,0.3775406687981454,0.5646723016861364,True
Localizing Q&A Semantic Parsers for Any Language in a Day,"We propose Semantic Parser Localizer (SPL), a toolkit that leverages Neural Machine Translation (NMT) systems to localize a semantic parser for a new language. Our methodology is to (1) generate training data automatically in the target language by augmenting machine-translated datasets with local entities scraped from public websites, (2) add a few-shot boost of human-translated sentences and train a novel XLMR-LSTM semantic parser, and (3) test the model on natural utterances curated using human translators. 
We assess the effectiveness of our approach by extending the current capabilities of Schema2QA, a system for English Question Answering (QA) on the open web, to 10 new languages for the restaurants and hotels domains. Our models achieve an overall test accuracy ranging between 61% and 69% for the hotels domain and between 64% and 78% for restaurants domain, which compares favorably to 69% and 80% obtained for English parser trained on gold English data and a few examples from validation set. We show our approach outperforms the previous state-of-the-art methodology by more than 30% for hotels and 40% for restaurants with localized ontologies for the subset of languages tested. 
Our methodology enables any software developer to add a new language capability to a QA system for a new domain, leveraging machine translation, in less than 24 hours.",0.8,0.7787685990333557,True,0.3318122278318339,0.5552904134325948,True
Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning,"Language model probing is often used to test specific capabilities of models. However, conclusions from such studies may be limited when the probing benchmarks are small and lack statistical power. In this work, we introduce new, larger datasets for negation (NEG-1500-SIMP) and role reversal (ROLE-1500) inspired by psycholinguistic studies. We dramatically extend existing NEG-136 and ROLE-88 benchmarks using GPT3, increasing their size from 18 and 44 sentence pairs to 750 each. We also create another version of extended negation dataset (NEG-1500-SIMP-TEMP), created using template-based generation. It consists of 770 sentence pairs. We evaluate 22 models on the extended datasets, seeing model performance dip 20-57% compared to the original smaller benchmarks. We observe high levels of negation sensitivity in models like BERT and ALBERT demonstrating that previous findings might have been skewed due to smaller test sets. Finally, we observe that while GPT3 has generated all the examples in ROLE-1500 is only able to solve 24.6% of them during probing. The datasets and code are available on $\href{https://github.com/text-machine-lab/extending_psycholinguistic_dataset}{Github}$.",1.0,0.8007845282554626,True,0.3775406687981454,0.5891625985268041,True
“So You Think You’re Funny?”: Rating the Humour Quotient in Standup Comedy,"Computational Humour (CH) has attracted the interest of Natural Language Processing and Computational Linguistics communities. Creating datasets for automatic measurement of humour quotient is difficult due to multiple possible interpretations of the content. In this work, we create a multi-modal humour-annotated dataset (~40 hours) using stand-up comedy clips. We devise a novel scoring mechanism to annotate the training data with a humour quotient score using the audience’s laughter. The normalized duration (laughter duration divided by the clip duration) of laughter in each clip is used to compute this humour coefficient score on a five-point scale (0-4). This method of scoring is validated by comparing with manually annotated scores, wherein a quadratic weighted kappa of 0.6 is obtained. We use this dataset to train a model that provides a ‘funniness’ score, on a five-point scale, given the audio and its corresponding text. We compare various neural language models for the task of humour-rating and achieve an accuracy of 0.813 in terms of Quadratic Weighted Kappa (QWK). Our ‘Open Mic’ dataset is released for further research along with the code.",2.3,0.9623324871063232,True,0.6899744811276125,0.8261534841169679,True
Content Planning for Neural Story Generation with Aristotelian Rescoring,"Long-form narrative text generated from large language models manages a fluent impersonation of human writing, but only at the local sentence level, and lacks structure or global cohesion. We posit that many of the problems of story generation can be addressed via high-quality content planning, and present a system that focuses on how to learn good plot structures to guide story generation. We utilize a plot-generation language model along with an ensemble of rescoring models that each implement an aspect of good story-writing as detailed in Aristotle's Poetics. We find that stories written with our more principled plot-structure are both more relevant to a given prompt and higher quality than baselines that do not content plan, or that plan in an unprincipled way.",1.0,0.7473657727241516,True,0.3775406687981454,0.5624532207611486,True
Surprisingly Easy Hard-Attention for Sequence to Sequence Learning,"In this paper we show that a simple beam approximation of the joint distribution between attention and output is an easy, accurate, and efficient attention mechanism for sequence to sequence learning. The method combines the advantage of sharp focus in hard attention and the implementation ease of soft attention. On five translation tasks we show effortless and consistent gains in BLEU compared to existing attention mechanisms.",1.0,0.7611641883850098,True,0.3775406687981454,0.5693524285915776,True
PUNR: Pre-training with User Behavior Modeling for News Recommendation,"News recommendation aims to predict click behaviors based on user behaviors. How to effectively model the user representations is the key to recommending preferred news. Existing works are mostly focused on improvements in the supervised fine-tuning stage. However, there is still a lack of PLM-based unsupervised pre-training methods optimized for user representations. In this work, we propose an unsupervised pre-training paradigm with two tasks, i.e. user behavior masking and user behavior generation, both towards effective user behavior modeling. Firstly, we introduce the user behavior masking pre-training task to recover the masked user behaviors based on their contextual behaviors. In this way, the model could capture a much stronger and more comprehensive user news reading pattern. Besides, we incorporate a novel auxiliary user behavior generation pre-training task to enhance the user representation vector derived from the user encoder. We use the above pre-trained user modeling encoder to obtain news and user representations in downstream fine-tuning. Evaluations on the real-world news benchmark show significant performance improvements over existing baselines.",1.0,0.8728859424591064,True,0.3775406687981454,0.625213305628626,True
Autoregressive Text Generation Beyond Feedback Loops,"Autoregressive state transitions, where predictions are conditioned on past predictions, are the predominant choice for both deterministic and stochastic sequential models. However, autoregressive feedback exposes the evolution of the hidden state trajectory to potential biases from well-known train-test discrepancies. In this paper, we combine a latent state space model with a CRF observation model. We argue that such autoregressive observation models form an interesting middle ground that expresses local correlations on the word level but keeps the state evolution non-autoregressive. On unconditional sentence generation we show performance improvements compared to RNN and GAN baselines while avoiding some prototypical failure modes of autoregressive models.",1.0,0.9326730370521545,True,0.3775406687981454,0.65510685292515,True
Is BERT a Cross-Disciplinary Knowledge Learner? A Surprising Finding of Pre-trained Models' Transferability,"This paper investigates whether the power of the models pre-trained on text data, such as BERT, can be transferred to general token sequence classiﬁcation applications. To verify pre-trained models’ transferability, we test the pre-trained models on text classiﬁcation tasks with meanings of tokens mismatches, and real-world non-text token sequence classiﬁcation data, including amino acid, DNA, and music. We ﬁnd that even on non-text data, the models pre-trained on text converge faster, perform better than the randomly initialized models, and only slightly worse than the models using task-speciﬁc knowledge. We also ﬁnd that the representations of the text and non-text pretrained models share non-trivial similarities.",1.3,0.7504140734672546,True,0.45016600268752216,0.6002900380773883,True
ArabicTransformer: Efficient Large Arabic Language Model with Funnel Transformer and ELECTRA Objective,"Pre-training Transformer-based models such as BERT and ELECTRA on a collection of Arabic corpora, demonstrated by both AraBERT and AraELECTRA, shows an impressive result on downstream tasks. However, pre-training Transformer-based language models is computationally expensive, especially for large-scale models. Recently, Funnel Transformer has addressed the sequential redundancy inside Transformer architecture by compressing the sequence of hidden states, leading to a significant reduction in the pretraining cost. This paper empirically studies the performance and efficiency of building an Arabic language model with Funnel Transformer and ELECTRA objective. We find that our model achieves state-of-the-art results on several Arabic downstream tasks despite using less computational resources compared to other BERT-based models.",1.0,0.8311762809753418,True,0.3775406687981454,0.6043584748867437,True
RiSAWOZ: A Large-Scale Multi-Domain Wizard-of-Oz Dataset with Rich Semantic Annotations for Task-Oriented Dialogue Modeling,"In order to alleviate the shortage of multi-domain data and to capture discourse phenomena for task-oriented dialogue modeling, we propose RiSAWOZ, a large-scale multi-domain Chinese Wizard-of-Oz dataset with Rich Semantic Annotations. RiSAWOZ contains 11.2K human-to-human (H2H) multi-turn semantically annotated dialogues, with more than 150K utterances spanning over 12 domains, which is larger than all previous annotated H2H conversational datasets. Both single- and multi-domain dialogues are constructed, accounting for 65% and 35%, respectively. Each dialogue is labeled with comprehensive dialogue annotations, including dialogue goal in the form of natural language description, domain, dialogue states and acts at both the user and system side. In addition to traditional dialogue annotations, we especially provide linguistic annotations on discourse phenomena, e.g., ellipsis and coreference, in dialogues, which are useful for dialogue coreference and ellipsis resolution tasks. Apart from the fully annotated dataset, we also present a detailed description of the data collection procedure, statistics and analysis of the dataset. A series of benchmark models and results are reported, including natural language understanding (intent detection & slot filling), dialogue state tracking and dialogue context-to-text generation, as well as coreference and ellipsis resolution, which facilitate the baseline comparison for future research on this corpus.",1.0,0.8333820104598999,True,0.3775406687981454,0.6054613396290227,True
UR-FUNNY: A Multimodal Language Dataset for Understanding Humor,"Humor is a unique and creative communicative behavior often displayed during social interactions. It is produced in a multimodal manner, through the usage of words (text), gestures (visual) and prosodic cues (acoustic). Understanding humor from these three modalities falls within boundaries of multimodal language; a recent research trend in natural language processing that models natural language as it happens in face-to-face communication. Although humor detection is an established research area in NLP, in a multimodal context it has been understudied. This paper presents a diverse multimodal dataset, called UR-FUNNY, to open the door to understanding multimodal language used in expressing humor. The dataset and accompanying studies, present a framework in multimodal humor detection for the natural language processing community. UR-FUNNY is publicly available for research.",2.0,0.9925354719161987,True,0.6224593312018546,0.8074974015590266,True
Homophonic Pun Generation with Lexically Constrained Rewriting,"Punning is a creative way to make conversation enjoyable and literary writing elegant. In this paper, we focus on the task of generating a pun sentence given a pair of homophones. We first find the constraint words supporting the semantic incongruity for a sentence. Then we rewrite the sentence with explicit positive and negative constraints. Our model achieves the state-of-the-art results in both automatic and human evaluations. We further make an error analysis and discuss the challenges for the computational pun models.",1.0,0.9761993288993835,True,0.3775406687981454,0.6768699988487645,True
Analyzing the Surprising Variability in Word Embedding Stability Across Languages,"Word embeddings are powerful representations that form the foundation of many natural language processing architectures, both in English and in other languages. To gain further insight into word embeddings, we explore their stability (e.g., overlap between the nearest neighbors of a word in different embedding spaces) in diverse languages. We discuss linguistic properties that are related to stability, drawing out insights about correlations with affixing, language gender systems, and other features. This has implications for embedding use, particularly in research that uses them to study language trends.",1.0,0.7559584975242615,True,0.3775406687981454,0.5667495831612035,True
"Beto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of BERT","Pretrained contextual representation models (Peters et al., 2018; Devlin et al., 2018) have pushed forward the state-of-the-art on many NLP tasks. A new release of BERT (Devlin, 2018) includes a model simultaneously pretrained on 104 languages with impressive performance for zero-shot cross-lingual transfer on a natural language inference task. This paper explores the broader cross-lingual potential of mBERT (multilingual) as a zero shot language transfer model on 5 NLP tasks covering a total of 39 languages from various language families: NLI, document classification, NER, POS tagging, and dependency parsing. We compare mBERT with the best-published methods for zero-shot cross-lingual transfer and find mBERT competitive on each task. Additionally, we investigate the most effective strategy for utilizing mBERT in this manner, determine to what extent mBERT generalizes away from language specific features, and measure factors that influence cross-lingual transfer.",1.0,0.8828986287117004,True,0.3775406687981454,0.630219648754923,True
GROOViST: A Metric for Grounding Objects in Visual Storytelling,"A proper evaluation of stories generated for a sequence of images -- the task commonly referred to as visual storytelling -- must consider multiple aspects, such as coherence, grammatical correctness, and visual grounding. In this work, we focus on evaluating the degree of grounding, that is, the extent to which a story is about the entities shown in the images. We analyze current metrics, both designed for this purpose and for general vision-text alignment. Given their observed shortcomings, we propose a novel evaluation tool, GROOViST, that accounts for cross-modal dependencies, temporal misalignments (the fact that the order in which entities appear in the story and the image sequence may not match), and human intuitions on visual grounding. An additional advantage of GROOViST is its modular design, where the contribution of each component can be assessed and interpreted individually.",1.0,0.8040167689323425,True,0.3775406687981454,0.590778718865244,True
The Myth of Double-Blind Review Revisited: ACL vs. EMNLP,"The review and selection process for scientific paper publication is essential for the quality of scholarly publications in a scientific field. The double-blind review system, which enforces author anonymity during the review period, is widely used by prestigious conferences and journals to ensure the integrity of this process. Although the notion of anonymity in the double-blind review has been questioned before, the availability of full text paper collections brings new opportunities for exploring the question: Is the double-blind review process really double-blind? We study this question on the ACL and EMNLP paper collections and present an analysis on how well deep learning techniques can infer the authors of a paper. Specifically, we explore Convolutional Neural Networks trained on various aspects of a paper, e.g., content, style features, and references, to understand the extent to which we can infer the authors of a paper and what aspects contribute the most. Our results show that the authors of a paper can be inferred with accuracy as high as 87% on ACL and 78% on EMNLP for the top 100 most prolific authors.",1.0,0.8653627634048462,True,0.3775406687981454,0.6214517161014959,True
Learn to Copy from the Copying History: Correlational Copy Network for Abstractive Summarization,"The copying mechanism has had considerable success in abstractive summarization, facilitating models to directly copy words from the input text to the output summary. Existing works mostly employ encoder-decoder attention, which applies copying at each time step independently of the former ones. However, this may sometimes lead to incomplete copying. In this paper, we propose a novel copying scheme named Correlational Copying Network (CoCoNet) that enhances the standard copying mechanism by keeping track of the copying history. It thereby takes advantage of prior copying distributions and, at each time step, explicitly encourages the model to copy the input word that is relevant to the previously copied one. In addition, we strengthen CoCoNet through pre-training with suitable corpora that simulate the copying behaviors. Experimental results show that CoCoNet can copy more accurately and achieves new state-of-the-art performances on summarization benchmarks, including CNN/DailyMail for news summarization and SAMSum for dialogue summarization. The code and checkpoint will be publicly available.",1.0,0.7825570106506348,True,0.3775406687981454,0.5800488397243901,True
Pun-GAN: Generative Adversarial Network for Pun Generation,"In this paper, we focus on the task of generating a pun sentence given a pair of word senses. A major challenge for pun generation is the lack of large-scale pun corpus to guide supervised learning. To remedy this, we propose an adversarial generative network for pun generation (Pun-GAN). It consists of a generator to produce pun sentences, and a discriminator to distinguish between the generated pun sentences and the real sentences with specific word senses. The output of the discriminator is then used as a reward to train the generator via reinforcement learning, encouraging it to produce pun sentences which can support two word senses simultaneously. Experiments show that the proposed Pun-GAN can generate sentences that are more ambiguous and diverse in both automatic and human evaluation.",1.0,0.9784247279167175,True,0.3775406687981454,0.6779826983574315,True
"Blackbird language matrices (BLM), a new task for rule-like generalization in neural networks: Can Large Language Models pass the test?",",",1.1,0.9337010979652405,True,0.401312339887548,0.6675067189263942,True
Event Extraction by Answering (Almost) Natural Questions,"The problem of event extraction requires detecting the event trigger and extracting its corresponding arguments. Existing work in event argument extraction typically relies heavily on entity recognition as a preprocessing/concurrent step, causing the well-known problem of error propagation. To avoid this issue, we introduce a new paradigm for event extraction by formulating it as a question answering (QA) task, which extracts the event arguments in an end-to-end manner. Empirical results demonstrate that our framework outperforms prior methods substantially; in addition, it is capable of extracting event arguments for roles not seen at training time (zero-shot learning setting).",0.8,0.7836503386497498,True,0.3318122278318339,0.5577312832407918,True
Multi-view Story Characterization from Movie Plot Synopses and Reviews,"This paper considers the problem of characterizing stories by inferring properties such as theme and style using written synopses and reviews of movies. We experiment with a multi-label dataset of movie synopses and a tagset representing various attributes of stories (e.g., genre, type of events). Our proposed multi-view model encodes the synopses and reviews using hierarchical attention and shows improvement over methods that only use synopses. Finally, we demonstrate how can we take advantage of such a model to extract a complementary set of story-attributes from reviews without direct supervision. We have made our dataset and source code publicly available at https://ritual.uh.edu/ multiview-tag-2020.",1.0,0.7853784561157227,True,0.3775406687981454,0.5814595624569341,True
Wider & Closer: Mixture of Short-channel Distillers for Zero-shot Cross-lingual Named Entity Recognition,"Zero-shot cross-lingual named entity recognition (NER) aims at transferring knowledge from annotated and rich-resource data in source languages to unlabeled and lean-resource data in target languages. Existing mainstream methods based on the teacher-student distillation framework ignore the rich and complementary information lying in the intermediate layers of pre-trained language models, and domain-invariant information is easily lost during transfer. In this study, a mixture of short-channel distillers (MSD) method is proposed to fully interact the rich hierarchical information in the teacher model and to transfer knowledge to the student model sufficiently and efficiently. Concretely, a multi-channel distillation framework is designed for sufficient information transfer by aggregating multiple distillers as a mixture. Besides, an unsupervised method adopting parallel domain adaptation is proposed to shorten the channels between the teacher and student models to preserve domain-invariant features. Experiments on four datasets across nine languages demonstrate that the proposed method achieves new state-of-the-art performance on zero-shot cross-lingual NER and shows great generalization and compatibility across languages and fields.",0.8,0.8771607875823975,True,0.3318122278318339,0.6044865077071157,True
WECA: A WordNet-Encoded Collocation-Attention Network for Homographic Pun Recognition,"Homographic puns have a long history in human writing, widely used in written and spoken literature, which usually occur in a certain syntactic or stylistic structure. How to recognize homographic puns is an important research. However, homographic pun recognition does not solve very well in existing work. In this work, we first use WordNet to understand and expand word embedding for settling the polysemy of homographic puns, and then propose a WordNet-Encoded Collocation-Attention network model (WECA) which combined with the context weights for recognizing the puns. Our experiments on the SemEval2017 Task7 and Pun of the Day demonstrate that the proposed model is able to distinguish between homographic pun and non-homographic pun texts. We show the effectiveness of the model to present the capability of choosing qualitatively informative words. The results show that our model achieves the state-of-the-art performance on homographic puns recognition.",1.0,0.969329297542572,True,0.3775406687981454,0.6734349831703588,True
Nonsense!: Quality Control via Two-Step Reason Selection for Annotating Local Acceptability and Related Attributes in News Editorials,"Annotation quality control is a critical aspect for building reliable corpora through linguistic annotation. In this study, we present a simple but powerful quality control method using two-step reason selection. We gathered sentential annotations of local acceptance and three related attributes through a crowdsourcing platform. For each attribute, the reason for the choice of the attribute value is selected in a two-step manner. The options given for reason selection were designed to facilitate the detection of a nonsensical reason selection. We assume that a sentential annotation that contains a nonsensical reason is less reliable than the one without such reason. Our method, based solely on this assumption, is found to retain the annotations with satisfactory quality out of the entire annotations mixed with those of low quality.",1.3,0.7643435597419739,True,0.45016600268752216,0.607254781214748,True
Translate & Fill: Improving Zero-Shot Multilingual Semantic Parsing with Synthetic Data,"While multilingual pretrained language models (LMs) fine-tuned on a single language have shown substantial cross-lingual task transfer capabilities, there is still a wide performance gap in semantic parsing tasks when target language supervision is available. In this paper, we propose a novel Translate-and-Fill (TaF) method to produce silver training data for a multilingual semantic parser. This method simplifies the popular Translate-Align-Project (TAP) pipeline and consists of a sequence-to-sequence filler model that constructs a full parse conditioned on an utterance and a view of the same parse. Our filler is trained on English data only but can accurately complete instances in other languages (i.e., translations of the English training utterances), in a zero-shot fashion. Experimental results on three multilingual semantic parsing datasets show that data augmentation with TaF reaches accuracies competitive with similar systems which rely on traditional alignment techniques.",0.8,0.8189574480056763,True,0.3318122278318339,0.575384837918755,True
Counterfactual Story Reasoning and Generation,"Counterfactual reasoning requires predicting how alternative events, contrary to what actually happened, might have resulted in different outcomes. Despite being considered a necessary component of AI-complete systems, few resources have been developed for evaluating counterfactual reasoning in narratives. In this paper, we propose Counterfactual Story Rewriting: given an original story and an intervening counterfactual event, the task is to minimally revise the story to make it compatible with the given counterfactual event. Solving this task will require deep understanding of causal narrative chains and counterfactual invariance, and integration of such story reasoning capabilities into conditional language generation models. We present TIMETRAVEL, a new dataset of 29,849 counterfactual rewritings, each with the original story, a counterfactual event, and human-generated revision of the original story compatible with the counterfactual event. Additionally, we include 81,407 counterfactual “branches” without a rewritten storyline to support future work on semi- or un-supervised approaches to counterfactual story rewriting. Finally, we evaluate the counterfactual rewriting capacities of several competitive baselines based on pretrained language models, and assess whether common overlap and model-based automatic metrics for text generation correlate well with human scores for counterfactual rewriting.",1.0,0.885002076625824,True,0.3775406687981454,0.6312713727119847,True
Specializing Word Embeddings (for Parsing) by Information Bottleneck,"Pre-trained word embeddings like ELMo and BERT contain rich syntactic and semantic information, resulting in state-of-the-art performance on various tasks. We propose a very fast variational information bottleneck (VIB) method to nonlinearly compress these embeddings, keeping only the information that helps a discriminative parser. We compress each word embedding to either a discrete tag or a continuous vector. In the discrete version, our automatically compressed tags form an alternative tag set: we show experimentally that our tags capture most of the information in traditional POS tag annotations, but our tag sequences can be parsed more accurately at the same level of tag granularity. In the continuous version, we show experimentally that moderately compressing the word embeddings by our method yields a more accurate parser in 8 of 9 languages, unlike simple dimensionality reduction.",0.8,0.821064293384552,True,0.3318122278318339,0.5764382606081929,True
Enhancing Multiple-choice Machine Reading Comprehension by Punishing Illogical Interpretations,"Machine Reading Comprehension (MRC), which requires a machine to answer questions given the relevant documents, is an important way to test machines’ ability to understand human language. Multiple-choice MRC is one of the most studied tasks in MRC due to the convenience of evaluation and the flexibility of answer format. Post-hoc interpretation aims to explain a trained model and reveal how the model arrives at the prediction. One of the most important interpretation forms is to attribute model decisions to input features. Based on post-hoc interpretation methods, we assess attributions of paragraphs in multiple-choice MRC and improve the model by punishing the illogical attributions. Our method can improve model performance without any external information and model structure change. Furthermore, we also analyze how and why such a self-training method works.",1.0,0.7989315986633301,True,0.3775406687981454,0.5882361337307378,True
Quick and (not so) Dirty: Unsupervised Selection of Justification Sentences for Multi-hop Question Answering,"We propose an unsupervised strategy for the selection of justification sentences for multi-hop question answering (QA) that (a) maximizes the relevance of the selected sentences, (b) minimizes the overlap between the selected facts, and (c) maximizes the coverage of both question and answer. This unsupervised sentence selection can be coupled with any supervised QA model. We show that the sentences selected by our method improve the performance of a state-of-the-art supervised QA model on two multi-hop QA datasets: AI2’s Reasoning Challenge (ARC) and Multi-Sentence Reading Comprehension (MultiRC). We obtain new state-of-the-art performance on both datasets among systems that do not use external resources for training the QA system: 56.82% F1 on ARC (41.24% on Challenge and 64.49% on Easy) and 26.1% EM0 on MultiRC. Our justification sentences have higher quality than the justifications selected by a strong information retrieval baseline, e.g., by 5.4% F1 in MultiRC. We also show that our unsupervised selection of justification sentences is more stable across domains than a state-of-the-art supervised sentence selection method.",0.8,0.9740487933158875,True,0.3318122278318339,0.6529305105738606,True
Cut to the Chase: A Context Zoom-in Network for Reading Comprehension,"In recent years many deep neural networks have been proposed to solve Reading Comprehension (RC) tasks. Most of these models suffer from reasoning over long documents and do not trivially generalize to cases where the answer is not present as a span in a given document. We present a novel neural-based architecture that is capable of extracting relevant regions based on a given question-document pair and generating a well-formed answer. To show the effectiveness of our architecture, we conducted several experiments on the recently proposed and challenging RC dataset ‘NarrativeQA’. The proposed architecture outperforms state-of-the-art results by 12.62% (ROUGE-L) relative improvement.",1.0,0.8968257308006287,True,0.3775406687981454,0.6371831997993871,True
Don't Take This Out of Context!: On the Need for Contextual Models and Evaluations for Stylistic Rewriting,"Most existing stylistic text rewriting methods and evaluation metrics operate on a sentence level, but ignoring the broader context of the text can lead to preferring generic, ambiguous, and incoherent rewrites. In this paper, we investigate integrating the preceding textual context into both the rewriting and evaluation stages of stylistic text rewriting, and introduce a new composite contextual evaluation metric CtxSimFit that combines similarity to the original sentence with contextual cohesiveness. We comparatively evaluate non-contextual and contextual rewrites in formality, toxicity, and sentiment transfer tasks. Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic metrics (e.g., ROUGE, SBERT) correlate poorly with human preferences (ρ=0-0.3). In contrast, human preferences are much better reflected by both our novel CtxSimFit (ρ=0.7-0.9) as well as proposed context-infused versions of common metrics (ρ=0.4-0.7). Overall, our findings highlight the importance of integrating context into the generation and especially the evaluation stages of stylistic text rewriting.",1.3,0.7761589288711548,True,0.45016600268752216,0.6131624657793384,True
EtriCA: Event-Triggered Context-Aware Story Generation Augmented by Cross Attention,"One of the key challenges of automatic story generation is how to generate a long narrative that can maintain fluency, relevance, and coherence. Despite recent progress, current story generation systems still face the challenge of how to effectively capture contextual and event features, which has a profound impact on a model's generation performance. To address these challenges, we present EtriCA, a novel neural generation model, which improves the relevance and coherence of the generated stories through residually mapping context features to event sequences with a cross-attention mechanism. Such a feature capturing mechanism allows our model to better exploit the logical relatedness between events when generating stories. Extensive experiments based on both automatic and human evaluations show that our model significantly outperforms state-of-the-art baselines, demonstrating the effectiveness of our model in leveraging context and event features.",1.0,0.8001108765602112,True,0.3775406687981454,0.5888257726791783,True
"The Iron(ic) Melting Pot: Reviewing Human Evaluation in Humour, Irony and Sarcasm Generation","Human evaluation is often considered to be the gold standard method of evaluating a Natural Language Generation system. However, whilst its importance is accepted by the community at large, the quality of its execution is often brought into question. In this position paper, we argue that the generation of more esoteric forms of language - humour, irony and sarcasm - constitutes a subdomain where the characteristics of selected evaluator panels are of utmost importance, and every effort should be made to report demographic characteristics wherever possible, in the interest of transparency and replicability. We support these claims with an overview of each language form and an analysis of examples in terms of how their interpretation is affected by different participant variables. We additionally perform a critical survey of recent works in NLG to assess how well evaluation procedures are reported in this subdomain, and note a severe lack of open reporting of evaluator demographic information, and a significant reliance on crowdsourcing platforms for recruitment.",0.8,0.987373948097229,True,0.3318122278318339,0.6595930879645314,True
A Bag of Tricks for Dialogue Summarization,"Dialogue summarization comes with its own peculiar challenges as opposed to news or scientific articles summarization. In this work, we explore four different challenges of the task: handling and differentiating parts of the dialogue belonging to multiple speakers, negation understanding, reasoning about the situation, and informal language understanding. Using a pretrained sequence-to-sequence language model, we explore speaker name substitution, negation scope highlighting, multi-task learning with relevant tasks, and pretraining on in-domain data. Our experiments show that our proposed techniques indeed improve summarization performance, outperforming strong baselines.",1.0,0.8520690202713013,True,0.3775406687981454,0.6148048445347234,True
DiffuVST: Narrating Fictional Scenes with Global-History-Guided Denoising Models,"Recent advances in image and video creation, especially AI-based image synthesis, have led to the production of numerous visual scenes that exhibit a high level of abstractness and diversity. Consequently, Visual Storytelling (VST), a task that involves generating meaningful and coherent narratives from a collection of images, has become even more challenging and is increasingly desired beyond real-world imagery. While existing VST techniques, which typically use autoregressive decoders, have made significant progress, they suffer from low inference speed and are not well-suited for synthetic scenes. To this end, we propose a novel diffusion-based system DiffuVST, which models the generation of a series of visual descriptions as a single conditional denoising process. The stochastic and non-autoregressive nature of DiffuVST at inference time allows it to generate highly diverse narratives more efficiently. In addition, DiffuVST features a unique design with bi-directional text history guidance and multimodal adapter modules, which effectively improve inter-sentence coherence and image-to-text fidelity. Extensive experiments on the story generation task covering four fictional visual-story datasets demonstrate the superiority of DiffuVST over traditional autoregressive models in terms of both text quality and inference speed.",1.0,0.7635253667831421,True,0.3775406687981454,0.5705330177906438,True
"BERT Knows Punta Cana Is Not Just Beautiful, It’s Gorgeous: Ranking Scalar Adjectives with Contextualised Representations","Adjectives like pretty, beautiful and gorgeous describe positive properties of the nouns they modify but with different intensity. These differences are important for natural language understanding and reasoning. We propose a novel BERT-based approach to intensity detection for scalar adjectives. We model intensity by vectors directly derived from contextualised representations and show they can successfully rank scalar adjectives. We evaluate our models both intrinsically, on gold standard datasets, and on an Indirect Question Answering task. Our results demonstrate that BERT encodes rich knowledge about the semantics of scalar adjectives, and is able to provide better quality intensity rankings than static embeddings and previous models with access to dedicated resources.",1.0,0.8783579468727112,True,0.3775406687981454,0.6279493078354283,True
Dats Wassup!!: Investigating African-American Vernacular English in Transformer-Based Text Generation,"The growth of social media has encouraged the written use of African American Vernacular English (AAVE), which has traditionally been used only in oral contexts. However, NLP models have historically been developed using dominant English varieties, such as Standard American English (SAE), due to text corpora availability. We investigate the performance of GPT-2 on AAVE text by creating a dataset of intent-equivalent parallel AAVE/SAE tweet pairs, thereby isolating syntactic structure and AAVE- or SAE-specific language for each pair. We evaluate each sample and its GPT-2 generated text with pretrained sentiment classifiers and find that while AAVE text results in more classifications of negative sentiment than SAE, the use of GPT-2 generally increases occurrences of positive sentiment for both. Additionally, we conduct human evaluation of AAVE and SAE text generated with GPT-2 to compare contextual rigor and overall quality.",1.3,0.9877382516860962,True,0.45016600268752216,0.7189521271868091,True
"Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual, Intensional, and Extensional Learning for Faithful Natural Language Generation","We show that LLMs hallucinate because their output is not constrained to be synonymous with claims for which they have evidence: a condition that we call evidential closure. Information about the truth or falsity of sentences is not statistically identified in the standard neural probabilistic language model setup, and so cannot be conditioned on to generate new strings. We then show how to constrain LLMs to produce output that does satisfy evidential closure. A multimodal LLM must learn about the external world (perceptual learning); it must learn a mapping from strings to states of the world (extensional learning); and, to achieve fluency when generalizing beyond a body of evidence, it must learn mappings from strings to their synonyms (intensional learning). The output of a unimodal LLM must be synonymous with strings in a validated evidence set. Finally, we present a heuristic procedure, Learn-Babble-Prune, that yields faithful output from an LLM by rejecting output that is not synonymous with claims for which the LLM has evidence.",0.8,0.7865824103355408,True,0.3318122278318339,0.5591973190836873,True
Mapping (Dis-)Information Flow about the MH17 Plane Crash,"Digital media enables not only fast sharing of information, but also disinformation. One prominent case of an event leading to circulation of disinformation on social media is the MH17 plane crash. Studies analysing the spread of information about this event on Twitter have focused on small, manually annotated datasets, or used proxys for data annotation. In this work, we examine to what extent text classifiers can be used to label data for subsequent content analysis, in particular we focus on predicting pro-Russian and pro-Ukrainian Twitter content related to the MH17 plane crash. Even though we find that a neural classifier improves over a hashtag based baseline, labeling pro-Russian and pro-Ukrainian content with high precision remains a challenging problem. We provide an error analysis underlining the difficulty of the task and identify factors that might help improve classification in future work. Finally, we show how the classifier can facilitate the annotation task for human annotators.",0.8,0.9151148796081543,True,0.3318122278318339,0.6234635537199941,True
Sound of Story: Multi-modal Storytelling with Audio,"Storytelling is multi-modal in the real world. When one tells a story, one may use all of the visualizations and sounds along with the story itself. However, prior studies on storytelling datasets and tasks have paid little attention to sound even though sound also conveys meaningful semantics of the story. Therefore, we propose to extend story understanding and telling areas by establishing a new component called""background sound""which is story context-based audio without any linguistic information. For this purpose, we introduce a new dataset, called""Sound of Story (SoS)"", which has paired image and text sequences with corresponding sound or background music for a story. To the best of our knowledge, this is the largest well-curated dataset for storytelling with sound. Our SoS dataset consists of 27,354 stories with 19.6 images per story and 984 hours of speech-decoupled audio such as background music and other sounds. As benchmark tasks for storytelling with sound and the dataset, we propose retrieval tasks between modalities, and audio generation tasks from image-text sequences, introducing strong baselines for them. We believe the proposed dataset and tasks may shed light on the multi-modal understanding of storytelling in terms of sound. Downloading the dataset and baseline codes for each task will be released in the link: https://github.com/Sosdatasets/SoS_Dataset.",1.0,0.804574728012085,True,0.3775406687981454,0.5910576984051152,True
Diversity Enhanced Narrative Question Generation for Storybooks,"Question generation (QG) from a given context can enhance comprehension, engagement, assessment, and overall efficacy in learning or conversational environments. Despite recent advancements in QG, the challenge of enhancing or measuring the diversity of generated questions often remains unaddressed. In this paper, we introduce a multi-question generation model (mQG), which is capable of generating multiple, diverse, and answerable questions by focusing on context and questions. To validate the answerability of the generated questions, we employ a SQuAD2.0 fine-tuned question answering model, classifying the questions as answerable or not. We train and evaluate mQG on the FairytaleQA dataset, a well-structured QA dataset based on storybooks, with narrative questions. We further apply a zero-shot adaptation on the TellMeWhy and SQuAD1.1 datasets. mQG shows promising results across various evaluation metrics, among strong baselines.",1.0,0.9197825193405151,True,0.3775406687981454,0.6486615940693303,True
A Skeleton-Based Model for Promoting Coherence Among Sentences in Narrative Story Generation,"Narrative story generation is a challenging problem because it demands the generated sentences with tight semantic connections, which has not been well studied by most existing generative models. To address this problem, we propose a skeleton-based model to promote the coherence of generated stories. Different from traditional models that generate a complete sentence at a stroke, the proposed model first generates the most critical phrases, called skeleton, and then expands the skeleton to a complete and fluent sentence. The skeleton is not manually defined, but learned by a reinforcement learning method. Compared to the state-of-the-art models, our skeleton-based model can generate significantly more coherent text according to human evaluation and automatic evaluation. The G-score is improved by 20.1% in human evaluation.",1.0,0.7669795155525208,True,0.3775406687981454,0.5722600921753331,True
TextHacker: Learning based Hybrid Local Search Algorithm for Text Hard-label Adversarial Attack,"Existing textual adversarial attacks usually utilize the gradient or prediction confidence to generate adversarial examples, making it hard to be deployed in real-world applications. To this end, we consider a rarely investigated but more rigorous setting, namely hard-label attack, in which the attacker can only access the prediction label. In particular, we find we can learn the importance of different words via the change on prediction label caused by word substitutions on the adversarial examples. Based on this observation, we propose a novel adversarial attack, termed Text Hard-label attacker (TextHacker). TextHacker randomly perturbs lots of words to craft an adversarial example. Then, TextHacker adopts a hybrid local search algorithm with the estimation of word importance from the attack history to minimize the adversarial perturbation. Extensive evaluations for text classification and textual entailment show that TextHacker significantly outperforms existing hard-label attacks regarding the attack performance as well as adversary quality.",1.0,0.9013420343399048,True,0.3775406687981454,0.6394413515690252,True
Context-Situated Pun Generation,"Previous work on pun generation commonly begins with a given pun word (a pair of homophones for heterographic pun generation and a polyseme for homographic pun generation) and seeks to generate an appropriate pun. While this may enable efficient pun generation, we believe that a pun is most entertaining if it fits appropriately within a given context, e.g., a given situation or dialogue. In this work, we propose a new task, context-situated pun generation, where a specific context represented by a set of keywords is provided, and the task is to first identify suitable pun words that are appropriate for the context, then generate puns based on the context keywords and the identified pun words. We collect a new dataset, CUP (Context-sitUated Pun), containing 4.5k tuples of context words and pun pairs. Based on the new data and setup, we propose a pipeline system for context-situated pun generation, including a pun word retrieval module that identifies suitable pun words for a given context, and a pun generation module that generates puns from context keywords and pun words. Human evaluation shows that 69% of our top retrieved pun words can be used to generate context-situated puns, and our generation module yields successful puns 31% of the time given a plausible tuple of context words and pun pair, almost tripling the yield of a state-of-the-art pun generation model. With an end-to-end evaluation, our pipeline system with the top-1 retrieved pun pair for a given context can generate successful puns 40% of the time, better than all other modeling variations but 32% lower than the human success rate. This highlights the difficulty of the task, and encourages more research in this direction.",1.0,0.9581321477890015,True,0.3775406687981454,0.6678364082935735,True
A Deeper (Autoregressive) Approach to Non-Convergent Discourse Parsing,"Online social platforms provide a bustling arena for information-sharing and for multi-party discussions. Various frameworks for dialogic discourse parsing were developed and used for the processing of discussions and for predicting the productivity of a dialogue. However, most of these frameworks are not suitable for the analysis of contentious discussions that are commonplace in many online platforms. A novel multi-label scheme for contentious dialog parsing was recently introduced by Zakharov et al. (2021). While the schema is well developed, the computational approach they provide is both naive and inefficient, as a different model (architecture) using a different representation of the input, is trained for each of the 31 tags in the annotation scheme. Moreover, all their models assume full knowledge of label collocations and context, which is unlikely in any realistic setting. In this work, we present a unified model for Non-Convergent Discourse Parsing that does not require any additional input other than the previous dialog utterances. We fine-tuned a RoBERTa backbone, combining embeddings of the utterance, the context and the labels through GRN layers and an asymmetric loss function. Overall, our model achieves results comparable with SOTA, without using label collocation and without training a unique architecture/model for each label.",0.8,0.7808148860931396,True,0.3318122278318339,0.5563135569624867,True
Sanskrit Sandhi Splitting using seq2(seq)2,"In Sanskrit, small words (morphemes) are combined to form compound words through a process known as Sandhi. Sandhi splitting is the process of splitting a given compound word into its constituent morphemes. Although rules governing word splitting exists in the language, it is highly challenging to identify the location of the splits in a compound word. Though existing Sandhi splitting systems incorporate these pre-defined splitting rules, they have a low accuracy as the same compound word might be broken down in multiple ways to provide syntactically correct splits. In this research, we propose a novel deep learning architecture called Double Decoder RNN (DD-RNN), which (i) predicts the location of the split(s) with 95% accuracy, and (ii) predicts the constituent words (learning the Sandhi splitting rules) with 79.5% accuracy, outperforming the state-of-art by 20%. Additionally, we show the generalization capability of our deep learning model, by showing competitive results in the problem of Chinese word segmentation, as well.",0.8,0.8574708700180054,True,0.3318122278318339,0.5946415489249196,True
Controllable Story Generation with External Knowledge Using Large-Scale Language Models,"Existing pre-trained large language models have shown unparalleled generative capabilities. However, they are not controllable. In this paper, we propose MEGATRON-CNTRL, a novel framework that uses large-scale language models and adds control to text generation by incorporating an external knowledge base. Our framework consists of a keyword predictor, a knowledge retriever, a contextual knowledge ranker, and a conditional text generator. As we do not have access to ground-truth supervision for the knowledge ranker, we make use of weak supervision from sentence embedding. The empirical results show that our model generates more fluent, consistent, and coherent stories with less repetition and higher diversity compared to prior work on the ROC story dataset. We showcase the controllability of our model by replacing the keywords used to generate stories and re-running the generation process. Human evaluation results show that 77.5% of these stories are successfully controlled by the new keywords. Furthermore, by scaling our model from 124 million to 8.3 billion parameters we demonstrate that larger models improve both the quality of generation (from 74.5% to 93.0% for consistency) and controllability (from 77.5% to 91.5%).",1.0,0.7734290957450867,True,0.3775406687981454,0.5754848822716161,True
Comprehensive Punctuation Restoration for English and Polish,"Punctuation restoration is a fundamental re-quirement for the readability of text derived from Automatic Speech Recognition (ASR) systems. Most contemporary solutions are limited to predicting only a few of the most frequently occurring marks, such as periods, commas, and question marks — and only one per word. However, in written language, we deal with a much larger number of punctuation characters (such as parentheses, hyphens, etc.), and their combinations (like parenthesis followed by a dot). Such comprehensive punctuation cannot always be unambiguously reduced to a basic set of the most frequently occurring marks. In this work, we evaluate several methods in the comprehensive punctuation reconstruction task. We conduct experiments on parallel corpora of two different languages, English and Polish — languages with a relatively simple and complex morphology, respectively. We also investigate the inﬂuence of building a model on comprehensive punctuation on the quality of the basic punctuation restoration task.",1.0,0.7949375510215759,True,0.3775406687981454,0.5862391099098607,True
Supervised neural machine translation based on data augmentation and improved training & inference process,"This is the second time for SRCB to participate in WAT. This paper describes the neural machine translation systems for the shared translation tasks of WAT 2019. We participated in ASPEC tasks and submitted results on English-Japanese, Japanese-English, Chinese-Japanese, and Japanese-Chinese four language pairs. We employed the Transformer model as the baseline and experimented relative position representation, data augmentation, deep layer model, ensemble. Experiments show that all these methods can yield substantial improvements.",0.8,0.7709475755691528,True,0.3318122278318339,0.5513799017004933,True
Sunny and Dark Outside?! Improving Answer Consistency in VQA through Entailed Question Generation,"While models for Visual Question Answering (VQA) have steadily improved over the years, interacting with one quickly reveals that these models lack consistency. For instance, if a model answers “red” to “What color is the balloon?”, it might answer “no” if asked, “Is the balloon red?”. These responses violate simple notions of entailment and raise questions about how effectively VQA models ground language. In this work, we introduce a dataset, ConVQA, and metrics that enable quantitative evaluation of consistency in VQA. For a given observable fact in an image (e.g. the balloon’s color), we generate a set of logically consistent question-answer (QA) pairs (e.g. Is the balloon red?) and also collect a human-annotated set of common-sense based consistent QA pairs (e.g. Is the balloon the same color as tomato sauce?). Further, we propose a consistency-improving data augmentation module, a Consistency Teacher Module (CTM). CTM automatically generates entailed (or similar-intent) questions for a source QA pair and fine-tunes the VQA model if the VQA’s answer to the entailed question is consistent with the source QA pair. We demonstrate that our CTM-based training improves the consistency of VQA models on the Con-VQA datasets and is a strong baseline for further research.",1.6,0.9036673307418823,True,0.52497918747894,0.7143232591104112,True
Structural generalization in COGS: Supertagging is (almost) all you need,"In many Natural Language Processing applications, neural networks have been found to fail to generalize on out-of-distribution examples. In particular, several recent semantic parsing datasets have put forward important limitations of neural networks in cases where compositional generalization is required. In this work, we extend a neural graph-based semantic parsing framework in several ways to alleviate this issue. Notably, we propose: (1) the introduction of a supertagging step with valency constraints, expressed as an integer linear program; (2) a reduction of the graph prediction problem to the maximum matching problem; (3) the design of an incremental early-stopping training strategy to prevent overfitting. Experimentally, our approach significantly improves results on examples that require structural generalization in the COGS dataset, a known challenging benchmark for compositional generalization. Overall, our results confirm that structural constraints are important for generalization in semantic parsing.",0.8,0.7807143330574036,True,0.3318122278318339,0.5562632804446187,True
Keep It Surprisingly Simple: A Simple First Order Graph Based Parsing Model for Joint Morphosyntactic Parsing in Sanskrit,"Morphologically rich languages seem to benefit from joint processing of morphology and syntax, as compared to pipeline architectures. We propose a graph-based model for joint morphological parsing and dependency parsing in Sanskrit. Here, we extend the Energy based model framework (Krishna et al., 2020), proposed for several structured prediction tasks in Sanskrit, in 2 simple yet significant ways. First, the framework’s default input graph generation method is modified to generate a multigraph, which enables the use of an exact search inference. Second, we prune the input search space using a linguistically motivated approach, rooted in the traditional grammatical analysis of Sanskrit. Our experiments show that the morphological parsing from our joint model outperforms standalone morphological parsers. We report state of the art results in morphological parsing, and in dependency parsing, both in standalone (with gold morphological tags) and joint morphosyntactic parsing setting.",1.0,0.9036885499954224,True,0.3775406687981454,0.6406146093967839,True
Visual Storytelling with Question-Answer Plans,"Visual storytelling aims to generate compelling narratives from image sequences. Existing models often focus on enhancing the representation of the image sequence, e.g., with external knowledge sources or advanced graph structures. Despite recent progress, the stories are often repetitive, illogical, and lacking in detail. To mitigate these issues, we present a novel framework which integrates visual representations with pretrained language models and planning. Our model translates the image sequence into a visual prefix, a sequence of continuous embeddings which language models can interpret. It also leverages a sequence of question-answer pairs as a blueprint plan for selecting salient visual concepts and determining how they should be assembled into a narrative. Automatic and human evaluation on the VIST benchmark (Huang et al., 2016) demonstrates that blueprint-based models generate stories that are more coherent, interesting, and natural compared to competitive baselines and state-of-the-art systems.",1.0,0.9458345770835876,True,0.3775406687981454,0.6616876229408666,True
Does My Multimodal Model Learn Cross-modal Interactions? It’s Harder to Tell than You Might Think!,"Modeling expressive cross-modal interactions seems crucial in multimodal tasks, such as visual question answering. However, sometimes high-performing black-box algorithms turn out to be mostly exploiting unimodal signals in the data. We propose a new diagnostic tool, empirical multimodally-additive function projection (EMAP), for isolating whether or not cross-modal interactions improve performance for a given model on a given task. This function projection modifies model predictions so that cross-modal interactions are eliminated, isolating the additive, unimodal structure. For seven image+text classification tasks (on each of which we set new state-of-the-art benchmarks), we find that, in many cases, removing cross-modal interactions results in little to no performance degradation. Surprisingly, this holds even when expressive models, with capacity to consider interactions, otherwise outperform less expressive models; thus, performance improvements, even when present, often cannot be attributed to consideration of cross-modal feature interactions. We hence recommend that researchers in multimodal machine learning report the performance not only of unimodal baselines, but also the EMAP of their best-performing model.",0.8,0.971824586391449,True,0.3318122278318339,0.6518184071116414,True
Telling the Whole Story: A Manually Annotated Chinese Dataset for the Analysis of Humor in Jokes,"Humor plays important role in human communication, which makes it important problem for natural language processing. Prior work on the analysis of humor focuses on whether text is humorous or not, or the degree of funniness, but this is insufficient to explain why it is funny. We therefore create a dataset on humor with 9,123 manually annotated jokes in Chinese. We propose a novel annotation scheme to give scenarios of how humor arises in text. Specifically, our annotations of linguistic humor not only contain the degree of funniness, like previous work, but they also contain key words that trigger humor as well as character relationship, scene, and humor categories. We report reasonable agreement between annota-tors. We also conduct an analysis and exploration of the dataset. To the best of our knowledge, we are the first to approach humor annotation for exploring the underlying mechanism of the use of humor, which may contribute to a significantly deeper analysis of humor. We also contribute with a scarce and valuable dataset, which we will release publicly.",2.0,0.9178386330604553,True,0.6224593312018546,0.7701489821311549,True
Inferring the Reader: Guiding Automated Story Generation with Commonsense Reasoning,"Transformer-based language model approaches to automated story generation currently provide state-of-the-art results. However, they still suffer from plot incoherence when generating narratives over time, and critically lack basic commonsense reasoning. Furthermore, existing methods generally focus only on single-character stories, or fail to track characters at all. To improve the coherence of generated narratives and to expand the scope of character-centric narrative generation, we introduce Commonsense-inference Augmented neural StoryTelling (CAST), a framework for introducing commonsense reasoning into the generation process with the option to model the interaction between multiple characters. We find that our CAST method produces significantly more coherent, on-topic, enjoyable and fluent stories than existing models in both the single-character and two-character settings in three storytelling domains.",1.0,0.7623980641365051,True,0.3775406687981454,0.5699693664673253,True
(Mis)alignment Between Stance Expressed in Social Media Data and Public Opinion Surveys,"Stance detection, which aims to determine whether an individual is for or against a target concept, promises to uncover public opinion from large streams of social media data. Yet even human annotation of social media content does not always capture “stance” as measured by public opinion polls. We demonstrate this by directly comparing an individual’s self-reported stance to the stance inferred from their social media data. Leveraging a longitudinal public opinion survey with respondent Twitter handles, we conducted this comparison for 1,129 individuals across four salient targets. We find that recall is high for both “Pro’’ and “Anti’’ stance classifications but precision is variable in a number of cases. We identify three factors leading to the disconnect between text and author stance: temporal inconsistencies, differences in constructs, and measurement errors from both survey respondents and annotators. By presenting a framework for assessing the limitations of stance detection models, this work provides important insight into what stance detection truly measures.",0.8,0.8313897252082825,True,0.3318122278318339,0.5816009765200582,True
Narrative Order Aware Story Generation via Bidirectional Pretraining Model with Optimal Transport Reward,",",1.0,0.7270264029502869,True,0.3775406687981454,0.5522835358742162,True
A Unified Framework for Pun Generation with Humor Principles,"We propose a unified framework to generate both homophonic and homographic puns to resolve the split-up in existing works. Specifically, we incorporate three linguistic attributes of puns to the language models: ambiguity, distinctiveness, and surprise. Our framework consists of three parts: 1) a context words/phrases selector to promote the aforementioned attributes, 2) a generation model trained on non-pun sentences to incorporate the context words/phrases into the generation output, and 3) a label predictor that learns the structure of puns which is used to steer the generation model at inference time. Evaluation results on both pun types demonstrate the efficacy of our model over strong baselines.",1.0,0.9926990270614624,True,0.3775406687981454,0.685119847929804,True
Finding Microaggressions in the Wild: A Case for Locating Elusive Phenomena in Social Media Posts,"Microaggressions are subtle, often veiled, manifestations of human biases. These uncivil interactions can have a powerful negative impact on people by marginalizing minorities and disadvantaged groups. The linguistic subtlety of microaggressions in communication has made it difficult for researchers to analyze their exact nature, and to quantify and extract microaggressions automatically. Specifically, the lack of a corpus of real-world microaggressions and objective criteria for annotating them have prevented researchers from addressing these problems at scale. In this paper, we devise a general but nuanced, computationally operationalizable typology of microaggressions based on a small subset of data that we have. We then create two datasets: one with examples of diverse types of microaggressions recollected by their targets, and another with gender-based microaggressions in public conversations on social media. We introduce a new, more objective, criterion for annotation and an active-learning based procedure that increases the likelihood of surfacing posts containing microaggressions. Finally, we analyze the trends that emerge from these new datasets.",1.0,0.8983628749847412,True,0.3775406687981454,0.6379517718914434,True
Function Assistant: A Tool for NL Querying of APIs,"In this paper, we describe Function Assistant, a lightweight Python-based toolkit for querying and exploring source code repositories using natural language. The toolkit is designed to help end-users of a target API quickly find information about functions through high-level natural language queries, or descriptions. For a given text query and background API, the tool finds candidate functions by performing a translation from the text to known representations in the API using the semantic parsing approach of (Richardson and Kuhn, 2017). Translations are automatically learned from example text-code pairs in example APIs. The toolkit includes features for building translation pipelines and query engines for arbitrary source code projects. To explore this last feature, we perform new experiments on 27 well-known Python projects hosted on Github.",1.0,0.8825572729110718,True,0.3775406687981454,0.6300489708546086,True
A Predicate-Function-Argument Annotation of Natural Language for Open-Domain Information Expression,"Existing OIE (Open Information Extraction) algorithms are independent of each other such that there exist lots of redundant works; the featured strategies are not reusable and not adaptive to new tasks. This paper proposes a new pipeline to build OIE systems, where an Open-domain Information eXpression (OIX) task is proposed to provide a platform for all OIE strategies. The OIX is an OIE friendly expression of a sentence without information loss. The generation procedure of OIX contains shared works of OIE algorithms so that OIE strategies can be developed on the platform of OIX as inference operations focusing on more critical problems. Based on the same platform of OIX, the OIE strategies are reusable, and people can select a set of strategies to assemble their algorithm for a specific task so that the adaptability may be significantly increased. This paper focuses on the task of OIX and propose a solution – Open Information Annotation (OIA). OIA is a predicate-function-argument annotation for sentences. We label a data set of sentence-OIA pairs and propose a dependency-based rule system to generate OIA annotations from sentences. The evaluation results reveal that learning the OIA from a sentence is a challenge owing to the complexity of natural language sentences, and it is worthy of attracting more attention from the research community.",1.0,0.7298957705497742,True,0.3775406687981454,0.5537182196739598,True
You Told Me That Joke Twice: A Systematic Investigation of Transferability and Robustness of Humor Detection Models,"In this study, we focus on automatic humor detection, a highly relevant task for conversational AI. To date, there are several English datasets for this task, but little research on how models trained on them generalize and behave in the wild. To fill this gap, we carefully analyze existing datasets, train RoBERTabased and Naïve Bayes classifiers on each of them, and test on the rest. Training and testing on the same dataset yields good results, but the transferability of the models varies widely. Models trained on datasets with jokes from different sources show better transferability, while the amount of training data has a smaller impact. The behavior of the models on out-of-domain data is unstable, suggesting that some of the models overfit, while others learn non-specific humor characteristics. An adversarial attack shows that models trained on pun datasets are less robust. We also evaluate the sense of humor of the chatGPT and Flan-UL2 models in a zero-shot scenario. The LLMs demonstrate competitive results on humor datasets and a more stable behavior on out-of-domain data. We believe that the obtained results will facilitate the development of new datasets and evaluation methodologies in the field of computational humor. We've made all the data from the study and the trained models publicly available: https://github.com/ Humor-Research/Humor-detection.",1.0,0.9893193244934082,True,0.3775406687981454,0.6834299966457769,True
Multi-Domain Goal-Oriented Dialogues (MultiDoGO): Strategies toward Curating and Annotating Large Scale Dialogue Data,"The need for high-quality, large-scale, goal-oriented dialogue datasets continues to grow as virtual assistants become increasingly wide-spread. However, publicly available datasets useful for this area are limited either in their size, linguistic diversity, domain coverage, or annotation granularity. In this paper, we present strategies toward curating and annotating large scale goal oriented dialogue data. We introduce the MultiDoGO dataset to overcome these limitations. With a total of over 81K dialogues harvested across six domains, MultiDoGO is over 8 times the size of MultiWOZ, the other largest comparable dialogue dataset currently available to the public. Over 54K of these harvested conversations are annotated for intent classes and slot labels. We adopt a Wizard-of-Oz approach wherein a crowd-sourced worker (the “customer”) is paired with a trained annotator (the “agent”). The data curation process was controlled via biases to ensure a diversity in dialogue flows following variable dialogue policies. We provide distinct class label tags for agents vs. customer utterances, along with applicable slot labels. We also compare and contrast our strategies on annotation granularity, i.e. turn vs. sentence level. Furthermore, we compare and contrast annotations curated by leveraging professional annotators vs the crowd. We believe our strategies for eliciting and annotating such a dialogue dataset scales across modalities and domains and potentially languages in the future. To demonstrate the efficacy of our devised strategies we establish neural baselines for classification on the agent and customer utterances as well as slot labeling for each domain.",0.8,0.7865204811096191,True,0.3318122278318339,0.5591663544707265,True
Affective and Dynamic Beam Search for Story Generation,"Storytelling's captivating potential makes it a fascinating research area, with implications for entertainment, education, therapy, and cognitive studies. In this paper, we propose Affective Story Generator (AffGen) for generating interesting narratives. AffGen introduces""intriguing twists""in narratives by employing two novel techniques-Dynamic Beam Sizing and Affective Reranking. Dynamic Beam Sizing encourages less predictable, more captivating word choices using a contextual multi-arm bandit model. Affective Reranking prioritizes sentence candidates based on affect intensity. Our empirical evaluations, both automatic and human, demonstrate AffGen's superior performance over existing baselines in generating affectively charged and interesting narratives. Our ablation study and analysis provide insights into the strengths and weaknesses of AffGen.",1.0,0.9067509770393372,True,0.3775406687981454,0.6421458229187413,True
"Cross-Cultural Analysis of Human Values, Morals, and Biases in Folk Tales","Folk tales are strong cultural and social inﬂu-ences in children’s lives, and they are known to teach morals and values. However, existing studies on folk tales are largely limited to European tales. In our study, we compile a large corpus of over 1,900 tales originating from 27 diverse cultures across six continents. Using a range of lexicons and correlation analyses, we examine how human values, morals, and gender biases are expressed in folk tales across cultures. We discover differences between cultures in prevalent values and morals, as well as cross-cultural trends in problematic gender biases. Furthermore, we ﬁnd trends of reduced value expression when examining public-domain ﬁction stories, extrin-sically validate our analyses against the multicultural Schwartz Survey of Cultural Values, and ﬁnd traditional gender biases associated with values, morals, and agency. This large-scale cross-cultural study of folk tales paves the way for future studies on how literature in-ﬂuences and reﬂects cultural norms.",1.0,0.8172557353973389,True,0.3775406687981454,0.5973982020977422,True
LittleBird: Efficient Faster & Longer Transformer for Question Answering,"BERT has shown a lot of sucess in a wide variety of NLP tasks. But it has a limitation dealing with long inputs due to its attention mechanism. Longformer, ETC and BigBird addressed this issue and effectively solved the quadratic dependency problem.However we find that these models are not sufficient, and propose LittleBird, a novel model based on BigBird with improved speed and memory footprint while maintaining accuracy.In particular, we devise a more flexible and efficient position representation method based on Attention with Linear Biases(ALiBi). We also show that replacing the method of global information represented in the BigBird with pack and unpack attention is more effective.The proposed model can work on long inputs even after being pre-trained on short inputs, and can be trained efficiently reusing existing pre-trained language model for short inputs. This is a significant benefit for low-resource languages where large amounts of long text data are difficult to obtain.As a result, our experiments show that LittleBird works very well in a variety of languages, achieving high performance in question answering tasks, particularly in KorQuAD2.0, Korean Question Answering Dataset for long paragraphs.",0.8,0.9253009557723999,True,0.3318122278318339,0.6285565918021169,True
Learning To Split and Rephrase From Wikipedia Edit History,"Split and rephrase is the task of breaking down a sentence into shorter ones that together convey the same meaning. We extract a rich new dataset for this task by mining Wikipedia’s edit history: WikiSplit contains one million naturally occurring sentence rewrites, providing sixty times more distinct split examples and a ninety times larger vocabulary than the WebSplit corpus introduced by Narayan et al. (2017) as a benchmark for this task. Incorporating WikiSplit as training data produces a model with qualitatively better predictions that score 32 BLEU points above the prior best result on the WebSplit benchmark.",1.0,0.8458388447761536,True,0.3775406687981454,0.6116897567871495,True
"(Male, Bachelor) and (Female, Ph.D) have different connotations: Parallelly Annotated Stylistic Language Dataset with Multiple Personas","Stylistic variation in text needs to be studied with different aspects including the writer’s personal traits, interpersonal relations, rhetoric, and more. Despite recent attempts on computational modeling of the variation, the lack of parallel corpora of style language makes it difficult to systematically control the stylistic change as well as evaluate such models. We release PASTEL, the parallel and annotated stylistic language dataset, that contains ~41K parallel sentences (8.3K parallel stories) annotated across different personas. Each persona has different styles in conjunction: gender, age, country, political view, education, ethnic, and time-of-writing. The dataset is collected from human annotators with solid control of input denotation: not only preserving original meaning between text, but promoting stylistic diversity to annotators. We test the dataset on two interesting applications of style language, where PASTEL helps design appropriate experiment and evaluation. First, in predicting a target style (e.g., male or female in gender) given a text, multiple styles of PASTEL make other external style variables controlled (or fixed), which is a more accurate experimental design. Second, a simple supervised model with our parallel text outperforms the unsupervised models using nonparallel text in style transfer. Our dataset is publicly available.",0.8,0.917500376701355,True,0.3318122278318339,0.6246563022665944,True
CodRED: A Cross-Document Relation Extraction Dataset for Acquiring Knowledge in the Wild,"Existing relation extraction (RE) methods typically focus on extracting relational facts between entity pairs within single sentences or documents. However, a large quantity of relational facts in knowledge bases can only be inferred across documents in practice. In this work, we present the problem of cross-document RE, making an initial step towards knowledge acquisition in the wild. To facilitate the research, we construct the first human-annotated cross-document RE dataset CodRED. Compared to existing RE datasets, CodRED presents two key challenges: Given two entities, (1) it requires finding the relevant documents that can provide clues for identifying their relations; (2) it requires reasoning over multiple documents to extract the relational facts. We conduct comprehensive experiments to show that CodRED is challenging to existing RE methods including strong BERT-based models.",1.0,0.7531011700630188,True,0.3775406687981454,0.5653209194305822,True
RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes,"Understanding and reasoning about cooking recipes is a fruitful research direction towards enabling machines to interpret procedural text. In this work, we introduce RecipeQA, a dataset for multimodal comprehension of cooking recipes. It comprises of approximately 20K instructional recipes with multiple modalities such as titles, descriptions and aligned set of images. With over 36K automatically generated question-answer pairs, we design a set of comprehension and reasoning tasks that require joint understanding of images and text, capturing the temporal flow of events and making sense of procedural knowledge. Our preliminary results indicate that RecipeQA will serve as a challenging test bed and an ideal benchmark for evaluating machine comprehension systems. The data and leaderboard are available at http://hucvl.github.io/recipeqa.",1.0,0.9274789094924927,True,0.3775406687981454,0.6525097891453191,True
DeltaScore: Fine-Grained Story Evaluation with Perturbations,"Numerous evaluation metrics have been developed for natural language generation tasks, but their effectiveness in evaluating stories is limited as they are not specifically tailored to assess intricate aspects of storytelling, such as fluency and interestingness. In this paper, we introduce DELTASCORE, a novel methodology that employs perturbation techniques for the evaluation of nuanced story aspects. Our central proposition posits that the extent to which a story excels in a specific aspect (e.g., fluency) correlates with the magnitude of its susceptibility to particular perturbations (e.g., the introduction of typos). Given this, we measure the quality of an aspect by calculating the likelihood difference between pre- and post-perturbation states using pre-trained language models. We compare DELTASCORE with existing metrics on storytelling datasets from two domains in five fine-grained story aspects: fluency, coherence, relatedness, logicality, and interestingness. DELTASCORE demonstrates remarkable performance, revealing a surprising finding that a specific perturbation proves highly effective in capturing multiple aspects.",1.0,0.8338895440101624,True,0.3775406687981454,0.6057151064041539,True
When is Wall a Pared and when a Muro?: Extracting Rules Governing Lexical Selection,"Learning fine-grained distinctions between vocabulary items is a key challenge in learning a new language. For example, the noun “wall” has different lexical manifestations in Spanish – “pared” refers to an indoor wall while “muro” refers to an outside wall. However, this variety of lexical distinction may not be obvious to non-native learners unless the distinction is explained in such a way. In this work, we present a method for automatically identifying fine-grained lexical distinctions, and extracting rules explaining these distinctions in a human- and machine-readable format. We confirm the quality of these extracted rules in a language learning setup for two languages, Spanish and Greek, where we use the rules to teach non-native speakers when to translate a given ambiguous word into its different possible translations.",1.1,0.8664233684539795,True,0.401312339887548,0.6338678541707637,True
“Was it “stated” or was it “claimed”?: How linguistic bias affects generative language models,"People use language in subtle and nuanced ways to convey their beliefs. For instance, saying claimed instead of said casts doubt on the truthfulness of the underlying proposition, thus representing the author’s opinion on the matter. Several works have identified such linguistic classes of words that occur frequently in natural language text and are bias-inducing by virtue of their framing effects. In this paper, we test whether generative language models (including GPT-2 (CITATION) are sensitive to these linguistic framing effects. In particular, we test whether prompts that contain linguistic markers of author bias (e.g., hedges, implicatives, subjective intensifiers, assertives) influence the distribution of the generated text. Although these framing effects are subtle and stylistic, we find evidence that they lead to measurable style and topic differences in the generated text, leading to language that is, on average, more polarised and more skewed towards controversial entities and events.",1.1,0.8628968000411987,True,0.401312339887548,0.6321045699643734,True
Bootstrapping Small & High Performance Language Models with Unmasking-Removal Training Policy,"BabyBERTa, a language model trained on small-scale child-directed speech while none of the words are unmasked during training, has been shown to achieve a level of grammaticality comparable to that of RoBERTa-base, which is trained on 6,000 times more words and 15 times more parameters (Huebner et al., 2021). Relying on this promising result, we explore in this paper the performance of BabyBERTabased models in downstream tasks, focusing on Semantic Role Labeling (SRL) and two Extractive Question Answering tasks, with the aim of building more efficient systems that rely on less data and smaller models. We investigate the influence of these models both alone and as a starting point to larger pre-trained models, separately examining the contribution of the pre-training data, the vocabulary, and the masking policy on the downstream task performance. Our results show that BabyBERTa trained with unmasking-removal policy is a much stronger starting point for downstream tasks compared to the use of RoBERTa masking policy when 10M words are used for training and that this tendency persists, although to a lesser extent, when adding more training data. 1",0.8,0.7707523703575134,True,0.3318122278318339,0.5512822990946736,True
ExPUNations: Augmenting Puns with Keywords and Explanations,"The tasks of humor understanding and generation are challenging and subjective even for humans, requiring commonsense and real-world knowledge to master. Puns, in particular, add the challenge of fusing that knowledge with the ability to interpret lexical-semantic ambiguity. In this paper, we present the ExPUNations (ExPUN) dataset, in which we augment an existing dataset of puns with detailed crowdsourced annotations of keywords denoting the most distinctive words that make the text funny, pun explanations describing why the text is funny, and fine-grained funniness ratings. This is the first humor dataset with such extensive and fine-grained annotations specifically for puns. Based on these annotations, we propose two tasks: explanation generation to aid with pun classification and keyword-conditioned pun generation, to challenge the current state-of-the-art natural language understanding and generation models’ ability to understand and generate humor. We showcase that the annotated keywords we collect are helpful for generating better novel humorous texts in human evaluation, and that our natural language explanations can be leveraged to improve both the accuracy and robustness of humor classifiers.",1.0,0.9577338695526123,True,0.3775406687981454,0.6676372691753789,True
Tired of Topic Models? Clusters of Pretrained Word Embeddings Make for Fast and Good Topics Too!,"Topic models are a useful analysis tool to uncover the underlying themes within document collections. Probabilistic models which assume a generative story have been the dominant approach for topic modeling. We propose an alternative approach based on clustering readily available pre-trained word embeddings while incorporating document information for weighted clustering and reranking top words. We provide benchmarks for the combination of different word embeddings and clustering algorithms, and analyse their performance under dimensionality reduction with PCA. The best performing combination for our approach is comparable to classical models, and complexity analysis indicate that this is a practical alternative to traditional topic modeling.",0.8,0.9535967111587524,True,0.3318122278318339,0.6427044694952931,True
"""Be nice to your wife! The restaurants are closed"": Can Gender Stereotype Detection Improve Sexism Classification?","In this paper, we focus on the detection of sexist hate speech against women in tweets studying for the ﬁrst time the impact of gender stereotype detection on sexism classiﬁcation. We propose: (1) the ﬁrst dataset annotated for gender stereotype detection, (2) a new method for data augmentation based on sentence similarity with multilingual external datasets, and (3) a set of deep learning experiments ﬁrst to detect gender stereotypes and then, to use this auxiliary task for sexism detection. Although the presence of stereotypes does not necessarily entail hateful content, our results show that sexism classiﬁcation can deﬁnitively beneﬁt from gender stereotype detection.",0.8,0.9652106761932373,True,0.3318122278318339,0.6485114520125356,True
Multi-Class Grammatical Error Detection for Correction: A Tale of Two Systems,"In this paper, we show how a multi-class grammatical error detection (GED) system can be used to improve grammatical error correction (GEC) for English. Specifically, we first develop a new state-of-the-art binary detection system based on pre-trained ELECTRA, and then extend it to multi-class detection using different error type tagsets derived from the ERRANT framework. Output from this detection system is used as auxiliary input to fine-tune a novel encoder-decoder GEC model, and we subsequently re-rank the N-best GEC output to find the hypothesis that most agrees with the GED output. Results show that fine-tuning the GEC system using 4-class GED produces the best model, but re-ranking using 55-class GED leads to the best performance overall. This suggests that different multi-class GED systems benefit GEC in different ways. Ultimately, our system outperforms all other previous work that combines GED and GEC, and achieves a new single-model NMT-based state of the art on the BEA-test benchmark.",0.8,0.8751734495162964,True,0.3318122278318339,0.6034928386740651,True
Is it Time to Swish? Comparing Deep Learning Activation Functions Across NLP tasks,"Activation functions play a crucial role in neural networks because they are the nonlinearities which have been attributed to the success story of deep learning. One of the currently most popular activation functions is ReLU, but several competitors have recently been proposed or ‘discovered’, including LReLU functions and swish. While most works compare newly proposed activation functions on few tasks (usually from image classification) and against few competitors (usually ReLU), we perform the first largescale comparison of 21 activation functions across eight different NLP tasks. We find that a largely unknown activation function performs most stably across all tasks, the so-called penalized tanh function. We also show that it can successfully replace the sigmoid and tanh gates in LSTM cells, leading to a 2 percentage point (pp) improvement over the standard choices on a challenging NLP task.",1.3,0.9512190222740173,True,0.45016600268752216,0.7006925124807697,True
Filling the Blanks (hint: plural noun) for Mad Libs Humor,"Computerized generation of humor is a notoriously difficult AI problem. We develop an algorithm called Libitum that helps humans generate humor in a Mad Lib, which is a popular fill-in-the-blank game. The algorithm is based on a machine learned classifier that determines whether a potential fill-in word is funny in the context of the Mad Lib story. We use Amazon Mechanical Turk to create ground truth data and to judge humor for our classifier to mimic, and we make this data freely available. Our testing shows that Libitum successfully aids humans in filling in Mad Libs that are usually judged funnier than those filled in by humans with no computerized help. We go on to analyze why some words are better than others at making a Mad Lib funny.",0.8,0.9910724759101868,True,0.3318122278318339,0.6614423518710103,True
The Devil is in the Detail: Simple Tricks Improve Systematic Generalization of Transformers,"Recently, many datasets have been proposed to test the systematic generalization ability of neural networks. The companion baseline Transformers, typically trained with default hyper-parameters from standard tasks, are shown to fail dramatically. Here we demonstrate that by revisiting model configurations as basic as scaling of embeddings, early stopping, relative positional embedding, and Universal Transformer variants, we can drastically improve the performance of Transformers on systematic generalization. We report improvements on five popular datasets: SCAN, CFQ, PCFG, COGS, and Mathematics dataset. Our models improve accuracy from 50% to 85% on the PCFG productivity split, and from 35% to 81% on COGS. On SCAN, relative positional embedding largely mitigates the EOS decision problem (Newman et al., 2020), yielding 100% accuracy on the length split with a cutoff at 26. Importantly, performance differences between these models are typically invisible on the IID data split. This calls for proper generalization validation sets for developing neural networks that generalize systematically. We publicly release the code to reproduce our results.",1.0,0.9388487935066223,True,0.3775406687981454,0.6581947311523839,True
"Integrating Visuospatial, Linguistic, and Commonsense Structure into Story Visualization","While much research has been done in text-to-image synthesis, little work has been done to explore the usage of linguistic structure of the input text. Such information is even more important for story visualization since its inputs have an explicit narrative structure that needs to be translated into an image sequence (or visual story). Prior work in this domain has shown that there is ample room for improvement in the generated image sequence in terms of visual quality, consistency and relevance. In this paper, we first explore the use of constituency parse trees using a Transformer-based recurrent architecture for encoding structured input. Second, we augment the structured input with commonsense information and study the impact of this external knowledge on the generation of visual story. Third, we also incorporate visual structure via bounding boxes and dense captioning to provide feedback about the characters/objects in generated images within a dual learning setup. We show that off-the-shelf dense-captioning models trained on Visual Genome can improve the spatial structure of images from a different target domain without needing fine-tuning. We train the model end-to-end using intra-story contrastive loss (between words and image sub-regions) and show significant improvements in visual quality. Finally, we provide an analysis of the linguistic and visuo-spatial information.",1.0,0.795337438583374,True,0.3775406687981454,0.5864390536907598,True
MultiWOZ - A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling,"Even though machine learning has become the major scene in dialogue research community, the real breakthrough has been blocked by the scale of data available.To address this fundamental obstacle, we introduce the Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics.At a size of 10k dialogues, it is at least one order of magnitude larger than all previous annotated task-oriented corpora.The contribution of this work apart from the open-sourced dataset is two-fold:firstly, a detailed description of the data collection procedure along with a summary of data structure and analysis is provided. The proposed data-collection pipeline is entirely based on crowd-sourcing without the need of hiring professional annotators;secondly, a set of benchmark results of belief tracking, dialogue act and response generation is reported, which shows the usability of the data and sets a baseline for future studies.",1.0,0.8684672713279724,True,0.3775406687981454,0.623003970063059,True
Bag of Tricks for Optimizing Transformer Efficiency,"Improving Transformer efficiency has become increasingly attractive recently. A wide range of methods has been proposed, e.g., pruning, quantization, new architectures and etc. But these methods are either sophisticated in implementation or dependent on hardware. In this paper, we show that the efficiency of Transformer can be improved by combining some simple and hardware-agnostic methods, including tuning hyper-parameters, better design choices and training strategies. On the WMT news translation tasks, we improve the inference efficiency of a strong Transformer system by 3.80X on CPU and 2.52X on GPU. The code is publicly available at https://github.com/Lollipop321/mini-decoder-network.",1.0,0.8004149198532104,True,0.3775406687981454,0.588977794325678,True
A Video Is Worth 4096 Tokens: Verbalize Story Videos To Understand Them In Zero Shot,"Multimedia content, such as advertisements and story videos, exhibit a rich blend of creativity and multiple modalities. They incorporate elements like text, visuals, audio, and storytelling techniques, employing devices like emotions, symbolism, and slogans to convey meaning. While previous research in multi-media understanding has focused mainly on videos with specific actions like cooking, there is a dearth of large annotated training datasets, hindering the development of supervised learning models with satisfactory performance for real-world applications. However, the rise of large language models (LLMs) has witnessed remarkable zero-shot performance in various natural language processing (NLP) tasks, such as emotion classification, question-answering, and topic classification. To bridge this performance gap in multimedia understanding, we propose verbalizing story videos to generate their descriptions in natural language and then performing video-understanding tasks on the generated story as opposed to the original video. Through extensive experiments on five video-understanding tasks, we demonstrate that our method, despite being zero-shot, achieves significantly better results than supervised base-lines for video understanding. Further, alleviating a lack of story understanding benchmarks, we publicly release the first dataset on a crucial task in computational social science, persuasion strategy identification.",1.0,0.7634742856025696,True,0.3775406687981454,0.5705074772003575,True
Picking Apart Story Salads,"During natural disasters and conflicts, information about what happened is often confusing and messy, and distributed across many sources. We would like to be able to automatically identify relevant information and assemble it into coherent narratives of what happened. To make this task accessible to neural models, we introduce Story Salads, mixtures of multiple documents that can be generated at scale. By exploiting the Wikipedia hierarchy, we can generate salads that exhibit challenging inference problems. Story salads give rise to a novel, challenging clustering task, where the objective is to group sentences from the same narratives. We demonstrate that simple bag-of-words similarity clustering falls short on this task, and that it is necessary to take into account global context and coherence.",1.0,0.9377414584159851,True,0.3775406687981454,0.6576410636070653,True
Domain Adaptation based Topic Modeling Techniques for Engagement Estimation in the Wild,"In recent years, student engagement estimation has gained focus in the affective computing community. The absence of student monitoring during online MOOC courses makes it challenging to estimate behavioural student engagement during online classes. The non availability of consistent engagement datasets makes it difficult to build cross data automatic behavioural engagement estimation technique. In this paper, we propose an unsupervised topic modeling technique for engagement detection as it captures multiple behavioral cues which are indicators of engagement level such as eye gaze, head movement, facial expression and body posture. We have addressed the various challenges such as less volume of our datasets, large decision unit (annotated for 5 minutes duration) and uneven distribution of different engagement categories with domain adaptation based solution for cross data implementation. We present results on engagement prediction using different clustering techniques such as K-Means and Latent Dirichlet Allocation (LDA) along with different regressors and neural network based attention mechanisms.",1.0,0.7590097188949585,True,0.3775406687981454,0.568275193846552,True
"MAGIC: A Fundamental Framework for Gesture Representation, Comparison and Assessment","Gestures play a fundamental role in instructional processes between agents. However, effectively transferring this non-verbal information becomes complex when the agents are not physically co-located. Recently, remote collaboration systems that transfer gestural information have been developed. Nonetheless, these systems relegate gestures to an illustrative role: only a representation of the gesture is transmitted. We argue that further comparisons between the gestures can provide information of how well the tasks are being understood and performed. While gesture comparison frameworks exist, they only rely on gesture’s appearance, leaving semantics and pragmatical aspects aside. This work introduces the Multi-Agent Gestural Instructions Comparer (MAGIC), an architecture that represents and compares gestures at the morphological, semantical and pragmatical levels. MAGIC abstracts gestures via a three-stage pipeline based on a taxonomy classification, a dynamic semantics framework and a constituency parsing; and utilizes a comparison scheme based on subtrees intersections to describe gesture similarity. This work shows the feasibility of the framework by assessing MAGIC’s gesture matching accuracy against other gesture comparison frameworks during a mentor-mentee remote collaborative physical task scenario.",2.0,0.7047317624092102,True,0.6224593312018546,0.6635955468055323,True
"Multimodal(Audio, Facial and Gesture) based Emotion Recognition challenge","The emotion recognition in the wild has been a hot research topic in the field of a affective computing. Though some progresses have been achieved, the emotion recognition in the wild is still an unsolved problem due to the challenge of head movement, face deformation, illumination variation etc. To deal with these unconstrained challenges, we expand the focus to several expression forms to facilitate research on emotion recognition in the wild. The state-of-the-art CNN based object recognition models are employed to facilitate the facial expression recognition performance such as FAN[1],TSM[2]. The best experimental result shows that the overall accuracy of our algorithm on the validation dataset of the challenge is 76.43%.",0.8,0.8600711822509766,True,0.3318122278318339,0.5959417050414052,True
Driver Glance Classification In-the-wild: Towards Generalization Across Domains and Subjects,"Distracted drivers are dangerous drivers. Equipping advanced driver assistance systems (ADAS) with the ability to detect driver distraction can help prevent accidents and improve driver safety. In order to detect driver distraction, an ADAS must be able to monitor their visual attention. We propose a model that takes as input a patch of the driver's face along with a crop of the eye-region and classifies their glance into 6 coarse regions-of-interest (ROIs) in the vehicle. We demonstrate that an hourglass network, trained with an additional reconstruction loss, allows the model to learn stronger contextual feature representations than a traditional encoder-only classification module. To make the system robust to subject-specific variations in appearance and behavior, we design a personalized hourglass model tuned with an auxiliary input representing the driver's baseline glance behavior. Finally, we present a weakly supervised multi-domain training regimen that enables the hourglass to jointly learn representations from different domains (varying in camera type, angle), utilizing unlabeled samples and thereby reducing annotation cost.",1.0,0.7727543115615845,True,0.3775406687981454,0.575147490179865,True
Fully End-to-End Composite Recurrent Convolution Network for Deformable Facial Tracking In The Wild,"Human facial tracking is an important task in computer vision, which has recently lost pace compared to other facial analysis tasks. The majority of current available tracker possess two major limitations: their little use of temporal information and the widespread use of handcrafted features, without taking full advantage of the large annotated datasets that have recently become available. In this paper we present a fully end-to-end facial tracking model based on current state of the art deep model architectures that can be effectively trained from the available annotated facial landmark datasets. We build our model from the recently introduced general object tracker Re3, which allows modeling the short and long temporal dependency between frames by means of its internal Long Short Term Memory (LSTM) layers. Facial tracking experiments on the challenging 300-VW dataset show that our model can produce state of the art accuracy and far lower failure rates than competing approaches. We specifically compare the performance of our approach modified to work in tracking-by-detection mode and showed that, as such, it can produce results that are comparable to state of the art trackers. However, upon activation of our tracking mechanism, the results improve significantly, confirming the advantage of taking into account temporal dependencies.",1.0,0.7753227353096008,True,0.3775406687981454,0.5764317020538732,True
Facial Expression Recognition for In-the-wild Videos,"In this paper, we propose a method for facial expression recognition for in-the-wild videos. Our method combines Deep Residual Network (ResNet) and Bidirectional Recurrent Neutral Network with Long-Short-Term Memory Unit (BLSTM). This method won the 2nd place in the seven basic expression classification track of Affective Behavior Analysis in-the-wild Competition held in conjunction with the IEEE International Conference on Automatic Face and Gesture Recognition (FG) 2020, achieving 66.9% accuracy and 40.8% final metric on the test set. We also visualize the learned attention maps and analyze the importance of different regions in facial expression recognition.",1.0,0.8408755660057068,True,0.3775406687981454,0.6092081174019262,True
Context-Aware Person Re-Identification in the Wild Via Fusion of Gait and Anthropometric Features,"In this work, we present a context-aware ensemble fusion framework based on soft-biometric features, for long term person re-identification (Re-ID) in wild surveillance scenarios. The characteristics of a person that best correlate to its identity depend strongly on the view point. For instance, a person with a short stride gait is better perceived from a lateral view, whereas a person with a large chest is more distinct from a frontal view. Thus we associate context to the viewing direction of walking people in a surveillance scenario and choose the best features for each case. Using the MS KinectTM sensor v.2, we collect data from walking subjects and extract associated anthropometric and gait features. Each context is analysed with a Feature selection technique (Sequential Forward Selection) so that only the most relevant features for the context are retained. Then, individual context-specific classifiers are trained leveraging those selected features. Finally, we propose a contextaware ensemble fusion strategy, which we term as 'Contextspecific score-level fusion', based on the adaptive weighted sum of the results of individual classifiers. The proposed contextaware Re-ID framework demonstrate significant performance improvement both in terms of speed (up to 4.5 times faster) and accuracy (up to 17% rank-1 Re-ID rate) compared to the Context-unaware systems. From the study, we show that gait features are better for lateral views and anthropometric features are better for frontal views, confirming the results of previous studies.",1.0,0.8097085952758789,True,0.3775406687981454,0.5936246320370122,True
Solving the Families In the Wild Kinship Verification Challenge by Program Synthesis,"Kinship verification is the task of determining whether a parent-child, sibling, or grandparent-grandchild relationship exists between two people and is important in social media applications, forensic investigations, finding missing children, and reuniting families. We demonstrate high quality kinship verification by participating in the 2021 Recognizing Families in the Wild challenge which provides the largest publicly available dataset in the field. Our approach is among the top 3 winning entries in the competition. We ensemble models written by both human experts and a foundation model, OpenAI Codex, trained on text and code. We use Codex to generate model variants, and also demonstrate its ability to generate entire running programs for kinship verification tasks of specific relationships.",1.0,0.8771845698356628,True,0.3775406687981454,0.6273626193169042,True
Boosting-POOF: Boosting Part Based One vs One Feature for Facial Expression Recognition in the Wild,"Recent years, facial expression recognition has remained a challenging and interesting problem, especially for faces in the real world. Most of the traditional approaches are based on Action Units (AUs) detection or low-level features (e.g. LBP, HOG, SIFT and Gabor). Thus, when recognizing real-world facial expressions, these methods might result in poor performance. In this paper, we propose an automatic framework called ‘Boosting-POOF’ to extract discriminative Mid-Level features using low-level features extracted from local face regions. Rather than cascade local features altogether, we adopt class-pairwise Mid-Level descriptors for each local region to extract Mid-Level features and Adaboost feature selection to choose more discriminative features. In experiments, four facial expression benchmarks (CK+, SFEW, RAF-BASIC, RAFCOMPOUND) are evaluated. The ‘Boosting-POOF’ achieves state-of-the-art performance compared with recent approaches. What’ more, the ‘Boosting-POOF’ can automatically provide the most significant difference between two expression categories, which is more useful than AUs detection for real world images.",1.0,0.9639534950256348,True,0.3775406687981454,0.6707470819118901,True
Linear and Non-Linear Multimodal Fusion for Continuous Affect Estimation In-the-Wild,"Automatic continuous affect recognition from multiple modality in the wild is arguably one of the most challenging research areas in affective computing. In addressing this regression problem, the advantages of the each modality, such as audio, video and text, have been frequently explored but in an isolated way. Little attention has been paid so far to quantify the relationship within these modalities. Motivated to leverage the individual advantages of each modality, this study investigates behavioral modeling of continuous affect estimation, in multimodal fusion approaches, using Linear Regression, Exponent Weighted Decision Fusion and Multi-Gene Genetic Programming. The capabilities of each fusion approach are illustrated by applying it to the formulation of affect estimation generated from multiple modality using classical Support Vector Regression. The proposed fusion methods were applied in the public Sentiment Analysis in the Wild (SEWA) multimodal dataset and the experimental results indicate that employing proper fusion can deliver a significant performance improvement for all affect estimation. The results further show that the proposed systems is competitive or outperform the other state-of-the-art approaches.",1.0,0.8604754209518433,True,0.3775406687981454,0.6190080448749944,True
Two-Stream Aural-Visual Affect Analysis in the Wild,"Human affect recognition is an essential part of natural human-computer interaction. However, current methods are still in their infancy, especially for in-the-wild data. In this work, we introduce our submission to the Affective Behavior Analysis in-the-wild (ABAW) 2020 competition. We propose a two-stream aural-visual analysis model to recognize affective behavior from videos. Audio and image streams are first processed separately and fed into a convolutional neural network. Instead of applying recurrent architectures for temporal analysis we only use temporal convolutions. Furthermore, the model is given access to additional features extracted during face-alignment. At training time, we exploit correlations between different emotion representations to improve performance. Our model achieves promising results on the challenging Aff-Wild2 database.The code is publicly available1.1https://github.com/kuhnkeF/ABAW2020TNT",1.0,0.8010795712471008,True,0.3775406687981454,0.5893101200226232,True
Enhancing Interior and Exterior Deep Facial Features for Face Detection in the Wild,"Although face detection has been intensely studied for decades, it is still a challenging topic due to numerous conditions, e.g. heavy occlusions, low resolutions, extreme poses, non-face patterns that look like human faces, etc. This paper proposes a novel region-based ConvNet to address these issues. Our approach enhances the interior deep facial features and explicitly incorporates the exterior deep features. The enhanced interior features provide fine details for small faces. The exterior features capture the local information surrounding the face, supporting the detection under challenging conditions. Experiments show that our proposed components improve the baseline method significantly. Additionally, our approach consistently achieves competitive performance in four challenging databases, i.e. Wider Face, AFW, PASCAL Faces, and FDDB. We also introduce a new challenging non-face dataset 1 of 6,000 images to benchmark false positive rates for future research.",1.0,0.7816399335861206,True,0.3775406687981454,0.5795903011921331,True
Using Deep 3D Features and an LSTM Based Sequence Model for Automatic Pain Detection in the Wild,"Automatic pain detection is an important problem in diagnostic and therapeutic applications. In this paper, we aim to develop a computational framework to automatically detect pain in videos in the wild. The videos in the wild vary with respect to gender, age, ethnicity and even other qualitative attributes like upbringing. Previous systems focused on methodologies confined to one particular dataset that is hard to generalize for the population in the wild, or based on invasive methods that collect data using many physiological sensors and induced stressors. We propose a method to automatically detect pain in videos using state-of-the-art expression recognition system along with deep learning. We curated a dataset of 194 videos in the wild with pain and non-pain. We used a sliding window strategy to obtain a fixed-length input sample for the LSTM (Long Short Term Memory) network. We then carefully concatenate the network output of every segment to generate a video-level output. The proposed end-to-end framework can predict binary classification label (pain/non-pain) at video level. Our method achieves promising results on the dataset we collected.",1.0,0.7623785138130188,True,0.3775406687981454,0.5699595913055822,True
Facial Expression Recognition Using Deep Siamese Neural Networks with a Supervised Loss function,"This paper presents a novel algorithm for an end-to-end facial expression recognition(FER) system based on deep Siamese neural networks equipped with a supervised loss function. Our method learns a powerful FER system by dynamically modulating verification signal over identification/classification signal. The identification signal increases the inter-class variations by maximizing the distance between the features for different classes, while the verification signal reduces the intra-class variations by minimizing the distance between features for the same class. We have evaluated our method on the AffectNet dataset [10] and achieved promising results compared to other deep learning models.",1.0,0.7783106565475464,True,0.3775406687981454,0.577925662672846,True
Smile Detection in the Wild Based on Transfer Learning,"Smile detection from unconstrained facial images is a specialized and challenging problem. As one of the most informative expressions, smiles convey basic underlying emotions, such as happiness and satisfaction, and leads to multiple applications, such as human behavior analysis and interactive controlling. Compared to the size of databases for face recognition, far less labeled data is available for training smile detection systems. This paper proposes an efficient transfer learning-based smile detection approach to leverage the large amount of labeled data from face recognition datasets and to alleviate overfitting on smile detection. A well-trained deep face recognition model is explored and fine-tuned for smile detection in the wild, unlike previous works which use either hand-engineered features or train deep convolutional networks from scratch. Three different models are built as a result of fine-tuning the face recognition model with different inputs, including aligned, unaligned and grayscale images generated from the GENKI-4K dataset. Experiments show that the proposed approach achieves improved state-of-the-art performance. Robustness of the model to noise and blur artifacts is also evaluated in this paper.",1.0,0.9165281653404236,True,0.3775406687981454,0.6470344170692846,True
Hierarchical Group-level Emotion Recognition in the Wild,"We propose a method for group-level emotion recognition in the wild. The main novelty of our method lies with the recognition of group-level emotions using a hierarchical classification approach. We consider that using the facial expressions of people will only be effective in differentiating images labeled as ""Positive"" because those labeled as ""Neutral"" or ""Negative"" are likely to include similar facial expressions (i.e., less discriminative). Therefore, we first perform binary classification based on facial expression recognition to distinguish ""Positive"" labels that include discriminative facial expressions (e.g., smile) from the others. We evaluate outcomes that are not classified as ""Positive"" at the first classification by exploiting scene features that describe what type of events (e.g., demonstration or funeral) are taking place in the image. Classification using scene features will not only be effective in differentiating ""Negative"" and ""Neutral"" labels but also in recognizing ""Positive"" labels, where facial expression features show less discriminative characteristics. The other novelty of the proposed method is to the exploitation of visual attention. Using visual attention allows us to estimate which faces are the main subjects in the target image, thereby suppressing the influences of faces in the background that contribute less to group-level emotion. We demonstrate the effectiveness of our proposed method through experiments using a public dataset.",1.0,0.8012908101081848,True,0.3775406687981454,0.5894157394531652,True
LRW-1000: A Naturally-Distributed Large-Scale Benchmark for Lip Reading in the Wild,"Large-scale datasets have successively proven their fundamental importance in several research fields, especially for early progress in some emerging topics. In this paper, we focus on the problem of visual speech recognition, also known as lip-reading, which has received increasing interest in recent years. We present a naturally-distributed large-scale benchmark for lip-reading in the wild, named LRW-1000, which contains 1,000 classes with 718,018 samples from more than 2,000 individual speakers. Each class corresponds to the syllables of a Mandarin word composed of one or several Chinese characters. To the best of our knowledge, it is currently the largest word-level lipreading dataset and also the only public large-scale Mandarin lip-reading dataset. This dataset aims at covering a ""natural"" variability over different speech modes and imaging conditions to incorporate challenges encountered in practical applications. It has shown a large variation in this benchmark in several aspects, including the number of samples in each class, video resolution, lighting conditions, and speakers’ attributes such as pose, age, gender, and make-up. Besides providing a detailed description of the dataset and its collection pipeline, we evaluate several typical popular lip-reading methods and perform a thorough analysis of the results from several aspects. The results demonstrate the consistency and challenges of our dataset, which may open up some new promising directions for future work.",1.0,0.8296842575073242,True,0.3775406687981454,0.6036124631527349,True
The Many Faces of Anger: A Multicultural Video Dataset of Negative Emotions in the Wild (MFA-Wild),"The portrayal of negative emotions such as anger can vary widely between cultures and contexts, depending on the acceptability of expressing full-blown emotions rather than suppression to maintain harmony. The majority of emotional datasets collect data under the broad label “anger”, but social signals can range from annoyed, contemptuous, angry, furious, hateful, and more. In this work, we curated the first in-the-wild multicultural video dataset of emotions, and deeply explored anger-related emotional expressions by asking culture-fluent annotators to label the videos with 6 labels and 13 emojis in a multi-label framework. We provide a baseline multi-label classifier on our dataset, and show how emojis can be effectively used as a language-agnostic tool for annotation.",1.8,0.8707354068756104,True,0.574442516811659,0.7225889618436347,True
Monitoring Patients in the Wild,"This demo will show an abridged version of aresearch prototype for remotely monitoring the physiologicalstatus of patients in the wild. In the demo, we will show real timemeasurement of pulse and breathing rates of multiple subjectsin an uncontrolled setting. The applications of this system arewide, a typical example being the monitoring of patients in thewaiting room of a hospital’s emergency department",1.0,0.7614547610282898,True,0.3775406687981454,0.5694977149132177,True
Quantificational Subordination as Anaphora to a Function,", a semantics for cross-sentential and donkey anaphora is presented that is inspired by approaches using dependent types but couched in simple type theory with parametric polymorphism. In this paper, the approach is extended to cover quantificational subordination. It is argued that the approach enjoys advantages over existing accounts in type-theoretical semantics.",1.0,0.73684161901474,True,0.3775406687981454,0.5571911439064428,True
Tree-gated Deep Regressor Ensemble For Face Alignment In The Wild,"Face alignment consists in aligning a shape model on a face in an image. It is an active domain in computer vision as it is a preprocessing for applications like facial expression recognition, face recognition and tracking, face animation, etc. Current state-of-the-art methods already perform well on ""easy"" datasets, i.e. those that present moderate variations in head pose, expression, illumination or partial occlusions, but may not be robust to ""in-the-wild"" data. In this paper, we address this problem by using an ensemble of deep regressors instead of a single large regressor. Furthermore, instead of averaging the ouputs of each regressor, we propose an adaptative weighting scheme that uses a tree-structured gate. Experiments on several challenging face datasets demonstrate that our approach outperforms the state-of-the-art methods.",1.0,0.8123480677604675,True,0.3775406687981454,0.5949443682793065,True
Real-time Facial Expression Recognition “In The Wild” by Disentangling 3D Expression from Identity,"Human emotions analysis has been the focus of many studies, especially in the field of Affective Computing, and is important for many applications, e.g. human-computer intelligent interaction, stress analysis, interactive games, animations, etc. Solutions for automatic emotion analysis have also benefited from the development of deep learning approaches and the availability of vast amount of visual facial data on the internet. This paper proposes a novel method for human emotion recognition from a single RGB image. We construct a largescale dataset of facial videos (FaceVid), rich in facial dynamics, identities, expressions, appearance and 3D pose variations. We use this dataset to train a deep Convolutional Neural Network for estimating expression parameters of a 3D Morphable Model and combine it with an effective back-end emotion classifier. Our proposed framework runs at 50 frames per second and is capable of robustly estimating parameters of 3D expression variation and accurately recognizing facial expressions from in the-wild images. We present extensive experimental evaluation that shows that the proposed method outperforms the compared techniques in estimating the 3D expression parameters and achieves state-of-the-art performance in recognising the basic emotions from facial images, as well as recognising stress from facial videos.",1.0,0.9337460994720459,True,0.3775406687981454,0.6556433841350957,True
Beyond MAGIC: Matching Collaborative Gestures using an optimization-based Approach,"Gestures are a key aspect of communication during collaboration: through gestures we can express ideas, inquires and formalize instructions as we collaborate. Nevertheless, gesture analysis is not currently used to assess quality of task collaboration. One possible reason for this is that there is no consensus on how to represent and compare gestures from the semantic standpoint. To address this, this paper introduces three novel approaches to compare gestures performed by individuals as they collaborate to complete a physical task. Our approach relies on solving three variations of an integer optimization assignment problem, i.e. based on gesture similarity, based on temporal synchrony, and based on a combination of both. We collected the gestures of 40 participants (divided into 20 pairs) as they performed two collaborative tasks, and generated a human baseline that compared and matched their gestures. Afterwards, our gesture comparison approach was evaluated against other gestures comparison approaches based on how well they replicated the human baseline. Our approach outperformed the other approaches, agreeing with the human baseline over 85% of the times. Thus, the obtained results support the proposed technique for gesture comparison. This in turn can lead to the development of better methods to evaluate collaborative physical tasks.",1.0,0.9094918966293335,True,0.3775406687981454,0.6435162827137395,True
Recognizing Families In the Wild (RFIW): The 4th Edition,"Recognizing Families In the Wild (RFIW)– an annual large-scale, multi-track automatic kinship recognition evaluation– supports various visual kin-based problems on scales much higher than ever before. Organized in conjunction with the as a Challenge, RFIW provides a platform for publishing original work and the gathering of experts for a discussion of the next steps. This paper summarizes the supported tasks (i.e., kinship verification, tri-subject verification, and search & retrieval of missing children) in the evaluation protocols, which include the practical motivation, technical background, data splits, metrics, and benchmark results. Furthermore, top submissions (i.e., leader-board stats) are listed and reviewed as a high-level analysis on the state of the problem. In the end, the purpose of this paper is to describe the 2020 RFIW challenge, end-to-end, along with forecasts in promising future directions.",1.8,0.7451572418212891,True,0.574442516811659,0.6597998793164741,True
Leveraging Semantic Scene Characteristics and Multi-Stream Convolutional Architectures in a Contextual Approach for Video-Based Visual Emotion Recognition in the Wild,"In this work we tackle the task of video-based visual emotion recognition in the wild. Standard methodologies that rely solely on the extraction of bodily and facial features often fall short of accurate emotion prediction in cases where the aforementioned sources of affective information are inaccessible due to head/body orientation, low resolution and poor illumination. We aspire to alleviate this problem by leveraging visual context in the form of scene characteristics and attributes, as part of a broader emotion recognition framework. Temporal Segment Networks (TSN) constitute the backbone of our proposed model. Apart from the RGB input modality, we make use of dense Optical Flow, following an intuitive multi-stream approach for a more effective encoding of motion. Furthermore, we shift our attention towards skeleton-based learning and leverage action-centric data as means of pretraining a Spatial-Temporal Graph Convolutional Network (ST-GCN) for the task of emotion recognition. Our extensive experiments on the challenging Body Language Dataset (BoLD) verify the superiority of our methods over existing approaches, while by properly incorporating all of the aforementioned modules in a network ensemble, we manage to surpass the previous best published recognition scores, by a large margin.",1.0,0.8205721974372864,True,0.3775406687981454,0.599056433117716,True
Multifaceted Engagement in Social Interaction with a Machine: The JOKER Project,"This paper addresses the problem of evaluating engagement of the human participant by combining verbal and nonverbal behaviour along with contextual information. This study will be carried out through four different corpora. Four different systems designed to explore essential and complementary aspects of the JOKER system in terms of paralinguistic/linguistic inputs were used for the data collection. An annotation scheme dedicated to the labeling of verbal and non-verbal behavior have been designed. From our experiment, engagement in HRI should be multifaceted.",1.0,0.9879618883132935,True,0.3775406687981454,0.6827512785557195,True
Unleash the Black Magic in Age: A Multi-Task Deep Neural Network Approach for Cross-Age Face Verification,"Facial aging is a complicated process which usually affects the facial appearance (e.g., wrinkles). Variations of facial appearance pose a big challenge to the automatic face recognition problem. How to eliminate the influence of aging factors to the verification performance is a very challenging problem. Multi-task learning has provided a principled framework for jointly learning multiple related tasks to improve generalization performance. In this paper, we leverage this powerful technique to improve the task of cross-age face verification. We present an end-to-end learning framework for cross-age face verification by designing a multi-task deep neural network architecture that exploits the intrinsic low-dimensional representation shared between the tasks of face verification and age estimation. We show that the algorithm effectively balances feature sharing and feature exclusion between the two given tasks. We evaluate the proposed framework on two standard benchmarks. Experimental results demonstrate that our algorithm has significant improvement over the state-of-theart (2.2% EER on MORPH and 7.8% EER on FG-NET, by more than 50.0% and 59.70% performance gain respectively).",1.0,0.9754436016082764,True,0.3775406687981454,0.6764921352032109,True
The 5th Recognizing Families in the Wild Data Challenge: Predicting Kinship from Faces,"Recognizing Families In the Wild (RFIW), held as a data challenge in conjunction with the 16th IEEE International Conference on Automatic Face and Gesture Recognition (FG), is a large-scale, multi-track visual kinship recognition evaluation. For the fifth edition of RFIW, we continue to attract scholars, bring together professionals, publish new work, and discuss prospects. In this paper, we summarize submissions for the three tasks of this year's RFIW: specifically, we review the results for kinship verification, tri-subject verification, and family member search and retrieval. We look at the RFIW problem, share current efforts, and make recommendations for promising future directions.",1.0,0.7552037835121155,True,0.3775406687981454,0.5663722261551305,True
Synthesising 3D Facial Motion from “In-the-Wild” Speech,"Synthesising 3D facial motion from speech is a crucial problem manifesting in a multitude of applications such as computer games and movies. Recently proposed methods tackle this problem in controlled conditions of speech. In this paper, we introduce the first methodology for 3D facial motion synthesis from speech captured in arbitrary recording conditions (“in-the-wild”) and independent of the speaker. For our purposes, we captured 4D sequences of people uttering 500 words, contained in the Lip Reading in the Wild (LRW) words, a publicly available large-scale in-the-wild dataset, and built a set of 3D blendshapes appropriate for speech. We correlate the 3D shape parameters of the speech blendshapes to the LRW audio samples by means of a novel time-warping technique, named Deep Canonical Attentional Warping (DCAW), that can simultaneously learn hierarchical non-linear representations and a warping path in an end-to-end manner. We thoroughly evaluate our proposed methods, and show the ability of a deep learning model to synthesise 3D facial motion in handling different speakers and continuous speech signals in uncontrolled conditions1.",1.0,0.8383068442344666,True,0.3775406687981454,0.607923756516306,True
Exploiting Data Redundancy for Error Detection in Degraded Biometric Signatures Resulting From in the Wild Environments,"An error-correcting code (ECC) is a process of adding redundant data to a message, such that it can be recovered by a receiver even if a number of errors are introduced in transmission. Inspired by the principles of ECC, we introduce a method capable of detecting degraded features in biometric signatures by exploiting feature correlation. The main novelty is that, unlike existing biometric cryptosystems, the proposed method works directly on the biometric signature. Our approach performs a redundancy analysis of non-degraded data to build an undirected graphical model (Markov Random Field), whose energy minimization determines the sequence of degraded components of the biometric sample. Experiments carried out in different biometric traits ascertain the improvements attained when disregarding degraded features during the matching phase. Also, we stress that the proposed method is general enough to work in different classification methods, such as CNNs.",1.0,0.7948195934295654,True,0.3775406687981454,0.5861801311138555,True
The MAGIC of E-Health: A Gesture-Based Approach to Estimate Understanding and Performance in Remote Ultrasound Tasks,"This work presents an approach to estimate task understanding and performance during a remote ultrasound training task via gestures. These task understanding insights are obtained through the PIA metric, a score that represents how well are gestures being used to complete a shared task. To evaluate our hypothesis, 20 participants performed a remote ultrasound training task consisting of three subtasks: vessel detection, blood extraction, and foreign body detection. Afterwards, their task understanding and performance was estimated using our PIA metric and three other metrics: error rate, idle time rate, and task completion percentage. After performing a correlation analysis, we found significant correlations between the PIA metric and all the other metrics for task understanding estimation. In addition, the insights generated from our PIA score explained inconsistencies in the participants’ scores that were not expressed using the other metrics. Finally, we used two post-experiment questionnaires to subjectively evaluate the participants’ perceived understanding and performance, and found that the PIA score was significantly correlated with the participants’ overall task understanding. All these results indicate that a gesture-based metric can be used to estimate task understanding, which can have a positive impact in the way remote ultrasound tasks are performed and assessed.",1.0,0.9081412553787231,True,0.3775406687981454,0.6428409620884343,True
Valence and Arousal Estimation In-The-Wild with Tensor Methods,"While it is relatively easy and natural for humans to detect and interpret non-verbal cues, it is a hard task for computer systems. Automatic recognition of emotions has been the subject of extensive studies in the past decade, but despite the various methods that have been implemented, the problem remains challenging. In particular, most existing works focus on predicting a set discrete stereotypical emotion categories. We are instead interested in predicting continuous values of valence and arousal, which are able to model accurately a broader range of spontaneous emotions. Moreover, as opposed to much of the prior work that focused on controlled (laboratory) conditions, we are interested in analysis in naturalist (in-the-wild) conditions. To do so, we propose to leverage the structure in the data using tensor methods. In addition to preserving the structure, these have the potential to also reduce the total number of parameters in the models, thus improving the computational performance. We first consider a model with analytic solution in the form of a Tucker Tensor Regression. We then investigate a deep, gradient based method, namely Tensor Regression Networks. We perform thorough experiments on two publicly available databases, AFEW-VA and SEWA, for facial affect estimation in-the-wild, in terms of valence and arousal levels. Experimental results demonstrate that tensor-based methods successfully leverage the structure in the data and on average outperform baseline methods.",1.0,0.8063017725944519,True,0.3775406687981454,0.5919212206962987,True
Affective Expression Analysis in-the-wild using Multi-Task Temporal Statistical Deep Learning Model,"Affective behavior analysis plays an important role in human-computer interaction, customer marketing, health monitoring. ABAW Challenge and Aff-Wild2 dataset raise the new challenge for classifying basic emotions and regression valence-arousal value under in-the-wild environments. In this paper, we present an affective expression analysis model that deals with the above challenges. Our approach includes STAT and Temporal Module for fine-tuning again face feature model. We experimented on Aff-Wild2 dataset, a large-scale dataset for ABAW Challenge with the annotations for both the categorical and valence-arousal emotion. We achieved the expression score 0.543 and valence-arousal score 0.534 on the validation set.",1.0,0.7667483687400818,True,0.3775406687981454,0.5721445187691137,True
M3F: Multi-Modal Continuous Valence-Arousal Estimation in the Wild,"In this paper, we propose a multi-modal multi-feature (M$^{3}F$) approach for in-the-wild valence-arousal estimation. In the proposed M$^{3}F$ framework, we fuse both visual features from videos and acoustic features from the audio tracks to estimate the valence and arousal. We follow a CNN-RNN paradigm, where the spatio-temporal visual features are extracted with a 3D convolutional network and/or a pretrained 2D convolutional network, and a bidirectional recurrent neural network. We evaluated the M$^{3}F$ framework on the validation set provided by the Affective Behavior Analysis in-the-wild (ABAW) Challenge, held in conjunction with the IEEE International Conference on Automatic Face and Gesture Recognition (FG) 2020, and it significantly outperforms the baseline method.",1.0,0.7966436147689819,True,0.3775406687981454,0.5870921417835637,True
Multi-modal Expression Recognition in the Wild Using Sequence Modeling,"As we exceed upon the procedures for modelling the different aspects of behaviour, expression recognition has become a key field of research in Human Computer Interactions. Expression recognition in the wild is a very interesting problem and is challenging as it involves detailed feature extraction and heavy computation. This paper presents the methodologies and techniques used in our contribution to recognize different expressions i.e., neutral, anger, disgust, fear, happiness, sadness, surprise in ABAW competition on Aff-Wild2 database. Aff-Wild2 database consists of videos in the wild labelled for seven different expressions at frame level. We used a bi-modal approach by fusing audio and visual features and train a sequence-to-sequence model that is based on Gated Recurrent Units (GRU) and Long Short Term Memory (LSTM) network. We show experimental results on validation data. The overall accuracy of the proposed approach is 41.5 %, which is better than the competition baseline of 37%.",1.0,0.7477207183837891,True,0.3775406687981454,0.5626306935909673,True
Multi-modal Sequence-to-sequence Model for Continuous Affect Prediction in the Wild Using Deep 3D Features,"Continuous affect prediction in the wild is a very interesting problem and is challenging as continuous prediction involves heavy computation. This paper presents the methodologies and techniques used in our contribution to predict continuous emotion dimensions i.e., valence and arousal in ABAW competition on Aff-Wild2 database. Aff-Wild2 database consists of videos in the wild labelled for valence and arousal at frame level. Our proposed methodology uses fusion of both audio and video features (multi-modal) extracted using state-of-the-art methods. These audio-video features are used to train a sequence-to-sequence model that is based on Gated Recurrent Units (GRU). We show promising results on validation data with simple architecture. The overall valence and arousal of the proposed approach is 0.22 and 0.34, which is better than the competition baseline of 0.14 and 0.24 respectively.",1.0,0.7999255657196045,True,0.3775406687981454,0.588733117258875,True
Sayette Group Formation Task (GFT) Spontaneous Facial Expression Database,"Despite the important role that facial expressionsplay in interpersonal communication and our knowledge thatinterpersonal behavior is influenced by social context, nocurrently available facial expression database includes multipleinteracting participants. The Sayette Group Formation Task(GFT) database addresses the need for well-annotated videoof multiple participants during unscripted interactions. Thedatabase includes 172,800 video frames from 96 participantsin 32 three-person groups. To aid in the development ofautomated facial expression analysis systems, GFT includesexpert annotations of FACS occurrence and intensity, faciallandmark tracking, and baseline results for linear SVM, deeplearning, active patch learning, and personalized classification.Baseline performance is quantified and compared using identicalpartitioning and a variety of metrics (including meansand confidence intervals). The highest performance scores werefound for the deep learning and active patch learning methods.Learn more at http://osf.io/7wcyz.",0.8,0.8755505084991455,True,0.3318122278318339,0.6036813681654897,True
Q-GPU: A Recipe of Optimizations for Quantum Circuit Simulation Using GPUs,"In recent years, quantum computing has undergone significant developments and has established its supremacy in many application domains. While quantum hardware is accessible to the public through the cloud environment, a robust and efficient quantum circuit simulator is necessary to investigate the constraints and foster quantum computing development, such as quantum algorithm development and quantum device architecture exploration. In this paper, we observe that most of the publicly available quantum circuit simulators (e.g., QISKit from IBM, QDK from Microsoft, and Qsim-Cirq from Google) suffer from slow simulation and poor scalability when the number of qubits increases. To this end, we systematically investigate the deficiencies in quantum circuit simulation (QCS) and propose Q-GPU, a framework that leverages GPUs with comprehensive optimizations to allow efficient and scalable QCS. Specifically, Q-GPU features i) proactive state amplitude transfer, ii) zero state amplitude pruning, iii) delayed qubit involvement, and iv) lossless nonzero state amplitude compression. Experimental results across nine representative quantum circuits indicate that Q-GPU significantly reduces the execution time of the state-of-the-art GPU-based QCS by 71.89% (3.55× speedup). Q-GPU also outperforms the state-of-the-art OpenMP CPU implementation, the Google Qsim-Cirq simulator, and the Microsoft QDK simulator by 1.49×, 2.02×, and 10.82×, respectively.",1.0,0.7319953441619873,True,0.3775406687981454,0.5547680064800664,True
The DRAM Latency PUF: Quickly Evaluating Physical Unclonable Functions by Exploiting the Latency-Reliability Tradeoff in Modern Commodity DRAM Devices,"Physically Unclonable Functions (PUFs) are commonly used in cryptography to identify devices based on the uniqueness of their physical microstructures. DRAM-based PUFs have numerous advantages over PUF designs that exploit alternative substrates: DRAM is a major component of many modern systems, and a DRAM-based PUF can generate many unique identiers. However, none of the prior DRAM PUF proposals provide implementations suitable for runtime-accessible PUF evaluation on commodity DRAM devices. Prior DRAM PUFs exhibit unacceptably high latencies, especially at low temperatures (e.g., >125.8s on average for a 64KiB memory segment below 55C), and they cause high system interference by keeping part of DRAM unavailable during PUF evaluation. In this paper, we introduce the DRAM latency PUF, a new class of fast, reliable DRAM PUFs. The key idea is to reduce DRAM read access latency below the reliable datasheet specications using software-only system calls. Doing so results in error patterns that reect the compound eects of manufacturing variations in various DRAM structures (e.g., capacitors, wires, sense ampli- ers). Based on a rigorous experimental characterization of 223 modern LPDDR4 DRAM chips, we demonstrate that these error patterns 1) satisfy runtime-accessible PUF requirements, and 2) are quickly generated (i.e., at 88.2ms) irrespective of operating temperature using a real system with no additional hardware modications. We show that, for a constant DRAM capacity overhead of 64KiB, our implementation of the DRAM latency PUF enables an average (minimum, maximum) PUF evaluation time speedup of 152x (109x, 181x) at 70C and 1426x (868x, 1783x) at 55C when compared to a DRAM retention PUF and achieves greater speedups at even lower temperatures.",1.0,0.7415012121200562,True,0.3775406687981454,0.5595209404591008,True
Amdahl's Law in Big Data Analytics: Alive and Kicking in TPCx-BB (BigBench),"Big data, specifically data analytics, is responsible for driving many of consumers' most common online activities, including shopping, web searches, and interactions on social media. In this paper, we present the first (micro)architectural investigation of a new industry-standard, open source benchmark suite directed at big data analytics applications—TPCx-BB (BigBench). Where previous work has usually studied benchmarks which oversimplify big data analytics, our study of BigBench reveals that there is immense diversity among applications, owing to their varied data types, computational paradigms, and analyses. In our analysis, we also make an important discovery generally restricting processor performance in big data. Contrary to conventional wisdom that big data applications lend themselves naturally to parallelism, we discover that they lack sufficient thread-level parallelism (TLP) to fully utilize all cores. In other words, they are constrained by Amdahl's law. While TLP may be limited by various factors, ultimately we find that single-thread performance is as relevant in scale-out workloads as it is in more classical applications. To this end we present core packing: a software and hardware solution that could provide as much as 20% execution speedup for some big data analytics applications.",0.8,0.8641683459281921,True,0.3318122278318339,0.597990286880013,True
Filesystem Encryption or Direct-Access for NVM Filesystems? Let’s Have Both!,"Emerging Non-Volatile Memories (NVMs) are promising candidates to build ultra-low idle power memory and storage devices in future computing systems. Unlike DRAM, NVMs do not require frequent refresh operations, and they can retain data after crashes and power loss. With such features, NVM memory modules can be used partly as a conventional memory to host memory pages and partly as file storage to host filesystems and persistent data. Most importantly, and unlike current storage technologies, NVMs can be directly attached to the memory bus and accessed through conventional load/store operations.As NVMs feature ultra-low access latency, it is necessary to minimize software overheads for accessing files to enable the full potential. In legacy storage devices, e.g., Flash and Harddisk drives, access latency dominates the software overheads. However, emerging NVMs’ performance can be burdened by the software overheads since memory access latency is minimal. Modern Operating Systems (OSes) allow direct-access (DAX) for NVM-hosted files through direct load/store operations by eliminating intermediate software layers. Unfortunately, we observe that such a direction ignores filesystem encryption and renders most of the current filesystem encryption implementations inapplicable to future NVM systems. In this paper, we propose a novel hardware/software co-design architecture that enables transparent filesystem encryption without sacrificing the direct-access feature of files in emerging NVMs with minimal change in OS and memory controller. Our proposed model incurs a negligible overall slowdown of 3.8% for workloads representative of real-world applications, while software-based encryption can incur as high as 5x slowdown for some applications.",0.8,0.8772090077400208,True,0.3318122278318339,0.6045106177859273,True
Do You Follow?: A Fully Automated System for Adaptive Robot Presenters,"An interesting application for social robots is to act as a presenter, for example as a museum guide. In this paper, we present a fully automated system architecture for building adaptive presentations for embodied agents. The presentation is generated from a knowledge graph, which is also used to track the grounding state of information, based on multimodal feedback from the user. We introduce a novel way to use large-scale language models (GPT-3 in our case) to lexicalise arbitrary knowledge graph triples, greatly simplifying the design of this aspect of the system. We also present an evaluation where 43 participants interacted with the system. The results show that users prefer the adaptive system and consider it more human-like and flexible than a static version of the same system, but only partial results are seen in their learning of the facts presented by the robot.",1.1,0.7473447918891907,True,0.401312339887548,0.5743285658883693,True
"Virtual, Augmented, and Mixed Reality for Human-Robot Interaction (VAM-HRI)","The 3rd International Workshop on Virtual, Augmented, and Mixed Reality for Human-Robot Interactions (VAM-HRI) will bring together HRI, Robotics, and Mixed Reality researchers to address challenges in mixed reality interactions between humans and robots. Topics relevant to the workshop include development of robots that can interact with humans in mixed reality, use of virtual reality for developing interactive robots, the design of augmented reality interfaces that mediate communication between humans and robots, comparisons of the capabilities and perceptions of robots and virtual agents, and best design practices. VAM-HRI 2020 will follow on the success of VAM-HRI 2018 and 2019, and advance the cause of this nascent research community",0.8,0.7953218817710876,True,0.3318122278318339,0.5635670548014607,True
I Need Your Help... or Do I?: Maintaining Situation Awareness through Performative Autonomy,"Interactive intelligent systems are increasingly being deployed in safety critical contexts like Space Exploration. For humans to safely and successfully complete collaborative tasks with robots in these contexts, they must maintain Situational Awareness of their task context without being cognitively overloaded -- regardless of whether they are co-located with robots or interacting with them from a distance of thousands or millions of miles. In this paper, we present a novel autonomy design strategy we term Performative Autonomy, in which robots behave as if they have a lower level of autonomy than they are truly capable of (i.e., asking for advice they do not believe they truly need), for the sole purpose of maintaining interactants' Situational Awareness. In our first experiment (n=264), we begin by demonstrating that Performative Autonomy can increase Situational Awareness (SA) without overly increasing workload, and that this is true across tasks with different baseline levels of Mental Workload. In our second experiment (n=318), we consider cases where robots do not believe they need advice, but in fact have faulty perception or decision making capabilities. In this experiment, we only observed benefits to Performative Autonomy for specific types of questions, and only when there was significant cognitive load imposed by a secondary task; yet we observed uniform benefit on task performance for asking these types of questions regardless of task-imposed Mental workload. Our results from these two studies (total n=582) thus provide strong support for using this autonomy design strategy in future safety-critical missions as humanity explores the Moon, Mars, and beyond.",1.1,0.7642809152603149,True,0.401312339887548,0.5827966275739315,True
Rebellion and Disobedience in Human-Robot Interaction (RaD-HRI),,0.8,0.9174763560295105,True,0.3318122278318339,0.6246442919306722,True
My Humorous Robot: Effects of a Robot Telling Jokes on Perceived Intelligence and Liking,"Research suggests, interpersonal competences such as having a sense of humor can help establish sociality in human-robot interaction. This study tested the effect of different types of jokes told by either a human or a robot (NAO) on the perceived intelligence and liking of the narrator. Results of a mixed-design ANOVA showed that only clever jokes could increase the attribution of intelligence to a robot. No significant differences were found for different types of jokes on liking the robot.",1.0,0.9940898418426514,True,0.3775406687981454,0.6858152553203984,True
How Did We Miss This?: A Case Study on Unintended Biases in Robot Social Behavior,"With societies growing more and more conscious of human social biases that are implicit in most of our interactions, the development of automated robot social behavior is failing to address these issues as more than just an afterthought. In the present work, we describe how we unintentionally implemented robot listener behavior that was biased toward the gender of the participants, while following typical design procedures in the field. In a post-hoc analysis of data collected in a between-subject user study (n=60), we find that both a rule-based and a deep learning-based listener behavior models produced a higher number of backchannels (listener feedback, through nodding or vocal utterances) if the participant identified as a male. We investigate the cause of this bias in both models and discuss the implications of our findings. Further, we provide approaches that may be taken to address the issue of algorithmic fairness, and preventative measures to avoid the development of biased social robot behavior.",1.1,0.868916928768158,True,0.401312339887548,0.635114634327853,True
Softy's Magic Touch: Altering Old Toys into Interactive Friends!,,1.5,0.9778222441673279,True,0.5,0.7389111220836639,True
A Social Robot for Explaining Medical Tests and Procedures: An Exploratory Study in the Wild,"Healthcare professionals often have little time to explain medical tests and procedures. Social robots capable of verbal dialogues may contribute to informing patients and the public in general about such tests and procedures, for example in general practitioner or hospital waiting rooms, nursery homes, as well as in public spaces. As an example of latter, an exploratory study was conducted at the Lowlands music festival in August 2022. A social robot explained a blood pressure measurement and a grip strength measurement to participants. Participants were asked to value the expected clarity of the explanation before the explanation, the experienced clarity after the robot explanation but before the actual physical measurements, and after the physical measurements. 172 participants completed the interaction (99 female, 57 male, 8 non-binary, 8 undisclosed). The mean interaction duration was 2.02 minutes (SD=0.40 minutes). Participants found the explanation after the interaction with Pepper clearer than they expected beforehand. Participants found the clarity of the explanation, after they had actually undergone the physical examination, even higher than before the physical examination. This study indicates that social robots are potentially useful to explain medical tests and procedures.",1.0,0.9459188580513,True,0.3775406687981454,0.6617297634247228,True
Designing an Engaging & Affable Robot (DEAR),"1. DEAR Goals Recent advances in robotics technology offer many new opportunities to innovate how children learn. These opportunities can be actualized and substantiated only through rigorous, pedagogically guided designs of collaborative tasks and interactions with the robot. Acknowledging the constant need for learning a second language worldwide, this project explored how we could make best use of the unique affordances of an embodied robot in order to support young children’s language learning experiences while interacting with the robot. Our design goal was to create child/robot interactions that were engaging, developmentally appropriate, and thereby sustaining. We used a mobile phone-based robot that helped achieve the goals at an affordable range. In this demonstration, we will present our designs, which were grounded in well-known theories on child development and second language acquisition, and how the robot’s advanced features supported producing engaging and creative solutions.",1.6,0.8014592528343201,True,0.52497918747894,0.66321922015663,True
Robocamp at Home: Exploring Families' Co-Learning with a Social Robot: Findings from a One-Month Study in the Wild,"Social robots are becoming important agents in several sectors of people's lives. They can act in different contexts, e.g., public spaces, schools, and homes. Operating, programming and interacting with these robots will be an essential skill in the future. We present a qualitative and explorative study on how family members collaboratively learn (co-learn) about social robots at their homes. Our one-month in the wild study took place at homes of eight families (N=32) in Finland. We defined a novel model for co-learning about and with a social robot at home, Robocamp. In Robocamp, Alpha Mini robot was introduced and left within the families, who were then provided with weekly robotic challenges to be conducted with the robot. The research data was collected by semi-structured interviews and online diaries. This study provides novel insights about family-based co-learning with social robots in the home context. It also offers recommendations for implementing family-based co-learning with social robots at homes.",1.0,0.7514347434043884,True,0.3775406687981454,0.564487706101267,True
Out for In!: Empirical Study on the Combination Power of Two Service Robots for Product Recommendation,"Service robots have increasingly been investigated in retailing. Previous studies mainly focused on the effectiveness of recommendation with regard to a single robot, and whether and how the use of two robots combined can achieve better performance remain unclear. In this study, we address this by exploring the combination power of two service robots for product recommendation in a bakery. We placed one robot inside the store for product recommendation and the other robot outside to promote the inside robot. Particularly, we are interested in the effects of the outside robot on the inside robot's performance in product recommendation. Our results indicate that using the outside robot to promote the inside robot achieved more purchases over using the inside robot alone. Particularly, we discovered that the outside robot increased the attention of customers toward the inside robot; hence, more customers checked and purchased the products. Based on the findings, we discuss the important points for the effective use of service robots.",1.3,0.8750022649765015,True,0.45016600268752216,0.6625841338320118,True
A Persuasive Hand Sanitizer Robot in the Wild: The Effect of Persuasive Speech on the Use of a Hand Sanitizer Robot,"In this paper, we report on field tests of a hand sanitizer robot, which tracks people's movements using gaze and which uses several different persuasive utterances when people are approaching. Our results show that adding speech made people significantly more aware of the opportunity of using hand sanitizer, but that people do not use the hand sanitizer more often than with eye gaze only. Furthermore, the different utterances themselves did not lead to significant differences in attention or use, in spite of their effectiveness in other situations.",1.0,0.8305630683898926,True,0.3775406687981454,0.604051868594019,True
The Unexpected Daily Situations (UDS) Dataset: A New Benchmark for Socially-Aware Assistive Robots,"This article presents the progress in building a new dataset of 'unexpected daily situations' (like someone tripping on a box, while carrying a tray to the kitchen, or someone burning him/herself with hot water and dropping a mug). Each of the situations involve one or two humans in a familiar, structured environment (eg, a kitchen, a living room) with rich semantics. Correctly interpreting the situation (including recognising an error, undesired effect or incongruity when it occurs, as well as selecting the best repair action) requires beyond-state-of-art spatio-temporal, semantic and socio-cognitive modelling. As such, the aim of the dataset is to offer (i) a realistic source of data to train and test such novel algorithms and (ii) provide a new benchmark against which algorithms can be demonstrated.",0.8,0.7734201550483704,True,0.3318122278318339,0.5526161914401021,True
Emotion-Behavior Interplay in Human Animal-Robot Interaction (HARI),,0.8,0.776040256023407,True,0.3318122278318339,0.5539262419276204,True
Lessons From a Robot Asking for Directions In-the-wild,"Robots operating in human spaces need to be able to communicate with people. Understanding how humans and robots communicate about the shared space around them allows us to build robots that can interact fluidly with others. We performed a field study with a telepresence robot and a perceived autonomous robot to explore how humans give directions to robots and how the interactions differ based on the perceived identity of the robot operator. In this work we present some initial findings from our in-the-wild study including: 1) participants were more considerate to the robot in the telepresence condition, 2) participants considered the sensing and physical limitations of the robot when giving directions, and 3) participants were uncertain about the realness or identity of the robot and the robot operator.",1.0,0.7662585973739624,True,0.3775406687981454,0.571899633086054,True
Human-Robot Conversational Interaction (HRCI),"Conversation is one of the primary methods of interaction between humans and robots. It provides a natural way of communication with the robot, thereby reducing the obstacles that can be faced through other interfaces (e.g., text or touch) that may cause difficulties to certain populations, such as the elderly or those with disabilities, promoting inclusivity in Human-Robot Interaction (HRI). Work in HRI has contributed significantly to the design, understanding and evaluation of human-robot conversational interactions. Concurrently, the Conversational User Interfaces (CUI) community has developed with similar aims, though with a wider focus on conversational interactions across a range of devices and platforms. This workshop aims to bring together the CUI and HRI communities through a one-day workshop to outline key shared opportunities and challenges in developing conversational interactions with robots, resulting in collaborative publications targeted at the CUI 2023 provocations track.",0.8,0.7879146933555603,True,0.3318122278318339,0.5598634605936971,True
Comparing a Robotic Storyteller versus Audio Book with Integration of Sound Effects and Background Music,"Regardless of newly developed forms of narration, listening to stories remains a popular leisure activity. However, storytelling is also evolving. With social robots taking on activities initially conducted by humans, they are emerging as a new storytelling medium. Robots are able to extend human storytelling by adding sounds to the narrative to enhance recipients' emotional reaction to and transportation into the story. To this end, we conducted an online study to compare the traditional audio book to a robotic storyteller, focusing on the influence of adding sound effects and music in both storytelling approaches. Results show that neither emotion induction nor transportation was significantly affected by storytelling medium or additional sounds, but descriptive values indicate a trend towards higher emotion induction and transportation when adding sound to robotic storytelling relative to the audio book condition without additional sounds. Live replications based on this preliminary study might reveal less ambiguous findings.",1.0,0.8879850506782532,True,0.3775406687981454,0.6327628597381993,True
Do You Have Pain?: A Robot who Cares,"Patient Reported Outcome Measures (PROMs) are a means of collecting information on the effectiveness of care delivered to patients as perceived by the patients themselves. A patient's pain level is a typical parameter only a patient him/herself can describe. It is an important measure for a person?s quality of life. When a patient stays in a Dutch hospital, nursing staff needs to ask a patient for its pain level at least three times a day. Due to their work pressure, this requirement is regularly not met. A social robot available as a bed side companion for a patient during his hospital stay, might be able to ask the patient's pain level regularly. The video shows that this innovation in PROM data acquisition is feasible in older persons.",1.1,0.7971805930137634,True,0.401312339887548,0.5992464664506557,True
The Uncanny Valley Effect in Zoomorphic Robots: The U-Shaped Relation Between Animal Likeness and Likeability,"The uncanny valley effect denotes a dip in the positive relation between a robot’s human likeness and likeability. This paper provides first evidence that this design-guiding effect is not limited to humanoids, but extends to zoomorphic robots. In a first online survey, a diverse group of 235 participants rated the animal likeness of 140 robots. Three predictors for high or low animal likeness emerged: surface properties, such as joint visibility; facial properties, such as presence of a pupil; animal-specific properties, such as presence of snout. In a second online survey, 187 participants rated the likeability of 53 robots of varying degrees of animal likeness drawn from the first study. The relation between animal likeness and likeability followed a U-shaped function and showed an uncanny valley effect: robots high and low in animal likeness were preferred over those mixing realistic and unrealistic features. Besides theoretical implications tentative guidelines for the design of zoomorphic robots are discussed. Acm Reference Format: Diana Löffler, Judith Dörrenbächer and Marc Hassenzahl. 2020. The Uncanny Valley Effect in Zoomorphic Robots: The U-Shaped Relation between Animal Likeness and Likeability. In Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction (HRI’20), March 23–26, 2020, Cambridge, UK. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3319502.3374788",1.0,0.8217582702636719,True,0.3775406687981454,0.5996494695309087,True
What is Human-like?: Decomposing Robots’ Human-like Appearance Using the Anthropomorphic roBOT (ABOT) Database,"Anthropomorphic robots, or robots with human-like appearance features such as eyes, hands, or faces, have drawn considerable attention in recent years. To date, what makes a robot appear human-like has been driven by designers’ and researchers’ intuitions, because a systematic understanding of the range, variety, and relationships among constituent features of anthropomorphic robots is lacking. To fill this gap, we introduce the ABOT (Anthropomorphic roBOT) Database—a collection of 200 images of real-world robots with one or more human-like appearance features (http://www.abotdatabase.info). Harnessing this database, Study 1 uncovered four distinct appearance dimensions (i.e., bundles of features) that characterize a wide spectrum of anthropomorphic robots and Study 2 identified the dimensions and specific features that were most predictive of robots’ perceived human-likeness. With data from both studies, we then created an online estimation tool to help researchers predict how human-like a new robot will be perceived given the presence of various appearance features. The present research sheds new light on what makes a robot look human, and makes publicly accessible a powerful new tool for future research on robots’ human-likeness.",1.9,0.6795462369918823,True,0.598687660112452,0.6391169485521672,True
Are You Not Entertained? Computational Storytelling with Non-Verbal Interaction,"We describe the design and implementation of a multi-modal storytelling system. Multiple robots narrate and act out an AI-generated story whose plots can be dynamically altered via non-verbal audience feedback. The enactment and interaction focuses on gestures and facial expression, which are embedded in a computational framework that draws on cognitive-linguistic insights to enrich the storytelling experience. With the absence of in-person user studies in this late breaking research, we present the validity of the separate modules of this project and introduce it to the HRI field.",1.3,0.8681526184082031,True,0.45016600268752216,0.6591593105478626,True
"Virtual, Augmented, and Mixed Reality for HRI (VAM-HRI)","The 5th International Workshop on Virtual, Augmented, and Mixed Reality for Human-Robot Interaction (VAM-HRI) will bring together HRI, robotics, and mixed reality researchers to address challenges in mixed reality interactions between humans and robots. Topics relevant to the workshop include development of robots that can interact with humans in mixed reality, use of virtual reality for developing interactive robots, the design of augmented reality interfaces that mediate communication between humans and robots, social applications for virtual and mixed reality in HRI, the investigations of mixed reality interfaces for robot learning, comparisons of the capabilities and perceptions of robots and virtual agents, and best design practices. Special topics of interest this year include VAM-HRI research during the ongoing COVID-19 pandemic as well as the ethical implications of VAM-HRI research. VAM-HRI 2022 will follow on the success of VAM-HRI 2018–21 and advance the cause of this nascent research community. Website: https://vam-hri.github.io",0.8,0.817688524723053,True,0.3318122278318339,0.5747503762774434,True
Where is My Phone?: Towards Developing an Episodic Memory Model for Companion Robots to Track Users' Salient Objects,"Persons with Dementia face the issue of a deteriorating memory. As assistive robots are being increasingly adapted as a helper to persons with dementia, this paper presents an additional feature to such robots. Assistive robots that might assist with different tasks in users' households can also be utilized to track salient objects to quickly find them in case they are misplaced. This paper presents an episodic memory system that can enable a robot to recognize salient objects and track them while moving in and out of the environment. We also demonstrate how to develop access to the robot's memory in an easy-to-understand way using a graphical user interface (GUI). The proposed system is integrated with a Fetch mobile manipulator robot to track, store and visualize various household objects in an environment. Results from a system evaluation study are encouraging and the system will be further investigated in future co-design and user studies.",1.1,0.7403135895729065,True,0.401312339887548,0.5708129647302272,True
Robotic Mental Well-being Coaches for the Workplace: An In-the-Wild Study on Form,"The World Health Organization recommends that employers take action to protect and promote mental well-being at work. However, the extent to which these recommended practices can be implemented in the workplace is limited by the lack of resources and personnel availability. Robots have been shown to have great potential for promoting mental well-being, and the gradual adoption of such assistive technology may allow employers to overcome the aforementioned resource barriers. This paper presents the first study that investigates the deployment and use of two different forms of robotic well-being coaches in the workplace in collaboration with a tech company whose employees (26 coachees) interacted with either a QTrobot (QT ) or a Misty robot (M). We endowed the robots with a coaching personality to deliver positive psychology exercises over four weeks (one exercise per week). Our results show that the robot form significantly impacts coachees' perceptions of the robotic coach in the workplace. Coachees perceived the robotic coach in M more positively than in QT (both in terms of behaviour appropriateness and perceived personality), and they felt more connection with the robotic coach in M. Our study provides valuable insights for robotic well-being coach design and deployment, and contributes to the vision of taking robotic coaches into the real world.",1.0,0.9093427062034607,True,0.3775406687981454,0.6434416875008031,True
Who's in Charge?: Using Personalization vs. Customization Distinction to Inform HRI Research on Adaptation to Users,"This paper presents a conceptual approach regarding robot-to-user adaptation, with a focus on the psychological effects of this adaptation process during human-robot interaction (HRI). This approach emphasizes the pertinent role of users in shaping adaptation processes. First, a literature review revealed perceived personal relevance as the central determinant of successful robot-to-user adaptation. Second, we distinguish two main types of adaptations which depend on the extent to which a user is involved: Personalization and customization. We then illustrate effects of personalization vs. customization on potential end users. In particular, anthropomorphism and psychological ownership should be taken into account in prospective research. Finally, we propose to interpret personalization and customization as two opposites of a continuum to guide future empirical research about robot adaptation, before suggesting some leads for future research about the psychological effects of adaptation processes in HRI.",1.1,0.9228904247283936,True,0.401312339887548,0.6621013823079708,True
Effects of Colored LEDs in Robotic Storytelling on Storytelling Experience and Robot Perception,"Social robots can use biomimetic modalities such as gestures to convey emotions. The use of colored light for emotion expression is also possible, but rarely explored. In this paper, colored LEDs are used in addition to contextual gestures to communicate emotions in robotic storytelling. Results show that adding colored light to the storytelling did not improve the recipients' transportation into the story. Their cognitive absorption was significantly decreased. The users' perception of the NAO robot was not influenced by colored lights except for animacy which was higher using only white LEDs. Problems might have been mismatches between colors and emotions, the lack of emotional gestures, and the too small light emission from NAO's eye LEDs. Since smart rooms lighting can affect the users' whole visual field, they could enhance emotional effects. Thus, future studies should investigate the integration of a robotic storyteller in smart rooms allowing for smart light control.",1.0,0.8113602995872498,True,0.3775406687981454,0.5944504841926976,True
What Does It Mean to Anthropomorphize Robots?: Food For Thought for HRI Research,"Anthropomorphism is a well-used but vague concept that demands further understanding and clarification to be effectively used in HRI research. Although most HRI research defines and uses anthropomorphism as a human-like attribution process, there is lack of distinction between its deployment in design versus its manifestation in user response. Furthermore, researchers need to separate mindless from mindful anthropomorphism and find ways to theorize and measure each. Researchers also need to consider the dynamic and contextual nature of anthropomorphism to generate relevant findings for research as well as practice.",1.1,0.80843585729599,True,0.401312339887548,0.604874098591769,True
Magic iCub: A Humanoid Robot Autonomously Catching Your Lies in a Card Game,"Games are often used to foster human partners’ engagement and natural behavior, even when they are played with or against robots. Therefore, beyond their entertainment value, games represent ideal interaction paradigms where to investigate natural human-robot interaction and to foster robots’ diffusion in the society. However, most of the state-of-the-art games involving robots, are driven with a Wizard of Oz approach. To address this limitation, we present an end-to-end (E2E) architecture to enable the iCub robotic platform to autonomously lead an entertaining magic card trick with human partners. We demonstrate that with this architecture a robot is capable of autonomously directing the game from beginning to end. In particular, the robot could detect in real-time when the players lied in the description of one card in their hands (the secret card). In a validation experiment the robot achieved an accuracy of 88.2% (against a chance level of 16.6%) in detecting the secret card while the social interaction naturally unfolded. The results demonstrate the feasibility of our approach and its effectiveness in entertaining the players and maintaining their engagement. Additionally, we provide evidence on the possibility to detect important measures of the human partner’s inner state such as cognitive load related to lie creation with pupillometry in a short and ecological game-like interaction with a robot. CCS CONCEPTS • Human-centered Computing~Interaction design process and methods",1.0,0.9595149159431458,True,0.3775406687981454,0.6685277923706456,True
Wizard-of-Oz vs. GPT-4: A Comparative Study of Perceived Social Intelligence in HRI Brainstorming,,1.0,0.9441298246383667,True,0.3775406687981454,0.6608352467182561,True
First Things First: A Survey Exploring Key Services and Functions of a Robot,"In order to find out the home robot's services and functions that should be developed with priority, we created three scenarios for the robot services including cleaning, laundry, and cooking with detailed functions for each service. We investigated the effect of service types on service evaluation. Robot's laundry service was evaluated as the greatest positive compared to cleaning and cooking service. Furthermore, we explored which robot attributes or task attributes affected robot service evaluation and purchase intention for each function. By service types, different attributes of the robot and the task affected service evaluation and purchase intention.",1.0,0.7351576089859009,True,0.3775406687981454,0.5563491388920232,True
"Out of Sight, Out of Mind?: Investigating People's Assumptions About Object Permanence in Self-Driving Cars","Safe and efficient interaction with autonomous road vehicles requires that human road users, including drivers, cyclists, and pedestrians, understand differences between the capabilities and limitations of self-driving vehicles and those of human drivers. In this study, we explore how people judge the ability of self-driving cars versus human drivers to keep track of out-of-sight objects by engaging online study participants in cognitive perspective taking toward a car in an animated traffic scene. The results indicate that people may expect self-driving cars to have similar object permanence capability as human drivers. This finding is important because unmet expectations on autonomous road vehicles can result in undesirable interaction outcomes, such as traffic accidents.",1.1,0.8227570652961731,True,0.401312339887548,0.6120347025918605,True
"""Off Script:"" Design Opportunities Emerging from Long-Term Social Robot Interactions In-the-Wild","Social robots are becoming increasingly prevalent in the real world. Unsupervised user interactions in a natural and familiar setting, such as the home, can reveal novel design insights and opportunities. This paper presents an analysis and key design insights from family-robot interactions, captured via on-robot recordings during an unsupervised four-week in-home deployment of an autonomous reading companion robot for children. We analyzed interviews and 160 interaction videos involving six families who regularly interacted with a robot for four weeks. Throughout these interactions, we observed how the robot's expressions facilitated unique interactions with the child, as well as how family members interacted with the robot. In conclusion, we discuss five design opportunities derived from our analysis of natural interactions in the wild.",1.0,0.9404271841049194,True,0.3775406687981454,0.6589839264515325,True
Health-e-Eater: Dinnertime Companion Robot and Magic Plate for Improving Eating Habits in Children from Low-Income Families,"Obesity causes physical and mental health problems (e.g., high blood pressure, diabetes, and depression). Currently, 1 in 3 American children are overweight or obese, and the prevalence of this issue is increasing. Disproportionately affected are children from low-income families. As unhealthy eating habits are the primary driver of this epidemic, we designed Health-e-Eater - a system for encouraging children aged 2-5 from low-income families to eat healthy food, leading to better nutritional intake and the development of healthy eating habits. Health-e-Eater is a low-cost system consisting of a magic plate and a robotic companion, which motivates and educates during dinnertime.",1.0,0.7851109504699707,True,0.3775406687981454,0.5813258096340581,True
Inclusive'R'Stories: An Inclusive Storytelling Activity with an Emotional Robot,"Storytelling has the potential to be an inclusive and collaborative activity. However, it is unclear how interactive storytelling systems can support such activities, particularly when considering mixed-visual ability children. In this paper, we present an interactive multisensory storytelling system and explore the extent to which an emotional robot can be used to support inclusive experiences. We investigate the effect of the robot's emotional behavior on the joint storytelling process, resulting narratives, and collaboration dynamics. Results show that when children co-create stories with a robot that exhibits emotional behaviors, they include more emotive elements in their stories and explicitly accept more ideas from their peers. We contribute with a multisensory environment that enables children with visual impairments to engage in joint storytelling activities with their peers and analyze the effect of a robot's emotional behaviors on an inclusive storytelling experience.",1.0,0.8551076054573059,True,0.3775406687981454,0.6163241371277257,True
"Virtual, Augmented, and Mixed Reality for Human-Robot Interaction (VAM-HRI)","The 2 nd International Workshop on Virtual, Augmented, and Mixed Reality for Human-Robot Interactions (VAM-HRI) will bring together HRI, Robotics, and Mixed Reality researchers to identify challenges in mixed reality interactions between humans and robots. Topics relevant to the workshop include development of robots that can interact with humans in mixed reality, use of virtual reality for developing interactive robots, the design of new augmented reality interfaces that mediate communication between humans and robots, comparisons of the capabilities and perceptions of robots and virtual agents, and best design practices. VAM-HRI was held for the first time at HRI 2018, where it served as the first workshop of its kind at an academic AI or Robotics conference, and served as a timely call to arms to the academic community in response to the growing promise of this emerging field. VAM-HRI 2019 will follow on the success of VAM-HRI 2018, and present new opportunities for expanding this nascent research community. Website http://vam-hri.xyz/",0.8,0.7953218817710876,True,0.3318122278318339,0.5635670548014607,True
Dog Sit! Domestic Dogs (Canis familiaris) Follow a Robot's Sit Commands,"As personal social robots become more prevalent, the need for the designs of these systems to explicitly consider pets become more apparent. However, it is not known whether dogs would interact with a social robot. In two experiments, we investigate whether dogs respond to a social robot after the robot called their names, and whether dogs follow the 'sit' commands given by the robot. We conducted a between-subjects study (n = 34) to compare dogs' reactions to a social robot with a loudspeaker. Results indicate that dogs gazed at the robot more often after the robot called their names than after the loudspeaker called their names. Dogs followed the 'sit' commands more often given by the robot than given by the loudspeaker. The contribution of this study is that it is the first study to provide preliminary evidence that 1) dogs showed positive behaviors to social robots and that 2) social robots could influence dog's behaviors. This study enhance the understanding of the nature of the social interactions between humans and social robots from the evolutionary approach. Possible explanations for the observed behavior might point toward dogs perceiving robots as agents, the embodiment of the robot creating pressure for socialized responses, or the multimodal (i.e., verbal and visual) cues provided by the robot being more attractive than our control condition.",1.3,0.7790811061859131,True,0.45016600268752216,0.6146235544367176,True
HRI 2018 Workshop: Social Robots in the Wild,"Commercially available social robots are finally here. Previously accessible only to companies or wealthy individuals, affordable, mass-produced autonomous robot companions are poised to take the global market by storm in 2018. It is an exciting time for social roboticists, as some of the theories and techniques developed and tested for years under controlled conditions are finally released to the general public. However, the social robots available to the public differ significantly from those currently used in labs and field studies due to commercial requirements such as affordability, reliability, and ability to function despite environmental variability. This workshop focuses on the state of social robots in the market today---the lessons learned from mass-producing and distributing actual products, and the cutting-edge research that could be brought to bear on the many issues faced. Through presentations, panels, and hands-on interactions, participants from both academia and industry give each other feedback on what is working and what is not, and set goals for the near future.",1.0,0.8131906390190125,True,0.3775406687981454,0.595365653908579,True
Carrot or Stick: The Effect of Reward and Punishment in Robot Assisted Language Learning,"Feedback plays an important role in language learning. However, limited research can be found on the influence of feedback in robot-assisted language learning. Therefore, this study aims to identify the effects of robot-feedback on learning gain, motivation, and anthropomorphism. In total, 60 students participated in a language learning task, with a robot using one of three feedback conditions: reward, punishment, and no feedback. The results showed that feedback only affected learning gain: students learned more with punishment, followed by reward, compared to no feedback. Thus, our results underscore the importance of feedback in RALL.",1.0,0.9722347259521484,True,0.3775406687981454,0.674887697375147,True
The Effect of Gender on Perceived Anthropomorphism and Intentional Acceptance of a Storytelling Robot,"Gender and anthropomorphism play a substantial role in how social robots are perceived. In child-robot interaction, children's perception of the robot can be influenced by individual factors, such as the robot's gender. The purpose of this study is to examine how gender congruity affects the way children perceive social storytelling robots. Furthermore, the relationships among gender congruity, anthropomorphism, and intentional acceptance were investigated. Sixty-four children interacted with a storytelling robot. The results indicated that children did not humanize the robot to a higher degree if the robot's gender matched with the children's gender. Moreover, children who anthropomorphised the robot to a higher degree found the robot more sociable and had higher intentions of using the robot repeatedly. The findings of this studies contrast with previous scientific work, and indicate more research should be conducted to find out which factors play a vital role in the humanization and gendering of robots.",1.0,0.9026633501052856,True,0.3775406687981454,0.6401020094517156,True
Hey?: ! What did you think about that Robot? Groups Polarize Users' Acceptance and Trust of Food Delivery Robots,"As food delivery robots are spreading onto streets and college campuses worldwide, users' views of these robots will depend on their direct and indirect interactions with the robots and their conversations with other people, such as those with whom they are ordering food via a robot. We examined if being in a group of 2 to 3 people affects the acceptance and trust of the robot compared to being an individual user. First-time users of the food delivery robot service (N = 60) ordered food either as an Individual or in a Group. We measured the acceptance and trust of the robots after three Exposures (pre-exposure, after ordering food on the app, and after the robots delivered the food). Results indicated that Individual users had more acceptance and trust compared to Group users. Further, as hypothesized, groups had more variation in acceptance and trust compared to individual users, consistent with patterns of group polarization i.e., group members influencing each other's perceptions to become more positive or negative. Further analysis demonstrated that group members were highly influenced by their groupmates. Designers and restaurant operators should consider how to enhance group members' experience of delivery robots.",1.6,0.9449211955070496,True,0.52497918747894,0.7349501914929948,True
A Wizard of Oz Approach to Robotic Therapy for Older Adults With Depressive Symptoms,"Older adults with late-life depression often suffer from cognitive symptoms, such as dementia. This patient group is not prioritised for psychotherapy and therefore often medicated with antidepressants. However, in the last 20-years, the evidence base for psychotherapy has increased and one promising area is technology-based psychotherapy. Investigations of the possibilities in this area are also motivated by the Covid-19 pandemic, where many older adults are isolated, which makes it impossible for them to meet with a therapist. Therefore, we have developed a Wizard of Oz system allowing a human therapist to control a humanoid robot through a graphical user interface, including natural speech for natural conversations, which enables the robot to be stationed in, for example, a care home. For future research, we will conduct user-centered studies with both therapists and older adults to further develop the system.",1.0,0.9868087768554688,True,0.3775406687981454,0.6821747228268071,True
"The Purr-suit of Happiness: A Tale of Three Kittens. Robots, Humans, Cats, and AI",,0.8,0.9692298769950867,True,0.3318122278318339,0.6505210524134603,True
A Prototype of a Robot Memory Game: Exploring the Technical Limitations of Human-Robot Interaction in a Playful Context,"We explored the feasibility and limitations of designing and developing a Robot-Human interactive board game known as memory, a turn-based game of matching card pairs. Our analysis of this case study suggests significant limitations and further interactive improvements before exposing the prototype to the users. In terms of technical limitations, the variability of light and the lack of sharp camera imaging makes it challenging to identify cards uniquely. Open MANIPULATOR-X's (robotic arm used) dexterity is limited and could not mimic the interaction of card flipping. For interactive design terms, we analysed the robot morphology, expressiveness and modifications in the cards. We suggest running comparative studies with well-known humanoid robots and humans. This project is the initial step to developing more engaging and interactive games between Humans and Robots. Future experiments aim to explore the emotional, physical and mental benefit users could obtain from playing games with robots.",1.0,0.9946824908256531,True,0.3775406687981454,0.6861115798118993,True
“Is this all you can do? Harder!”: The Effects of (Im)Polite Robot Encouragement on Exercise Effort,"Most social robot behaviors in human-robot interaction are designed to be polite, but there is little research about how or when a robot could be impolite, and if that may ever be beneficial. We explore the potential benefits and tradeoffs of different politeness levels for human-robot interaction in an exercise context. We designed impolite and polite phrases for a robot exercise trainer and conducted a 24-person experiment where people squat in front of the robot as it uses (im)polite phrases to encourage them. We found participants exercised harder and felt competitive with the impolite robot, while the polite robot was found to be friendly, but sometimes uncompelling and disingenuous. Our work provides evidence that human-robot interaction should continue to aim for more nuanced and complex models of communication.",1.6,0.9852275848388672,True,0.52497918747894,0.7551033861589036,True
Hacking the Human Bias in Robotics,"Many of us, roboticists and those who collaborate with them, experience delight, excitement, and sometimes deep-seated, but rarely unvoiced, fears as we witness our robotic systems begin to impact human lives in countless ways. From automating driving to reshaping various facets of health care delivery, robotic systems are growing in their prevalence and intrusiveness into our daily lives. In combination with our siblings in the Artificial Intelligence (AI) community, scholars continue to predict a wide range of benefits from robotics and AI systems but also serious harms, including potential existential threats to humanity. Recognized pillars of science and engineering, including Elon Musk and the late great Stephen Hawking, have given voice to the apocalyptic kinds of fears that the public may have about an increasingly automated future. Whether these fears should be taken seriously is an issue that has divided scholars for awhile now, as illustrated by debates between Bill Joy [7] and Ray Kurzweil [8] at the beginning of the 21st century. On a different scale of granularity, a category of harms that users and others are more likely to experience on a day-to-day basis is from the various types of bias encoded in, or learned by, AI systems. This category of harms is especially troublesome in the world of physical robotics. Nonembodied AI systems can obviously make decisions that have effects on human beings, such as a chatbot determining what to say in response to a customer’s question on a company’s helpline. Yet it will need to rely on an embodied entity (often a human) to have a direct impact on the physical world. Typically, a nonembodied AI agent provides input to humans who may then execute a physical action – whether those humans are making an employment decision to hire or fire or deciding on a health care intervention for a patient. By definition, it lacks the capability of acting on the world without assistance. Robots that have a physical form, on the other hand, can perform actions on their own. This can raise the ethical stakes in terms of the potential benefits and harms that may result from the technology. The benefits and harms that we are particularly concerned about here are related to bias.",1.0,0.7316278219223022,True,0.3775406687981454,0.5545842453602239,True
Does the Appearance of an Agent Affect How We Perceive his/her Voice?: Audio-visual Predictive Processes in Human-robot Interaction,"Robots increasingly become part of our lives. How we perceive and predict their behavior has been an important issue in HRI. To address this issue, we adapted a well-established prediction paradigm from cognitive science for HRI. Participants listened a greeting phrase that sounds either human-like or robotic. They indicated whether the voice belongs to a human or a robot as fast as possible with a key press. Each voice was preceded with a human or robot image (a human-like robot or a mechanical robot) to cue the participant about the upcoming voice. The image was either congruent or incongruent with the sound stimulus. Our findings show that people reacted faster to robotic sounds in congruent trials than incongruent trials, suggesting the role of predictive processes in robot perception. In sum, our study provides insights about how robots should be designed, and suggests that designing robots that do not violate our expectations may result in a more efficient interaction between humans and robots.",1.1,0.7974900007247925,True,0.401312339887548,0.5994011703061702,True
Symbiotic Society with Avatars (SSA): Beyond Space and Time,"Avatar robots can help people extend their physical, cognitive, and perceptual capabilities, allowing people to exceed time and space constraints. In that sense, avatar robots can greatly influence people's lives. However, we have many challenges to be addressed in various scenarios such as avatar-human interaction, operator-avatar interaction, avatar-avatar interaction, ethical and legal issues, technical challenges, and so on. It is indispensable to discuss what the necessary research and technologies are to realize avatars that are well accepted in society while envisioning a future symbiotic society in which people communicate with other people and their avatars. In our previous workshop ""Symbiotic Society with Avatars: Social Acceptance, Ethics, and Technologies (SSA)"" we focused on the ethical aspect of avatars. In this workshop, our aim is to provide an opportunity for researchers from different backgrounds including social robotics, teleoperation, and mixed reality to come together and discuss the advances and values in a symbiotic society with avatars.",0.8,0.8750688433647156,True,0.3318122278318339,0.6034405355982747,True
Blossom: A Tensile Social Robot Design with a Handcrafted Shell (Demo Abstract),"We describe the design and implementation of Blossom, a social robot that diverges from convention by being flexible both internally and externally. Internally, Blossom»s actuation mechanism is a compliant tensile structure supporting a free-floating platform. This design enables organic and lifelike movements with a small number of motors and simple software control. Blossom»s exterior is also flexible in that it is made of fabric and not rigidly attached to the mechanism, enabling it to freely shift and deform. The handcrafted nature of the shell allows Blossom to take on a variety of forms and appearances. Blossom is envisioned as an open platform for user-crafted human-robot interaction.",0.8,0.7962048053741455,True,0.3318122278318339,0.5640085166029897,True
Hearing a Nose?: User Expectations of Robot Appearance Induced by Different Robot Voices,"Congruence between the visual appearance of a robot and its behavioral and communicative characteristics has been shown to be a crucial determinant of user acceptance. Given the growing popularity of speech interfaces, a coherent design of a robot's looks and its voice is becoming more important. Which robot voice fits which appearance, however, has hardly been investigated to date. This is where the present research comes in. A randomized lab experiment was conducted, in which 165 participants listened to one of five more or less humanlike robot voices and subsequently drew a sketch corresponding to their imagination of the robot. The sketches were analyzed regarding the presence of various body features. While some features appeared in almost all drawings regardless of the condition (e.g., head, eyes), other features were significantly more prevalent in voice conditions characterized by low human-likeness (wheels) or high human-likeness (e.g., nose). Our results give first hints on which embodiment users might expect from different robotic voices.",1.1,0.7267012596130371,True,0.401312339887548,0.5640067997502926,True
Juno: An Interactive Storytelling Robot for Early Constructive Childhood Intervention,"Early life adversity is a major risk factor for the development of psychological and behavioral problems in adult life. Traumatic experiences in childhood are linked to higher rates of depression, anxiety disorders and a range of mental health issues.[4] Additionally, stories form the basis of understanding in children and help develop empathy and cultivate imaginative and divergent thinking in them. In this paper, we expound on the idea of leveraging the potential of storytelling through an interactive toy i.e. transitional object as a means of intentful intervention to help children understand and cope better with stressors in developmental ages.",1.0,0.8601873517036438,True,0.3775406687981454,0.6188640102508947,True
Would You Help Me?: Linking Robot's Perspective-Taking to Human Prosocial Behavior,"Despite the growing literature on human attitudes toward robots, particularly prosocial behavior, little is known about how robots' perspective-taking, the capacity to perceive and understand the world from other viewpoints, could influence such attitudes and perceptions of the robot. To make robots and AI more autonomous and self-aware, more researchers have focused on developing cognitive skills such as perspective-taking and theory of mind in robots and AI. The present study investigated whether a robot's perspective-taking choices could influence the occurrence and extent of exhibiting prosocial behavior toward the robot. We designed an interaction consisting of a perspective-taking task, where we manipulated how the robot instructs the human to find objects by changing its frame of reference and measured the human's exhibition of prosocial behavior toward the robot. In a between-subject study (N=70), we compared the robot's egocentric and addressee-centric instructions against a control condition, where the robot's instructions were object-centric. Participants' prosocial behavior toward the robot was measured using a voluntary data collection session. Our results imply that the occurrence and extent of prosocial behavior toward the robot were significantly influenced by the robot's visuospatial perspective-taking behavior. Furthermore, we observed, through questionnaire responses, that the robot's choice of perspective-taking could potentially influence the humans' perspective choices, were they to reciprocate the instructions to the robot.",1.1,0.7413758039474487,True,0.401312339887548,0.5713440719174984,True
Human-Interactive Robot Learning (HIRL),"With robots poised to enter our daily environments, we conjecture that they will not only need to work for people, but also learn from them. An active area of investigation in the robotics, machine learning, and human-robot interaction communities is the design of teachable robotic agents that can learn interactively from human input. To refer to these research efforts, we use the umbrella term Human-Interactive Robot Learning (HIRL). While algorithmic solutions for robots learning from people have been investigated in a variety of ways, HIRL, as a fairly new research area, is still lacking: 1) a formal set of definitions to classify related but distinct research problems or solutions, 2) benchmark tasks, interactions, and metrics to evaluate the performance of HIRL algorithms and interactions, and 3) clear long-term research challenges to be addressed by different communities. The main goal of this workshop will be to consolidate relevant recent work falling under the HIRL umbrella into a coherent set of long, medium, and short-term research problems, and identify the most pressing future research goals in this area. As HIRL is a developing research area, this workshop is an opportunity to break the existing boundaries between relevant research communities by developing and sharing a diverse set of benchmark tasks and metrics for HIRL, inspired by other fields including neuroscience, biology, and ethics research.",0.8,0.8342901468276978,True,0.3318122278318339,0.5830511873297658,True
What Could Go Wrong?! 2nd Workshop: Lessons Learned When Doing HRI User Studies with Off-the-Shelf Social Robots,"Nowadays, off-the-shelf social robots are used more frequently by the HRI community to research social interactions with different types of users across a range of domains such as education, retail, health care, public places and other domains. Everyone doing HRI research with end-users is invited to submit a case study to our workshop. We are particularly interested in case studies where things did not go as planned. Case studies describing research in the lab or in the wild are both welcome. Examples of unplanned experiences could include, but are not limited to, unexpected responses from the user, issues with the experimental setup or simply having challenges with transferring theory to the real world. In this workshop, we focus on off-the-shelf robots. In order to generalize and compare differences across multiple HRI domains and create common solutions, we will provide a template for your case study. We are interested in learning how such unexpected HRI results can be reported. In the workshop, we will discuss and study how failures are reported and be inspired to create a list of good ways to report failures, which can hopefully be inspiring for the HRI community.",1.6,0.9481187462806702,True,0.52497918747894,0.7365489668798051,True
Wizard of Awwws: Exploring Psychological Impact on the Researchers in Social HRI Experiments,"In social Human-Robot Interaction (sHRI) people have studied social interactions with awkward, confrontational, or unsettling robots. In order to create these situations, researchers often secretly control the robot (the ""Wizard of Oz"", WoZ, technique), use confederates (researchers pretending to be participants), or the researchers themselves create the desired social condition. While these studies may be antagonistic, they are designed to be ethical; when conducting a study, IRB (Institutional Review Board) processes are in place to assess the study design for potential risk to participants, and to ultimately protect the public. However, these processes do not generally involve assessment of impact on the researchers conducting the study. In our own work, we have noted how researcher ""wizards"" in social HRI experiments, particularly those which place participants in awkward or confrontational situations, can themselves be negatively impacted from the experience when their experiment protocol has them antagonize, deceive, or argue with participants. In this paper, we explore how experimental design can impact the wellbeing of the researchers, particularly for wizards in social HRI experiments. By building a psychological grounding for the impact on people who do socially stressful actions, we evaluate the potential for researcher social stress in recent sHRI studies. Our summary and discussion of this survey results in recommendations for future HRI research to reduce the burden on wizards in their own experiments.",1.0,0.9829292297363281,True,0.3775406687981454,0.6802349492672368,True
"Coffee, Tea, Robots?: The Performative Staging of Service Robots in 'Robot Cafes' in Japan","We present an ethnographic observational study of six robot cafes in Japan to understand how service robots are performatively staged and presented to the public. We particularly attend to the diverse ways in which the physical setting and ambience of the cafes, the verbal characterization of and staff behaviors toward robots, explicit and implicit instructions on appropriate interactions with robots, and handling of robot malfunctions constitute robots as socially acceptable and useful in daily life. Such scaffolding enables robots to provide material and affective services to cafe visitors, and visitors to explore various interaction possibilities with robots. Our work contributes to the critical study of the ongoing construction of ""robot cultures"" in Japan, and calls attention to public interactions with robots and the importance of contextual staging beyond individual robot features in human-robot interaction design.",1.1,0.8518649935722351,True,0.401312339887548,0.6265886667298916,True
Get This!? Mixed Reality Improves Robot Communication Regardless of Mental Workload,"We present the first experiment analyzing the effectiveness of robot-generated mixed reality gestures using real robotic and mixed reality hardware. Our findings demonstrate how these gestures increase user effectiveness by decreasing user response time during visual search tasks, and show that robots can safely pair longer, more natural referring expressions with mixed reality gestures without worrying about cognitively overloading their interlocutors.",1.6,0.9520268440246582,True,0.52497918747894,0.7385030157517991,True
Do Robots Distract us as much as Humans?: The Effect ofHuman-like Appearance and Perceptual Load,"Attention is an important mechanism for solving certain tasks, but our environment can distract us via irrelevant information. As robots increasingly become part of our lives, one important question is whether they could distract us as much as humans do, and if so to what extent. To address this question, we conducted a study in which subjects were engaged in a central letter detection task. The task irrelevant distractors were pictures of three agents; a mechanical robot, a human-like robot, and a real human. We also manipulated the perceptual load to investigate whether the demands of the task influence how much these agents distract us. Our results show that robots distract people as much as humans, as demonstrated by significant increase in reaction times and decrease in task accuracy in the presence of agent distractors as compared to the situation when there was no distractor. However, we found that the task difficulty interacted with the human-likeness of the distractor agent. When the task was less demanding, the agent that distracted most was the most human-like agent, whereas when the task was more demanding, the least human-like agent distracted the most. These results not only provide insights about how to design humanoid robots but also sets as a great example of a fruitful collaboration between human-robot interaction and cognitive sciences.",1.1,0.7121342420578003,True,0.401312339887548,0.5567232909726741,True
Demonstration of a Robo- Barista for In the Wild Interactions,"We present a demonstration of a Robo-Barista: a social robot that takes hot beverage orders through verbal interaction and completes them via a Bluetooth enabled coffee machine. The demonstration is highly robust and it is the intention that this could be installed as a permanent feature, enabling “In the Wild” experimentation and long term studies. In the demonstration video, we show a user interacting with a Furhat robot to order a coffee. The robot has a novel architecture that allows it to exhibit both verbal and non-verbal cues, such as shared attention and chitchat. Furthermore, it is enabled with a unique tiredness detector based on visual facial features.",1.0,0.9454157948493958,True,0.3775406687981454,0.6614782318237706,True
You’re Wigging Me Out! Is Personalization of Telepresence Robots Strictly Positive?,"With their ability to embody users in physically distant spaces, telepresence robots have gained popularity in environments including hospitals, schools, and offices. However, with platforms lacking in individuation and social presence, users often personalize telepresence robots with clothing and accessories to increase their recognizability and sense of embodiment. Toward understanding personahzation preferences, as well as perceptions of personalized platforms, we conducted a series of five studies that investigate patterns in personalization of a telepresence robot and evaluate the impacts of common personalizations along five dimensions (robot uniqueness, humanness, pleasantness/unpleasantness, and people’s willingness to interact with it). Finding a strong preference for the use of clothing and headwear in Studies 1-2 (N=52), we systematically manipulated a robot’s appearance using these items and evaluated the qualitative and quantitative impacts on observer perceptions in Studies 3-4 (N=160). Observing that personalization increased perceptions of uniqueness and humanness, but also decreased positive responding, we then investigated the associations between personalization preferences and perceptions via a fifth study (N=100). Across the five studies, tensions emerged between operators’ interest in using wigs and interlocutors’ dislike of wigs. This result highlights a need to consider both operator and interlocutor perspectives when personalizing telepresence robots.CCS CONCEPTS•Computer systems organization $\rightarrow$Robotics;• Human-centered computing $\rightarrow$Collaborative and social computing, Interaction paradigms.",0.8,0.9795204401016235,True,0.3318122278318339,0.6556663339667287,True
Costume vs. Wizard of Oz vs. Telepresence: How Social Presence Forms of Tele-operated Robots Influence Customer Behavior,"In this study, we explore the effective form of social presence for a tele-operated robot to provide customer service. Particularly, we address the question on if and how a tele-operated robot displays the presence of an operator, and what effects it would have on people's perception and behavior toward it. We launched a tele-operated robot in a supermarket and had it deliver recipe flyers. We adjusted the robot's social presence by showing or not showing the photo of an operator's face (F) and using or not using voice conversion (V), leading to three forms of presence: Wizard of Oz (F: no, V: yes), costume (F: yes, V: yes), and telepresence (F: yes, V: no), which indicated the operator's presence from a low to a high level. We determined that the customers behaved significantly different when they faced the tele-operated robot in different forms. Our robot that exhibited a moderate presence of the operator (costume form) achieved the overall best performance. Based on these findings, we discuss both the strengths and weaknesses of the three forms of presence for a tele-operated robot and recommend the appropriate form for various applications.",1.0,0.8728432655334473,True,0.3775406687981454,0.6251919671657964,True
What Kind of Mind Do I Want in My Robot?: Developing a Measure of Desired Mental Capacities in Social Robots,"We took a first step in developing a measurement tool for the social and mental capacities that people desire in social robots. 291 respondents indicated the degree to which they would like to see 16 capacities in either a home robot, nursing robot, or military robot. Four orthogonal dimensions emerged: Social-Moral Skills, Autonomous Evaluation, Objective Reasoning, and Negative Feelings. These dimensions were robust across the three robot types and across two assessment years (2013 and 2016).",1.1,0.7483136653900146,True,0.401312339887548,0.5748130026387813,True
"Combining Emotional Gestures, Sound Effects, and Background Music for Robotic Storytelling - Effects on Storytelling Experience, Emotion Induction, and Robot Perception",,1.0,0.8663378953933716,True,0.3775406687981454,0.6219392820957585,True
"What a Pity, Pepper!: How Warmth in Robots' Language Impacts Reactions to Errors during a Collaborative Task","We investigate the impact of warmth in robots' language on the perception of errors in a shopping assistance task (N=81) and found that error-free behavior was favored over erroneous if the dialogue is machine-like, while errors do not negatively impact liking, trust and acceptance if the robot uses human-like language. Warmth in robots' language thus seems to mitigate negative consequences and should be considered as a crucial design aspect.",1.3,0.8663161993026733,True,0.45016600268752216,0.6582411009950977,True
Conversational Bootstrapping and Other Tricks of a Concierge Robot,"We describe the effective use of online learning to enhance the conversational capabilities of a concierge robot that we have been developing over the last two years. The robot was designed to interact naturally with visitors and uses a speech recognition system in conjunction with a natural language classifier. The online learning component monitors interactions and collects explicit and implicit user feedback from a conversation and feeds it back to the classifier in the form of new class instances and adjusted threshold values for triggering the classes. In addition, it enables a trusted master to teach it new question-answer pairs via question-answer paraphrasing, and solicits help with maintaining question-answer-class relationships when needed, obviating the need for explicit programming. The system has been completely implemented and demonstrated using the SoftBank Robotics [34] humanoid robots Pepper and NAO, and the telepresence robot known as Double from Double Robotics [4].",1.0,0.9281460046768188,True,0.3775406687981454,0.6528433367374822,True
What if a Social Robot Excluded You?: Using a Conversational Game to Study Social Exclusion in Teen-robot Mixed Groups,"Belonging to a group is a natural need for human beings. Being left out and rejected represents a negative event, which can cause discomfort and stress to the excluded person and other members. Social robots have been shown to have the potential to be optimal tools for studying influence in group interactions, providing valuable insights into how human group dynamics can be modeled, replicated, and leveraged. In this work, we aim to study the effect of being excluded by a social robot in a teenagers-robot interaction. We propose a conversational turn-taking game, inspired by the Cyberball paradigm and rooted in social exclusion mechanisms, to explore how the humanoid robot iCub can affect group dynamics by excluding one of the group members. Preliminary results show that the included player tries to re-engage with the one excluded by the robot. We interpret this dynamic as an included player's tentative to compensate for the exclusion and reestablish a balance, in line with findings in human-human interaction research. Furthermore, the paradigm we developed seems a suitable tool for researching social influence in different Human-Robot Interaction contexts.",1.1,0.8506320714950562,True,0.401312339887548,0.6259722056913021,True
Marionette: Enabling On-Road Wizard-of-Oz Autonomous Driving Studies,"There is a growing need to study the interactions between drivers and their increasingly autonomous vehicles. This paper describes a method of using a low-cost, portable, and versatile driver interaction system in commercial passenger vehicles to enable on-road partial and fully autonomous driving interaction studies. By conducting on-road Wizard-of-Oz studies in naturalistic settings, we can explore a range of driving conditions and scenarios far beyond what can be conducted in laboratory simulator environments. The Marionette system uses off-the-shelf components to create bidirectional communication between the driving controls of a Wizard-of-Oz vehicle operator and a driving study participant. It signals to the study participant what the car is doing and enables researchers to study participant intervention in driving activity. Marionette is designed to be easily replicated for researchers studying partially autonomous driving interaction. This paper describes the design and evaluation of this system.",1.0,0.9260461926460266,True,0.3775406687981454,0.6517934307220861,True
Touch or Talk?: Comparing Social Robots and Tablet PCs for an Elderly Assistant Recommender System,"This work is targeted towards the development of a recommender system that fosters the well-being of elderly people in their domestic environment. Since seniors can have a rather high barrier of using newer technologies, the interaction device utilized in such a system has to be selected carefully. This paper compares an anthropomorphic presentation of recommendations by a social robot with a graphical presentation on a tablet PC in terms of the perceived usability, the users' experience and the system's persuasion.",1.1,0.8822102546691895,True,0.401312339887548,0.6417612972783687,True
"""Can You Guess My Moves?: Playing Charades with a Humanoid Robot Employing Mutual Learning with Emotional Intelligence","Social play is essential in human interactions, increasing social bonding, mitigating stress, and relieving anxiety. With advancements in robotics, social robots can employ this role to assist in human-robot interaction scenarios for clinical and healthcare purposes. However, robotic intelligence still needs further development to match the wide spectrum of social behaviors and contexts in human interactions. In this paper, we present our robotic intelligence framework with a mutual learning paradigm in which we apply deep learning based on emotion recognition and behavior perception, through which the robot learns human movements and contexts through the interactive game of charades. Furthermore, we designed a gesture-based social game to provide a more empathetic and engaging social robot for the user. We also created a custom behavior database containing contextual behaviors for the proposed social games. A pilot study was conducted with participants ranging in age from 12 to 19 for a preliminary evaluation.",1.1,0.973089873790741,True,0.401312339887548,0.6872011068391445,True
Where Should Robots Talk?: Spatial Arrangement Study from a Participant Workload Perspective,"Several benefits obtained using multiple robots in conversation have been reported in the human–robot interaction field. This paper first presents pre-trial results by which elderly people assigned a lower rating to a conversation with two robots than to one with a single robot. Observations of the trial suggest the hypothesis that an inappropriate spatial arrangement between robots and humans increases the workload in a conversation. Reducing the workload is important, especially when robots are used by elderly people. Therefore, we specifically examine the workload that is influenced by the spatial arrangement in group conversation. To verify the hypothesis, we use a NASA-TLX and a dual-task method to evaluate the workload and to conduct a comparative experiment in which the participant talks with two robots in two spatial arrangements. We also conduct a case study for elderly people in the same conversational conditions. From these experiments, we demonstrate that the spatial arrangement in which people cannot see both robots simultaneously increases their conversational workload and decreases their evaluation of the dialogue compared to a spatial arrangement by which people can see both robots simultaneously. We also show that the primary cause of the workload by positioning is not physical but mental.",1.1,0.7167544960975647,True,0.401312339887548,0.5590334179925563,True
"Models of (Often) Ambivalent Robot Stereotypes: Content, Structure, and Predictors of Robots' Age and Gender Stereotypes","This study focused on investigating the content, structure, and predictors of robots' stereotypes. We involved 120 participants in an online study and asked them to rate 80 robots on communion, agency, suitability for female and suitability for male tasks. In line with the stereotype content model, we discovered that robots' stereotypes are described by two dimensions, communion and agency, which combine to form univalent (e.g., low communion/low agency), as well as ambivalent clusters (e.g., low communion/high agency). Moreover, we found out that a robot's stereotypical appearance has a role in activating stereotypes. Indeed, in our study, female robots featuring appearance cues socio-culturally associated with femininity (e.g., eyelashes or apparel) were perceived as more communal, and juvenile robots featuring appearance cues tapping into the baby schema (e.g., cartoony eyes) were perceived as more communal, less agentic, and less suited to perform tasks. Given the renowned relationship between stereotyping, prejudice and discrimination, the causal link between appearance and stereotyping we establish in this paper can help HRI researchers disentangle the relation between robots' design and people's behavioral tendencies towards them, including proneness to harm.",0.8,0.8095172643661499,True,0.3318122278318339,0.5706647460989919,True
Your Eyes Never Lie: A Robot Magician Can Tell if You Are Lying,"Detecting lies in a real-world scenario is an important skill for a humanoid robot that aims to act as a teacher, a therapist, or a caregiver. In these contexts, it is essential to detect lies while preserving the pleasantness of the social interaction and the informality of the relation. This study investigates whether pupil dilation related to an increase in cognitive load can be used to swiftly identify a lie in an entertaining scenario. The iCub humanoid robot plays the role of a magician in a card game, telling which card the human partner is lying about. The results show a greater pupil dilation in presence of a false statement even if in front of a robot and without the need of a strictly controlled scenario. We developed a heuristic method (accuracy of 71.4% against 16.6% chance level) and a random forest classifier (precision and recall of 83.3%) to detect the false statement. Additionally, the current work suggests a potential method to assess the lying strategy of the partner.",1.0,0.860823929309845,True,0.3775406687981454,0.6191822990539952,True
Developing a Zoomorphic Robot for Animal Welfare Education,,1.0,0.7717058062553406,True,0.3775406687981454,0.574623237526743,True
"""Cool glasses, where did you get them?"": Generating Visually Grounded Conversation Starters for Human-Robot Dialogue",,1.3,0.9495935440063477,True,0.45016600268752216,0.6998797733469349,True
3rd Workshop on Human-Interactive Robot Learning (HIRL),,0.8,0.8078316450119019,True,0.3318122278318339,0.5698219364218678,True
What? That's Not a Chair!: How Robot Informational Errors Affect Children's Trust Towards Robots,"Robots that interact with children are becoming more common in places such as child care and hospital environments. While such robots may mistakenly provide nonsensical information, or have mechanical malfunctions, we know little of how these robot errors are perceived by children, and how they impact trust. This is particularly important when robots provide children with information or instructions, such as in education or health care. Drawing inspiration from established psychology literature investigating how children trust entities who teach or provide them with information (informants), we designed and conducted an experiment to examine how robot errors affect how young children (3–5 years old) trust robots. Our results suggest that children utilize their understanding of people to develop their perceptions of robots, and use this to determine how to interact with robots. Specifically, we found that children developed their trust model of a robot based on the robot's previous errors, similar to how they would for a person. We however failed to replicate other prior findings with robots. Our results provide insight into how children as young as 3 years old might perceive robot errors and develop trust.",1.6,0.9112032651901245,True,0.52497918747894,0.7180912263345323,True
Designing Functional Clothing for Human-robot Interaction,"We believe that we can design robot clothes to help robots become better robots-help them to be useful in a wider array of contexts, or to better adapt or function in the contexts they are already in. We propose that robot clothing should avoid mere mimicry of human apparel, and instead be motivated by what robots need. While we have seen robots dressed in clothes in the last few decades, we believe that robot clothes can be designed with thoughtful intention and should be studied as its own field. In this workshop, we explore this new area within human robot interaction by bringing together HRI researchers, designers, fashion and costume designers, and artists. We will focus on potential functions of robot clothes, discuss potential trends, and design clothes for robots together in an interactive prototyping session. Through this workshop, we hope to build a community of people who will push forward the field of robot clothing design.",1.0,0.799051821231842,True,0.3775406687981454,0.5882962450149938,True
Who is that?! Does Changing the Robot as a Learning Companion Impact Preschoolers' Language Learning?,"In child-robot interaction research, many studies pursue the goal to support children's language development. While research in human-human interaction suggests that changing human partners during children's language learning can reduce their recall performance of the learning content, little is known whether a change in social robots as interaction partners influence children's learning in the same way. In this paper, we present findings from a word learning study, in which we changed the robotic partner for one group of children while the other group interacted with the same robot. Contrary to work with human social partners, we found that children did not retrieve words differently when interacting with different humanoid robots as their social interaction partners.",1.6,0.9723145961761475,True,0.52497918747894,0.7486468918275437,True
Robot vs. Voice Assistant: Is Playing with Pepper More Fun than Playing with Alexa?,"Entertainment applications for robots are often based on voice interaction. In these scenarios, the robot is primarily used as a voice assistant with a physical body. We conducted a study to investigate whether the entertainment value of a robot during a game can be attributed to the experience of voice interaction alone, or whether it is related to the physical presence of a robot and its expressivity through gestures and movement. The study examined the user experience for three different set-ups of a quiz game (with voice assistant, robot without animation, and animated robot). The results indicate that the perceived hedonic quality increases with physical presence and movement of the robot. Pragmatic quality was not rated differently for the three game versions. Additional qualitative interviews suggest that it might be desirable to design not overly expressive, but meaningful robot behavior for entertainment applications, in order to promote both, hedonic and pragmatic experience.",1.3,0.9894282221794128,True,0.45016600268752216,0.7197971124334674,True
Who is a Better Salesperson?: People Conform more to a Human than Robot Facilitator in the Wild,,2.1,0.8476751446723938,True,0.6456563062257954,0.7466657254490946,True
Persuasion Based on Personality Traits: Using a Social Robot as Storyteller,"We propose to create a model based on Personality Traits (PT) to persuade players interacting with a social robot in the context of Interactive Storytelling (IS). With this model, we expect to predict the best decisions based on players' PT and be able to persuade them to make decisions improving motivation, satisfaction and memorization. For this, the PT will be categorized according to the MBTI theory and a storytelling scenario will be used to create, measure and evaluate the model. Our work requires experiments regarding persuasion techniques based on PT using social robots, and how to relate the decision points in IS to PT.",1.0,0.8122537732124329,True,0.3775406687981454,0.5948972210052892,True
What Would You Like to Drink?: Engagement and Interaction Styles in HRI,"In this paper, we address the question of how specific barman/robot interaction styles can affect users' engagement. To this extent, we implemented a barman-robot called ""BRILLO"" with neutral, entertaining, and emphatic behavioral style suggesting drinks and taking orders from customers. Results show that a robot's interaction style may determine users' level of engagement. Indeed, interacting with an emphatic robot that modulates its behavior according to the user's one is more effective than a neutral robot in improving engagement and positive emotions in public-service contexts. Moreover, users experienced more positive emotions when they perceived BRILLO as safe and as more similar to a human.",1.1,0.7911771535873413,True,0.401312339887548,0.5962447467374447,True
Cheating with a Socially Assistive Robot?: A Matter of Personality,"Socially assistive robots might improve the quality of life of individuals by carrying out therapeutic interventions. However, when users try to cheat with robots by disregarding their recommendations, they might not be able to perform their supporting functions. In the present study, we aimed to evaluate how the robot behavior style could affect the users' compliance and cheating behavior. Sixty volunteers underwent neuro-psychological testing administered by Pepper that was configured as neutral, friendly, or authoritarian. The results revealed that the robot characterized by neutral behavioral style seems to reduce individuals' compliance.",1.1,0.9659360647201538,True,0.401312339887548,0.6836242023038509,True
What’s in a Name?: Effects of Category Labels on the Consumers’ Acceptance of Robotic Products,"A study was conducted to investigate the effects of category labels of domestic robots on their consumer acceptance. The authors posited that compared to the label robots, a pre-existent category label such as home appliances would increase the consumers’ evaluation of and purchase intention towards the products. It is suggested that the pre-existent category label helps consumers to perceive the functional values they stand to gain by consuming the product more than the label robots, which is often related to the concepts generated around cultural artifacts. The results of the study confirmed the hypotheses, and further discussions are provided in this paper. CCS CONCEPTS • Human-centered computing → Human computer interaction (HCI) → Empirical studies in HCI; HCI theory, concepts and models; • Applied computing → Law, social and behavioral sciences → Psychology; ACM Reference format: Jun San Kim, Sonya S. Kwak, Dahyun Kang, and JongSuk Choi. 2020. What’s in a Name?: Effects of Category Labels on the Consumers’ Acceptance of Robotic Products. In Proceedings of 2020 ACM/IEEE International Conference on Human-Robot Interaction (HRI’20), March 23–26, 2020, Cambridge, United Kingdom. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3319502.3374799",1.1,0.8005511164665222,True,0.401312339887548,0.6009317281770351,True
Apprentice of Oz: Human in the Loop System for Conversational Robot Wizard of Oz,"Conversational robots that exhibit human-level abilities in physical and verbal conversation are widely used in human-robot interaction studies, along with the Wizard of Oz protocol. However, even with the protocol, manipulating the robot to move and talk is cognitively demanding. A preliminary study with a humanoid was conducted to observe difficulties wizards experienced in each of four subtasks: attention, decision, execution, and reflection. Apprentice of Oz is a human-in-the-loop Wizard of Oz system designed to reduce the wizard's cognitive load in each subtask. Each task is co-performed by the wizard and the system. This paper describes the system design from the view of each subtask.",1.0,0.916637659072876,True,0.3775406687981454,0.6470891639355107,True
CardBot: Towards an affordable humanoid robot platform for Wizard of Oz Studies in HRI,"CardBot is a cardboard based programmable humanoid robot platform designed for inexpensive and rapid prototyping of Wizard of Oz interactions in HRI incorporating technologies such as Arduino, Android and Unity3d. The table demonstration showcases the design of the CardBot and its wizard controls such as animating the movements, coordinating speech and gaze etc for orchestrating an interaction.",1.0,0.8954355716705322,True,0.3775406687981454,0.6364881202343389,True
Exploring the Effects of Self-Disclosed Backstory of Social Robots on Development of Trust in Human-Robot Interaction,"This paper investigated the influence of a social robot which discloses a backstory of its experiences on the development of trust in human-robot interaction with respect to the nature of backstories. We compared three cases of backstories, a happy backstory, a sorrowful backstory and no backstory told by the robot during interaction with participants. The results indicated that the robot disclosing a happy backstory provided the participants with higher impression of trustworthiness in general and affective trust compared to the robot telling no backstory. However, the robot with sorrowful backstory was not evaluated to lead to higher trustworthiness than the robot with no backstory. Furthermore, the happy backstory condition scored higher than the sorrowful backstory condition in general, affective and cognitive trust. Thus, participants rated a happy backstory tied to positive self-disclosed emotion, to be significantly more influential in human-robot trust.",1.0,0.7420832514762878,True,0.3775406687981454,0.5598119601372167,True
"Toy, Tutor, Peer, or Pet?: Preliminary Findings from Child-Robot Interactions in a Community School","Research focused upon Child-Robot Interaction shows that robots in the classroom can support diverse learning goals amongst pre-school children. However, studies with children and robots in the Global South are currently limited. To address this gap, we conducted a study with children aged 4-8 years at a community school in New Delhi, India, to understand their interaction and experiences with a social robot. The children were asked to teach the English alphabet to a Cozmo robot using flash cards. Preliminary findings suggest that the children orient to the robot in a variety of ways including as a toy or pet. These orientations need to be explored further within the context of the Global South.",1.1,0.945740282535553,True,0.401312339887548,0.6735263112115505,True
Buddy: A Speech Therapy Robot Companion For Children With Cleft Lip and Palate (CL/P) Disorder,"Children born with cleft lip and palate (CL/P) disorder go through several years of corrective surgeries, dental procedures, and jaw correction. These children suffer from varying degrees of speech impediment. Current treatments include speech therapy, but such treatments are not equally accessible for children from different socio-economic backgrounds. When available, speech therapists find it difficult to evaluate the children's progress in articulation over time. Buddy is a therapy robot for CL/P children that can provide contextual speech therapy in a gamified story-building format. To improve articulation, Buddy will provide robust visual feedback during these sessions and guide the children in enunciating tough words while collecting data of speech pattern for further analysis by the speech therapist.",0.8,0.8136721253395081,True,0.3318122278318339,0.572742176585671,True
Comparing the Effects of False Alarms and Misses on Humans' Trust in (Semi)Autonomous Vehicles,"Trust in automated driving systems is crucial for effective driver-(semi)autonomous vehicles interaction. Drivers that do not trust the system appropriately are not able to leverage its benefits. This study presents a mixed design user experiment where participants conducted a non-driving task while traveling in a simulated semi-autonomous vehicle with forward collision alarm and emergency braking functions. Occasionally, the system missed obstacles or provided false alarms. We varied these system error types as well as road shapes, and measured the effects of these variations on trust development. Results reveal that misses are more harmful to trust development than false alarms, and that these effects are strengthened by operation on risky roads. Our findings provide additional insight into the development of trust in automated driving systems, and are useful for the design of such technologies.",0.8,0.7751844525337219,True,0.3318122278318339,0.5534983401827779,True
Who is a Better Tutor?: Gaze Hints with a Human or Humanoid Tutor in Game Play,"In this paper, we present a study that analyses the effects of robot or human gaze hints on people's choices in a card game. We asked human participants to play a matching card game in the presence of a human or a robotic tutor. Our aim was to find out if gaze hints provided by the tutor can direct the attention and influence the choices of the human participants. The results show that participants performed significantly better when they received gaze hints from a tutor than when they did not. Furthermore, we found that people identified the tutor hints more often in robot condition than in human condition and, as a result, performed significantly better.",1.1,0.9889541864395142,True,0.401312339887548,0.6951332631635311,True
Robot-Assisted Language Learning Increases Functional Connectivity in Children's Brain,"The current study investigated how robot tutors influence brain activity during child-robot interaction (CRI) for learning of second language vocabulary. We gathered EEG signals from two groups of children; 1) Robot group (N=21) who listened to a storytelling social robot and learned French words, and 2) Display group (N=20) who listened to the same story in the French language mediated by only a computer screen. To measure learning-induced changes in the brain, functional connectivity analysis was conducted on EEG signals, which quantifies the communication between brain regions during the learning phase. Results showed a significantly higher functional brain connectivity for the Robot group in the theta frequency band, which has been previously associated with language functions in neuroscientific literature. Our results provide neurophysiological evidence for the benefit of robot tutors in second language learning in children.",1.0,0.8179407119750977,True,0.3775406687981454,0.5977406903866216,True
Unlocking Potentials of Virtual Reality as a Research Tool in Human-Robot Interaction: A Wizard-of-Oz Approach,,1.0,0.977644681930542,True,0.3775406687981454,0.6775926753643438,True
Engaging Children as a Storyteller: Backchanneling Models for Social Robots,"In this video, we provide an overview of the analyses, design, and evaluation of a backchannel opportunity prediction (BOP) model for a social robot listener.",1.0,0.7883127331733704,True,0.3775406687981454,0.5829267009857579,True
The Way You See Me - Comparing Results from Online Video-Taped and In-Person Robotic Storytelling Research,,1.0,0.7812222838401794,True,0.3775406687981454,0.5793814763191625,True
Let's Make this Fun!: Activities to Motivate Children and Teens to Complete Questionnaires,,2.3,0.9950640201568604,True,0.6899744811276125,0.8425192506422364,True
"The Peculiarities of Robot Embodiment (EmCorp-Scale) : Development, Validation and Initial Test of the Embodiment and Corporeality of Artificial Agents Scale","We propose a new theoretical framework assuming that embodiment effects in HAI and HRI are mediated by users’ perceptions of an artificial entity’s body-related capabilities. To enable the application of our framework to foster more theoretical-driven research, we developed a new self-report measurement that assesses bodily- related perceptions of the embodiment and corporeality - which we reveal as not being a binary characteristic of artificial entities. For the development and validation of the new scale we conducted two surveys and one video-based experiment. Exploratory factor analysis reveal a four-factorial solution with good reliability (Study 2, n = 442), which was confirmed via confirmatory factor analysis (Study 3, n = 260). In addition, we present first insights into the explanatory power of the scale: We reveal that humans’ perceptions of an artificial entity’s capabilities vary between virtual and physical embodiments, and that the evaluation of the artificial counterpart can be explained through the perceived capabilities. Practical applications and future research lines are discussed.",0.8,0.8575868010520935,True,0.3318122278318339,0.5946995144419637,True
Good Robot Design or Machiavellian? An In-the-Wild Robot Leveraging Minimal Knowledge of Passersby's Culture,"Social robots are being designed to use human-like communication techniques, including body language, social signals, and empathy, to work effectively with people. Just as between people, some robots learn about people and adapt to them. In this paper we present one such robot design: we developed Sam, a robot that learns minimal information about a person's background, and adapts to this background. Our in-the-wild study found that people helped Sam for significantly longer when it adapted to match their background. While initially we saw this as a success, in re-considering our study we started seeing a different angle. Our robot effectively deceived people (changed its story and text), based on some knowledge of their background, to get more work from them. There was little direct benefit to the person from this adaptation, yet the robot stood to gain free labor. We would like to pose the question to the community: is this simply good robot design, or, is our robot being manipulative? Where does the ethical line lay between a robot leveraging social techniques to improve interaction, and the more negative framing of a robot or algorithm taking advantage of people? How can we decide what is good here, and what is less desirable?",1.3,0.9025387763977051,True,0.45016600268752216,0.6763523895426136,True
SAIL: Simulation-Informed Active In-the-Wild Learning,"Robots in real-world environments may need to adapt context-specific behaviors learned in one environment to new environments with new constraints. In many cases, copresent humans can provide the robot with information, but it may not be safe for them to provide hands-on demonstrations and there may not be a dedicated supervisor to provide constant feedback. In this work we present the SAIL (Simulation-Informed Active In-the-Wild Learning) algorithm for learning new approaches to manipulation skills starting from a single demonstration. In this three-step algorithm, the robot simulates task execution to choose new potential approaches; collects unsupervised data on task execution in the target environment; and finally, chooses informative actions to show to co-present humans and obtain labels. Our approach enables a robot to learn new ways of executing two different tasks by using success/failure labels obtained from naïve users in a public space, performing 496 manipulation actions and collecting 163 labels from users in the wild over six 45-minute to 1-hour deployments. We show that classifiers based low-level sensor data can be used to accurately distinguish between successful and unsuccessful motions in a multi-step task ($\mathbf{p} < 0.005$), even when trained in the wild. We also show that using the sensor data to choose which actions to sample is more effective than choosing the least-sampled action.",1.0,0.8403922915458679,True,0.3775406687981454,0.6089664801720067,True
Your New Friend NAO vs. Robot No. 783 - Effects of Personal or Impersonal Framing in a Robotic Storytelling Use Case,"The users' positive or negative attitude towards robots is a crucial factor in human-robot interaction (HRI). We conducted a preliminary online study comparing a storytelling scenario including personal respectively impersonal framing to investigate effects of the robot's self-introduction on the users' attitude towards and likeability of the robot, their transportation into and memory of the story told. No significant group differences were found, but transportation correlated significantly with attitude, likeability and memory. Thus, transportation might be a promising factor which can when increased positively affect HRI.",1.0,0.810932457447052,True,0.3775406687981454,0.5942365631225988,True
"Virtual, Augmented, and Mixed Reality for Human-Robot Interaction (VAM-HRI)","The 6th International Workshop on Virtual, Augmented, and Mixed Reality for Human-Robot Interaction (VAM-HRI) will bring together HRI, robotics, and mixed reality researchers to address challenges in mixed reality interactions between humans and robots. Topics relevant to the workshop include the development of robots that can interact with humans in mixed reality, the use of virtual reality for developing interactive robots, the design of augmented reality interfaces that mediate communication between humans and robots, the investigations of mixed reality interfaces for robot learning, comparisons of the capabilities and perceptions of robots and virtual agents, and best design practices. VAM-HRI 2023 will follow the success of VAM-HRI 2018-22 and advance the cause of this nascent research community.",0.8,0.7953213453292847,True,0.3318122278318339,0.5635667865805593,True
2nd Workshop on Human-Interactive Robot Learning (HIRL),"With robots poised to enter our daily environments, they will not only need to work for people, but also learn from them. An active area of investigation in the robotics, machine learning, and human-robot interaction communities is the design of teachable robots that can learn interactively from human input. To refer to these research efforts, we use the umbrella term Human-Interactive Robot Learning (HIRL). While algorithmic solutions for robots learning from people have been investigated in a variety of ways, HIRL, as a fairly new research area, is still lacking: 1) a formal set of definitions to classify related but distinct research problems or solutions, 2) benchmark tasks, interactions, and metrics to evaluate the performance of HIRL algorithms and interactions, and 3) clear long-term research challenges to be addressed by different communities. Last year we began consolidating the needed definitions and vocabulary to enable fruitful discussions between researchers from these interdisciplinary fields, and identified a preliminary list of long, medium, and short-term research problems for the community to tackle, and existing tools and frameworks that can be leveraged to this end. This workshop will build upon these discussions, focusing on promoting the specification and design of HIRL benchmarks.",0.8,0.8036523461341858,True,0.3318122278318339,0.5677322869830098,True
Telling Stories to Robots: The Effect of Backchanneling on a Child's Storytelling *,"While there has been a growing body of work in child-robot interaction, we still have very little knowledge regarding young children's speaking and listening dynamics and how a robot companion should decode these behaviors and encode its own in a way children can understand. In developing a backchannel prediction model based on observed nonverbal behaviors of 4–6 year-old children, we investigate the effects of an attentive listening robot on a child's storytelling. We provide an extensive analysis of young children's nonverbal behavior with respect to how they encode and decode listener responses and speaker cues. Through a collected video corpus of peer-to-peer storytelling interactions, we identify attention-related listener behaviors as well as speaker cues that prompt opportunities for listener backchannels. Based on our findings, we developed a backchannel opportunity prediction (BOP) model that detects four main speaker cue events based on prosodic features in a child's speech. This rule-based model is capable of accurately predicting backchanneling opportunities in our corpora. We further evaluate this model in a human-subjects experiment where children told stories to an audience of two robots, each with a different backchanneling strategy. We find that our BOP model produces contingent backchannel responses that conveys an increased perception of an attentive listener, and children prefer telling stories to the BOP model robot.",1.0,0.7854007482528687,True,0.3775406687981454,0.5814707085255071,True
A Comparison of Kindergarten Storytelling by Human and Humanoid Robot with Different Social Behavior,"In this paper, we present a study on the influence of different social behavior on preschool children's perception of stories narrated either by a humanoid robot or by a human teacher. Four conditions were considered: static human, static robot, expressive human and expressive robot. Two stories, with knowledge and emotional content, were narrated in two different encounters. After each story, children draw what they remember of the story. We examined drawings of 81 children to study whether the sociability of the teacher (robot or human) could influence elements and details recorded. Results suggest a positive effect of the expressive behavior in robot storytelling, whose efficacy is comparable to the human with the same behavior or better if the expressive robot is compared with a static inexpressive human.",1.0,0.7351520657539368,True,0.3775406687981454,0.5563463672760411,True
Looks Can Permit Deceiving: How Reward or Punishment Decisions are Influenced by Robot Embodiment,"As robots and artificially intelligent systems are given more cognitive capabilities and become more prevalent in our societies, the relationships they share with humans have become more nuanced. This paper aims to investigate the influences that embodiment has on a person's decision to reward or punish an honest or deceptive intelligent agent. We cast this exploration within a financial advisement scenario. Our results suggest that people are more likely to choose to reward a physically embodied intelligent agent over a virtual one irrespective of whether the agent has been deceptive or honest and even if this deception or honesty resulted in the individual gaining or losing money. Additionally, our results show that people are more averse to punishing intelligent agents, irrespective of the embodiment, which matches prior research in relation to human-human interaction. These results suggest that embodiment choices can have meaningful effects on the permissibility of deception conducted by intelligent agents.",1.0,0.8758943676948547,True,0.3775406687981454,0.6267175182465001,True
Workshop YOUR Study Design 2023!: Participatory Critique and Refinement of Participants' Studies,"A well-designed and evaluated study plays an essential role in highlighting the impact and contribution of a research idea. However, novice Human-Robot Interaction (HRI) researchers often lack the experience and know-how to devise an effective study. This workshop aims to provide a platform for those doing research in HRI, and related fields to obtain expert feedback on their study design before running a user study. The workshop invites a 2-4 page long contribution from participants outlining an upcoming user study focusing on the methods section and planned analyses. Participants will take part in two separate mentoring sessions led by different mentors. The workshop is interactive in nature and will also include mentor-led discussion sessions on topics relevant to study design such as hypothesis design and analysis, and human-centered study design.",1.3,0.7289429306983948,True,0.45016600268752216,0.5895544666929584,True
"Hello Pepper, May I Tickle You?: Children's and Adults' Responses to an Entertainment Robot at a Shopping Mall","We took a social robot Pepper to a shopping mall for one day to see what kind of initial responses it draws from people. We observed that the robot was quickly surrounded by children when there were others-especially adults-interacting with it. The children seemed to especially enjoy the activity-related applications, such as tickling the robot or giving a high-five. Adults were interested in hearing about useful applications and tended to talk to the robot as if it were any machine capable of speech recognition. These observations will help to design more interactive and entertaining applications for shopping mall robots.",1.1,0.977374255657196,True,0.401312339887548,0.689343297772372,True
Robot Curiosity in Human-Robot Interaction (RCHRI),"One of the fundamental modes of learning in children is through curiosity. Children (and adults) interact with new people, learn about novel objects, activities and other stimuli through curiosity and other intrinsic motivations. Creating autonomous robots that learn continually through intrinsic curiosity may result in breakthroughs in artificial intelligence. Such robots could continue to learn about themselves and the world around them through curiosity, thus improving their abilities over their ‘lifetime’. Although recent works on curiosity in different fields have produced significant results, most of these works have focused on constrained simulated environments which do not involve human interaction. However, in real-world applications such as healthcare, home-assistance etc., robots generally have to interact with humans on a regular basis. In these scenarios, it is imperative that curiosity is directed towards seeking out and learning important information from the humans when needed rather than simply learning in an unsupervised manner. Further, there is limited work on how humans perceive such curious robots and whether humans prefer curious robots that adapt over time to other robots that simply perform their assigned tasks. In this workshop, our goal is to bring together researchers and practitioners in different multidisciplinary fields to discuss the role of robot curiosity in real-world applications and its implications in human-robot interaction (HRI).",0.8,0.8104008436203003,True,0.3318122278318339,0.5711065357260671,True
IV. Sanierungskonzept (IDW S 6),,0.8,0.8152615427970886,True,0.3318122278318339,0.5735368853144612,True
Ludic-HRI: Designing Playful Experiences with Robots,"People are inherently playful, and playfulness matters not only when engaging in actual play but also in all other activities. Based on this, I propose using a ludic design approach as a means to broaden the design space for Human-Robot Interaction (HRI). In this paper, I discuss the application of ludic design in HRI and explore how ludic activities can act as a mechanism for achieving new understandings from people during their interactions with robots. Two projects, BubbleBot and Sketching Robot, are presented as cases of designing ludic activities with robots. In my work, I have investigated how people perceived robots by applying exploratory research through design methods in creating the ludic experiences. I am continuously learning from my design and exploring potential areas for designing robots while identifying new values and goals for having robots in our lives.",1.0,0.9885490536689758,True,0.3775406687981454,0.6830448612335607,True
What a Thing to Say! Which Linguistic Politeness Strategies Should Robots Use in Noncompliance Interactions?,,0.8,0.974118709564209,True,0.3318122278318339,0.6529654686980214,True
Haru He's Here to Help!: A Demonstration of Implementing Comedic Rapid Turn-taking for a Social Robot,"Current robot dialog systems are predominantly implemented using a sequential, utterance based, two-party, speak-wait/speak-wait approach. This is inadequate for any interaction where rapid timed turn-taking is required. In this demo we show how a conversational listener can support a comedy dialogue with the social robot 'Haru'. The system depends on fast local word-spotting and can be extended to support scripted and semi-scripted interactions where conversational timing is important such as fictive dialogues for educational purposes, or to support acting within a story telling context. The system could also be integrated with a full dialogue manager for non-scripted open dialogue applications.",1.3,0.9747991561889648,True,0.45016600268752216,0.7124825794382434,True
"Virtual, Augmented, and Mixed Reality for Human-Robot Interaction (VAM-HRI)","The 4th International Workshop on Virtual, Augmented, and Mixed Reality for Human-Robot Interaction (VAM-HRI) will bring together HRI, robotics, and mixed reality researchers to address challenges in mixed reality interactions between humans and robots. Topics relevant to the workshop include development of robots that can interact with humans in mixed reality, use of virtual reality for developing interactive robots, the design of augmented reality interfaces that mediate communication between humans and robots, the investigations of mixed reality interfaces for robot learning, comparisons of the capabilities and perceptions of robots and virtual agents, and best design practices. Special topics of interest this year include VAM-HRI research during the COVID-19 pandemic as well as the ethical implications of VAM-HRI research. VAM-HRI 2021 will follow on the success of VAM-HRI 2018-20 and advance the cause of this nascent research community.",0.8,0.7953213453292847,True,0.3318122278318339,0.5635667865805593,True
Ready for the Next Step?: Investigating the Effect of Incremental Information Presentation in an Object Fetching Task,In this paper we present a human-agent interaction study investigating the effect of incremental (just in time) information presentation on human task performance and the subjective ratings of the agent. On the one hand we show that the task of fetching ingredients and utensils for cooking is better performed in case of incremental information presentation. On the other hand it yields a negative effect on the subjective ratings of the agent.,1.1,0.77790766954422,True,0.401312339887548,0.589610004715884,True
MindScribe: Reflective Inquiry through Scaffolded Storytelling for Low-Income and Multilingual Early Childhood Communities,"When young children create, they are exploring their emerging skills by engaging with the world. When young children reflect, they are deepening their learning experiences by extracting insights. And when young children share, they are strengthening their community by creating opportunities for collaboration. To support such constructionist learning, we present MindScribe, an affordable interactive robotic object that engages preliterate children in reflective inquiry. As children create artifacts, MindScribe invites them to ""tell a story"" about their creation---in any language. And through scaffolded questioning, MindScribe elicits children»s insights into their creative discoveries. Together, they spark child-led communication and innovation in early learning communities.",1.0,0.772738516330719,True,0.3775406687981454,0.5751395925644323,True
"‘Cool glasses, where did you get them?” Generating Visually Grounded Conversation Starters for Human-Robot Dialogue","Visually situated language interaction is an important challenge in multi-modal Human-Robot Interaction (URI). In this context we present a data-driven method to generate situated conversation starters based on visual context. We take visual data about the interactants and generate appropriate greetings for conversational agents in the context of HRI. For this, we constructed a novel open-source data set consisting of 4000 URI-oriented images of people facing the camera, each augmented by three conversation-starting questions. We compared a baseline retrieval-based model and a generative model. Human evaluation of the models using crowdsourcing shows that the generative model scores best, specifically at correctly referencing visual features. We also investigated how automated metrics can be used as a proxy for human evaluation and found that common automated metrics are a poor substitute for human judgement. Finally, we provide a proof-of-concept demonstrator through an interaction with a Furhat social robot.",1.3,0.9618892073631287,True,0.45016600268752216,0.7060276050253254,True
You're delaying my task?! The Impact of Task Order and Motive on Perceptions of a Robot,"Recent work has suggested that a robot that in-terrupts assigned tasks for the sake of curiosity is perceived as less competent, but that communicating acknowledgment of the curious behavior can mitigate some of those feelings [1]. In real-world situations, there are many reasons why a robot's task could be interrupted in favor of another. For example, a robot handling requests for tasks from people in different locations could navigate more efficiently if it interleaves those tasks, but it ideally would not do so at the expense of the users' perceptions of the robot. In order to understand the impact of different task interleaving patterns on human perceptions of a robot's behavior, we performed a study in which a robot performed a delivery task and an investigative task, interleaving them in various ways. The participants were told either that the investigative task was motivated by a request from another person, motivated by curiosity, or they received no information about why the robot performed the action. While participants acknowledged that interleaving tasks should be allowed, they rated the robot as more competent when its tasks were not interleaved. They were most receptive to interleaving when they knew the investigative task was for another person and less receptive to long task detours away from the delivery route, especially when the inspection task was motivated by curiosity.",1.6,0.976628839969635,True,0.52497918747894,0.7508040137242875,True
Friends or Foes?: Socioemotional Support and Gaze Behaviors in Mixed Groups of Humans and Robots,"This study investigated non-verbal behavior and socioemotional interactions in small-groups of humans and robots. Sixty-participants were involved in a group setting in which they were required to play a card game with another human and two robots (playing as partners or as opponents). The two robots displayed different goal orientations: a competitive robot (named Emys-) and a relationship-driven cooperative robot (named Glin+). Video recordings of the interactions were analyzed in three game play sessions. Eye gaze and socioemotional support behaviors were coded based on Bales» Interaction Process Analysis. Results indicated that gaze behavior towards partners was more frequently displayed to the relationship-driven robot than to the competitive robot and the human partners. In contrast, gaze towards opponents occurred more often towards the competitive robot than to the relationship-driven robot and the human opponents. Socioemotional support occurred more frequently towards partners than opponents, and was also displayed more often towards humans than towards robots. Moreover, in the sessions where the robots were opponents, participants provided more support to the competitive robot. This investigation in small groups of humans and robots provided evidence of different interaction patterns towards robots displaying distinct orientation goals, which can be useful in guiding the successful design of social robots.",1.1,0.7224621772766113,True,0.401312339887548,0.5618872585820797,True
Anthropomorphize me!: Effects of Robot Gender on Listeners' Perception of the Social Robot NAO in a Storytelling Use Case,"Social robots have started taking on storytelling, an age-old human tradition. However, the narrator's voice is central in storytelling and a robot cannot match the capabilities of human voice modulation, which might affect the perception of the robot by the listener. Using a robot and gendered voice as a medium for storytelling, we take a first step towards identifying effects of narrators' voice on anthropomorphism. We examine the robot's perceived anthropomorphism and the influence of its voice (female, male, or neutral) on recipients' attitude towards the robotic storyteller concerning gender and cross-gender effects. In addition, transportation indicating the quality of storytelling is investigated. We found no significant results, neither for attitudes toward the robot nor for transportation. Our gender-based voice manipulation did not affect the storytelling process. A lack of anthropomorphism of the robot may explain these findings and should be investigated in further studies.",2.3,0.9502052068710327,True,0.6899744811276125,0.8200898439993226,True
"Hey Robot, Can You Help Me Feel Less Lonely?: An Explorative Study to Examine the Potential of Using Social Robots to Alleviate Loneliness in Young Adults","An often-forgotten group of people which is heavily affected by loneliness are young adults. The perceived social isolation often stems from attachment insecurities and social skill deficiencies. Since robots can function as social interaction partners who exert less social pressure and display less social complexity, they may pose a promising approach to alleviate this problematic situation. The goal would not be to replace human interaction partners, but to diminish acute loneliness and accompanying detrimental effects and to function as social skills coach and practice interaction partner. To explore the potential of this approach, a preregistered quantitative online study (N = 150) incorporating a video-based interaction with a social robot and qualitative elements was conducted. First results show that young adults report less state loneliness after interacting with the robot than before. Technically affine people evaluate the robot's sociability as well as the interaction with it more positively, people with a general negative attitude towards robots less positively. Furthermore, the more trait loneliness people report to experience, the less sociable they perceive the robot.",1.1,0.9789046049118042,True,0.401312339887548,0.6901084723996761,True
LaSofa: Integrating Fantasy Storytelling in Human-Robot Interaction through an Interactive Sofa Robot,,1.0,0.909543514251709,True,0.3775406687981454,0.6435420915249273,True
Design Patterns for an Interactive Storytelling Robot to Support Children’s Engagement and Agency,"In this paper we specify and validate three interaction design patterns for an interactive storytelling experience with an autonomous social robot. The patterns enable the child to make decisions about the story by talking with the robot, reenact parts of the story together with the robot, and recording self-made sound effects. The design patterns successfully support children’s engagement and agency. A user study $(\mathrm{N}=27$, 8-10 y.o.) showed that children paid more attention to the robot, enjoyed the storytelling experience more, and could recall more about the story, when the design patterns were employed by the robot during storytelling. All three aspects are important features of engagement. Children felt more autonomous during storytelling with the design patterns and highly appreciated that the design patterns allowed them to express themselves more freely. Both aspects are important features of children’s agency. Important lessons we have learned are that reducing points of confusion and giving the children more time to make themselves heard by the robot will improve the patterns efficiency to support engagement and agency. Allowing children to pick and choose from a diverse set of stories and interaction settings would make the storytelling experience more inclusive for a broader range of children. CCS CONCEPTS • Human-centered computing → Empirical studies in interaction design; • Computing methodologies → Cognitive robotics; •Applied computing → Consumer health. ACM Reference Format: Mike E.U. Ligthart, Mark A. Neerincx, and Koen V. Hindriks. 2020. Design Patterns for an Interactive Storytelling Robot to Support Children’s Engagement and Agency. In Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction (HRI ’20), March 23–26, 2020, Cambridge, United Kingdom. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3319502.3374826",1.0,0.7972899675369263,True,0.3775406687981454,0.5874153181675359,True
Tube Convolutional Neural Network (T-CNN) for Action Detection in Videos,"Deep learning has been demonstrated to achieve excellent results for image classification and object detection. However, the impact of deep learning on video analysis has been limited due to complexity of video data and lack of annotations. Previous convolutional neural networks (CNN) based video action detection approaches usually consist of two major steps: frame-level action proposal generation and association of proposals across frames. Also, most of these methods employ two-stream CNN framework to handle spatial and temporal feature separately. In this paper, we propose an end-to-end deep network called Tube Convolutional Neural Network (T-CNN) for action detection in videos. The proposed architecture is a unified deep network that is able to recognize and localize action based on 3D convolution features. A video is first divided into equal length clips and next for each clip a set of tube proposals are generated based on 3D Convolutional Network (ConvNet) features. Finally, the tube proposals of different clips are linked together employing network flow and spatio-temporal action detection is performed using these linked video proposals. Extensive experiments on several video datasets demonstrate the superior performance of T-CNN for classifying and localizing actions in both trimmed and untrimmed videos compared to state-of-the-arts.",0.8,0.842121958732605,True,0.3318122278318339,0.5869670932822194,True
Neural-GIF: Neural Generalized Implicit Functions for Animating People in Clothing,"We present Neural Generalized Implicit Functions (Neural-GIF), to animate people in clothing as a function of the body pose. Given a sequence of scans of a subject in various poses, we learn to animate the character for new poses. Existing methods have relied on template-based representations of the human body (or clothing). However such models usually have fixed and limited resolutions, require difficult data pre-processing steps and cannot be used with complex clothing. We draw inspiration from template-based methods, which factorize motion into articulation and nonrigid deformation, but generalize this concept for implicit shape learning to obtain a more flexible model. We learn to map every point in the space to a canonical space, where a learned deformation field is applied to model non-rigid effects, before evaluating the signed distance field. Our formulation allows the learning of complex and non-rigid deformations of clothing and soft tissue, without computing a template registration as it is common with current approaches. Neural-GIF can be trained on raw 3D scans and reconstructs detailed complex surface geometry and deformations. Moreover, the model can generalize to new poses. We evaluate our method on a variety of characters from different public datasets in diverse clothing styles and show significant improvements over baseline methods, quantitatively and qualitatively. We also extend our model to multiple shape setting. To stimulate further research, we will make the model, code and data publicly available at [1].",1.0,0.7547474503517151,True,0.3775406687981454,0.5661440595749303,True
Space-Time Crop & Attend: Improving Cross-modal Video Representation Learning,"The quality of the image representations obtained from self-supervised learning depends strongly on the type of data augmentations used in the learning formulation. Recent papers have ported these methods from still images to videos and found that leveraging both audio and video signals yields strong gains; however, they did not find that spatial augmentations such as cropping, which are very important for still images, work as well for videos. In this paper, we improve these formulations in two ways unique to the spatio-temporal aspect of videos. First, for space, we show that spatial augmentations such as cropping do work well for videos too, but that previous implementations, due to the high processing and memory cost, could not do this at a scale sufficient for it to work well. To address this issue, we first introduce Feature Crop, a method to simulate such augmentations much more efficiently directly in feature space. Second, we show that as opposed to naïve average pooling, the use of transformer-based attention improves performance significantly, and is well suited for processing feature crops. Combining both of our discoveries into a new method, Space-Time Crop & Attend (STiCA) we achieve state-of-the-art performance across multiple video-representation learning benchmarks. In particular, we achieve new state-of-the-art accuracies of 67.0% on HMDB-51 and 93.1% on UCF-101 when pre-training on Kinetics-400. Code and pretrained models are available 1.",0.8,0.788444459438324,True,0.3318122278318339,0.5601283436350789,True
Fingerspelling Recognition in the Wild With Iterative Visual Attention,"Sign language recognition is a challenging gesture sequence recognition problem, characterized by quick and highly coarticulated motion. In this paper we focus on recognition of fingerspelling sequences in American Sign Language (ASL) videos collected in the wild, mainly from YouTube and Deaf social media. Most previous work on sign language recognition has focused on controlled settings where the data is recorded in a studio environment and the number of signers is limited. Our work aims to address the challenges of real-life data, reducing the need for detection or segmentation modules commonly used in this domain. We propose an end-to-end model based on an iterative attention mechanism, without explicit hand detection or segmentation. Our approach dynamically focuses on increasingly high-resolution regions of interest. It out-performs prior work by a large margin. We also introduce a newly collected data set of crowdsourced annotations of fingerspelling in the wild, and show that performance can be further improved with this additional data set.",1.0,0.9364023804664612,True,0.3775406687981454,0.6569715246323033,True
Generating Realistic Images from In-the-wild Sounds,"Representing wild sounds as images is an important but challenging task due to the lack of paired datasets between sound and images and the significant differences in the characteristics of these two modalities. Previous studies have focused on generating images from sound in limited categories or music. In this paper, we propose a novel approach to generate images from in-the-wild sounds. First, we convert sound into text using audio captioning. Second, we propose audio attention and sentence attention to represent the rich characteristics of sound and visualize the sound. Lastly, we propose a direct sound optimization with CLIPscore and AudioCLIP and generate images with a diffusion-based model. In experiments, it shows that our model is able to generate high quality images from wild sounds and outperforms baselines in both quantitative and qualitative evaluations on wild audio datasets.",1.0,0.7442728877067566,True,0.3775406687981454,0.560906778252451,True
Fake it till you make it: face analysis in the wild using synthetic data alone,"We demonstrate that it is possible to perform face-related computer vision in the wild using synthetic data alone. The community has long enjoyed the benefits of synthesizing training data with graphics, but the domain gap between real and synthetic data has remained a problem, especially for human faces. Researchers have tried to bridge this gap with data mixing, domain adaptation, and domain-adversarial training, but we show that it is possible to synthesize data with minimal domain gap, so that models trained on synthetic data generalize to real in-the-wild datasets. We describe how to combine a procedurally-generated parametric 3D face model with a comprehensive library of hand-crafted assets to render training images with unprecedented realism and diversity. We train machine learning systems for face-related tasks such as landmark localization and face parsing, showing that synthetic data can both match real data in accuracy as well as open up new approaches where manual labeling would be impossible.",1.0,0.9840559363365173,True,0.3775406687981454,0.6807983025673314,True
NeuRBF: A Neural Fields Representation with Adaptive Radial Basis Functions,"We present a novel type of neural fields that uses general radial bases for signal representation. State-of-the-art neural fields typically rely on grid-based representations for storing local neural features and N-dimensional linear kernels for interpolating features at continuous query points. The spatial positions of their neural features are fixed on grid nodes and cannot well adapt to target signals. Our method instead builds upon general radial bases with flexible kernel position and shape, which have higher spatial adaptivity and can more closely fit target signals. To further improve the channel-wise capacity of radial basis functions, we propose to compose them with multi-frequency sinusoid functions. This technique extends a radial basis to multiple Fourier radial bases of different frequency bands without requiring extra parameters, facilitating the representation of details. Moreover, by marrying adaptive radial bases with grid-based ones, our hybrid combination inherits both adaptivity and interpolation smoothness. We carefully designed weighting schemes to let radial bases adapt to different types of signals effectively. Our experiments on 2D image and 3D signed distance field representation demonstrate the higher accuracy and compactness of our method than prior arts. When applied to neural radiance field reconstruction, our method achieves state-of-the-art rendering quality, with small model size and comparable training speed.",1.0,0.7505185604095459,True,0.3775406687981454,0.5640296146038457,True
OpenForensics: Large-Scale Challenging Dataset For Multi-Face Forgery Detection And Segmentation In-The-Wild,"The proliferation of deepfake media is raising concerns among the public and relevant authorities. It has become essential to develop countermeasures against forged faces in social media. This paper presents a comprehensive study on two new countermeasure tasks: multi-face forgery detection and segmentation in-the-wild. Localizing forged faces among multiple human faces in unrestricted natural scenes is far more challenging than the traditional deepfake recognition task. To promote these new tasks, we have created the first large-scale dataset posing a high level of challenges that is designed with face-wise rich annotations explicitly for face forgery detection and segmentation, namely Open-Forensics. With its rich annotations, our OpenForensics dataset has great potentials for research in both deepfake prevention and general human face detection. We have also developed a suite of benchmarks for these tasks by conducting an extensive evaluation of state-of-the-art instance detection and segmentation methods on our newly constructed dataset in various scenarios.",1.0,0.7811156511306763,True,0.3775406687981454,0.5793281599644109,True
Learning specialized activation functions with the Piecewise Linear Unit,"The choice of activation functions is crucial for modern deep neural networks. Popular hand-designed activation functions like Rectified Linear Unit(ReLU) and its variants show promising performance in various tasks and models. Swish, the automatically discovered activation function, has been proposed and outperforms ReLU on many challenging datasets. However, it has two main drawbacks. First, the tree-based search space is highly discrete and restricted, which is difficult for searching. Second, the sample-based searching method is inefficient, making it infeasible to find specialized activation functions for each dataset or neural architecture. To tackle these drawbacks, we propose a new activation function called Piecewise Linear Unit(PWLU), which incorporates a carefully designed formulation and learning method. It can learn specialized activation functions and achieves SOTA performance on large-scale datasets like ImageNet and COCO. For example, on ImageNet classification dataset, PWLU improves 0.9%/0.53%/1.0%/1.7%/1.0% top-1 accuracy over Swish for ResNet-18/ResNet-50/MobileNet-V2/MobileNetV3/EfficientNet-B0. PWLU is also easy to implement and efficient at inference, which can be widely applied in real-world applications.",1.0,0.8262558579444885,True,0.3775406687981454,0.601898263371317,True
Story Visualization by Online Text Augmentation with Context Memory,"Story visualization (SV) is a challenging text-to-image generation task for the difficulty of not only rendering visual details from the text descriptions but also encoding a long-term context across multiple sentences. While prior efforts mostly focus on generating a semantically relevant image for each sentence, encoding a context spread across the given paragraph to generate contextually convincing images (e.g., with a correct character or with a proper background of the scene) remains a challenge. To this end, we propose a novel memory architecture for the Bi-directional Transformer framework with an online text augmentation that generates multiple pseudo-descriptions as supplementary supervision during training for better generalization to the language variation at inference. In extensive experiments on the two popular SV benchmarks, i.e., the Pororo-SV and Flintstones-SV, the proposed method significantly outperforms the state of the arts in various metrics including FID, character F1, frame accuracy, BLEU-2/3, and R-precision with similar or less computational complexity.",1.0,0.7480461001396179,True,0.3775406687981454,0.5627933844688817,True
SpinCam: High-Speed Imaging via a Rotating Point-Spread Function,"High-speed cameras are an indispensable tool used for the slow-motion analysis of scenes. However, the fixed bandwidth of any imaging system quickly becomes a bottleneck, resulting in a fundamental trade-off between the camera’s spatial and temporal resolutions. In recent years, compressive high-speed imaging systems have been proposed to circumvent these issues by optically encoding the signal and using a reconstruction procedure to recover a video. Our work proposes a novel approach for compressive high-speed imaging based on temporally coding the camera’s point-spread function (PSF). By mechanically spinning a diffraction grating in front of a camera, the sensor integrates an image blurred by a PSF that continuously rotates over time. We also propose a deconvolution-based reconstruction algorithm to reconstruct videos from these measurements. Our method achieves superior light efficiency and handles a wider scene class than prior methods. Also, our mechanical design yields flexible temporal resolution that can be easily increased, potentially allowing capture at 192 kHz—far higher than prior works. We demonstrate a prototype for various applications, including motion capture and particle image velocimetry (PIV).",1.0,0.7254188060760498,True,0.3775406687981454,0.5514797374370977,True
Chop & Learn: Recognizing and Generating Object-State Compositions,"Recognizing and generating object-state compositions has been a challenging task, especially when generalizing to unseen compositions. In this paper, we study the task of cutting objects in different styles and the resulting object state changes. We propose a new benchmark suite Chop & Learn, to accommodate the needs of learning objects and different cut styles using multiple viewpoints. We also propose a new task of Compositional Image Generation, which can transfer learned cut styles to different objects, by generating novel object-state images. Moreover, we also use the videos for Compositional Action Recognition, and show valuable uses of this dataset for multiple video tasks. Project website: https://chopnlearn.github.io.",0.8,0.9379702210426331,True,0.3318122278318339,0.6348912244372334,True
"Cut, Paste and Learn: Surprisingly Easy Synthesis for Instance Detection","A major impediment in rapidly deploying object detection models for instance detection is the lack of large annotated datasets. For example, finding a large labeled dataset containing instances in a particular kitchen is unlikely. Each new environment with new instances requires expensive data collection and annotation. In this paper, we propose a simple approach to generate large annotated instance datasets with minimal effort. Our key insight is that ensuring only patch-level realism provides enough training signal for current object detector models. We automatically ‘cut’ object instances and ‘paste’ them on random backgrounds. A naive way to do this results in pixel artifacts which result in poor performance for trained models. We show how to make detectors ignore these artifacts during training and generate data that gives competitive performance on real data. Our method outperforms existing synthesis approaches and when combined with real images improves relative performance by more than 21% on benchmark datasets. In a cross-domain setting, our synthetic data combined with just 10% real data outperforms models trained on all real data.",1.0,0.8824203610420227,True,0.3775406687981454,0.6299805149200841,True
Kick Back & Relax: Learning to Reconstruct the World by Watching SlowTV,"Self-supervised monocular depth estimation (SS-MDE) has the potential to scale to vast quantities of data. Unfortunately, existing approaches limit themselves to the automotive domain, resulting in models incapable of generalizing to complex environments such as natural or indoor settings.To address this, we propose a large-scale SlowTV dataset curated from YouTube, containing an order of magnitude more data than existing automotive datasets. SlowTV contains 1.7M images from a rich diversity of environments, such as worldwide seasonal hiking, scenic driving and scuba diving. Using this dataset, we train an SS-MDE model that provides zero-shot generalization to a large collection of indoor/outdoor datasets. The resulting model outperforms all existing SSL approaches and closes the gap on supervised SoTA, despite using a more efficient architecture.We additionally introduce a collection of best-practices to further maximize performance and zero-shot generalization. This includes 1) aspect ratio augmentation, 2) camera intrinsic estimation, 3) support frame randomization and 4) flexible motion estimation. Code is available at https://github.com/jspenmar/slowtv_monodepth.",0.8,0.941122829914093,True,0.3318122278318339,0.6364675288729634,True
Siamese Networks: The Tale of Two Manifolds,"Siamese networks are non-linear deep models that have found their ways into a broad set of problems in learning theory, thanks to their embedding capabilities. In this paper, we study Siamese networks from a new perspective and question the validity of their training procedure. We show that in the majority of cases, the objective of a Siamese network is endowed with an invariance property. Neglecting the invariance property leads to a hindrance in training the Siamese networks. To alleviate this issue, we propose two Riemannian structures and generalize a well-established accelerated stochastic gradient descent method to take into account the proposed Riemannian structures. Our empirical evaluations suggest that by making use of the Riemannian geometry, we achieve state-of-the-art results against several algorithms for the challenging problem of fine-grained image classification.",0.8,0.9491187334060669,True,0.3318122278318339,0.6404654806189504,True
Novel Scenes & Classes: Towards Adaptive Open-set Object Detection,"Domain Adaptive Object Detection (DAOD) transfers an object detector to a novel domain free of labels. However, in the real world, besides encountering novel scenes, novel domains always contain novel-class objects de facto, which are ignored in existing research. Thus, we formulate and study a more practical setting, Adaptive Open-set Object Detection (AOOD), considering both novel scenes and classes. Directly combing off-the-shelled cross-domain and open-set approaches is sub-optimal since their low-order dependence, e.g., the confidence score, is insufficient for the AOOD with two dimensions of novel information. To address this, we propose a novel Structured Motif Matching (SOMA) framework for AOOD, which models the high-order relation with motifs, i.e., statistically significant subgraphs, and formulates AOOD solution as motif matching to learn with high-order patterns. In a nutshell, SOMA consists of Structure-aware Novel-class Learning (SNL) and Structure-aware Transfer Learning (STL). As for SNL, we establish an instance-oriented graph to capture the class-independent object feature hidden in different base classes. Then, a high-order metric is proposed to match the most significant motif as high-order patterns, serving for motif-guided novel-class learning. In STL, we set up a semantic-oriented graph to model the class-dependent relation across domains, and match unlabelled objects with high-order motifs to align the crossdomain distribution with structural awareness. Extensive experiments demonstrate that the proposed SOMA achieves state-of-the-art performance. Codes are available at https://github.com/CityU-AIM-Group/SOMA.",0.8,0.8858369588851929,True,0.3318122278318339,0.6088245933585134,True
F&F Attack: Adversarial Attack against Multiple Object Trackers by Inducing False Negatives and False Positives,"Multi-object tracking (MOT) aims to build moving trajectories for number-agnostic objects. Modern multi-object trackers commonly follow the tracking-by-detection strategy. Therefore, fooling detectors can be an effective solution but it usually requires attacks in multiple successive frames, resulting in low efficiency. Attacking association processes improves efficiency but may require model-specific design, leading to poor generalization. In this paper, we propose a novel False negative and False positive attack (F&F attack) mechanism: it perturbs the input image to erase original detections and to inject deceptive false alarms around original ones while integrating the association attack implicitly. The mechanism can produce effective identity switches against multi-object trackers by only fooling detectors in a few frames. To demonstrate the flexibility of the mechanism, we deploy it to three multi-object trackers (ByteTrack, SORT, and CenterTrack) which are enabled by two representative detectors (YOLOX and CenterNet). Comprehensive experiments on MOT17 and MOT20 datasets show that our method significantly outperforms existing attackers, revealing the vulnerability of the tracking-by-detection paradigm to detection attacks.",0.8,0.9829891324043274,True,0.3318122278318339,0.6574006801180806,True
Racial Faces in the Wild: Reducing Racial Bias by Information Maximization Adaptation Network,"Racial bias is an important issue in biometric, but has not been thoroughly studied in deep face recognition. In this paper, we first contribute a dedicated dataset called Racial Faces in-the-Wild (RFW) database, on which we firmly validated the racial bias of four commercial APIs and four state-of-the-art (SOTA) algorithms. Then, we further present the solution using deep unsupervised domain adaptation and propose a deep information maximization adaptation network (IMAN) to alleviate this bias by using Caucasian as source domain and other races as target domains. This unsupervised method simultaneously aligns global distribution to decrease race gap at domain-level, and learns the discriminative target representations at cluster level. A novel mutual information loss is proposed to further enhance the discriminative ability of network output without label information. Extensive experiments on RFW, GBU, and IJB-A databases show that IMAN successfully learns features that generalize well across different races and across different databases.",1.0,0.9165626764297485,True,0.3775406687981454,0.647051672613947,True
Contextual Attention for Hand Detection in the Wild,"We present Hand-CNN, a novel convolutional network architecture for detecting hand masks and predicting hand orientations in unconstrained images. Hand-CNN extends MaskRCNN with a novel attention mechanism to incorporate contextual cues in the detection process. This attention mechanism can be implemented as an efficient network module that captures non-local dependencies between features. This network module can be inserted at different stages of an object detection network, and the entire detector can be trained end-to-end. We also introduce large-scale annotated hand datasets containing hands in unconstrained images for training and evaluation. We show that Hand-CNN outperforms existing methods on the newly collected datasets and the publicly available PASCAL VOC human layout dataset. Data and code: https://www3.cs.stonybrook.edu/~cvl/projects/hand_det_attention/",1.0,0.7401353716850281,True,0.3775406687981454,0.5588380202415868,True
Drive&Act: A Multi-Modal Dataset for Fine-Grained Driver Behavior Recognition in Autonomous Vehicles,"We introduce the novel domain-specific Drive&Act benchmark for fine-grained categorization of driver behavior. Our dataset features twelve hours and over 9.6 million frames of people engaged in distractive activities during both, manual and automated driving. We capture color, infrared, depth and 3D body pose information from six views and densely label the videos with a hierarchical annotation scheme, resulting in 83 categories. The key challenges of our dataset are: (1) recognition of fine-grained behavior inside the vehicle cabin; (2) multi-modal activity recognition, focusing on diverse data streams; and (3) a cross view recognition benchmark, where a model handles data from an unfamiliar domain, as sensor type and placement in the cabin can change between vehicles. Finally, we provide challenging benchmarks by adopting prominent methods for video- and body pose-based action recognition.",0.8,0.8872821927070618,True,0.3318122278318339,0.6095472102694478,True
Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks for Defending Adversarial Examples,"Deep Neural Networks (DNNs) for 3D point cloud recognition are vulnerable to adversarial examples, threatening their practical deployment. Despite the many research endeavors have been made to tackle this issue in recent years, the diversity of adversarial examples on 3D point clouds makes them more challenging to defend against than those on 2D images. For examples, attackers can generate adversarial examples by adding, shifting, or removing points. Consequently, existing defense strategies are hard to counter unseen point cloud adversarial examples. In this paper, we first establish a comprehensive, and rigorous point cloud adversarial robustness benchmark to evaluate adversarial robustness, which can provide a detailed understanding of the effects of the defense and attack methods. We then collect existing defense tricks in point cloud adversarial defenses and then perform extensive and systematic experiments to identify an effective combination of these tricks. Furthermore, we propose a hybrid training augmentation methods that consider various types of point cloud adversarial examples to adversarial training, significantly improving the adversarial robustness. By combining these tricks, we construct a more robust defense framework achieving an average accuracy of 83.45% against various attacks, demonstrating its capability to enabling robust learners. Our codebase are open-sourced on: https://github.com/qiufan319/benchmark_pc_attack.git.",1.0,0.8105332851409912,True,0.3775406687981454,0.5940369769695684,True
Regularizing Nighttime Weirdness: Efficient Self-supervised Monocular Depth Estimation in the Dark,"Monocular depth estimation aims at predicting depth from a single image or video. Recently, self-supervised methods draw much attention since they are free of depth annotations and achieve impressive performance on several daytime benchmarks. However, they produce weird outputs in more challenging nighttime scenarios because of low visibility and varying illuminations, which bring weak textures and break brightness-consistency assumption, respectively. To address these problems, in this paper we propose a novel framework with several improvements: (1) we introduce Priors-Based Regularization to learn distribution knowledge from unpaired depth maps and prevent model from being incorrectly trained; (2) we leverage Mapping-Consistent Image Enhancement module to enhance image visibility and contrast while maintaining brightness consistency; and (3) we present Statistics-Based Mask strategy to tune the number of removed pixels within textureless regions, using dynamic statistics. Experimental results demonstrate the effectiveness of each component. Mean-while, our framework achieves remarkable improvements and state-of-the-art results on two nighttime datasets. Code is available at https://github.com/w2kun/RNW.",1.0,0.8654489517211914,True,0.3775406687981454,0.6214948102596685,True
A Simple Recipe to Meta-Learn Forward and Backward Transfer,"Meta-learning holds the potential to provide a general and explicit solution to tackle interference and forgetting in continual learning. However, many popular algorithms introduce expensive and unstable optimization processes with new key hyper-parameters and requirements, hindering their applicability. We propose a new, general, and simple meta-learning algorithm for continual learning (SiM4C) that explicitly optimizes to minimize forgetting and facilitate forward transfer. We show our method is stable, introduces only minimal computational overhead, and can be integrated with any memory-based continual learning algorithm in only a few lines of code. SiM4C meta-learns how to effectively continually learn even on very long task sequences, largely outperforming prior meta-approaches. Naively integrating with existing memory-based algorithms, we also record universal performance benefits and state-of-the-art results across different visual classification benchmarks without introducing new hyper-parameters.",1.0,0.8675852417945862,True,0.3775406687981454,0.6225629552963658,True
"Three-D Safari: Learning to Estimate Zebra Pose, Shape, and Texture From Images “In the Wild”","We present the first method to perform automatic 3D pose, shape and texture capture of animals from images acquired in-the-wild. In particular, we focus on the problem of capturing 3D information about Grevy's zebras from a collection of images. The Grevy's zebra is one of the most endangered species in Africa, with only a few thousand individuals left. Capturing the shape and pose of these animals can provide biologists and conservationists with information about animal health and behavior. In contrast to research on human pose, shape and texture estimation, training data for endangered species is limited, the animals are in complex natural scenes with occlusion, they are naturally camouflaged, travel in herds, and look similar to each other. To overcome these challenges, we integrate the recent SMAL animal model into a network-based regression pipeline, which we train end-to-end on synthetically generated images with pose, shape, and background variation. Going beyond state-of-the-art methods for human shape and pose estimation, our method learns a shape space for zebras during training. Learning such a shape space from images using only a photometric loss is novel, and the approach can be used to learn shape in other settings with limited 3D supervision. Moreover, we couple 3D pose and shape prediction with the task of texture synthesis, obtaining a full texture map of the animal from a single image. We show that the predicted texture map allows a novel per-instance unsupervised optimization over the network features. This method, SMALST (SMAL with learned Shape and Texture) goes beyond previous work, which assumed manual keypoints and/or segmentation, to regress directly from pixels to 3D animal shape, pose and texture.",1.0,0.9197513461112976,True,0.3775406687981454,0.6486460074547216,True
Patch2CAD: Patchwise Embedding Learning for In-the-Wild Shape Retrieval from a Single Image,"3D perception of object shapes from RGB image input is fundamental towards semantic scene understanding, grounding image-based perception in our spatially 3dimensional real-world environments. To achieve a mapping between image views of objects and 3D shapes, we leverage CAD model priors from existing large-scale databases, and propose a novel approach towards constructing a joint embedding space between 2D images and 3D CAD models in a patch-wise fashion – establishing correspondences between patches of an image view of an object and patches of CAD geometry. This enables part similarity reasoning for retrieving similar CADs to a new image view without exact matches in the database. Our patch embedding provides more robust CAD retrieval for shape estimation in our end-to-end estimation of CAD model shape and pose for detected objects in a single input image. Experiments on in-the-wild, complex imagery from ScanNet show that our approach is more robust than state of the art in real-world scenarios without any exact CAD matches.",1.0,0.8100548982620239,True,0.3775406687981454,0.5937977835300847,True
Be Everywhere - Hear Everything (BEE): Audio Scene Reconstruction by Sparse Audio-Visual Samples,"Fully immersive and interactive audio-visual scenes are dynamic such that the listeners and the sound emitters move and interact with each other. Reconstruction of an immersive sound experience, as it happens in the scene, requires detailed reconstruction of the audio perceived by the listener at an arbitrary location. The audio at the listener location is a complex outcome of sound propagation through the scene geometry and interacting with surfaces and also the locations of the emitters and the sounds they emit. Due to these aspects, detailed audio reconstruction requires extensive sampling of audio at any potential listener location. This is usually difficult to implement in realistic real-time dynamic scenes. In this work, we propose to circumvent the need for extensive sensors by leveraging audio and visual samples from only a handful of A/V receivers placed in the scene. In particular, we introduce a novel method and end-to-end integrated rendering pipeline which allows the listener to be everywhere and hear everything (BEE) in a dynamic scene in real-time. BEE reconstructs the audio with two main modules, Joint Audio-Visual Representation, and Integrated Rendering Head. The first module extracts the informative audio-visual features of the scene from sparse A/V reference samples, while the second module integrates the audio samples with learned time-frequency transformations to obtain the target sound. Our experiments indicate that BEE outperforms existing methods by a large margin in terms of quality of sound reconstruction, can generalize to scenes not seen in training and runs in real-time speed.",0.8,0.8450427651405334,True,0.3318122278318339,0.5884274964861836,True
COOL-CHIC: Coordinate-based Low Complexity Hierarchical Image Codec,"We introduce COOL-CHIC, a Coordinate-based Low Complexity Hierarchical Image Codec. It is a learned alternative to autoencoders with 629 parameters and 680 multiplications per decoded pixel. COOL-CHIC offers compression performance close to modern conventional MPEG codecs such as HEVC and is competitive with popular autoencoder-based systems. This method is inspired by Coordinate-based Neural Representations, where an image is represented as a learned function which maps pixel coordinates to RGB values. The parameters of the mapping function are then sent using entropy coding. At the receiver side, the compressed image is obtained by evaluating the mapping function for all pixel coordinates. COOL-CHIC implementation is made open-source1.",1.0,0.7881661653518677,True,0.3775406687981454,0.5828534170750066,True
Learning Discriminative Data Fitting Functions for Blind Image Deblurring,"Solving blind image deblurring usually requires defining a data fitting function and image priors. While existing algorithms mainly focus on developing image priors for blur kernel estimation and non-blind deconvolution, only a few methods consider the effect of data fitting functions. In contrast to the state-of-the-art methods that use a single or a fixed data fitting term, we propose a data-driven approach to learn effective data fitting functions from a large set of motion blurred images with the associated ground truth blur kernels. The learned data fitting function facilitates estimating accurate blur kernels for generic scenes and domain-specific problems with corresponding image priors. In addition, we extend the learning approach for data fitting function to latent image restoration and nonuniform deblurring. Extensive experiments on challenging motion blurred images demonstrate the proposed algorithm performs favorably against the state-of-the-art methods.",1.0,0.7446891069412231,True,0.3775406687981454,0.5611148878696843,True
3DHacker: Spectrum-based Decision Boundary Generation for Hard-label 3D Point Cloud Attack,"With the maturity of depth sensors, the vulnerability of 3D point cloud models has received increasing attention in various applications such as autonomous driving and robot navigation. Previous 3D adversarial attackers either follow the white-box setting to iteratively update the coordinate perturbations based on gradients, or utilize the output model logits to estimate noisy gradients in the black-box setting. However, these attack methods are hard to be deployed in real-world scenarios since realistic 3D applications will not share any model details to users. Therefore, we explore a more challenging yet practical 3D attack setting, i.e., attacking point clouds with black-box hard labels, in which the attacker can only have access to the prediction label of the input. To tackle this setting, we propose a novel 3D attack method, termed 3D Hard-label attacker (3DHacker), based on the developed decision boundary algorithm to generate adversarial samples solely with the knowledge of class labels. Specifically, to construct the class-aware model decision boundary, 3DHacker first randomly fuses two point clouds of different classes in the spectral domain to craft their intermediate sample with high imperceptibility, then projects it onto the decision boundary via binary search. To restrict the final perturbation size, 3DHacker further introduces an iterative optimization strategy to move the intermediate sample along the decision boundary for generating adversarial point clouds with smallest trivial perturbations. Extensive evaluations show that, even in the challenging hard-label setting, 3DHacker still competitively outperforms existing 3D attacks regarding the attack performance as well as adversary quality.",1.0,0.9017146229743958,True,0.3775406687981454,0.6396276458862706,True
Beyond Planar Symmetry: Modeling Human Perception of Reflection and Rotation Symmetries in the Wild,"Humans take advantage of real world symmetries for various tasks, yet capturing their superb symmetry perception mechanism with a computational model remains elusive. Motivated by a new study demonstrating the extremely high inter-person accuracy of human perceived symmetries in the wild, we have constructed the first deeplearning neural network for reflection and rotation symmetry detection (Sym-NET), trained on photos from MS-COCO (Microsoft-Common Object in COntext) dataset with nearly 11K consistent symmetry-labels from more than 400 human observers. We employ novel methods to convert discrete human labels into symmetry heatmaps, capture symmetry densely in an image and quantitatively evaluate Sym-NET against multiple existing computer vision algorithms. On CVPR 2013 symmetry competition testsets and unseen MSCOCO photos, Sym-NET significantly outperforms all other competitors. Beyond mathematically well-defined symmetries on a plane, Sym-NET demonstrates abilities to identify viewpoint-varied 3D symmetries, partially occluded symmetrical objects, and symmetries at a semantic level.",1.0,0.7376309633255005,True,0.3775406687981454,0.557585816061823,True
Meta-Learning with Task-Adaptive Loss Function for Few-Shot Learning,"In few-shot learning scenarios, the challenge is to generalize and perform well on new unseen examples when only very few labeled examples are available for each task. Model-agnostic meta-learning (MAML) has gained the popularity as one of the representative few-shot learning methods for its flexibility and applicability to diverse problems. However, MAML and its variants often resort to a simple loss function without any auxiliary loss function or regularization terms that can help achieve better generalization. The problem lies in that each application and task may require different auxiliary loss function, especially when tasks are diverse and distinct. Instead of attempting to hand-design an auxiliary loss function for each application and task, we introduce a new meta-learning framework with a loss function that adapts to each task. Our proposed framework, named Meta-Learning with Task-Adaptive Loss Function (MeTAL), demonstrates the effectiveness and the flexibility across various domains, such as few-shot classification and few-shot regression.",1.0,0.7342311143875122,True,0.3775406687981454,0.5558858915928289,True
Aha! Adaptive History-driven Attack for Decision-based Black-box Models,"The decision-based black-box attack means to craft adversarial examples with only the top-1 label of the victim model available. A common practice is to start from a large perturbation and then iteratively reduce it with a deterministic direction and a random one while keeping it adversarial. The limited information obtained from each query and inefficient direction sampling impede attack efficiency, making it hard to obtain a small enough perturbation within a limited number of queries. To tackle this problem, we propose a novel attack method termed Adaptive History-driven Attack (AHA) which gathers information from all historical queries as the prior for current sampling. Moreover, to balance between the deterministic direction and the random one, we dynamically adjust the coefficient according to the ratio of the actual magnitude reduction to the expected one. Such a strategy improves the success rate of queries during optimization, letting adversarial examples move swiftly along the decision boundary. Our method can also integrate with subspace optimization like dimension reduction to further improve efficiency. Extensive experiments on both ImageNet and CelebA datasets demonstrate that our method achieves at least 24.3% lower magnitude of perturbation on average with the same number of queries. Finally, we prove the practical potential of our method by evaluating it on popular defense methods and a real-world system provided by MEGVII Face++.",1.5,0.9175390005111694,True,0.5,0.7087695002555847,True
In-the-Wild Single Camera 3D Reconstruction Through Moving Water Surfaces,"We present a method for reconstructing the 3D shape of underwater environments from a single, stationary camera placed above the water. We propose a novel differentiable framework, which, to our knowledge, is the first single-camera solution that is capable of simultaneously retrieving the structure of dynamic water surfaces and static underwater scene geometry in the wild. This framework integrates ray casting of Snell’s law at the refractive interface, multi-view triangulation and specially designed loss functions.Our method is calibration-free, and thus it is easy to collect data outdoors in uncontrolled environments. Experimental results show that our method is able to realize robust and quality reconstructions on a variety of scenes, both in a laboratory environment and in the wild, and even in a salt water environment. We believe the method is promising for applications in surveying and environmental monitoring.",1.0,0.9218987226486206,True,0.3775406687981454,0.6497196957233831,True
The surprising impact of mask-head architecture on novel class segmentation,"Instance segmentation models today are very accurate when trained on large annotated datasets, but collecting mask annotations at scale is prohibitively expensive. We address the partially supervised instance segmentation problem in which one can train on (significantly cheaper) bounding boxes for all categories but use masks only for a subset of categories. In this work, we focus on a popular family of models which apply differentiable cropping to a feature map and predict a mask based on the resulting crop. Under this family, we study Mask R-CNN and discover that instead of its default strategy of training the mask-head with a combination of proposals and groundtruth boxes, training the mask-head with only groundtruth boxes dramatically improves its performance on novel classes. This training strategy also allows us to take advantage of alternative mask-head architectures, which we exploit by replacing the typical mask-head of 2-4 layers with significantly deeper off-the-shelf architectures (e.g. ResNet, Hourglass models). While many of these architectures perform similarly when trained in fully supervised mode, our main finding is that they can generalize to novel classes in dramatically different ways. We call this ability of mask-heads to generalize to unseen classes the strong mask generalization effect and show that without any specialty modules or losses, we can achieve state-of-the-art results in the partially supervised COCO instance segmentation benchmark. Finally, we demonstrate that our effect is general, holding across underlying detection methodologies (including anchor-based, anchor-free or no detector at all) and across different backbone networks. Code and pre-trained models are available at https://git.io/deepmac.",1.0,0.9241071343421936,True,0.3775406687981454,0.6508239015701696,True
FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods,"The field of explainable artificial intelligence (XAI) aims to uncover the inner workings of complex deep neural models. While being crucial for safety-critical domains, XAI inherently lacks ground-truth explanations, making its automatic evaluation an unsolved problem. We address this challenge by proposing a novel synthetic vision dataset, named FunnyBirds, and accompanying automatic evaluation protocols. Our dataset allows performing semantically meaningful image interventions, e.g., removing individual object parts, which has three important implications. First, it enables analyzing explanations on a part level, which is closer to human comprehension than existing methods that evaluate on a pixel level. Second, by comparing the model output for inputs with removed parts, we can estimate ground-truth part importances that should be reflected in the explanations. Third, by mapping individual explanations into a common space of part importances, we can analyze a variety of different explanation types in a single common framework. Using our tools, we report results for 24 different combinations of neural models and XAI methods, demonstrating the strengths and weaknesses of the assessed methods in a fully automatic and systematic manner.",2.0,0.9948142766952515,True,0.6224593312018546,0.808636803948553,True
Viewset Diffusion: (0-)Image-Conditioned 3D Generative Models from 2D Data,"We present Viewset Diffusion, a diffusion-based generator that outputs 3D objects while only using multi-view 2D data for supervision. We note that there exists a one-to-one mapping between viewsets, i.e., collections of several 2D views of an object, and 3D models. Hence, we train a diffusion model to generate viewsets, but design the neural network generator to reconstruct internally corresponding 3D models, thus generating those too. We fit a diffusion model to a large number of viewsets for a given category of objects. The resulting generator can be conditioned on zero, one or more input views. Conditioned on a single view, it performs 3D reconstruction accounting for the ambiguity of the task and allowing to sample multiple solutions compatible with the input. The model performs reconstruction efficiently, in a feed-forward manner, and is trained using only rendering losses using as few as three views per viewset. Project page: szymanowiczs.github.io/viewset-diffusion.",0.8,0.8287181258201599,True,0.3318122278318339,0.5802651768259969,True
SPEC: Seeing People in the Wild with an Estimated Camera,"Due to the lack of camera parameter information for in-the-wild images, existing 3D human pose and shape (HPS) estimation methods make several simplifying assumptions: weak-perspective projection, large constant focal length, and zero camera rotation. These assumptions often do not hold and we show, quantitatively and qualitatively, that they cause errors in the reconstructed 3D shape and pose. To address this, we introduce SPEC, the first in-the-wild 3D HPS method that estimates the perspective camera from a single image and employs this to reconstruct 3D human bodies more accurately. First, we train a neural network to estimate the field of view, camera pitch, and roll given an input image. We employ novel losses that improve the calibration accuracy over previous work. We then train a novel network that concatenates the camera calibration to the image features and uses these together to regress 3D body shape and pose. SPEC is more accurate than the prior art on the standard benchmark (3DPW) as well as two new datasets with more challenging camera views and varying focal lengths. Specifically, we create a new photorealistic synthetic dataset (SPEC-SYN) with ground truth 3D bodies and a novel in-the-wild dataset (SPEC-MTP) with calibration and high-quality reference bodies. Code and datasets are available for research purposes at https://spec.is.tue.mpg.de/.",1.0,0.7235924601554871,True,0.3775406687981454,0.5505665644768163,True
EMDB: The Electromagnetic Database of Global 3D Human Pose and Shape in the Wild,"We present EMDB, the Electromagnetic Database of Global 3D Human Pose and Shape in the Wild. EMDB is a novel dataset that contains high-quality 3D SMPL pose and shape parameters with global body and camera trajectories for in-the-wild videos. We use body-worn, wireless electromagnetic (EM) sensors and a hand-held iPhone to record a total of 58 minutes of motion data, distributed over 81 indoor and outdoor sequences and 10 participants. Together with accurate body poses and shapes, we also provide global camera poses and body root trajectories. To construct EMDB, we propose a multi-stage optimization procedure, which first fits SMPL to the 6-DoF EM measurements and then refines the poses via image observations. To achieve high-quality results, we leverage a neural implicit avatar model to reconstruct detailed human surface geometry and appearance, which allows for improved alignment and smoothness via a dense pixel-level objective. Our evaluations, conducted with a multi-view volumetric capture system, indicate that EMDB has an expected accuracy of 2.3 cm positional and 10.6 degrees angular error, surpassing the accuracy of previous in-the-wild datasets. We evaluate existing state-of-the-art monocular RGB methods for camera-relative and global pose estimation on EMDB. EMDB is publicly available under https://ait.ethz.ch/emdb.",1.0,0.7294382452964783,True,0.3775406687981454,0.5534894570473119,True
Building Bridge Across the Time: Disruption and Restoration of Murals In the Wild,"In this paper, we focus on the mural-restoration task, which aims to detect damaged regions in the mural and repaint them automatically. Different from traditional image restoration tasks like in/out/blind-painting and image renovation, the corrupted mural suffers from more complicated degradation. However, existing mural-restoration methods and datasets still focus on simple degradation like masking. Such a significant gap prevents mural-restoration from being applied to real scenarios. To fill this gap, in this work, we propose a systematic framework to simulate the physical process for damaged murals and provide a new benchmark dataset for mural-restoration. Limited by the simplification of the data synthesis process, the previous mural-restoration methods suffer from poor performance in our proposed dataset. To handle this problem, we propose the Attention Diffusion Framework (ADF) for this challenging task. Within the framework, a damage attention map module is proposed to estimate the damage extent. Facing the diversity of defects, we propose a series of loss functions to choose repair strategies adaptively. Finally, experimental results support the effectiveness of the proposed framework in terms of both mural synthesis and restoration.",1.0,0.7833973169326782,True,0.3775406687981454,0.5804689928654119,True
Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images,"Weird, unusual, and uncanny images pique the curiosity of observers because they challenge commonsense. For example, an image released during the 2022 world cup depicts the famous soccer stars Lionel Messi and Cristiano Ronaldo playing chess, which playfully violates our expectation that their competition should occur on the football field.1 Humans can easily recognize and interpret these unconventional images, but can AI models do the same? We introduce WHOOPS!, a new dataset and benchmark for visual commonsense. The dataset is comprised of purposefully commonsense-defying images created by designers using publicly-available image generation tools like Midjourney. We consider several tasks posed over the dataset. In addition to image captioning, cross-modal matching, and visual question answering, we introduce a difficult explanation generation task, where models must identify and explain why a given image is unusual. Our results show that state-of-the-art models such as GPT3 and BLIP2 still lag behind human performance on WHOOPS!. We hope our dataset will inspire the development of AI models with stronger visual commonsense reasoning abilities. 2",1.5,0.9631064534187317,True,0.5,0.7315532267093658,True
Interactive Sketch & Fill: Multiclass Sketch-to-Image Translation,"We propose an interactive GAN-based sketch-to-image translation method that helps novice users easily create images of simple objects. The user starts with a sparse sketch and a desired object category, and the network then recommends its plausible completion(s) and shows a corresponding synthesized image. This enables a feedback loop, where the user can edit the sketch based on the network's recommendations, while the network is able to better synthesize the image that the user might have in mind. In order to use a single model for a wide array of object classes, we introduce a gating-based approach for class conditioning, which allows us to generate distinct classes without feature mixing, from a single generator network.",0.8,0.900734007358551,True,0.3318122278318339,0.6162731175951924,True
Rosetta Neurons: Mining the Common Units in a Model Zoo,"Do different neural networks, trained for various vision tasks, share some common representations? In this paper, we demonstrate the existence of common features we call ""Rosetta Neurons"" across a range of models with different architectures, different tasks (generative and discriminative), and different types of supervision (class-supervised, text-supervised, self-supervised). We present an algorithm for mining a dictionary of Rosetta Neurons across several popular vision models: Class Supervised-ResNet50, DINO-ResNet50, DINO-ViT, MAE, CLIP-ResNet50, Big-GAN, StyleGAN-2, StyleGAN-XL. Our findings suggest that certain visual concepts and structures are inherently embedded in the natural world and can be learned by different models regardless of the specific task or architecture, and without the use of semantic labels. We can visualize shared concepts directly due to generative models included in our analysis. The Rosetta Neurons facilitate model-to-model translation enabling various inversion-based manipulations, including cross-class alignments, shifting, zooming, and more, without the need for specialized training.",1.0,0.776400625705719,True,0.3775406687981454,0.5769706472519323,True
Dynamic Surface Function Networks for Clothed Human Bodies,"We present a novel method for temporal coherent reconstruction and tracking of clothed humans. Given a monocular RGB-D sequence, we learn a person-specific body model which is based on a dynamic surface function network. To this end, we explicitly model the surface of the person using a multi-layer perceptron (MLP) which is embedded into the canonical space of the SMPL body model. With classical forward rendering, the represented surface can be rasterized using the topology of a template mesh. For each surface point of the template mesh, the MLP is evaluated to predict the actual surface location. To handle pose-dependent deformations, the MLP is conditioned on the SMPL pose parameters. We show that this surface representation as well as the pose parameters can be learned in a self-supervised fashion using the principle of analysis-by-synthesis and differentiable rasterization. As a result, we are able to reconstruct a temporally coherent mesh sequence from the input data. The underlying surface representation can be used to synthesize new animations of the reconstructed person including pose-dependent deformations.",1.0,0.8188786506652832,True,0.3775406687981454,0.5982096597317144,True
SAGA: Spectral Adversarial Geometric Attack on 3D Meshes,"A triangular mesh is one of the most popular 3D data representations. As such, the deployment of deep neural networks for mesh processing is widely spread and is increasingly attracting more attention. However, neural networks are prone to adversarial attacks, where carefully crafted inputs impair the model’s functionality. The need to explore these vulnerabilities is a fundamental factor in the future development of 3D-based applications. Recently, mesh attacks were studied on the semantic level, where classifiers are misled to produce wrong predictions. Nevertheless, mesh surfaces possess complex geometric attributes beyond their semantic meaning, and their analysis often includes the need to encode and reconstruct the geometry of the shape.We propose a novel framework for a geometric adversarial attack on a 3D mesh autoencoder. In this setting, an adversarial input mesh deceives the autoencoder by forcing it to reconstruct a different geometric shape at its output. The malicious input is produced by perturbing a clean shape in the spectral domain. Our method leverages the spectral decomposition of the mesh along with additional mesh-related properties to obtain visually credible results that consider the delicacy of surface distortions1.",1.0,0.8037775754928589,True,0.3775406687981454,0.5906591221455022,True
GlowGAN: Unsupervised Learning of HDR Images from LDR Images in the Wild,"Most in-the-wild images are stored in Low Dynamic Range (LDR) form, serving as a partial observation of the High Dynamic Range (HDR) visual world. Despite limited dynamic range, these LDR images are often captured with different exposures, implicitly containing information about the underlying HDR image distribution. Inspired by this intuition, in this work we present, to the best of our knowledge, the first method for learning a generative model of HDR images from in-the-wild LDR image collections in a fully unsupervised manner. The key idea is to train a generative adversarial network (GAN) to generate HDR images which, when projected to LDR under various exposures, are indistinguishable from real LDR images. The projection from HDR to LDR is achieved via a camera model that captures the stochasticity in exposure and camera response function. Experiments show that our method GlowGAN can synthesize photorealistic HDR images in many challenging cases such as landscapes, lightning, or windows, where previous supervised generative models produce overexposed images. With the assistance of GlowGAN, we showcase the novel application of unsupervised inverse tone mapping (GlowGAN-ITM) that sets a new paradigm in this field. Unlike previous methods that gradually complete information from LDR input, GlowGAN-ITM searches the entire HDR image manifold modeled by GlowGAN for the HDR images which can be mapped back to the LDR input. GlowGAN-ITM achieves more realistic reconstruction of overexposed regions compared to state-of-the-art supervised learning models, despite not requiring HDR images or paired multi-exposure images for training.",1.0,0.7354395389556885,True,0.3775406687981454,0.556490103876917,True
MagicFusion: Boosting Text-to-Image Generation Performance by Fusing Diffusion Models,"The advent of open-source AI communities has produced a cornucopia of powerful text-guided diffusion models that are trained on various datasets. While few explorations have been conducted on ensembling such models to combine their strengths. In this work, we propose a simple yet effective method called Saliency-aware Noise Blending (SNB) that can empower the fused text-guided diffusion models to achieve more controllable generation. Specifically, we experimentally find that the responses of classifier-free guidance are highly related to the saliency of generated images. Thus we propose to trust different models in their areas of expertise by blending the predicted noises of two diffusion models in a saliency-aware manner. SNB is training-free and can be completed within a DDIM sampling process. Additionally, it can automatically align the semantics of two noise spaces without requiring additional annotations such as masks. Extensive experiments show the impressive effectiveness of SNB in various applications. The project page is available at https://magicfusion.github.io/.",1.0,0.8639783263206482,True,0.3775406687981454,0.6207594975593969,True
SkeleTR: Towards Skeleton-based Action Recognition in the Wild,"We present SkeleTR, a new framework for skeleton-based action recognition. In contrast to prior work, which focuses mainly on controlled environments, we target more general scenarios that typically involve a variable number of people and various forms of interaction between people. SkeleTR works with a two-stage paradigm. It first models the intra-person skeleton dynamics for each skeleton sequence with graph convolutions, and then uses stacked Transformer encoders to capture person interactions that are important for action recognition in general scenarios. To mitigate the negative impact of inaccurate skeleton associations, SkeleTR takes relative short skeleton sequences as input and increases the number of sequences. As a unified solution, SkeleTR can be directly applied to multiple skeleton-based action tasks, including video-level action classification, instance-level action detection, and group-level activity recognition. It also enables transfer learning and joint training across different action tasks and datasets, which result in performance improvement. When evaluated on various skeleton-based action recognition benchmarks, SkeleTR achieves the state-of-the-art performance.",1.0,0.7445849180221558,True,0.3775406687981454,0.5610627934101506,True
How to Design a Three-Stage Architecture for Audio-Visual Active Speaker Detection in the Wild,"Successful active speaker detection requires a three-stage pipeline: (i) audio-visual encoding for all speakers in the clip, (ii) inter-speaker relation modeling between a reference speaker and the background speakers within each frame, and (iii) temporal modeling for the reference speaker. Each stage of this pipeline plays an important role for the final performance of the created architecture. Based on a series of controlled experiments, this work presents several practical guidelines for audio-visual active speaker detection. Correspondingly, we present a new architecture called ASDNet, which achieves a new state-of-the-art on the AVA-ActiveSpeaker dataset with a mAP of 93.5% outperforming the second best with a large margin of 4.7%. Our code and pretrained models are publicly available 1.",1.0,0.8225361704826355,True,0.3775406687981454,0.6000384196403905,True
Learning A Room with the Occ-SDF Hybrid: Signed Distance Function Mingled with Occupancy Aids Scene Representation,"Implicit neural rendering, using signed distance function (SDF) representation with geometric priors like depth or surface normal, has made impressive strides in the surface reconstruction of large-scale scenes. However, applying this method to reconstruct a room-level scene from images may miss structures in low-intensity areas and/or small, thin objects. We have conducted experiments on three datasets to identify limitations of the original color rendering loss and priors-embedded SDF scene representation.Our findings show that the color rendering loss creates an optimization bias against low-intensity areas, resulting in gradient vanishing and leaving these areas unoptimized. To address this issue, we propose a feature-based color rendering loss that utilizes non-zero feature values to bring back optimization signals. Additionally, the SDF representation can be influenced by objects along a ray path, disrupting the monotonic change of SDF values when a single object is present. Accordingly, we explore using the occupancy representation, which encodes each point separately and is unaffected by objects along a querying ray. Our experimental results demonstrate that the joint forces of the feature-based rendering loss and Occ-SDF hybrid representation scheme can provide high-quality reconstruction results, especially in challenging room-level scenarios. The code is available at https://github.com/shawLyu/Occ-SDF-Hybrid",1.0,0.8029333353042603,True,0.3775406687981454,0.5902370020512029,True
Zolly: Zoom Focal Length Correctly for Perspective-Distorted Human Mesh Reconstruction,"As it is hard to calibrate single-view RGB images in the wild, existing 3D human mesh reconstruction (3DHMR) methods either use a constant large focal length or estimate one based on the background environment context, which can not tackle the problem of the torso, limb, hand or face distortion caused by perspective camera projection when the camera is close to the human body. The naive focal length assumptions can harm this task with the incorrectly formulated projection matrices. To solve this, we propose Zolly, the first 3DHMR method focusing on perspective-distorted images. Our approach begins with analysing the reason for perspective distortion, which we find is mainly caused by the relative location of the human body to the camera center. We propose a new camera model and a novel 2D representation, termed distortion image, which describes the 2D dense distortion scale of the human body. We then estimate the distance from distortion scale features rather than environment context features. Afterwards, We integrate the distortion feature with image features to reconstruct the body mesh. To formulate the correct projection matrix and locate the human body position, we simultaneously use perspective and weak-perspective projection loss. Since existing datasets could not handle this task, we propose the first synthetic dataset PDHuman and extend two real-world datasets tailored for this task, all containing perspective-distorted human images. Extensive experiments show that Zolly outperforms existing state-of-the-art methods on both perspective-distorted datasets and the standard benchmark (3DPW). Code and dataset will be released at https://wenjiawang0312.github.io/projects/zolly/.",1.0,0.8467156887054443,True,0.3775406687981454,0.6121281787517949,True
SHIFT3D: Synthesizing Hard Inputs For Tricking 3D Detectors,"We present SHIFT3D, a differentiable pipeline for generating 3D shapes that are structurally plausible yet challenging to 3D object detectors. In safety-critical applications like autonomous driving, discovering such novel challenging objects can offer insight into unknown vulnerabilities of 3D detectors. By representing objects with a signed distanced function (SDF), we show that gradient error signals allow us to smoothly deform the shape or pose of a 3D object in order to confuse a downstream 3D detector. Importantly, the objects generated by SHIFT3D physically differ from the baseline object yet retain a semantically recognizable shape. Our approach provides interpretable failure modes for modern 3D object detectors, and can aid in preemptive discovery of potential safety risks within 3D perception systems before these risks become critical failures.",1.0,0.8329653143882751,True,0.3775406687981454,0.6052529915932103,True
PourIt!: Weakly-supervised Liquid Perception from a Single Image for Visual Closed-Loop Robotic Pouring,"Liquid perception is critical for robotic pouring tasks. It usually requires the robust visual detection of flowing liquid. However, while recent works have shown promising results in liquid perception, they typically require labeled data for model training, a process that is both time-consuming and reliant on human labor. To this end, this paper proposes a simple yet effective framework PourIt!, to serve as a tool for robotic pouring tasks. We design a simple data collection pipeline that only needs image-level labels to reduce the reliance on tedious pixel-wise annotations. Then, a binary classification model is trained to generate Class Activation Map (CAM) that focuses on the visual difference between these two kinds of collected data, i.e., the existence of liquid drop or not. We also devise a feature contrast strategy to improve the quality of the CAM, thus entirely and tightly covering the actual liquid regions. Then, the container pose is further utilized to facilitate the 3D point cloud recovery of the detected liquid region. Finally, the liquid-to-container distance is calculated for visual closed-loop control of the physical robot. To validate the effectiveness of our proposed method, we also contribute a novel dataset for our task and name it PourIt! dataset. Extensive results on this dataset and physical Franka robot have shown the utility and effectiveness of our method in the robotic pouring tasks. Our dataset, code and pre-trained models will be available on the project page 1.",1.3,0.7064295411109924,True,0.45016600268752216,0.5782977718992572,True
MoTIF: Learning Motion Trajectories with Local Implicit Neural Functions for Continuous Space-Time Video Super-Resolution,"This work addresses continuous space-time video super-resolution (C-STVSR) that aims to up-scale an input video both spatially and temporally by any scaling factors. One key challenge of C-STVSR is to propagate information temporally among the input video frames. To this end, we introduce a space-time local implicit neural function. It has the striking feature of learning forward motion for a continuum of pixels. We motivate the use of forward motion from the perspective of learning individual motion trajectories, as opposed to learning a mixture of motion trajectories with backward motion. To ease motion interpolation, we encode sparsely sampled forward motion extracted from the input video as the contextual input. Along with a reliability-aware splatting and decoding scheme, our framework, termed MoTIF, achieves the state-of-the-art performance on C-STVSR. The source code of MoTIF is available at https://github.com/sichun233746/MoTIF.",1.0,0.7259124517440796,True,0.3775406687981454,0.5517265602711126,True
A Dataset of Multi-Illumination Images in the Wild,"Collections of images under a single, uncontrolled illumination have enabled the rapid advancement of core computer vision tasks like classification, detection, and segmentation. But even with modern learning techniques, many inverse problems involving lighting and material understanding remain too severely ill-posed to be solved with single-illumination datasets. The data simply does not contain the necessary supervisory signals. Multi-illumination datasets are notoriously hard to capture, so the data is typically collected at small scale, in controlled environments, either using multiple light sources, or robotic gantries. This leads to image collections that are not representative of the variety and complexity of real world scenes. We introduce a new multi-illumination dataset of more than 1000 real scenes, each captured in high dynamic range and high resolution, under 25 lighting conditions. We demonstrate the richness of this dataset by training state-of-the-art models for three challenging applications: single-image illumination estimation, image relighting, and mixed-illuminant white balance.",1.0,0.7376221418380737,True,0.3775406687981454,0.5575814053181096,True
LoLep: Single-View View Synthesis with Locally-Learned Planes and Self-Attention Occlusion Inference,"We propose a novel method, LoLep, which regresses Locally-Learned planes from a single RGB image to represent scenes accurately, thus generating better novel views. Without the depth information, regressing appropriate plane locations is a challenging problem. To solve this issue, we pre-partition the disparity space into bins and design a disparity sampler to regress local offsets for multiple planes in each bin. However, only using such a sampler makes the network not convergent; we further propose two optimizing strategies that combine with different disparity distributions of datasets and propose an occlusion-aware reprojection loss as a simple yet effective geometric supervision technique. We also introduce a self-attention mechanism to improve occlusion inference and present a Block-Sampling Self-Attention (BS-SA) module to address the problem of applying self-attention to large feature maps. We demonstrate the effectiveness of our approach and generate state-of-the-art results on different datasets. Compared to MINE, our approach has an LPIPS reduction of 4.8%∼9.0% and an RV reduction of 74.9% ~ 83.5%. We also evaluate the performance on real-world images and demonstrate the benefits.",1.0,0.7931833863258362,True,0.3775406687981454,0.5853620275619908,True
A new dog learns old tricks: RL finds classic optimization algorithms,"We ask whether reinforcement learning can find theoretically optimal algorithms for online optimization problems, and introduce a novel learning framework in this setting. To answer this question, we introduce a number of key ideas from traditional algorithms and complexity theory. Specifically, we introduce the concept of adversarial distributions (universal and high-entropy training sets), which are distributions that encourage the learner to find algorithms that work well in the worst case. We test our new ideas on the AdWords problem, the online knapsack problem, and the secretary problem. Our results indicate that the models have learned behaviours that are consistent with the optimal algorithms for these problems derived using the online primal-dual framework.",1.0,0.9300817847251892,True,0.3775406687981454,0.6538112267616674,True
Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of On-Screen Sounds,"Recent progress in deep learning has enabled many advances in sound separation and visual scene understanding. However, extracting sound sources which are apparent in natural videos remains an open problem. In this work, we present AudioScope, a novel audio-visual sound separation framework that can be trained without supervision to isolate on-screen sound sources from real in-the-wild videos. Prior audio-visual separation work assumed artificial limitations on the domain of sound classes (e.g., to speech or music), constrained the number of sources, and required strong sound separation or visual segmentation labels. AudioScope overcomes these limitations, operating on an open domain of sounds, with variable numbers of sources, and without labels or prior visual segmentation. The training procedure for AudioScope uses mixture invariant training (MixIT) to separate synthetic mixtures of mixtures (MoMs) into individual sources, where noisy labels for mixtures are provided by an unsupervised audio-visual coincidence model. Using the noisy labels, along with attention between video and audio features, AudioScope learns to identify audio-visual similarity and to suppress off-screen sounds. We demonstrate the effectiveness of our approach using a dataset of video clips extracted from open-domain YFCC100m video data. This dataset contains a wide diversity of sound classes recorded in unconstrained conditions, making the application of previous methods unsuitable. For evaluation and semi-supervised experiments, we collected human labels for presence of on-screen and off-screen sounds on a small subset of clips.",1.0,0.9284965991973877,True,0.3775406687981454,0.6530186339977666,True
(Certified!!) Adversarial Robustness for Free!,"In this paper we show how to achieve state-of-the-art certified adversarial robustness to 2-norm bounded perturbations by relying exclusively on off-the-shelf pretrained models. To do so, we instantiate the denoised smoothing approach of Salman et al. 2020 by combining a pretrained denoising diffusion probabilistic model and a standard high-accuracy classifier. This allows us to certify 71% accuracy on ImageNet under adversarial perturbations constrained to be within an 2-norm of 0.5, an improvement of 14 percentage points over the prior certified SoTA using any approach, or an improvement of 30 percentage points over denoised smoothing. We obtain these results using only pretrained diffusion models and image classifiers, without requiring any fine tuning or retraining of model parameters.",2.1,0.9710876941680908,True,0.6456563062257954,0.8083720001969431,True
"Auxiliary Task Update Decomposition: the Good, the Bad and the neutral","While deep learning has been very beneficial in data-rich settings, tasks with smaller training set often resort to pre-training or multitask learning to leverage data from other tasks. In this case, careful consideration is needed to select tasks and model parameterizations such that updates from the auxiliary tasks actually help the primary task. We seek to alleviate this burden by formulating a model-agnostic framework that performs fine-grained manipulation of the auxiliary task gradients. We propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions differently depending on their impact on the problem of interest. We present a novel and efficient algorithm for that purpose and show its advantage in practice. Our method leverages efficient automatic differentiation procedures and randomized singular value decomposition for scalability. We show that our framework is generic and encompasses some prior work as particular cases. Our approach consistently outperforms strong and widely used baselines when leveraging out-of-distribution data for Text and Image classification tasks.",1.8,0.921068012714386,True,0.574442516811659,0.7477552647630226,True
When Data Geometry Meets Deep Function: Generalizing Offline Reinforcement Learning,"In offline reinforcement learning (RL), one detrimental issue to policy learning is the error accumulation of deep Q function in out-of-distribution (OOD) areas. Unfortunately, existing offline RL methods are often over-conservative, inevitably hurting generalization performance outside data distribution. In our study, one interesting observation is that deep Q functions approximate well inside the convex hull of training data. Inspired by this, we propose a new method, DOGE (Distance-sensitive Offline RL with better GEneralization). DOGE marries dataset geometry with deep function approximators in offline RL, and enables exploitation in generalizable OOD areas rather than strictly constraining policy within data distribution. Specifically, DOGE trains a state-conditioned distance function that can be readily plugged into standard actor-critic methods as a policy constraint. Simple yet elegant, our algorithm enjoys better generalization compared to state-of-the-art methods on D4RL benchmarks. Theoretical analysis demonstrates the superiority of our approach to existing methods that are solely based on data distribution or support constraints.",1.0,0.7434722781181335,True,0.3775406687981454,0.5605064734581395,True
Dynamic Time Lag Regression: Predicting What & When,"This paper tackles a new regression problem, called Dynamic Time-Lag Regression (DTLR), where a cause signal drives an effect signal with an unknown time delay. The motivating application, pertaining to space weather modelling, aims to predict the near-Earth solar wind speed based on estimates of the Sun's coronal magnetic field. DTLR differs from mainstream regression and from sequence-to-sequence learning in two respects: firstly, no ground truth (e.g., pairs of associated sub-sequences) is available; secondly, the cause signal contains much information irrelevant to the effect signal (the solar magnetic field governs the solar wind propagation in the heliosphere, of which the Earth's magnetosphere is but a minuscule region). A Bayesian approach is presented to tackle the specifics of the DTLR problem, with theoretical justifications based on linear stability analysis. A proof of concept on synthetic problems is presented. Finally, the empirical results on the solar wind modelling task improve on the state of the art in solar wind forecasting.",0.8,0.8339147567749023,True,0.3318122278318339,0.5828634923033681,True
Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile,"Owing to their connection with generative adversarial networks (GANs), saddle-point problems have recently attracted considerable interest in machine learning and beyond. By necessity, most theoretical guarantees revolve around convex-concave (or even linear) problems; however, making theoretical inroads towards efficient GAN training depends crucially on moving beyond this classic framework. To make piecemeal progress along these lines, we analyze the behavior of mirror descent (MD) in a class of non-monotone problems whose solutions coincide with those of a naturally associated variational inequality-a property which we call coherence. We first show that ordinary, ""vanilla"" MD converges under a strict version of this condition, but not otherwise; in particular, it may fail to converge even in bilinear models with a unique solution. We then show that this deficiency is mitigated by optimism: by taking an ""extra-gradient"" step, optimistic mirror descent (OMD) converges in all coherent problems. Our analysis generalizes and extends the results of Daskalakis et al. [2018] for optimistic gradient descent (OGD) in bilinear problems, and makes concrete headway for provable convergence beyond convex-concave games. We also provide stochastic analogues of these results, and we validate our analysis by numerical experiments in a wide array of GAN models (including Gaussian mixture models, and the CelebA and CIFAR-10 datasets).",0.8,0.9311342239379883,True,0.3318122278318339,0.6314732258849111,True
Learning Discrete Weights Using the Local Reparameterization Trick,"Recent breakthroughs in computer vision make use of large deep neural networks, utilizing the substantial speedup offered by GPUs. For applications running on limited hardware, however, high precision real-time processing can still be a challenge. One approach to solving this problem is training networks with binary or ternary weights, thus removing the need to calculate multiplications and significantly reducing memory size. In this work, we introduce LR-nets (Local reparameterization networks), a new method for training neural networks with discrete weights using stochastic parameters. We show how a simple modification to the local reparameterization trick, previously used to train Gaussian distributed weights, enables the training of discrete weights. Using the proposed training we test both binary and ternary models on MNIST, CIFAR-10 and ImageNet benchmarks and reach state-of-the-art results on most experiments.",1.0,0.7568872570991516,True,0.3775406687981454,0.5672139629486486,True
Improving MMD-GAN Training with Repulsive Loss Function,"Generative adversarial nets (GANs) are widely used to learn the data sampling process and their performance may heavily depend on the loss functions, given a limited computational budget. This study revisits MMD-GAN that uses the maximum mean discrepancy (MMD) as the loss function for GAN and makes two contributions. First, we argue that the existing MMD loss function may discourage the learning of fine details in data as it attempts to contract the discriminator outputs of real data. To address this issue, we propose a repulsive loss function to actively learn the difference among the real data by simply rearranging the terms in MMD. Second, inspired by the hinge loss, we propose a bounded Gaussian kernel to stabilize the training of MMD-GAN with the repulsive loss function. The proposed methods are applied to the unsupervised image generation tasks on CIFAR-10, STL-10, CelebA, and LSUN bedroom datasets. Results show that the repulsive loss function significantly improves over the MMD loss at no additional computational cost and outperforms other representative loss functions. The proposed methods achieve an FID score of 16.21 on the CIFAR-10 dataset using a single DCGAN network and spectral normalization.",1.0,0.7296887636184692,True,0.3775406687981454,0.5536147162083074,True
Contrastive Learning Can Find An Optimal Basis For Approximately View-Invariant Functions,"Contrastive learning is a powerful framework for learning self-supervised representations that generalize well to downstream supervised tasks. We show that multiple existing contrastive learning methods can be reinterpreted as learning kernel functions that approximate a fixed positive-pair kernel. We then prove that a simple representation obtained by combining this kernel with PCA provably minimizes the worst-case approximation error of linear predictors, under a straightforward assumption that positive pairs have similar labels. Our analysis is based on a decomposition of the target function in terms of the eigenfunctions of a positive-pair Markov chain, and a surprising equivalence between these eigenfunctions and the output of Kernel PCA. We give generalization bounds for downstream linear prediction using our Kernel PCA representation, and show empirically on a set of synthetic tasks that applying Kernel PCA to contrastive learning models can indeed approximately recover the Markov chain eigenfunctions, although the accuracy depends on the kernel parameterization as well as on the augmentation strength.",1.0,0.7288254499435425,True,0.3775406687981454,0.553183059370844,True
The Surprising Effectiveness of Equivariant Models in Domains with Latent Symmetry,"Extensive work has demonstrated that equivariant neural networks can significantly improve sample efficiency and generalization by enforcing an inductive bias in the network architecture. These applications typically assume that the domain symmetry is fully described by explicit transformations of the model inputs and outputs. However, many real-life applications contain only latent or partial symmetries which cannot be easily described by simple transformations of the input. In these cases, it is necessary to learn symmetry in the environment instead of imposing it mathematically on the network architecture. We discover, surprisingly, that imposing equivariance constraints that do not exactly match the domain symmetry is very helpful in learning the true symmetry in the environment. We differentiate between extrinsic and incorrect symmetry constraints and show that while imposing incorrect symmetry can impede the model's performance, imposing extrinsic symmetry can actually improve performance. We demonstrate that an equivariant model can significantly outperform non-equivariant methods on domains with latent symmetries both in supervised learning and in reinforcement learning for robotic manipulation and control problems.",1.0,0.7571669816970825,True,0.3775406687981454,0.567353825247614,True
Shifting Mean Activation Towards Zero with Bipolar Activation Functions,"We propose a simple extension to the ReLU-family of activation functions that allows them to shift the mean activation across a layer towards zero. Combined with proper weight initialization, this alleviates the need for normalization layers. We explore the training of deep vanilla recurrent neural networks (RNNs) with up to 144 layers, and show that bipolar activation functions help learning in this setting. On the Penn Treebank and Text8 language modeling tasks we obtain competitive results, improving on the best reported results for non-gated networks. In experiments with convolutional neural networks without batch normalization, we find that bipolar activations produce a faster drop in training error, and results in a lower test error on the CIFAR-10 classification task.",1.0,0.8429735898971558,True,0.3775406687981454,0.6102571293476506,True
Wizard of Wikipedia: Knowledge-Powered Conversational agents,"In open-domain dialogue intelligent agents should exhibit the use of knowledge, however there are few convincing demonstrations of this to date. The most popular sequence to sequence models typically ""generate and hope"" generic utterances that can be memorized in the weights of the model when mapping from input utterance(s) to output, rather than employing recalled knowledge as context. Use of knowledge has so far proved difficult, in part because of the lack of a supervised learning benchmark task which exhibits knowledgeable open dialogue with clear grounding. To that end we collect and release a large dataset with conversations directly grounded with knowledge retrieved from Wikipedia. We then design architectures capable of retrieving knowledge, reading and conditioning on it, and finally generating natural responses. Our best performing dialogue models are able to conduct knowledgeable discussions on open-domain topics as evaluated by automatic metrics and human evaluations, while our new benchmark allows for measuring further improvements in this important research direction.",1.0,0.8338651061058044,True,0.3775406687981454,0.605702887451975,True
CAMOU: Learning Physical Vehicle Camouflages to Adversarially Attack Detectors in the Wild,,1.0,0.732120931148529,True,0.3775406687981454,0.5548307999733373,True
PolyLoss: A Polynomial Expansion Perspective of Classification Loss Functions,"Cross-entropy loss and focal loss are the most common choices when training deep neural networks for classification problems. Generally speaking, however, a good loss function can take on much more flexible forms, and should be tailored for different tasks and datasets. Motivated by how functions can be approximated via Taylor expansion, we propose a simple framework, named PolyLoss, to view and design loss functions as a linear combination of polynomial functions. Our PolyLoss allows the importance of different polynomial bases to be easily adjusted depending on the targeting tasks and datasets, while naturally subsuming the aforementioned cross-entropy loss and focal loss as special cases. Extensive experimental results show that the optimal choice within the PolyLoss is indeed dependent on the task and dataset. Simply by introducing one extra hyperparameter and adding one line of code, our Poly-1 formulation outperforms the cross-entropy loss and focal loss on 2D image classification, instance segmentation, object detection, and 3D object detection tasks, sometimes by a large margin.",1.0,0.8373289108276367,True,0.3775406687981454,0.6074347898128911,True
Combining Symbolic Expressions and Black-box Function Evaluations in Neural Programs,"Neural programming involves training neural networks to learn programs, mathematics, or logic from data. Previous works have failed to achieve good generalization performance, especially on problems and programs with high complexity or on large domains. This is because they mostly rely either on black-box function evaluations that do not capture the structure of the program, or on detailed execution traces that are expensive to obtain, and hence the training data has poor coverage of the domain under consideration. We present a novel framework that utilizes black-box function evaluations, in conjunction with symbolic expressions that define relationships between the given functions. We employ tree LSTMs to incorporate the structure of the symbolic expression trees. We use tree encoding for numbers present in function evaluation data, based on their decimal representation. We present an evaluation benchmark for this task to demonstrate our proposed model combines symbolic reasoning and function evaluation in a fruitful manner, obtaining high accuracies in our experiments. Our framework generalizes significantly better to expressions of higher depth and is able to fill partial equations with valid completions.",1.0,0.7238126993179321,True,0.3775406687981454,0.5506766840580388,True
Blaschke Product Neural Networks (BPNN): A Physics-Infused Neural Network for Phase Retrieval of Meromorphic Functions,"Numerous physical systems are described by ordinary or partial differential equations whose solutions are given by holomorphic or meromorphic functions in the complex domain. In many cases, only the magnitude of these functions are observed on various points on the purely imaginary jw-axis since coherent measurement of their phases is often expensive. However, it is desirable to retrieve the lost phases from the magnitudes when possible. To this end, we propose a physics-infused deep neural network based on the Blaschke products for phase retrieval. Inspired by the Helson and Sarason Theorem, we recover coefficients of a rational function of Blaschke products using a Blaschke Product Neural Network (BPNN), based upon the magnitude observations as input. The resulting rational function is then used for phase retrieval. We compare the BPNN to conventional deep neural networks (NNs) on several phase retrieval problems, comprising both synthetic and contemporary real-world problems (e.g., metamaterials for which data collection requires substantial expertise and is time consuming). On each phase retrieval problem, we compare against a population of conventional NNs of varying size and hyperparameter settings. Even without any hyper-parameter search, we find that BPNNs consistently outperform the population of optimized NNs in scarce data scenarios, and do so despite being much smaller models. The results can in turn be applied to calculate the refractive index of metamaterials, which is an important problem in emerging areas of material science.",1.8,0.6002869009971619,True,0.574442516811659,0.5873647089044105,True
SE(3)-Equivariant Attention Networks for Shape Reconstruction in Function Space,"We propose a method for 3D shape reconstruction from unoriented point clouds. Our method consists of a novel SE(3)-equivariant coordinate-based network (TF-ONet), that parametrizes the occupancy field of the shape and respects the inherent symmetries of the problem. In contrast to previous shape reconstruction methods that align the input to a regular grid, we operate directly on the irregular point cloud. Our architecture leverages equivariant attention layers that operate on local tokens. This mechanism enables local shape modelling, a crucial property for scalability to large scenes. Given an unoriented, sparse, noisy point cloud as input, we produce equivariant features for each point. These serve as keys and values for the subsequent equivariant cross-attention blocks that parametrize the occupancy field. By querying an arbitrary point in space, we predict its occupancy score. We show that our method outperforms previous SO(3)-equivariant methods, as well as non-equivariant methods trained on SO(3)-augmented datasets. More importantly, local modelling together with SE(3)-equivariance create an ideal setting for SE(3) scene reconstruction. We show that by training only on single, aligned objects and without any pre-segmentation, we can reconstruct novel scenes containing arbitrarily many objects in random poses without any performance loss.",1.8,0.5683177709579468,False,0.574442516811659,0.571380143884803,True
Personalized Reward Learning with Interaction-Grounded Learning (IGL),"In an era of countless content offerings, recommender systems alleviate information overload by providing users with personalized content suggestions. Due to the scarcity of explicit user feedback, modern recommender systems typically optimize for the same fixed combination of implicit feedback signals across all users. However, this approach disregards a growing body of work highlighting that (i) implicit signals can be used by users in diverse ways, signaling anything from satisfaction to active dislike, and (ii) different users communicate preferences in different ways. We propose applying the recent Interaction Grounded Learning (IGL) paradigm to address the challenge of learning representations of diverse user communication modalities. Rather than requiring a fixed, human-designed reward function, IGL is able to learn personalized reward functions for different users and then optimize directly for the latent user satisfaction. We demonstrate the success of IGL with experiments using simulations as well as with real-world production traces.",0.8,0.8622020483016968,True,0.3318122278318339,0.5970071380667653,True
Let’s Find Fluorescein: Cross-Modal Dual Attention Learning For Fluorescein Leakage Segmentation In Fundus Fluorescein Angiography,"Automatic segmentation of fluorescein leakage in fundus fluorescein angiography images is important in the clinical diagnosis of advanced diabetic retinopathy. Despite the recent success of deep-learning-based models in improving medical image segmentation, segmentation of fluorescein leakage has been ignored owing to (1) a lack of publicly available data with sufficient annotations for training a segmentation network and (2) incapability of supervised models to accurately localize fluorescein leakage at different imaging angles. To address these issues, we studied the automatic segmentation of fluorescein leakage in fundus fluorescein angiography images and devised a method involving (1) a cross-modal learning framework for fluorescein leakage segmentation using both image and text data, (2) a dual attention learning module for identifying important linguistic and visual features, and (3) fluorescein-related-keyword classification for identifying meaningful textual expressions pertaining to the location and type of fluorescein leakage. We demonstrate the effectiveness of the proposed method for an in-house fundus fluorescein angiography image data set.",1.0,0.7510070204734802,True,0.3775406687981454,0.5642738446358129,True
From Thumbnails to Summaries-A Single Deep Neural Network to Rule Them All,"Video summaries come in many forms, from traditional single-image thumbnails, animated thumbnails, storyboards, to trailer-like video summaries. Content creators use the summaries to display the most attractive portion of their videos; the users use them to quickly evaluate if a video is worth watching. All forms of summaries are essential to video viewers, content creators, and advertisers. Often video content management systems have to generate multiple versions of summaries that vary in duration and presentational forms. We present a framework ReconstSum that utilizes LSTM-based autoencoder architecture to extract and select a sparse subset of video frames or keyshots that optimally represent the input video in an unsupervised manner. The encoder selects a subset from the input video while the decoder seeks to reconstruct the video from the selection. The goal is to minimize the difference between the original input video and the reconstructed video. Our method is easily extendable to generate a variety of applications including static video thumbnails, animated thumbnails, storyboards and “trailer-like” highlights. We specifically study and evaluate two most popular use cases: thumbnail generation and storyboard generation. We demonstrate that our methods generate better results than the state-of-the-art techniques in both use cases.",1.8,0.7722878456115723,True,0.574442516811659,0.6733651812116157,True
"Who, What and Where: Composite-semantic Instance Search for Story Videos","This paper studies Who-What-Where (3W) composite-semantic video instance search (INS) problem, which aims to find a specific person doing a queried action in a particular place. Mainstream approaches adopt a complete decomposition strategy, which divides a composite-semantic query into multiple single-semantic queries. However, due to the lack of necessary correlation analysis among constituent semantics, these methods cannot always generate identity-matching and semantics-consistent 3W INS results. To address the above challenges, we propose a partial decomposition scheme with action as the link. Specifically, we selectively split the 3W INS as person-action INS and action-location INS. The former ensures the retrieved person and action share the same identity by modeling their relative spatial positions at the frame level, while the latter improves the semantic consistency between action and location with a cross-semantic attention mechanism at the shot level. Particularly, we build a large-scale 3W INS dataset, containing over 470k video shots, on basis of NIST TRECVID 2016-2021 INS tasks and verify the effectiveness of the proposed method with both quantitative and qualitative experiments.",1.0,0.7906884551048279,True,0.3775406687981454,0.5841145619514867,True
Seethevoice: Learning from Music to Visual Storytelling of Shots,"Types of shots in the language of film are considered the key elements used by a director for visual storytelling. In filming a musical performance, manipulating shots could stimulate desired effects such as manifesting the emotion or deepening the atmosphere. However, while the visual storytelling technique is often employed in creating professional recordings of a live concert, audience recordings of the same event often lack such sophisticated manipulations. Thus it would be useful to have a versatile system that can perform video mashup to create a refined video from such amateur clips. To this end, we propose to translate the music into a near-professional shot (type) sequence by learning the relation between music and visual storytelling of shots. The resulting shot sequence can then be used to better portray the visual storytelling of a song and guide the concert video mashup process. Our method introduces a novel probabilistic-based fusion approach, named as multi-resolution fused recurrent neural networks (MF-RNNs) with film-language, which integrates multi-resolution fused RNNs and a film-language model for boosting the translation performance. The results from objective and subjective experiments demonstrate that MF-RNNs with film-language can generate an appealing shot sequence with better viewing experience.",1.0,0.9579155445098877,True,0.3775406687981454,0.6677281066540166,True
Double Shot: Preserve and Erase Based Class Attention Networks for Weakly Supervised Localization (Peca-Net),"Weakly supervised localization has attracted increasing attention since only image-wise labels are needed. One mainstream approach, CAM based top-down localization method, suffers from poor resolution and localizing only the most discriminative regions. Another kind, model agnostic perturbation based method, suffers from multiple iterations for each sample. In this paper, we introduce PECA-Net: Preserve and Erase Based Class Attention Networks, which adopts preserve and erase perturbed U-net as the basis, with class activation mechanism as attention to enhance localization capability. Class attention module strengthens informative features and achieves a basic localization. Preserve and erase perturbed U-net replaces the random and iterative extrinsic perturbation with meaningful erasing. In addition, this structure refines the preliminary localization. Since the target object is hit twice, therefore, entitled as double shot. Experiments validate that localization error of both CUB-200 and ILSVRC ImageNet dataset is the new state-of-the-art.",0.8,0.9760898947715759,True,0.3318122278318339,0.6539510613017049,True
Improving robustness of learning-based adaptive video streaming in wildly fluctuating networks,"With the development of wireless technology, the fifth-generation mobile communication network (5G) can offer ultra-high bandwidth to support high-quality video streaming services. However, such a network shows much wild fluctuation especially in the case of mmWave 5G, making it challenging to ensure a robust video streaming service. In this paper, we propose a robust adaptive bitrate algorithm based on deep reinforcement learning, named MAP-DRL. In ""robust"", we mean that MAP-DRL provides high quality of experience (QoE) streaming services under various network conditions and different QoE preferences. In particular, to avoid the gradient explosion caused by network fluctuation, we introduce several reinforcement learning designs into MAP-DRL, such as advantage function normalization and reward scaling. To fully utilize the limited environment feedback, we process environmental information via a multi-type data manner and design the corresponding network structures for each type of them. The experimental results on real-world network trace datasets demonstrate that MAP-DRL can succeed in improving the average QoE by 29% versus heterogeneous networks and user preferences as compared with the representative benchmarks.",1.0,0.8454126119613647,True,0.3775406687981454,0.6114766403797551,True
Low-Frequency Guided Self-Supervised Learning For High-Fidelity 3d Face Reconstruction In The Wild,"In this paper, we propose a low-frequency guided self-supervised learning method for high-fidelity 3D face reconstruction from an in-the-wild image. Unlike other self-supervised methods only using the color difference between the original image and the estimated image, we add low-frequency albedo information to enhance the self-supervised learning for more realistic albedo while insensitive to the non-skin regions. Specifically, based on a PCA albedo model, we first train a Boosting Network (B-Net) to provide illumination and intact albedo distribution. Then with above information, we learn an image-to-image non-linear Facial Albedo Network (FAN) by self-supervision to produce a high-fidelity albedo. We further propose a Detail Recovering Network (DRN) to recover geometric details such as wrinkles. FAN and DRN permit to reconstruct 3D faces with high-fidelity albedo and geometry details. Finally, experimental results demonstrate the effectiveness of the proposed method.",1.0,0.8178165555000305,True,0.3775406687981454,0.597678612149088,True
Enhancing Viewing Experience of Generated Visual Storylines for Promotional Videos,"Visual storyline generation is the problem of selecting and sequencing a set of visual materials (i.e. images and video clips) to produce a video to elicit certain cognitive or emotional responses from viewers. In this paper, we enhance the viewing experience of generated visual storylines with the Shot Composition, Selection and Plotting (ShotCSP) approach. Designed for generating promotional videos in ecommerce settings, ShotCSP considers three key film-making principles into the visual storyline generation pipeline: a) proximity-aware scene transition, b) sound logic flow, and c) graphic discontinuity. We propose two novel metrics to enhance viewing experience: 1) Semantic Distance, which measures how related a shot is to the product being promoted; and 2) Salient Region Ratio, which estimates attention to product details in a shot. Through large-scale user evaluation involving 1,748 pairwise comparisons against five state-of-the-art approaches, ShotCSP achieves significantly improved viewing experience. It is a promising approach to enable AI generated promotional videos to benefit e-commerce businesses.",1.0,0.7653849720954895,True,0.3775406687981454,0.5714628204468175,True
Occlusion-Aware GAN for Face De-Occlusion in the Wild,"Occluded faces–as a common scene in real life–have a significant negative impact on most face recognition systems. Existing methods try to remove the occlusions by a single-stage generative adversarial network (GAN), which is unaware of the occlusion and thus has difficulties in generalizing to a large variety of occlusion types, e.g., different objects at various positions. To this end, we propose the two-stage Occlusion-Aware GAN (OA-GAN), where the first GAN is for disentangling the occlusions, which will be served as the additional input of the second GAN for synthesizing the final de-occluded faces. In this way, our two-stage model can handle diverse occlusions in the wild and is naturally more explainable because of its awareness of the occluded objects. Extensive experiments on both synthetic and real-world datasets validate the superiority of the two-stage OAGAN design. Furthermore, by applying the generated de-occluded faces to facial expression recognition (FER) systems, we find that our two-stage de-occlusion process significantly increases the accuracy of FER under occlusion.",1.0,0.8903942704200745,True,0.3775406687981454,0.63396746960911,True
Global-Local Similarity Function for Automatic Playlist Generation,"This paper proposes the Global-Local Similarity Function (GLSF) to exploit the multi-scale cues in track sequences for automatic playlist generation (APG). Unlike previous neighborhood-based methods only looking on local similarities for a given playlist, GLTS is constructed by first modeling the fine-grained audio features of each track, then capturing the long-term relations among consecutive tracks. Specifically, the fine-grained audio features are captured beat-by-beat to represent the rhythmic variation of music. The long- term relations are modeled by a designed track distance constraint (TD-constraint) to alleviate the incoherences and un- smooth transition in track sequences. The fine-grained audio features and TD-constraint are aggregated as the final GLSF by a simple distance function. Objective and subjective evaluations show that GLSF-based APG achieves better smooth transition and ensure the long-term content consistency among the tracks. Furthermore, GLSF yields a better understanding of the sequential relationship between tracks and propose a promising way to improve APG algorithms. 1",1.0,0.8091780543327332,True,0.3775406687981454,0.5933593615654393,True
Learning High Frequency Surface Functions In Shells,"Recently, coordinate-based MLPs have been shown to be powerful representations for 3D surfaces, where learning high-frequency details is facilitated by modulating surface functions with periodic functions [1], [2]. While shortening the periodicity helps in learning high frequencies, it leads to increasing ambiguity, i.e., more points along the axis directions become similar in the embedded space, so that many points on the surface and outside the surface have similar predictions. In addition, short periodicity increases local geometric variations, leading to unexpected noisy artifacts in untrained regions. Unlike existing methods that learn surface functions in a regular cube, we find surfaces within shells, a coarse form of the target surfaces constructed by a binary classifier. The advantage of build surfaces in shells is that MLPs focus on regions of interest, which inherently reduces ambiguity and also promotes training efficiency and test accuracy. We demonstrate the effectiveness of shells and show significant improvements over baseline methods in 3D surface reconstruction from raw point clouds.",1.0,0.7969592213630676,True,0.3775406687981454,0.5872499450806066,True
"Development of automation and energy monitoring system of air-conditioning & mechanical ventilation (AEMS-ACMV) for 27 years old office building at Terengganu, Malaysia",,1.6,0.5756964683532715,False,0.52497918747894,0.5503378279161057,True
A Pair-Metamorphosis-Decouple Synthetic Data Scheme for Color Fundus Image Registration,"Color fundus (CF) image registration is crucial for accurate information fusion; it could obtain more details of retinal structure to assist clinical diagnosis. Existing methods suf-fer from costing time or dataset size, making CF image reg-istration still a challenging task. In this paper, we propose a novel pair-metamorphosis-decouple synthetic data scheme for learning-based CF image registration and ameliorate the registration model for retinal image. Specifically, we take ad-vantage of the pairing information of the registration task to decouple the differences between the pairing data and expand the representative ability of the dataset by synthesizing data. Furthermore, the registration framework is ameliorated ac-cording to the characteristics of the blood vessels in the retinal image. Experiments on the public dataset (FIRE) show that our synthetic data scheme could bring general performance promotion to registration models, and our registration method is superior to other state-of-the-art unsupervised algorithms.",1.0,0.7660517692565918,True,0.3775406687981454,0.5717962190273687,True
MKE-GCN: Multi-Modal Knowledge Embedded Graph Convolutional Network for Skeleton-Based Action Recognition in the Wild,"The graph convolutional networks (GCNs), which model human body skeletons as several spatial-temporal graphs, have been widely used and become a key to representative feature extraction. However, existing methods have limitations in recognizing action in the wild, where human body skeletons are captured from real-world scenes with diversified view-points, obvious motion blurs, complex interactions and fast varying resolutions of the human body. In this paper, we propose a Multi-modal Knowledge Embedded Graph Convolutional Network (MKE-GCN), which is a conceptually simple yet effective method for skeleton-based action recognition in the wild. In the proposed framework, we address two main problems: 1) how to design a simple yet effective pipeline for modeling multi-modal body skeletons; and 2) how to equip this pipeline with the ability of handling “in the wild”. To tackle these problems, in MKE-GCN, we first build an adaptive multi-modal aggregation (AMA) module and add it to traditional GCNs for multi-modal representation learning. Then, we further enhance the GCN model by a multi-modal knowledge distillation (MKD) strategy, where the proposed MKE-GCN mines action recognition knowledge from various multi-modal models. We discover that aside from the multi-modal representation, the MKD is of particular importance for improving the accuracy of skeleton-based action recognition “in the wild”. Notably, the proposed method is light-weight, which can be applied to any GCN based method. Furthermore, extensive experiments on three challenging benchmarks, e.g., UAV-Human, NTU-RGB+D 60 and NTU-RGB+D 120, demonstrate that our approach sets a new record for skeleton-based action recognition. Our anonymous code and models are also released 1.",1.0,0.7685917019844055,True,0.3775406687981454,0.5730661853912755,True
Face Inverse Rendering from Single Images in the Wild,"Face inverse rendering, an important and challenging task in computer vision and computer graphics, attempts to decompose face image into shape, reflectance, and illuminance. This problem becomes fundamentally difficult under non-laboratory conditions without controlled illumination. Though recent works have produced compelling results, most of these techniques rely on multiple lighting images captured under contronlled lighting by complex equipment, such as Light Stage, which is not flexible and applicable to common users. In this paper, we propose a novel face inverse rendering framework, which neither relies on complex devices nor labeled training data. Instead, it learns reflectance, shape, and illuminance from its physical constraints. Extensive experiments on both synthetic and real image datasets demonstrate consistently superior performance of the proposed method. Our code will be made publicly available.",1.0,0.7885302305221558,True,0.3775406687981454,0.5830354496601506,True
Effects of Culture Media on Viability of Beauveria Bassiana and Its Pathogenicity Against Coffee Bean Borer (Hyphotenemus Hampei),"Coffee bean borer (Hypothenemus hampei) attacks coffee when it is still in the plantation until it is in the storage that reduce the quality of coffee. To avoid the negative impact of chemical insecticides, biological control is carried out by using entomopathogen Beauveria bassiana. The aims of this research were to study the effects of culture media on viability of B. bassiana and its pathogenicity in controlling H. hampei. Laboratory experiment was arranged in Completely Random Design (CRD). This research used 8 (eight) treatments namely KO: Distilled water, Kk: Lamda Sihalothrin 25 EC (Chemical Insecticide), B1: 10 g/L B. bassiana cultured in rice bran media, B2: 20 g/L B. bassiana cultured in rice bran media, B3: 30 g/L B. bassiana cultured in rice bran media, B4: 10 g/L B. bassiana cultured in corn media, B5: 20 g/L B. bassiana cultured in corn media and B6: 30 g/L B. bassiana cultured in corn media. Each treatment was applied on coffee beans infested with 20 H. hampei and repeated 4 (four) times. The results showed that rice bran media produced the highest number of spores with highest viability. The application of B. bassiana could killed H. hampei. The concentration of 30 g/L of B. bassiana cultured in rice bran media resulted in the fastest mortality (Mortality time and Lethal Time 50%) of H. hampei.",0.8,0.7989358305931091,True,0.3318122278318339,0.5653740292124715,True
Pattern-Based Mining of Opinions in Q&A Websites,"Informal documentation contained in resources such as Q&A websites (e.g., Stack Overflow) is a precious resource for developers, who can find there examples on how to use certain APIs, as well as opinions about pros and cons of such APIs. Automatically identifying and classifying such opinions can alleviate developers' burden in performing manual searches, and can be used to recommend APIs that are good from some points of view (e.g., performance), or highlight those less ideal from other perspectives (e.g., compatibility). We propose POME (Pattern-based Opinion MinEr), an approach that leverages natural language parsing and pattern-matching to classify Stack Overflow sentences referring to APIs according to seven aspects (e.g., performance, usability), and to determine their polarity (positive vs negative). The patterns have been inferred by manually analyzing 4,346 sentences from Stack Overflow linked to a total of 30 APIs. We evaluated POME by (i) comparing the pattern-matching approach with machine learners leveraging the patterns themselves as well as n-grams extracted from Stack Overflow posts; (ii) assessing the ability of POME to detect the polarity of sentences, as compared to sentiment-analysis tools; (iii) comparing POME with the state-of-the-art Stack Overflow opinion mining approach, Opiner, through a study involving 24 human evaluators. Our study shows that POME exhibits a higher precision than a state-of-the-art technique (Opiner), in terms of both opinion aspect identification and polarity assessment.",0.8,0.8023155927658081,True,0.3318122278318339,0.567063910298821,True
How Magic Is Zero?: An Empirical Analysis of Initial Development Releases in Three Software Package Distributions,"Distributions of open source software packages dedicated to specific programming languages facilitate software development by allowing software projects to depend on the functionality provided by such reusable packages. The health of a software project can be affected by the maturity of the packages on which it depends. The version numbers of the used package releases provide an indication of their maturity. Packages with a 0.y.z version number are commonly assumed to be under initial development, implying that they are likely to be less stable, and depending on them may be less healthy. In this paper, we empirically study, for three open source package distributions (Cargo, npm and Packagist) to which extent 0.y.z package releases and ≥1.0.0 package releases behave differently. More specifically, we quantify the prevalence of 0.y.z releases, we explore how long packages remain in the initial development stage, we compare the update frequency of 0.y.z and ≥ 1.0.0 package releases, we study how often 0.y.z releases are required by other packages, and we assess whether semantic versioning is respected for dependencies towards them. Among others, we observe that package distributions are more permissive than what semantic versioning dictates for 0.y.z releases, and that many of the 0.y.z releases can be regarded as mature packages that are no longer under initial development. As a consequence, the version number does not provide a good indication of the health of a package release.",2.1,0.712024450302124,True,0.6456563062257954,0.6788403782639597,True
Analysis Prediction of Prambanan Temple Visitors with Fuzzy Time Series Chen Model and Seasonal Auto Regressive Integrated Moving Average (SARIMA) Model,"The number of visitors in tourist attractions are almost always changes each time, even for tourist attractions that are already well-known among local and foreign people, usually will tend to increase at certain times, as in the Prambanan Temple. Based on data from TWC (Taman Wisata Candi) unit office, the number of visitors of Prambanan Temple during holidays at the end of 2018 increased by 8% from the previous year. Because of its increase, the manager of tourist attractions must always try to provide the best service. Therefore, the manager of Prambanan Temple needs to know the prediction of the number of visitors in the future so that they can prepare services and innovations to increase its attractiveness. The data of Prambanan Temple visitors number is seasonal, so the visitors number prediction at Prambanan Temple will be determined using the method for seasonal data. This research tries to compare the two methods, namely Fuzzy Time Series Chen Model and Seasonal Auto Regressive Integrated Moving Average (SARIMA) Model. The results of these methods are the visitors number prediction with different errors, so it can be seen which method is better between the two.",0.8,0.8675873279571533,True,0.3318122278318339,0.5996997778944936,True
PonziGuard: Detecting Ponzi Schemes on Ethereum with Contract Runtime Behavior Graph (CRBG),,0.8,0.807379961013794,True,0.3318122278318339,0.5695960944228139,True
"Bots for Pull Requests: The Good, the Bad, and the Promising","Software bots automate tasks within Open Source Software (OSS) projects' pull requests and save reviewing time and effort (“the good”). However, their interactions can be disruptive and noisy and lead to information overload (“the bad”). To identify strategies to overcome such problems, we applied Design Fiction as a participatory method with 32 practitioners. We elicited 22 design strategies for a bot mediator or the pull request user interface (“the promising”). Participants envisioned a separate place in the pull request interface for bot interactions and a bot mediator that can summarize and customize other bots' actions to mitigate noise. We also collected participants' perceptions about a prototype implementing the envisioned strategies. Our design strategies can guide the development of future bots and social coding platforms.",1.8,0.812965989112854,True,0.574442516811659,0.6937042529622566,True
What happens in a control room during a cybersecurity attack?: Preliminary observations from a pilot study,"Cyberattacks on the critical infrastructure is a growing concern for businesses, national authorities and public in general. The increasing complexity and connectivity of the critical infrastructure systems have made them susceptible to cyberattacks. The traditional notion of safety systems being isolated is no longer applicable, as we have seen ample examples on how these systems can be exploited through gaps in e.g. supply chain, physical security, insiders. This places greater importance on how the staff belonging to owners and operators of these critical infrastructure, e.g. operators, IT/security personnel, system engineers, management, are prepared to handle cyberattacks. This paper presents our ongoing research on investigating the preparedness of organisations to handle cybersecurity incidents and providing holistic solutions to improve cybersecurity posture. We present one experiment that has been conducted using our cybersecurity centre and man-machine laboratory to study how operators and security team of a power plant will handle a cyberattack. We highlight the main observations made through this experiment.",1.1,0.7735191583633423,True,0.401312339887548,0.5874157491254451,True
SooLics (Smart Room for Learns Physics) with Augmented Reality Sound Technology Based on Camera as a Physics Learning Room for Blind Students,"A good educational process is one that is able to encompass existing communities, not expection for children with special needs. But the lack of adequate facilities makes them lack of maximum learning. SooLics (Smart Room for Learns Physics) with Augmented Reality Sound Technology based on Camera as a learning room for children with visual blindness is a room specifically designed for children with visual blindness to improve understanding about physics. In contrast to the usual learning room, Augmented Reality Sound Technology is used for visualization of physical matter that has been prepared in the room as a “visual aid” for children with visual blindness. We use Research and Development (R&D) methode which is consists of defining studies (define), the design phase (design), and development. This research uses a camera which is specially designed to be used as a scan media for markers on augmented reality technology that has been prepared and installed in the room and the results are sound about physics matter. This room is designed so that blind children can learns independently.",0.8,0.8104690909385681,True,0.3318122278318339,0.571140659385201,True
FuzzSlice: Pruning False Positives in Static Analysis Warnings through Function-Level Fuzzing,"Manual confirmation of static analysis reports is a daunting task. This is due to both the large number of warnings and the high density of false positives among them. Fuzzing techniques have been proposed to verify static analysis warnings. However, a major limitation is that fuzzing the whole project to reach all static analysis warnings is not feasible. This can take several days and exponential machine time to increase code coverage linearly. Therefore, we propose FuzzSlice, a novel framework that automatically prunes possible false positives among static analysis warnings. Unlike prior work that mostly focuses on confirming true positives among static analysis warnings, which requires end-to-end fuzzing, FuzzSlice focuses on ruling out potential false positives, which are the majority in static analysis reports. The key insight that we base our work on is that a warning that does not yield a crash when fuzzed at the function level in a given time budget is a possible false positive. To achieve this, FuzzSlice first aims to generate compilable code slices at the function level and then fuzzes these code slices instead of the entire binary. FuzzSlice is also unlikely to misclassify a true bug as a false positive because the crashing input can be reproduced by a fuzzer at the function level as well. We evaluate FuzzSlice on the Juliet synthetic dataset and real-world complex C projects. Our evaluation shows that the ground truth in the Juliet dataset had 864 false positives which were all detected by FuzzSlice. For the open-source repositories, we were able to get the developers from two of these open-source repositories to independently label these warnings. FuzzSlice automatically identifies 33 out of 53 false positives confirmed by developers in these two repositories. Thus FuzzSlice reduces false positives by 62.26% in the open-source repositories and by 100% in the Juliet dataset.",1.0,0.8912076354026794,True,0.3775406687981454,0.6343741521004125,True
How not to Structure Your Database-Backed Web Applications: A Study of Performance Bugs in the Wild,"Many web applications use databases for persistent data storage, and using Object Relational Mapping (ORM) frameworks is a common way to develop such database-backed web applications. Unfortunately, developing efficient ORM applications is challenging, as the ORM framework hides the underlying database query generation and execution. This problem is becoming more severe as these applications need to process an increasingly large amount of persistent data. Recent research has targeted specific aspects of performance problems in ORM applications. However, there has not been any systematic study to identify common performance anti-patterns in real-world such applications, how they affect resulting application performance, and remedies for them. In this paper, we try to answer these questions through a comprehensive study of 12 representative real-world ORM applications. We generalize 9 ORM performance anti-patterns from more than 200 performance issues that we obtain by studying their bug-tracking systems and profiling their latest versions. To prove our point, we manually fix 64 performance issues in their latest versions and obtain a median speedup of 2× (and up to 39× max) with fewer than 5 lines of code change in most cases. Many of the issues we found have been confirmed by developers, and we have implemented ways to identify other code fragments with similar issues as well.",1.0,0.841720700263977,True,0.3775406687981454,0.6096306845310613,True
Does the Stream API Benefit from Special Debugging Facilities? A Controlled Experiment on Loops and Streams with Specific Debuggers,"Java's Stream API, that massively makes use of lambda expressions, permits a more declarative way of defining operations on collections in comparison to traditional loops. While experimental results suggest that the use of the Stream API has measurable benefits with respect to code readability (in comparison to loops), a remaining question is whether it has other implications. And one of such implications is, for example, tooling in general and debugging in particular because of the following: While the traditional loop-based approach applies filters one after another to single elements, the Stream API applies filters on whole collections. In the meantime there are dedicated debuggers for the Stream API, but it remains unclear whether such a debugger (on the Stream API) has a measurable benefit in comparison to the traditional stepwise debugger (on loops). The present papers introduces a controlled experiment on the debugging of filter operations using a stepwise debugger versus a stream debugger. The results indicate that under the experiment's settings the stream debugger has a significant ($\mathrm{p} < .001$) and large, positive effect $(\eta_{p}^{2}=.899;\ \frac{M_{stepwise}}{M_{stream}} \sim 204\%)$. However, the experiment reveals that additional factors interact with the debugger treatment such as whether or not the failing object is known upfront. The mentioned factor has a strong and large disordinal interaction effect with the debugger ($\mathrm{p} < .001; \eta_{p}^{2}=.928$): In case an object is known upfront that can be used to identify a failing filter, the stream debugger is even less efficient than the stepwise debugger $(\frac{M_{stepwise}}{M_{stream}}\sim 72\%)$. Hence, while we found overall a positive effect of the stream debugger, the answer whether or not debugging is easier on loops or streams cannot be answered without taking the other variables into account. Consequently, we see a contribution of the present paper not only in the comparison of different debuggers but in the identification of additional factors.",1.3,0.7323964238166809,True,0.45016600268752216,0.5912812132521015,True
Automatic Extraction of Opinion-Based Q&A from Online Developer Chats,"Virtual conversational assistants designed specifically for software engineers could have a huge impact on the time it takes for software engineers to get help. Research efforts are focusing on virtual assistants that support specific software development tasks such as bug repair and pair programming. In this paper, we study the use of online chat platforms as a resource towards collecting developer opinions that could potentially help in building opinion Q&A systems, as a specialized instance of virtual assistants and chatbots for software engineers. Opinion Q&A has a stronger presence in chats than in other developer communications, thus mining them can provide a valuable resource for developers in quickly getting insight about a specific development topic (e.g., What is the best Java library for parsing JSON?). We address the problem of opinion Q&A extraction by developing automatic identification of opinion-asking questions and extraction of participants' answers from public online developer chats. We evaluate our automatic approaches on chats spanning six programming communities and two platforms. Our results show that a heuristic approach to opinion-asking questions works well (.87 precision), and a deep learning approach customized to the software domain outperforms heuristics-based, machine-learning-based and deep learning for answer extraction in community question answering.",0.8,0.8569579720497131,True,0.3318122278318339,0.5943850999407735,True
Dynamic Update for Synthesized GR(1) Controllers,"Reactive synthesis is an automated procedure to obtain a correct-by-construction reactive system from its temporal logic specification. GR(1) is an expressive fragment of LTL that enables efficient synthesis and has been recently used in different contexts and application domains. In this paper we investigate the dynamic-update problem for GR(1): updating the behavior of an already running synthesized controller such that it would safely and dynamically, without stopping, start conforming to a modified, up-to-date specification. We formally define the dynamic-update problem and present a sound and complete solution that is based on the computation of a bridge-controller. We implemented the work in the Spectra synthesis and execution environment and evaluated it over benchmark specifications. The evaluation shows the efficiency and effectiveness of using dynamic updates. The work advances the state-of-the-art in reactive synthesis and opens the way to its use in application domains where dynamic updates are a necessary requirement.",0.8,0.8022266030311584,True,0.3318122278318339,0.5670194154314961,True
Studying Test Annotation Maintenance in the Wild,"Since the introduction of annotations in Java 5, the majority of testing frameworks, such as JUnit, TestNG, and Mockito, have adopted annotations in their core design. This adoption affected the testing practices in every step of the test life-cycle, from fixture setup and test execution to fixture teardown. Despite the importance of test annotations, most research on test maintenance has mainly focused on test code quality and test assertions. As a result, there is little empirical evidence on the evolution and maintenance of test annotations. To fill this gap, we perform the first fine-grained empirical study on annotation changes. We developed a tool to mine 82,810 commits and detect 23,936 instances of test annotation changes from 12 open-source Java projects. Our main findings are: (1) Test annotation changes are more frequent than rename and type change refactorings. (2) We recover various migration efforts within the same testing framework or between different frameworks by analyzing common annotation replacement patterns. (3) We create a taxonomy by manually inspecting and classifying a sample of 368 test annotation changes and documenting the motivations driving these changes. Finally, we present a list of actionable implications for developers, researchers, and framework designers.",1.0,0.8001412153244019,True,0.3775406687981454,0.5888409420612737,True
Research Idea on How Language and Symbols (Semantics and Semiotics) Affect Emotions of Software Engineers,"This is essentially a 'call for research' and collaboration between industry and academia to improve the motivation and performance of software engineers through use of language, words and symbols. How languages and symbols shape the way people think, feel and behave has been a topic of wide research. Words have powerful association with perception and cognition and throughout history, language has been used as a medium for influencing minds and for mass propaganda. While this is widely understood in politics, psychology and sociology, very little research has been to study the implicit and explicit impact of words, phrases and language on the way software engineers think, feel, behave and perform. While software engineering could be seen as a science that lends itself to a formal process and methods, it can also be seen as a craft and art which needs imagination and creativity which in turn are influenced by emotions. We propose some hypotheses, research questions and ideas to trigger formal studies of deeper connections between language/ symbols and software engineers' performance. We also draw inspiration from a wide body of research already conducted in this area which have influenced the field of psychology, sociology and mass communication. This is essentially a 'call for research' and collaboration between industry and academia to improve the motivation and performance of software engineers through use of language, words and symbols.",0.8,0.7811281085014343,True,0.3318122278318339,0.5564701681666341,True
History-Driven Test Program Synthesis for JVM Testing,"Java Virtual Machine (JVM) provides the runtime environment for Java programs, which allows Java to be “write once, run anywhere”. JVM plays a decisive role in the correctness of all Java programs running on it. Therefore, ensuring the correctness and robustness of JVM implementations is essential for Java programs. To date, various techniques have been proposed to expose JVM bugs via generating potential bug-revealing test programs. However, the diversity and effectiveness of test programs generated by existing research are far from enough since they mainly focus on minor syntactic/semantic mutations. In this paper, we propose JavaTailor, the first history-driven test program synthesis technique, which synthesizes diverse test programs by weaving the ingredients extracted from JVM historical bug-revealing test programs into seed programs for covering more JVM behaviors/paths. More specifically, JavaTailor first extracts five types of code ingredients from the historical bug-revealing test programs. Then, to synthesize diverse test programs, it iteratively inserts the extracted ingredients into the seed programs and strengthens their interactions via introducing extra data dependencies between them. Finally, JavaTailor employs these synthesized test programs to differentially test JVMs. Our experimental results on popular JVM implementations (i.e., HotSpot and OpenJ9) show that JavaTailor outperforms the state-of-the-art technique in generating more diverse and effective test programs, e.g., test programs generated by JavaTailor can achieve higher JVM code coverage and detect many more unique inconsistencies than the state-of-the-art technique. Furthermore, JavaTailor has detected 10 previously unknown bugs, 6 of which have been confirmed/fixed by developers.",1.0,0.7490354180335999,True,0.3775406687981454,0.5632880434158727,True
Do You Just Discuss or Do You Solve?: Meeting Analysis in a Software Project at Early Stages,"Software development is a very cooperative and communicative task. In most software projects, meetings are a very important medium to share information. However, these meetings are often not as effective as expected. One big issue hindering productive and satisfying meetings is inappropriate behavior such as complaining. In particular, talking about problems without at least trying to solve them decreases motivation and mood of the team. Interaction analyses in meetings allow the assessment of appropriate and inappropriate behavior influencing the quality of a meeting. Derived from an established interaction analysis coding scheme in psychology, we present act4teams-short which allows real-time coding of meetings in software projects. We apply act4teams-short in an industrial case study at Volkswagen Commercial Vehicles, a large German company in the automotive domain. We analyze ten team-internal meetings at early project stages. Our results reveal difficulties due to missing project structure and the overall project goal. Furthermore, the team has an intrinsic interest in identifying problems and solving them, without any extrinsic input being required.",1.1,0.7071336507797241,True,0.401312339887548,0.5542229953336361,True
Symbolic Repairs for GR(1) Specifications,"Unrealizability is a major challenge for GR(1), an expressive assume-guarantee fragment of LTL that enables efficient synthesis. Some works attempt to help engineers deal with unrealizability by generating counter-strategies or computing an unrealizable core. Other works propose to repair the unrealizable specification by suggesting repairs in the form of automatically generated assumptions. In this work we present two novel symbolic algorithms for repairing unrealizable GR(1) specifications. The first algorithm infers new assumptions based on the recently introduced JVTS. The second algorithm infers new assumptions directly from the specification. Both algorithms are sound. The first is incomplete but can be used to suggest many different repairs. The second is complete but suggests a single repair. Both are symbolic and therefore efficient. We implemented our work, validated its correctness, and evaluated it on benchmarks from the literature. The evaluation shows the strength of our algorithms, in their ability to suggest repairs and in their performance and scalability compared to previous solutions.",0.8,0.9005075693130493,True,0.3318122278318339,0.6161598985724416,True
The Effect of Magic Book to Increase Interest in Learning Mathematics of Primary School Students,"Elementary School is a place to understand all learning for the next level, especially mathematics. Mathematics is also considered difficult by elementary school students because of its abstract and complex nature, especially with the large number of mathematical formulas, and its lack of interest in learning. So that student interest in learning is reduced. One interesting way to learn mathematics is by using learning media. This research introduces MagicBook contains a collection of formulas and mathematical games. This Magicbook is arranged in such a way with an attractive layout and color. Sources of data obtained from questionnaires and direct research on elementary school students in one of the lessons in Yogyakarta. The data of this study were analyzed descriptively quantitative and qualitative. The results showed that the magic book learning media can increase elementary school students' mathematics learning interest.the effect.",1.0,0.8861294388771057,True,0.3775406687981454,0.6318350538376256,True
"Git Blame Who?: Stylistic Authorship Attribution of Small, Incomplete Source Code Fragments","Abstract Program authorship attribution has implications for the privacy of programmers who wish to contribute code anonymously. While previous work has shown that individually authored complete files can be attributed, these efforts have focused on such ideal data sets as contest submissions and student assignments. We explore the problem of authorship attribution “in the wild,” examining source code obtained from open-source version control systems, and investigate how contributions can be attributed to their authors, either on an individual or a per-account basis. In this work, we present a study of attribution of code collected from collaborative environments and identify factors which make attribution of code fragments more or less successful. For individual contributions, we show that previous methods (adapted to be applied to short code fragments) yield an accuracy of approximately 50% or 60%, depending on whether we average by sample or by author, at identifying the correct author out of a set of 104 programmers. By ensembling the classification probabilities of a sufficiently large set of samples belonging to the same author we achieve much higher accuracy for assigning the set of samples to the correct author from a known suspect set. Additionally, we propose the use of calibration curves to identify which samples are by unknown and previously unencountered authors.",1.1,0.8581796288490295,True,0.401312339887548,0.6297459843682888,True
Development of The Story Book “Negeri Hastinapura” to Instill Patriotism Value in Primary School Student,"The phenomenon of radicalism in Indonesia is still rife, such as the bombing of the church in Surabaya, the shootout with radicalist in Yogyakarta, are some examples of recent events of radicalism. Likewise, the events of radicalism in the world, the radical group ISIS is a group that often carries out acts of radicalism and ISIS propaganda that should be watched out so as not to damage peace in Indonesia. This shows that the importance of efforts to overcome radicalism, namely through the prevention of the development of radicalism. The background of this research is motivated by the importance of preventing radicalism from developing among primary school students through instilling the values of patriotism. The story book ""Negeri Hastinapura"" was chosen because wayang can be used as an educational tool, because it contains elements of truth, justice, purpose, obedience, loyalty, heroism, spiritual, psychological, philosophical and all aspects of human disposition and its problems (Tofani, 2013). “Negeri Hastinapura” is the country contained in the Mahabharata puppet story. This story book ""Negeri Hastinapura"" takes place when it is led by Prabu Yudistira, where the country is safe, peaceful, and the community is prosperous, so students can be taught exemplary values and instilling the values of patriotism. The development of the story book ""Negeri Hastinapura"" was designed using the development research (R&D) method using the subject of primary school students. The story book ""Negeri Hastinapura"" was tested in primary schools, SDIT Insan Utama, Yogyakarta. The results of the analysis of the value of patriotism showed that the t-test score was 5.350 with Sig. 0,000. This shows that there is a significant increase in the value of students' patriotism between before and after learning using the story book ""Negeri Hastinapura"".",1.0,0.8217408657073975,True,0.3775406687981454,0.5996407672527715,True
Are Code Examples on an Online Q&A Forum Reliable?: A Study of API Misuse on Stack Overflow,"Programmers often consult an online Q&A forum such as Stack Overflow to learn new APIs. This paper presents an empirical study on the prevalence and severity of API misuse on Stack Overflow. To reduce manual assessment effort, we design ExampleCheck, an API usage mining framework that extracts patterns from over 380K Java repositories on GitHub and subsequently reports potential API usage violations in Stack Overflow posts. We analyze 217,818 Stack Overflow posts using ExampleCheck and find that 31% may have potential API usage violations that could produce unexpected behavior such as program crashes and resource leaks. Such API misuse is caused by three main reasons—missing control constructs, missing or incorrect order of API calls, and incorrect guard conditions. Even the posts that are accepted as correct answers or upvoted by other programmers are not necessarily more reliable than other posts in terms of API misuse. This study result calls for a new approach to augment Stack Overflow with alternative API usage details that are not typically shown in curated examples.",1.9,0.5931037664413452,False,0.598687660112452,0.5958957132768986,True
Kind Controllers and Fast Heuristics for Non-Well-Separated GR(1) Specifications,,0.8,0.8670024275779724,True,0.3318122278318339,0.5994073277049031,True
Maximum Spanning Tree Graph Model: National Examination Data Analysis of Junior High School in Lampung Province,"The purpose of this study is to determine the tendencies of learning in Lampung Province especially at junior high school level. Subjects of this study are all result of national examination data for junior high school in 2017 and 2018 in Lampung Province. The method of this study using model analysis of maximum spanning tree (MST) graph assisted by descriptive and inferential statistics technique. The data obtained are analysed using descriptive statistical analysis to find out the basic information of the data and inferential statistical analysis to get the value of coefficient correlation. Then, the MST graph is formed using Kruskal’s algorithm by interpreting the vertices as a subject and the edges as the value of coefficient correlation. The subject that have the closest relationship to any subject is a graph vertex with the greatest degree. Based on the MST graph model, the result of this study shows that the subject which has closest relationship with another subject is Science in 2017, while in 2018 are English and Mathematics. Based on these result and relevant research, the conclusion shows that Science and Mathematics to be the centre for the national examination of junior high school in 2017 and 2018 in Lampung Province.",1.0,0.7299909591674805,True,0.3775406687981454,0.553765813982813,True
Imperative versus Declarative Collection Processing: An RCT on the Understandability of Traditional Loops versus the Stream API in Java,"Java introduced in version 8 with the Stream API means to operate on collections using lambda expressions. Since then, this API is an alternative way to handle collections in a more declarative manner instead of the traditional, imperative style using loops. However, whether the Stream API is beneficial in comparison to loops in terms of usability is unclear. The present paper introduces a randomized control trial (RCT) on the understandability of collection operations performed on 20 participants with the dependent variables response time and correctness. As tasks, subjects had to determine the results for collection operations (either defined with the Stream API or with loops). The results indicate that the Stream API has a significant $(\mathrm{p} <. 001)$ and large $(\eta_{p}^{2}=.695;\frac{M_{loop}}{M_{stream}}\ \sim 178\%)$ positive effect on the response times. Furthermore, the usage of the Stream API caused significantly less errors. And finally, the participants perceived their speed with the Stream API higher compared to the loop-based code and the participants considered the code based on the Stream API as more readable. Hence, while existing studies found a negative effect of declarative constructs (in terms of lambda expressions) on the usability of a main stream programming language, the present study found the opposite: the present study gives evidence that declarative code on collections using the Stream API based on lambda expressions has a large, positive effect in comparison to traditional loops.",1.0,0.7904015779495239,True,0.3775406687981454,0.5839711233738347,True
Engineering Gender-Inclusivity into Software: Ten Teams' Tales from the Trenches,"Although the need for gender-inclusivity in software is gaining attention among SE researchers and SE practitioners, and at least one method (GenderMag) has been published to help, little has been reported on how to make such methods work in real-world settings. Real-world teams are ever-mindful of the practicalities of adding new methods on top of their existing processes. For example, how can they keep the time costs viable? How can they maximize impacts of using it? What about controversies that can arise in talking about gender? To find out how software teams “in the trenches” handle these and similar questions, we collected the GenderMag-based processes of 10 real-world software teams—more than 50 people—for periods ranging from 5 months to 3.5 years. We present these teams' insights and experiences in the form of 9 practices, 2 potential pitfalls, and 2 open issues, so as to provide their insights to other real-world software teams trying to engineer gender-inclusivity into their software products.",1.0,0.81831955909729,True,0.3775406687981454,0.5979301139477178,True
Does data sampling improve deep learning-based vulnerability detection? Yeas! and Nays!,"Recent progress in Deep Learning (DL) has sparked interest in using DL to detect software vulnerabilities automatically and it has been demonstrated promising results at detecting vulnerabilities. However, one prominent and practical issue for vulnerability detection is data imbalance. Prior study observed that the performance of state-of-the-art (SOTA) DL-based vulnerability detection (DLVD) approaches drops precipitously in real world imbalanced data and a 73% drop of F1-score on average across studied approaches. Such a significant performance drop can disable the practical usage of any DLVD approaches. Data sampling is effective in alleviating data imbalance for machine learning models and has been demonstrated in various software engineering tasks. Therefore, in this study, we conducted a systematical and extensive study to assess the impact of data sampling for data imbalance problem in DLVD from two aspects: i) the effectiveness of DLVD, and ii) the ability of DLVD to reason correctly (making a decision based on real vulnerable statements). We found that in general, oversampling outperforms undersampling, and sampling on raw data outperforms sampling on latent space, typically random oversampling on raw data performs the best among all studied ones (including advanced one SMOTE and OSS). Surprisingly, OSS does not help alleviate the data imbalance issue in DLVD. If the recall is pursued, random undersampling is the best choice. Random oversampling on raw data also improves the ability of DLVD approaches for learning real vulnerable patterns. However, for a significant portion of cases (at least 33% in our datasets), DVLD approach cannot reason their prediction based on real vulnerable statements. We provide actionable suggestions and a roadmap to practitioners and researchers.",0.8,0.7763434052467346,True,0.3318122278318339,0.5540778165392842,True
CoLeFunDa: Explainable Silent Vulnerability Fix Identification,"It is common practice for OSS users to leverage and monitor security advisories to discover newly disclosed OSS vulnerabilities and their corresponding patches for vulnerability remediation. It is common for vulnerability fixes to be publicly available one week earlier than their disclosure. This gap in time provides an opportunity for attackers to exploit the vulnerability. Hence, OSS users need to sense the fix as early as possible so that the vulnerability can be remediated before it is exploited. However, it is common for OSS to adopt a vulnerability disclosure policy which causes the majority of vulnerabilities to be fixed silently, meaning the commit with the fix does not indicate any vulnerability information. In this case even if a fix is identified, it is hard for OSS users to understand the vulnerability and evaluate its potential impact. To improve early sensing of vulnerabilities, the identification of silent fixes and their corresponding explanations (e.g., the corresponding common weakness enumeration (CWE) and exploitability rating) are equally important. However, it is challenging to identify silent fixes and provide explanations due to the limited and diverse data. To tackle this challenge, we propose CoLeFunDa: a framework consisting of a Contrastive Learner and FunDa, which is a novel approach for Function change Data augmentation. FunDa first increases the fix data (i.e., code changes) at the function level with unsupervised and supervised strategies. Then the contrastive learner leverages contrastive learning to effectively train a function change encoder, FCBERT, from diverse fix data. Finally, we leverage FCBERT to further fine-tune three downstream tasks, i.e., silent fix identification, CWE category classification, and exploitability rating classification, respectively. Our result shows that CoLeFunDa outperforms all the state-of-art baselines in all downstream tasks. We also conduct a survey to verify the effectiveness of CoLeFunDa in practical usage. The result shows that CoLeFunDa can categorize 62.5% (25 out of 40) CVEs with correct CWE categories within the top 2 recommendations.",1.0,0.9405125975608826,True,0.3775406687981454,0.659026633179514,True
Fuzzy Fine-Grained Code-History Analysis,"Existing software-history techniques represent source-code evolution as an absolute and unambiguous mapping of lines of code in prior revisions to lines of code in subsequent revisions. However, the true evolutionary lineage of a line of code is often complex, subjective, and ambiguous. As such, existing techniques are predisposed to, both, overestimate and underestimate true evolution lineage. In this paper, we seek to address these issues by providing a more expressive model of code evolution, the fuzzy history graph, by representing code lineage as a continuous (i.e., fuzzy) metric rather than a discrete (i.e., absolute) one. Using this more descriptive model, we additionally provide a novel multi-revision code-history analysis — fuzzy history slicing. In our experiments over three real-world software systems, we found that the fuzzy history graph provides a tunable balance of precision and recall, and an overall improved accuracy over existing code-evolution models. Furthermore, we found that the use of such a fuzzy model of history provided improved accuracy for code-history analysis tasks.",1.0,0.8656716346740723,True,0.3775406687981454,0.6216061517361089,True
"“Do this! Do that!, and Nothing will Happen” Do Specifications Lead to Securely Stored Passwords?","Does the act of writing a specification (how the code should behave) for a piece of security sensitive code lead to developers producing more secure code? We asked 138 developers to write a snippet of code to store a password: Half of them were asked to write down a specification of how the code should behave before writing the program, the other half were asked to write the code but without being prompted to write a specification first. We find that explicitly prompting developers to write a specification has a small positive effect on the security of password storage approaches implemented. However, developers often fail to store passwords securely, despite claiming to be confident and knowledgeable in their approaches, and despite considering an appropriate range of threats. We find a need for developer-centered usable mechanisms for telling developers how to store passwords: lists of what they must do are not working.",0.8,0.9597636461257935,True,0.3318122278318339,0.6457879369788136,True
"Graph-Based Mining of In-the-Wild, Fine-Grained, Semantic Code Change Patterns","Prior research exploited the repetitiveness of code changes to enable several tasks such as code completion, bug-fix recommendation, library adaption, etc. These and other novel applications require accurate detection of semantic changes, but the state-of-the-art methods are limited to algorithms that detect specific kinds of changes at the syntactic level. Existing algorithms relying on syntactic similarity have lower accuracy, and cannot effectively detect semantic change patterns. We introduce a novel graph-based mining approach, CPatMiner, to detect previously unknown repetitive changes in the wild, by mining fine-grained semantic code change patterns from a large number of repositories. To overcome unique challenges such as detecting meaningful change patterns and scaling to large repositories, we rely on fine-grained change graphs to capture program dependencies. We evaluate CPatMiner by mining change patterns in a diverse corpus of 5,000+ open-source projects from GitHub across a population of 170,000+ developers. We use three complementary methods. First, we sent the mined patterns to 108 open-source developers. We found that 70% of respondents recognized those patterns as their meaningful frequent changes. Moreover, 79% of respondents even named the patterns, and 44% wanted future IDEs to automate such repetitive changes. We found that the mined change patterns belong to various development activities: adaptive (9%), perfective (20%), corrective (35%) and preventive (36%, including refactorings). Second, we compared our tool with the state-of-the-art, AST-based technique, and reported that it detects 2.1x more meaningful patterns. Third, we use CPatMiner to search for patterns in a corpus of 88 GitHub projects with longer histories consisting of 164M SLOCs. It constructed 322K fine-grained change graphs containing 3M nodes, and detected 17K instances of change patterns from which we provide unique insights on the practice of change patterns among individuals and teams. We found that a large percentage (75%) of the change patterns from individual developers are commonly shared with others, and this holds true for teams. Moreover, we found that the patterns are not intermittent but spread widely over time. Thus, we call for a community-based change pattern database to provide important resources in novel applications.",1.0,0.803254246711731,True,0.3775406687981454,0.5903974577549382,True
One Fuzzing Strategy to Rule Them All,"Coverage-guided fuzzing has become mainstream in fuzzing to automatically expose program vulnerabilities. Recently, a group of fuzzers are proposed to adopt a random search mechanism namely Havoc, explicitly or implicitly, to augment their edge exploration. However, they only tend to adopt the default setup of Havoc as an implementation option while none of them attempts to explore its power under diverse setups or inspect its rationale for potential improvement. In this paper, to address such issues, we conduct the first empirical study on Havoc to enhance the understanding of its characteristics. Specifically, we first find that applying the default setup of Havoc to fuzzers can significantly improve their edge coverage performance. Interestingly, we further observe that even simply executing Havoc itself without appending it to any fuzzer can lead to strong edge coverage performance and outper-form most of our studied fuzzers. Moreover, we also extend the execution time of Havoc and find that most fuzzers can not only achieve significantly higher edge coverage, but also tend to perform similarly (i.e., their performance gaps get largely bridged). Inspired by the findings, we further propose HavocMAB, which models the Havoc mutation strategy as a multi-armed bandit problem to be solved by dynamically adjusting the mutation strategy. The evaluation result presents that HavocMAB can significantly increase the edge coverage by 11.1% on average for all the benchmark projects compared with Havoc and even slightly outperform state-of-the-art QSYM which augments its computing resource by adopting three parallel threads. We further execute HavocMAB with three parallel threads and result in 9% higher average edge coverage over QSYM upon all the benchmark projects.",1.8,0.9680432677268982,True,0.574442516811659,0.7712428922692787,True
Hierarchical Multi-resource Fair Queueing for Network Function Virtualization,"As the volume of traffic flows surges, providing Quality-of-Service (QoS) guarantees to flows by fair queueing has never been more challenging in Network Function Virtualization (NFV). There has been a recent effort in both industry and academia to develop fair queueing algorithms across multiple resources in NFV. However, all existing works fail to support hierarchical scheduling, a crucial feature that also provides QoS guarantees to grouped flows on tenant boundaries. In this paper, we present two new multi-resource fair queueing algorithms that support hierarchies, collapsed Hierarchical Dominant Resource Fair Queueing (collapsed H-DRFQ) and dove-tailing H-DRFQ, both of which provide hierarchical share guarantees. Through formal analysis, we find that the dove-tailing H-DRFQ outper-forms collapsed H-DRFQ by providing a smaller delay bound. However, according to the simulation results, both algorithms have their pros and cons. Dove-tailing H-DRFQ benefits to the flows with more complex hierarchies, while collapsed H-DRFQ is better for the flows with simpler attribution structures. Meanwhile, our simulation shows that both H-DRFQ algorithms can achieve near-perfect fairness.",1.0,0.7750742435455322,True,0.3775406687981454,0.5763074561718389,True
Letting off STEAM: Distributed Runtime Traffic Scheduling for Service Function Chaining,"Network function virtualization has introduced a high degree of flexibility for orchestrating service functions. The provisioning of chains of service functions requires making decisions on both (1) placement of service functions and (2) scheduling of traffic through them. The placement problem (1) can be tackled during the planning phase, by exploiting coarse-grained traffic information, and has been studied extensively. However, runtime traffic scheduling (2) for optimizing system utilization and service quality, as required for future edge cloud and mobile carrier scenarios, has not been addressed so far.We fill this gap by presenting a queuing-based system model to characterize the runtime traffic scheduling problem for service function chaining. We propose a throughput-optimal scheduling policy, called integer allocation maximum pressure policy (IA-MPP). To ensure practicality in large distributed settings, we propose multi-site cooperative IA-MPP (STEAM), fulfilling runtime requirements while achieving near-optimal performance. We examine our policies in various settings representing real-world scenarios. STEAM closely matches IA-MPP in terms of throughput, and significantly outperforms (possible adaptations of) existing static or coarse-grained dynamic solutions, requiring 30%-60% less server capacity for similar service quality. Our STEAM prototype shows feasibility running on a standard server.",1.0,0.7770253419876099,True,0.3775406687981454,0.5772830053928777,True
Do mobile phones improve per-capita income?: Granger causality test based on cross-country dataset,,1.1,0.7298704981803894,True,0.401312339887548,0.5655914190339687,True
MAGIC: Magnetic Resonant Coupling for Intra-body Communication,"This paper proposes MAGIC: magnetic resonant (MR) coupling for intra-body communication between implants and wearables. MAGIC includes not only the hardware-software design of the coupled coils and methods of manipulating the magnetic field for relaying information, but also the ability to raise immediate emergency-related alerts with guaranteed delivery time. MR coupling makes the design of the transmission link robust to channel-related parameters, as the magnetic permeability of skin and muscle is close to that of air. Thus, changes in tissue moisture content and thickness does not impact the design, which is a persistent problem in other approaches for implant communications like RF, ultrasound and galvanic coupling (GC). The paper makes three main contributions: It develops the theory leading to the design of the information relaying coils in MAGIC. It proposes a systems-level design of a communication link that extends up to 50cm with a low expected BER of 10−4. Finally, the paper includes an experimental setup demonstrating how MAGIC operates in air and muscle tissue, as well as a comparison with alternative implant communication technologies, such as classical radio frequency and GC. Results reveal that MAGIC offers instantaneous alerts with up to 5 times lower power consumption compared to other forms of communication.",1.0,0.8725704550743103,True,0.3775406687981454,0.6250555619362279,True
(How Much) Does a Private WAN Improve Cloud Performance?,"The construction of private WANs by cloud providers enables them to extend their networks to more locations and establish direct connectivity with end user ISPs. Tenants of the cloud providers benefit from this proximity to users, which is supposed to provide improved performance by bypassing the public Internet. However, the performance impact of cloud providers’ private WANs is not widely understood.To isolate the impact of a private WAN, we measure from globally distributed vantage points to two large cloud providers, comparing performance when using their worldwide WAN and when instead using the public Internet. The benefits are not universal. While 48% of our vantage points saw improved performance when using the WAN, 43% had statistically indistinguishable median performance, and 9% had better performance over the public Internet. We find that the benefits of the private WAN tend to improve with client-to-server distance, but the benefits (or drawbacks) for a particular vantage point depend on specifics of its geographic and network connectivity.",1.1,0.7287349700927734,True,0.401312339887548,0.5650236549901607,True
WebMythBusters: An In-depth Study of Mobile Web Experience,"The quality of experience (QoE) is an important issue for users when accessing the web. Although many metrics have been designed to estimate the QoE in the desktop environment, few studies have confirmed whether the QoE metrics are valid in the mobile environment. In this paper, we ask questions regarding the validity of using desktop-based QoE metrics for the mobile web and find answers. We first classify the existing QoE metrics into several groups according to three criteria and then identify the differences between the mobile and desktop environments. Based on the analysis, we ask three research questions and develop a system, called WebMythBusters, for collecting and analyzing mobile web experiences. Through an extensive analysis of the collected user data, we find that (1) the metrics focusing on fast completion or fast initiation of the page loading process cannot estimate the actual QoE, (2) the conventional scheme of calculating visual progress is not appropriate, and (3) focusing only on the above-the-fold area is not sufficient in the mobile environment. The findings indicate that QoE metrics designed for the desktop environment are not necessarily adequate for the mobile environment, and appropriate metrics should be devised to reflect the mobile web experience.",1.0,0.8908576965332031,True,0.3775406687981454,0.6341991826656743,True
Ant Colony based Online Learning Algorithm for Service Function Chain Deployment,"Network Function Virtualization (NFV) emerges as a promising paradigm with the potential for cost-efficiency, manage-convenience, and flexibility, where the service function chain (SFC) deployment scheme is a crucial technology. In this paper, we propose an Ant Colony Optimization (ACO) meta-heuristic algorithm for the Online SFC Deployment, called ACO-OSD, with the objectives of jointly minimizing the server operation cost and network latency. As a meta-heuristic algorithm, ACO-OSD performs better than the state-of-art heuristic algorithms, specifically 42.88% lower total cost on average. To reduce the time cost of ACO-OSD, we design two acceleration mechanisms: the Next-Fit (NF) strategy and the many-to-one model between SFC deployment schemes and ant-tours. Besides, for the scenarios requiring real-time decisions, we propose a novel online learning framework based on the ACO-OSD algorithm, called prior-based learning real-time placement (PLRP). It realizes near real-time SFC deployment with the time complexity of O(n), where n is the total number of VNFs of all newly arrived SFCs. It meanwhile maintains a performance advantage with 36.53% lower average total cost than the state-of-art heuristic algorithms. Finally, we perform extensive simulations to demonstrate the outstanding performance of ACO-OSD and PLRP compared with the benchmarks.",1.0,0.8071447014808655,True,0.3775406687981454,0.5923426851395055,True
FID: Function Modeling-based Data-Independent and Channel-Robust Physical-Layer Identification,"Trusted identification is critical to secure IoT devices. However, the limited memory and computation power of low-end IoT devices prevent the direct usage of conventional identification systems. RF fingerprinting is a promising technique to identify low-end IoT devices since it only requires the RF signals that most IoT devices can produce for communication. However, most existing RF fingerprinting systems are data-dependent and/or not robust to impacts from wireless channels. To address the above problems, we propose to exploit the mathematical expression of the physical-layer process, regarded as a function $\mathcal{F} (\cdot )$ for device identification. $\mathcal{F} (\cdot )$ is not directly derivable, so we further propose a model to learn it and employ this function model as the device fingerprint in our system, namely $\mathcal{F}{\rm{ID}}$. Our proposed function model characterizes the unique physical-layer process of a device that is independent of the transmitted data, and hence, our system $\mathcal{F}{\rm{ID}}$ is data-independent and thus resilient against signal replay attacks. Modeling and further separating channel effects from the function model makes $\mathcal{F}{\rm{ID}}$ channel-robust. We evaluate $\mathcal{F}{\rm{ID}}$ on thousands of random signal packets from 33 different devices in different environments and scenarios, and the overall identification accuracy is over 99%.",1.0,0.7296494841575623,True,0.3775406687981454,0.5535950764778539,True
Special ICT Report 世界のAR/VR(拡張現実/仮想現実)の最新動向 : ゲーム・娯楽から産業界へ用途を拡大,,0.8,0.901958703994751,True,0.3318122278318339,0.6168854659132924,True
Ongoing research agenda on the Internet of Things (IoT) in the context of Artificial Intelligence (AI),"This talk presents our ongoing research agenda on the Internet of Things (IoT) in the context of Artificial Intelligence (AI). sThree initiatives define this agenda: integration of IoT into business process management, agentification of things, and mutation of things. IoT is among the latest ICT developments that is making the boundaries between reality and fiction vanish. According to Mark Weiser, “…The most profound technologies are those that disappear. They weave themselves into the fabric of everyday life until they are indistinguishable from it”i. And according to Gartnerii, 6.4 billion connected things were in use in 2016, up 3% from 2015, and will reach 20.8 billion by 2020. In the first initiative, we adopt storytelling principles to design and develop Process of Things (PoT). A PoT is specified as a story whose script indicates the characters that things will play as well as the scenes that will feature these things. A PoT also allows things to collaborate by offering value-added services to end-users. A system implementing PoT will be presented during the talk. In the second initiative, we shed the light on some obstacles that are slowing downIoTexpansion and adoption, for instance diversity of things' development technologies and communication standards, users' reluctance and sometimes rejection due to privacy invasion, lack of killer applications that would demonstrate their necessity, lack of an IoT-oriented software engineering discipline, and finally, the passive nature of things. Because of this nature, things are restricted to sending data to third parties or (basic) processing data prior to their transfer to third parties, too. We are examining how to empower things with additional capabilities that would make them proactive. This means that things can for instance, reach out to peers that expose collaborative attitude, form dynamic communities when necessary, avoid peers that expose malicious attitude, be accountable for their actions, etc. While we already see some encouraging signs of thing empowerment through initiatives like semantic things, Internet of social things, Internet of agents, and agents of things, we propose the agentification of things from a conceptual perspective exemplified with norms and an operational perspective exemplified with commitments. In conjunction with thing agentification, we present during the talk the third initiative that examines thing mutation in the sense that things will bind and/or unbind capabilities on the fly (and as they see fit). To ensure mutation success we consider first, the context in which things operate and second, policies that impact things' decisions to bind/unbind capabilities. We motivate mutation decisions with 3 factors: performance so that a thing remains competitive/attractive, adaptation so that a thing remains responsive, and survivability so that a thing remains in business.",0.8,0.7791649103164673,True,0.3318122278318339,0.5554885690741506,True
Maximizing h-hop Independently Submodular Functions Under Connectivity Constraint,"This study is motivated by the maximum connected coverage problem (MCCP), which is to deploy a connected UAV network with given K UAVs in the top of a disaster area such that the number of users served by the UAVs is maximized. The deployed UAV network must be connected, since the received data by a UAV from its served users need to be sent to the Internet through relays of other UAVs. Motivated by this application, in this paper we study a more generalized problem – the h-hop independently submodular maximization problem, where the MCCP problem is one of its special cases with h = 4. We propose a $\frac{{1 - 1/e}}{{2h + 3}}$-approximation algorithm for the h-hop independently submodular maximization problem, where e is the base of the natural logarithm. Then, one direct result is a $\frac{{1 - 1/e}}{{11}}$-approximate solution to the MCCP problem with h = 4, which significantly improves its currently best $\frac{{1 - 1/e}}{{32}}$-approximate solution. We finally evaluate the performance of the proposed algorithm for the MCCP problem in the application of deploying UAV networks, and experimental results show that the number of users served by deployed UAVs delivered by the proposed algorithm is up to 12.5% larger than those by existing algorithms.",1.0,0.7445160150527954,True,0.3775406687981454,0.5610283419254705,True
Fast downstream to many (computational) RFIDs,We present Stork — an extension of the EPC C1G2 protocol allowing streaming of data to multiple Computational Radio Frequency IDentification tags (CRFIDs) simultaneously at up to 20 times faster than the prior state of the art. Stork introduces downstream attributes never before seen in (C)RFIDs: (i) fast feedback for CRFID downstream verification based on the internal EPC C1G2 memory check command — which we analytically and experimentally show to be the best possible downstream verification process based on EPC C1G2; (ii) ability to perform multi-CRFID transfer — which in our experiments speeds up downstream by more than two times compared to sequential transmission; and (iii) the use of compressed data streams — which improves firmware reprogramming times by up to 10% at large reader-to-CRFID distances.,0.8,0.8320338726043701,True,0.3318122278318339,0.581923050218102,True
Inferring Carrier-Grade NAT Deployment in the Wild,"Given the increasing scarcity of IPv4 addresses, network operators are resorting to measures to expand their address pool or prolong the life of existing addresses. One such approach is Carrier-Grade NAT (CGN), where many end-users in a network share a single public IPv4 address. There is limited data about the prevalence of CGN, despite the implications on performance, security, and ultimately, the adoption of IPv6. In this work, we present passive measurement-based techniques for detecting CGN deployments across the entire Internet, without the requirement of access to machines behind a CGN. Specifically, we identify patterns in how client IP addresses are observed at M-Lab servers and at the UCSD network telescope to infer whether those clients are behind a CGN. We apply our methods on data collected from 2014 to 2016. We find that CGN deployment is increasing rapidly. Overall, we infer that 4.1K autonomous systems are deploying CGN, 6 times the number inferred by the most recent studies.",1.0,0.725741446018219,True,0.3775406687981454,0.5516410574081823,True
MOM: MANETS (Mutual adjustment by neighbor nodes ensuring transmissions smoothly) on MANets (mobile ad hoc networks) provisioning quality of service at network layer,"In this paper the researchers have worked determinedly to create the clique of the best performing nodes by computing their respective degree of trust to each other w.r.t. Degree of Centrality (DC), Battery Power (BP) and other Route Involvement Activities (RI) in the form of multicast groups. Higher is the Trust value (T) more probable protagonist it stages to get engaged in route and its maintenance related activities. The algorithm is highly influenced by the civic and organized nature of all living species in the form of groups on the earth to tranquilize and ease each other's existence and stimulation. The MOM algorithm's modus operandi although abstracts approximately more time, initially to pick the momentum of route building (being novice to the underlying environment) including searching best possible intermediate nodes along with nominating two guarantor nodes for each selected node to replace/assist it when needed but once taken over, route is automatically roped dynamically for all the adaptations. This local approach of load balancing and adapting aptly with route related difficulties or problems, make it a good choice to circumvent the control overhead and instilling the graceful degradation. Hence don't exaggerate the broken links or intermediate nodes unavailability all along the route, through inhibiting re-initiations from the scratch.",0.8,0.8839982748031616,True,0.3318122278318339,0.6079052513174977,True
Japan ICT Trend : NTTドコモの農業ICTへの取り組み(3)本格普及を見据えた女性生産者ネットワークとの交流,,0.8,0.9196513295173645,True,0.3318122278318339,0.6257317786745992,True
A Close Look at 5G in the Wild: Unrealized Potentials and Implications,"This paper reports our in-depth measurement study of 5G experience with three US operators (AT&T, Verizon and T-Mobile). We not only quantitively characterize 5G coverage, availability and performance (over both mmWave and Sub-6GHz bands), but also identify several performance issues and analyze their root causes. We see that real 5G experience is not that satisfactory as anticipated. It is mainly because faster 5G is not used as it can and should. We have several surprising findings: Despite huge speed potentials (say, up to several hundreds of Mbps), more than half are not realized in practice; Such under-utilization is mainly stemmed from current practice and policies that manage radio resource in a performance-oblivious manner; 5G is even less used where 5G is co-deployed over both mmWave and Sub-6GHz bands; Transiently missing 5G is not uncommon and its negative impacts last much longer. Inspired by our findings, we design a patch solution called 5GBoost to fix the problems identified in legacy 5G operations. Our preliminary evaluation validates its effectiveness to realize more 5G potentials.",1.0,0.8024735450744629,True,0.3775406687981454,0.5900071069363042,True
Fast Beeping Protocols for Deterministic MIS and (Δ + 1)-Coloring in Sparse Graphs,"The beeping model is an extremely restrictive broadcast communication model that relies only on carrier sensing. We consider two problems in this model: (Δ+l)-vertex coloring and maximal independent set (MIS), for a network of unknown size <tex>$n$</tex> and unknown maximum degree Δ. Solving these problems allows to overcome communication interferences, and to break symmetry, a core component of many distributed protocols. The presented results apply to general graphs, but are efficient in graphs with low edge density (sparse graphs), such as bounded degree graphs, planar graphs and graphs of bounded arboricity. We present O(Δ<sup>2</sup> log n + Δ<sup>3</sup>) time deterministic uniform MIS and coloring protocols, which are asymptotically time optimal for bounded degree graphs. Furthermore, we devise O(a<sup>2</sup> log2 n+a<sup>3</sup>log n) time MIS and coloring protocols, as well as O(a<sup>2</sup> Δ <sup>2</sup> log<sup>2</sup> n + a<sup>3</sup> Δ <sup>3</sup> log n) time 2-hop MIS and 2-hop coloring protocols, where <tex>$a$</tex> is the arboricity of the communication graph. Building upon the 2-hop coloring protocols, we show how the strong CONGEST model can be simulated and by using this simulation we obtain an O (<tex>$a$</tex>) -coloring protocol. No results about coloring with less than Δ + 1 colors were known up to now in the beeping model.",0.8,0.8523762822151184,True,0.3318122278318339,0.5920942550234761,True
A multi-constraint based objective function and lion optimization for the data clustering,"Data clustering allows partitioning of the large database into smaller databases for improving the data mining. This paper introduces a multi-constraint based objective function for the selection of the optimal cluster centroids for clustering the data. The proposed objective function utilizes three parameters, such as intra-cluster distance, inter-cluster distance, and density, where various kernel functions, namely Gaussian kernel, tangential kernel, rational quadratic kernel and inverse multiquadratic kernel, are used for the distance measure. Then, Adaptive Dynamic Directive Operative Fractional Lion (ADDOFL) algorithm that makes use of proposed multikernel based objective function finds the optimal cluster center. From the simulation results, it is obvious that the ADDOFL algorithm with the proposed objective function has better performance than the ADDOFL algorithm, using the Clustering Accuracy (CA) and the Jaccard coefficient (JC) metrics. For the lung cancer database, the proposed ADDOFL with the multikernel based fitness achieved CA and JC values of 0.8670, and 0.85, for the cluster size of 2. Similarly, for the Pima Indian diabetes database, the proposed ADDOFL with the multikernel based fitness achieved CA and JC values of 0.84609, and 0.85, respectively.",1.0,0.8923471570014954,True,0.3775406687981454,0.6349439128998204,True
On Scalable Service Function Chaining with $\mathcal{O}(1)$ Flowtable Entries,"The emergence of Network Function Virtualization (NFV) enables flexible and agile service function chaining in a Software Defined Network (SDN). While this virtualization technology efficiently offers customization capability, it however comes with a cost of consuming precious TCAM resources. Due to this, the number of service chains that an SDN can support is limited by the flowtable size of a switch. To break this limitation, this paper presents CRT-Chain, a service chain forwarding protocol that requires only constant flowtable entries, regardless of the number of service chain requests. The core of CRT-Chain is an encoding mechanism that leverages Chinese Remainder Theorem (CRT) to compress the forwarding information into small labels. A switch does not need to insert forwarding rules for every service chain request, but only needs to conduct very simple modular arithmetic to extract the forwarding rules directly from CRT-Chain's labels attached in the header. We further incorporate prime reuse and path segmentation in CRT-Chain to reduce the header size and, hence, save bandwidth consumption. Our evaluation results show that, when a chain consists of no more than 5 functions, CRT-Chain actually generates a header smaller than the legacy 32-bit header defined in IETF. By enabling prime reuse and segmentation, CRT-Chain further reduces the total signaling overhead to a level lower than the conventional scheme, showing that CRT-Chain not only enables scalable flowtable-free chaining but also improves network efficiency.",1.8,0.620185375213623,True,0.574442516811659,0.5973139460126411,True
Dyssect: Dynamic Scaling of Stateful Network Functions,"Network Function Virtualization promises better utilization of computational resources by dynamically scaling resources on demand. However, most network functions (NFs) are stateful and require state updates on a per-packet basis. During a scaling operation, cores need to synchronize access to a shared state to avoid race conditions and to guarantee that NFs process packets in arrival order. Unfortunately, the classic approach to control concurrent access to a shared state with locks does not scale to today’s throughput and latency requirements. Moreover, network traffic is highly skewed, leading to load imbalances in systems that use only sharding to partition the NF states. To address these challenges, we present Dyssect, a system that enables dynamic scaling of stateful NFs by disaggregating the states of network functions. By carefully coordinating actions between cores and a central controller, Dyssect migrates shards and flows between cores for load balancing or traffic prioritization without resorting to locks or reordering packets. Our experimental evaluation shows that Dyssect reduces tail latency up to 32% and increases throughput up to 19.36% when compared to state-of-the-art competing solutions.",1.0,0.7519811391830444,True,0.3775406687981454,0.564760903990595,True
Puncturable Attribute-Based Encryption for Secure Data Delivery in Internet of Things,"While the Internet of Things (IoT) is embraced as important tools for efficiency and productivity, it is becoming an increasingly attractive target for cybercriminals. This work represents the first endeavor to develop practical Puncturable Attribute Based Encryption schemes that are light-weight and applicable in IoTs. In the proposed scheme, the attribute-based encryption is adopted for fine grained access control. The secret keys are puncturable to revoke the decryption capability for selected messages, recipients, or time periods, thus protecting selected important messages even if the current key is compromised. In contrast to conventional forward encryption, a distinguishing merit of the proposed approach is that the recipients can update their keys by themselves without key re-issuing from the key distributor. It does not require frequent communications between IoT devices and the key distribution center, neither does it need deleting components to expunge existing keys to produce a new key. Moreover, we devise a novel approach which efficiently integrates attribute-based key and punctured keys such that the key size is roughly the same as that of the original attribute-based encryption. We prove the correctness of the proposed scheme and its security under the Decisional Bilinear Diffie-Hellman (DBDH) assumption. We also implement the proposed scheme on Raspberry Pi and observe that the computation efficiency of the proposed approach is comparable to the original attribute-based encryption. Both encryption and decryption can be completed within tens of milliseconds.",1.0,0.7892521619796753,True,0.3775406687981454,0.5833964153889104,True
PAM & PAL: Policy-Aware Virtual Machine Migration and Placement in Dynamic Cloud Data Centers,"We focus on policy-aware data centers (PADCs), wherein virtual machine (VM) traffic traverses a sequence of middleboxes (MBs) for security and performance purposes, and propose two new VM placement and migration problems. We first study PAL: policy-aware virtual machine placement. Given a PADC with a data center policy that communicating VM pairs must satisfy, the goal of PAL is to place the VMs into the PADC to minimize their total communication cost. Due to dynamic traffic loads in PADCs, however, above VM placement may no longer be optimal after some time. We thus study PAM: policy-aware virtual machine migration. Given an existing VM placement in the PADC and dynamic traffic rates among communicating VMs, PAM migrates VMs in order to minimize the total cost of migration and communication of the VM pairs. We design optimal, approximation, and heuristic policyaware VM placement and migration algorithms. Our experiments show that i) VM migration is an effective technique, reducing total communication cost of VM pairs by 25%, ii) our PAL algorithms outperform state-of-the-art VM placement algorithm that is oblivious to data center policies by 40-50%, and iii) our PAM algorithms outperform the only existing policy-aware VM migration scheme by 30%.",0.8,0.7803672552108765,True,0.3318122278318339,0.5560897415213552,True
Shortest Path and Maximum Flow Problems Under Service Function Chaining Constraints,"With the advent of Network Function Virtualization (NFV), Physical Network Functions (PNFs) are gradually being replaced by Virtual Network Functions (VNFs) that are hosted on general purpose servers. Depending on the call flows for specific services, the packets need to pass through an ordered set of network functions (physical or virtual) called Service Function Chains (SFC) before reaching the destination. Conceivably for the next few years during this transition, these networks would have a mix of PNFs and VNFs, which brings an interesting mix of network problems that are studied in this paper: (1) How to find an SFC-constrained shortest path between any pair of nodes? (2) What is the achievable SFC-constrained maximum flow? (3) How to place the VNFs such that the cost (the number of nodes to be virtualized) is minimized, while the maximum flow of the original network can still be achieved even under the SFC constraint? In this work, we will try to address such emerging questions. First, for the SFC-constrained shortest path problem, we propose a transformation of the network graph to minimize the computational complexity of subsequent applications of any shortest path algorithm. Second, we formulate the SFC-constrained maximum flow problem as a fractional multicommodity flow problem, and develop a combinatorial algorithm for a special case of practical interest. Third, we prove that the VNFs placement problem is NP-hard and present an alternative Integer Linear Programming (ILP) formulation. Finally, we conduct simulations to elucidate our theoretical results.",1.0,0.8324815034866333,True,0.3775406687981454,0.6050110861423894,True
Code is the (F)Law: Demystifying and Mitigating Blockchain Inconsistency Attacks Caused by Software Bugs,"Blockchains promise to provide a tamper-proof medium for transactions, and thus enable many applications including cryptocurrency. As a system built on consensus, the correctness of a blockchain heavily relies on the consistency of states between its nodes. But consensus protocols of blockchains only guarantee the consistency in the transaction sequence rather than nodes’ internal states. Instead, nodes must replay and exe-cute all transactions to maintain their local states independently. When executing transactions, any different execution result could cause a node out-of-sync and thus gets isolated from other nodes.After systematically modeling the transaction execution process in blockchains, we present a new attack INCITE, which can lead different nodes to different states. Specifically, attackers could invoke an ambiguous transaction of a vulnerable smart contract, utilize software bugs in smart contracts to lead nodes that execute this transaction into different states. Unlike attacks that bring short-term inconsistencies, such as fork attacks, INCITE can cause nodes in the blockchain to fall into a long-term inconsistent state, which further leads to great damages to the chain (e.g., double-spending attacks and expelling mining power). We have discovered 7 0day vulnerabilities in 5 popular blockchains which can enable this attack. We also proposed a defense solution to mitigate this threat. Experiments showed that it is effective and lightweight.",0.8,0.775114119052887,True,0.3318122278318339,0.5534631734423604,True
Characterizing task-evoked and intrinsic functional networks from task-based fMRI data via two-stage sparse dictionary learning,"Recently, increasing studies suggest that task-evoked brain networks and intrinsic connectivity networks are concurrent during task performance in the architecture of functional brain organization. However, it remains challenging to identify and quantitatively characterize these mixtures of networks from task-based functional magnetic resonance imaging (fMRI) data. In this paper, we propose a two-stage sparse dictionary learning method by establishing spatial correspondences among the brain networks of multiple subjects and automatically categorize these networks into task-evoked, intrinsic and uncertain ones. The proposed framework is applied to Human Connectome Project (HCP) task-based fMRI data. Experimental results demonstrate that this method can effectively identify group-wise task-evoked and intrinsic networks simultaneously. Our study provides a novel data-driven method to facilitate a comprehensive understanding of the functional brain architecture.",1.0,0.7267962694168091,True,0.3775406687981454,0.5521684691074773,True
A novel hybrid approach for severity assessment of Diabetic Retinopathy in colour fundus images,"Diabetic Retinopathy (DR) is one of the leading causes of blindness worldwide. Detecting DR and grading its severity is essential for disease treatment. Convolutional neural networks (CNNs) have achieved state-of-the-art performance in many different visual classification tasks. In this paper, we propose to combine CNNs with dictionary based approaches, which incorporates pathology specific image representation into the learning framework, for improved DR severity classification. Specifically, we construct discriminative and generative pathology histograms and combine them with feature representations extracted from fully connected CNN layers. Our experimental results indicate that the proposed method shows improvement in quadratic kappa score (κ2 = 0.86) compared to the state-of-the-art CNN based method (κ2 = 0.81).",1.0,0.7464506030082703,True,0.3775406687981454,0.5619956359032079,True
3-way Parallel Fusion of Spatial (sMRI/dMRI) and Spatio-temporal (fMRI) Data with Application to Schizophrenia,"Advances in brain imaging acquisition techniques allow data from multiple modalities to be collected from each subject offering different but limited views of the structural, functional or temporal properties of human brain. Multimodal fusion can provide a way to leverage different perspectives from multiple complementary modalities. However, most current fMRI-related multimodal fusion approaches are restricted to the second-level 3D features, rather than the original 4D fMRI data. Here we are motivated to propose a novel 3-way fusion approach that can incorporate temporal information from fMRI by parallelizing “group ICA” and “parallel ICA” under a global optimization. Simulations show that GICA+pICA provides more accurate inter-modality linkage detection under both strong and weak correlations. In real data application, one linked fMRI-sMRI-dMRI component was identified showing differences between schizophrenia and controls in all modalities, demonstrating the stability of GICA+pICA to identify inter-modality linkage among three modalities.",0.8,0.8599355816841125,True,0.3318122278318339,0.5958739047579732,True
Ellipse Detection of Optic Disc-and-Cup Boundary in Fundus Images,"Glaucoma is an eye disease that damages the optic nerve and leads to loss of vision. The diagnosis of glaucoma involves measurement of cup-to-disc ratio from retinal fundus images, which necessitates the detection of the optic disc-and-cup boundary as a crucial task for glaucoma screening. Most existing computer-aided diagnosis (CAD) systems focus on the segmentation approaches but ignore the localization approaches, which requires less human annotation cost. In this paper, we propose a deep learning-based framework to jointly localize the ellipse for the optic disc (OD) and optic cup (OC) regions. Instead of detecting a bounding box like in most object detection approaches, we directly estimate the parameters of an ellipse that suffices to capture the morphology of each OD and OC region for calculating the cup-to-disc ratio. We use two modules to detect the ellipses for OD and OC regions, where the OD region serves as attention to the OC region. The proposed framework achieves competitive results against the state-of-the-art segmentation methods with less supervision. We empirically evaluate our framework with the recent state-of-the-art segmentation models on two scenarios where the training data and test data come from the same and different domains.",1.0,0.8040035963058472,True,0.3775406687981454,0.5907721325519963,True
A novel framework for groupwise registration of fMRI images based on common functional networks,"Accurate registration plays a critical role in group-wise functional Magnetic Resonance Imaging (fMRI) image analysis, as spatial correspondence among different brain images is a prerequisite for inferring meaningful patterns. However, the problem is challenging and remains open, and more effort should be made to advance the state-of-the-art image registration methods for fMRI images. Inspired by the observation that common functional networks can be reconstructed from fMRI image across individuals, we propose a novel computational framework for simultaneous groupwise fMRI image registration by utilizing those common functional networks as references for spatial alignments. In this framework, firstly, individualized functional networks in each subject are inferred using Independent Component Analysis (ICA); secondly, congealing groupwise registration that takes entropy of stacked independent components (ICs) from all the subjects as objective function is applied to register individual functional maps for maximal matching. The proposed framework is evaluated by and applied to an Alzheimer's Disease (AD) fMRI dataset and shows reasonably good results.",1.0,0.7265985012054443,True,0.3775406687981454,0.5520695850017949,True
A New Semi-Supervised Non-Negative Matrix Factorization Method For Brain Dynamic Functional Connectivity Analysis,"To overcome the shortcoming of static brain functional connectivity analysis, recent studies have analyzed brain functional connectivity from a time-varying view to identify subtle group differences as potential biomarkers. However, how to obtain reliable functional connectivity states from dynamic functional connectivity (DFC) is challenging, since the resulting states are often sensitive to the cluster or component number. In our present work, we propose a new semi-supervised non-negative matrix factorization method combining with a community detection technique, which can automatically estimate reliable functional connectivity states from DFC without a need of setting a cluster or component number. We applied our method to fMRI data of 36 schizophrenia patients and 49 healthy controls to investigate brain connectivity changes in schizophrenia. We found significant and meaningful group differences in four of five connectivity states. Our findings suggest that our method can help understand the mechanism of mental illness in a more effective way.",1.0,0.8916139006614685,True,0.3775406687981454,0.634577284729807,True
Template-guided Functional Network Identification via Supervised Dictionary Learning,"Functional network analysis based on matrix decomposition/factorization methods including ICA and dictionary learning models have become a popular approach in fMRI study. Yet it is still a challenging issue in interpreting the result networks because of the inter-subject variability and image noises, thus in many cases, manual inspection on the obtained networks is needed. Aiming to provide a fast and reliable functional network identification tool for both normal and diseased brain fMRI data analysis, in this work, we propose a novel supervised dictionary learning model based on rank-1 matrix decomposition algorithm (S-r1DL) with sparseness constraint. Application on the Autism Brain Imaging Data Exchange (ABIDE) database showed that S-r1DL can fast and accurately identify the functional networks based on the given templates, comparing to unsupervised learning method.",1.0,0.7853825092315674,True,0.3775406687981454,0.5814615890148565,True
A Novel Spatio-Temporal Hub Identification Method for Dynamic Functional Networks,"Functional connectivity (FC) has been widely investigated to understand the cognition and behavior that emerge from human brain. Recently, there is overwhelming evidence showing that quantifying temporal changes in FC may provide greater insight into fundamental properties of brain network. However, scant attentions has been given to characterize the functional dynamics of network organization. To address this challenge, we propose a novel spatio-temporal hub identification method for functional brain networks by simultaneously identifying hub nodes in each static sliding window and maintaining the reasonable dynamics across the sliding windows, which allows us to further characterize the full-spectrum evolution of hub nodes along with the subject-specific functional dynamics. We have evaluated our spatio-temporal hub identification method on resting-state functional resonance imaging (fMRI) data from an obsessive-compulsive disease (OCD) study, where our new functional hub detection method outperforms current methods (without considering functional dynamics) in terms of accuracy and consistency.",1.0,0.7445880770683289,True,0.3775406687981454,0.5610643729332372,True
Deep Variational Autoencoder for Modeling Functional Brain Networks and ADHD Identification,"In the neuroimaging and brain mapping communities, researchers have proposed a variety of computational methods and tools to learn functional brain networks (FBNs). Recently, it has already been proven that deep learning can be applied on fMRI data with superb representation power over traditional machine learning methods. Limited by the high-dimension of fMRI volumes, deep learning suffers from the lack of data and overfitting. Generative models are known to have intrinsic ability of modeling small dataset and a Deep Variational Autoencoder (DVAE) is proposed in this work to tackle the challenge of insufficient data and incomplete supervision. The FBNs learned from fMRI were examined to be interpretable and meaningful and it was proven that DVAE has better performance on neuroimaging dataset over traditional models. With an evaluation on ADHD-200 dataset, DVAE performed excellent on classification accuracies on 4 sites.",1.0,0.7806357145309448,True,0.3775406687981454,0.5790881916645452,True
Unsupervised Retinal Lesion Detection by Learning to Restore Corrupted Fundus Images,"Anomaly detection is an important topic in medical image analysis, and some unsupervised deep learning methods have been proposed for lesions detection in medical images. However, these unsupervised methods show poor performance on pixel-level lesion detection in fundus images, since retinal images contain many small lesions and retinal lesions usually show diversity in shapes, sizes, textures, and positions. This paper proposes a new unsupervised framework to solve this problem, in which a high-accuracy anomaly-free image will be reconstructed for a given retinal image, and thus diverse lesions are well separated by comparing these two images. In our framework, an autoencoder augmented by a memory module is forced to reconstruct high-accuracy anomaly-free retinal images from corrupted retinal images with synthetic lesions generated from Perlin noise during training, by which real lesions in anomalous images can be removed on the inference stage. Meanwhile, a false positive suppression algorithm (FPSA) is also proposed to reduce false positives caused by regions with low reconstruction quality. Comparative experiments show that our proposed framework achieves advanced performance and outperforms the state-of-the-art methods on the task of retinal lesion detection from fundus images.",1.0,0.7328926920890808,True,0.3775406687981454,0.5552166804436132,True
Self-Ensemble Distillation Using Mean Teachers with Long & Short Memory,"Ensemble of deep learning models is widely used to increase performance, however, doing so requires training and deploying several models. This can be mitigated by distilling the knowledge of several models into a single network. Yet, the cost of training numerous models remains. We propose a new consistency regularisation based methodology that eliminates the requirement of training several teacher networks, thus lowering training costs. We efficiently generate several teacher networks by taking exponential moving averages of student network parameters with varying decay rates that provide long and short memory from training routine. Random augmentation is applied individually to each teacher input, and a consistency loss is obtained between teacher & student output to improve model generalisation. We test our proposed method of self-ensembling distillation on two segmentation datasets - The MICCAI 2019 Challenge dataset & the Kaggle Prostate cANcer graDe Assessment (PANDA) Challenge dataset, and show significant gain in performance over baseline well as ensemble knowledge distillation.",0.8,0.7858248949050903,True,0.3318122278318339,0.5588185613684621,True
LADEN: Lesion-Aware Adversarial Deep Network for Grading of Macular Diseases Using Color Fundus Images,"Early detection of retinal illnesses such as diabetic macular edema (DME) and age-related macular degeneration (AMD) is essential for preventing central vision loss. Despite the fact that numerous solutions have been published, the performance of existing methods is inadequate due to the omission of lesion information in illness classification. A new lesion-aware adversarial deep network (LADeN) is proposed in this paper, which accurately exploits lesion information for clinically interpretable disease diagnosis. The first stage, which employs LADeN to efficiently reduce false positives, derives domain features from correct lesion segmentation maps. The extracted features from LADeN are combined with the baseline Efficient-Net-B7 model in the second stage to fine-tune disease classification and grading. Our proposed method exceeds the state-of-the-art in a range of tasks, including lesion segmentation, disease classification, and grading, as demonstrated by experiments on the IDRiD, MESSIDOR, and ADAM datasets.",1.0,0.8252580165863037,True,0.3775406687981454,0.6013993426922246,True
Graph slepians to strike a balance between local and global network interactions: Application to functional brain imaging,"Brain function exhibits coordinated activity patterns that are also reflected in anatomy, a finding that can be harnessed to constrain the dynamics of functional time series to the underlying structure while performing various signal processing operations. Graph signal processing (GSP) is such a framework, which we here equip with a new tool to uncover localised functional brain interactions. The functional magnetic resonance imaging (fMRI) signal is projected onto a collection of Slepian vectors defined on a graph extracted from structural and diffusion MRI data. This decomposition allows a multi-bandwidth description of signals that are maximally concentrated within a subset of nodes, as is often the case for neural activity. On simulated data, we compare this technique to classical Laplacian and localised Laplacian filtering. We then present, on real fMRI data, an illustration of the Slepians potential to retrieve localised interaction patterns in the context of a visual stimulation task.",1.0,0.9435312151908875,True,0.3775406687981454,0.6605359419945165,True
Belief Function-Based Semi-Supervised Learning For Brain Tumor Segmentation,"Precise segmentation of a lesion area is important for optimizing its treatment. Deep learning makes it possible to detect and segment a lesion field using annotated data. However, obtaining precisely annotated data is very challenging in the medical domain. Moreover, labeling uncertainty and imprecision make segmentation results unreliable. In this paper, we address the uncertain boundary problem by a new evidential neural network with an information fusion strategy, and the scarcity of annotated data by semi-supervised learning. Experimental results show that our proposal has better performance than state-of-the-art methods.",1.0,0.7634680271148682,True,0.3775406687981454,0.5705043479565068,True
Fusing Joint Features of Eeg Brain Functional Connectivity Networks for Anxiety Recognition,"Anxiety is one of the common mental disorders affecting adolescents, and about 5%-20% of adolescents worldwide are suffering from anxiety disorders. Currently, traditional diagnostic methods for anxiety disorders rely heavily on clinical DSM-IV scale screening. Functional connectivity networks as a new type of electroencephalogram (EEG) biomarker has been successfully applied to adolescent anxiety screening. Whereas the previous studies have only analyzed anxiety disorders from a single dimension, and easily overlooked the spatiotemporal covariation characteristics and physiological significance of frequency bands of EEG in anxiety disorders. Therefore, in this paper, we apply the group sparse canonical correlation analysis to joint feature learning (GSCCA JF) for accurate diagnosing and exploring the internal mechanism of the disease. The experimental results show that this method achieves good classification performances compared to other competing methods. In brief, the proposed method can be used to accurately screen and diagnose adolescent anxiety disorders at an early stage, which provides it clinical value.",1.0,0.7838340997695923,True,0.3775406687981454,0.5806873842838689,True
Fitting networks models for functional brain connectivity,"Functional connectivity of the human brain and the hierarchical modular architecture of functional networks can be investigated using functional magnetic resonance imaging (fMRI). Various network models, such as power-law networks and modular networks have been explored before to study brain networks. In order to investigate the plausibility of modeling functional brain networks with network models based on distribution of node degree and connection weights, we will compute the goodness-of-fit of several network models on resting-state fMRI scans gathered in the Human Connectome Project. Our experiments suggest that the power-law networks and stochastic block models aptly fit functional connectivity of the subjects and the stochastic block models have the potential to detect functional modules of the brain.",1.0,0.7333764433860779,True,0.3775406687981454,0.5554585560921117,True
Multi-Shot Sensitivity-Encoded Diffusion MRI Using Model-Based Deep Learning (Modl-Mussels),"We propose a model-based deep learning architecture for the correction of phase errors in multishot diffusion-weighted echo-planar MRI images. This work is a generalization of MUSSELS, which is a structured low-rank algorithm. We show that an iterative reweighted least-squares implementation of MUSSELS resembles the model-based deep learning (MoDL) framework. We propose to replace the self-learned linear filter bank in MUSSELS with a convolutional neural network, whose parameters are learned from exemplary data. The proposed algorithm reduces the computational complexity of MUSSELS by several orders of magnitude, while providing comparable image quality.",0.8,0.8610816597938538,True,0.3318122278318339,0.5964469438128438,True
Improving Diagnosis of Autism Spectrum Disorder and Disentangling its Heterogeneous Functional Connectivity Patterns Using Capsule Networks,"Functional connectivity (FC) analysis is an appealing tool to aid diagnosis and elucidate the neurophysiological underpinnings of autism spectrum disorder (ASD). Many machine learning methods have been developed to distinguish ASD patients from healthy controls based on FC measures and identify abnormal FC patterns of ASD. Particularly, several studies have demonstrated that deep learning models could achieve better performance for ASD diagnosis than conventional machine learning methods. Although promising classification performance has been achieved by the existing machine learning methods, they do not explicitly model heterogeneity of ASD, incapable of disentangling heterogeneous FC patterns of ASD. To achieve an improved diagnosis and a better understanding of ASD, we adopt capsule networks (CapsNets) to build classifiers for distinguishing ASD patients from healthy controls based on FC measures and stratify ASD patients into groups with distinct FC patterns. Evaluation results based on a large multi-site dataset have demonstrated that our method not only obtained better classification performance than state-of-the-art alternative machine learning methods, but also identified clinically meaningful subgroups of ASD patients based on their vectorized classification outputs of the CapsNets classification model.",1.0,0.7881448268890381,True,0.3775406687981454,0.5828427478435918,True
Association Between Dynamic Functional Connectivity and Intelligence,"Several studies have explored the relationship between intelligence and neuroimaging features. However, little is known about whether the temporal variations of functional connectivity of the brain regions at rest are relevant to the differences in intelligence. In this study, we have used the fMRI data and intelligence scores of 50 healthy adult subjects from the Human Connectome Project (HCP) database. We have investigated the correlation between individual intelligence scores and the total power of the high frequency components of the Fast Fourier transform (FFT) of the dynamic functional connectivity time series of the brain regions. We have found temporal variations of specific functional connections highly correlated with the individual intelligence scores. In other words, functional connections of individuals with high levels of the intelligence have smoother temporal variation or higher temporal stability than those of the individuals with low intelligence levels.",1.0,0.7334963083267212,True,0.3775406687981454,0.5555184885624334,True
A Novel Deep Learning Architecture By Integrating Visual Simultaneous Localization And Mapping (Vslam) Into Cnn For Real-Time Surgical Video Analysis,"Seven million people suffer surgical complications each year, but with sufficient surgical training and review, 50% of these complications could be prevented. To improve surgical performance, existing research uses various deep learning (DL) technologies including convolutional neural networks (CNN) and recurrent neural networks (RNN) to automate surgical tool and workflow detection. However, there is room to improve accuracy; real-time analysis is also minimal due to the complexity of CNN. In this research, a novel DL architecture is proposed to integrate visual simultaneous localization and mapping (vSLAM) into Mask R-CNN. This architecture, vSLAM-CNN (vCNN), for the first time, integrates the best of both worlds, inclusive of (1) vSLAM for object detection, by focusing on geometric information for region proposals, and (2) CNN for object recognition, by focusing on semantic information for image classification, combining them into one joint end-to-end training process. This method, using spatio-temporal information in addition to visual features, is evaluated on M2CAI 2016 challenge datasets, achieving the state-of-the-art results with 96.8 mAP for tool detection and 97.5 mean Jaccard score for workflow detection, surpassing all previous works, and reaching a 50 FPS performance, 10x faster than the region-based CNN. A region proposal module (RPM) replaces the region proposal network (RPN) in Mask R-CNN, accurately placing bounding boxes and lessening the annotation requirement. Furthermore, a Microsoft HoloLens 2 application is developed to provide an augmented reality (AR)-based solution for surgical training and assistance.",0.8,0.7884323000907898,True,0.3318122278318339,0.5601222639613118,True
"Exploring Intrinsic Functional Differences of Gyri, Sulci and 2-Hinge, 3-Hinge Joints on Cerebral Cortex","The human cerebral cortex has been commonly known as a highly-folded region which consists of convex gyri and concave sulci. Many previous studies have already revealed the fundamental differences of these convex and concave areas by analyzing structural and functional connectivity patterns. However, to our best knowledge, rare work has been done to explore their intrinsic functional differences from the perspective of neural activity, especially for 3-hinge gyral folding joints. Inspired by current evidences, in this paper, experiments based on classification models learned by convolutional neural network (CNN) are designed and performed on resting state functional magnetic resonance imaging (rsfMRI) data of both healthy controls and autism patients from the publicly available ABIDE II database. In our work, gyral and sulcal, 2-hinge and 3-hinge joint rsfMRI signals are modeled and predicted using CNNs with an average testing classification accuracy of 94.24% for controls, 95.24% for patients and 87.53% for controls, 87.72% for patients at individual level separately, which confirms different functional roles of neural activities under resting state in gyri and sulci, as well as 2-hinge and 3-hinge gyral folding joints in healthy subjects and autism groups. Besides, further analyses on learned characteristic features to differentiate gyral/sulcal, 2-hinge/3-hinge joint rsfMRI signals are also designed and performed to interpret our findings.",1.0,0.7231195569038391,True,0.3775406687981454,0.5503301128509923,True
CNN in CT Image Segmentation: Beyond Loss Function for Exploiting Ground Truth Images,"Exploiting more information from ground truth (GT) images now is a new research direction for further improving CNN's performance in CT image segmentation. Previous methods focus on devising the loss function for fulfilling such a purpose. However, it is rather difficult to devise a general and optimization-friendly loss function. We here present a novel and practical method that exploits GT images beyond the loss function. Our insight is that feature maps of two CNNs trained respectively on GT and CT images should be similar on some metric space, because they both are used to describe the same objects for the same purpose. We hence exploit GT images by enforcing such two CNNs' feature maps to be consistent. We assess the proposed method on two data sets, and compare its performance to several competitive methods. Extensive experimental results show that the proposed method is effective, outperforming all the compared methods.",1.0,0.7962654232978821,True,0.3775406687981454,0.5869030460480138,True
Enhanced-Quality Gan (EQ-GAN) on Lung CT Scans: Toward Truth and Potential Hallucinations,"Lung Computed Tomography (CT) scans are extensively used to screen lung diseases. Strategies such as large slice spacing and low-dose CT scans are often preferred to reduce radiation exposure and therefore the risk for patients’ health. The counterpart is a significant degradation of image quality and/or resolution. In this work we investigate a generative adversarial network (GAN) for lung CT image enhanced-quality (EQ). Our EQ-GAN is trained on a high-quality lung CT cohort to recover the visual quality of scans degraded by blur and noise. The capability of our trained GAN to generate EQ CT scans is further illustrated on two test cohorts. Results confirm gains in visual quality metrics, remarkable visual enhancement of vessels, airways and lung parenchyma, as well as other enhancement patterns that require further investigation. We also compared automatic lung lobe segmentation on original versus EQ scans. Average Dice scores vary between lobes, can be as low as 0.3 and EQ scans enable segmentation of some lobes missed in the original scans. This paves the way to using EQ as pre-processing for lung lobe segmentation, further research to evaluate the impact of EQ to add robustness to airway and vessel segmentation, and to investigate anatomical details revealed in EQ scans.",0.8,0.8478811383247375,True,0.3318122278318339,0.5898466830782857,True
MultiViT: Multimodal Vision Transformer for Schizophrenia Prediction using Structural MRI and Functional Network Connectivity Data,"Vision Transformer (ViT) is a pioneering deep learning framework that can address real-world computer vision issues, such as image classification and object recognition. Importantly, ViTs are proven to outperform traditional deep learning models, such as convolutional neural networks (CNNs). Relatively recently, a number of ViT mutations have been transplanted into the field of medical imaging, thereby resolving a variety of critical classification and segmentation challenges, especially in terms of brain imaging data. In this work, we provide a novel multimodal deep learning pipeline, MultiViT, which is capable of analyzing both structural MRI (sMRI) and static functional network connectivity (sFNC) data for the prediction of schizophrenia disease. On a dataset with minimal training subjects, our novel model can achieve an AUC of 0.832. Finally, we visualize multiple brain regions and covariance patterns most relevant to schizophrenia based on the resulting ViT attention maps by extracting features from transformer encoders.",1.0,0.747628390789032,True,0.3775406687981454,0.5625845297935888,True
Parse Challenge 2022: Pulmonary Arteries Segmentation Using Swin U-net Transformer(Swin UNETR) and U-net,"In this paper, we describe a deep neural network architecture based on Swin UNETR and U-Net for segmenting the pulmonary arteries from CT scans. The final segmentation masks were created using an ensemble of six models, three based on Swin UNETR and three based on 3D U-net with residual units. Using this strategy, our group scored 84.36 % on the multi-level dice. We conducted additional investigation and separated the task into three major subtasks: Task 1: Use the default hyperparameters for plain UNET segmentation and experiment with the patch size, a key hyperparameter for UNET segmentation models. Task 2 : Develop a lung segmentation model that distinguishes between the major pulmonary artery and the branches in order to precisely assess the model’s performance. Task 3 : Examining the mask by extracting small patches near the branches and large patches around the major pulmonary artery.The code of our work is available on the following link: https://github.com/akansh12/parse2022",0.8,0.9210595488548279,True,0.3318122278318339,0.6264358883433309,True
Exploring human brain activation via nested sparse coding and functional operators,"Traditional task-based fMRI activation detection methods, such as the general linear model (GLM), assume that the fMRI signals of activated brain regions follow the external stimulus paradigm. Typically, these activated regions are detected independently in a voxel-wise fashion, and the interaction among voxels is nevertheless neglected. Despite the wide use and remarkable success of GLM, the temporal and spatial relationships among activated regions remain unveiled. In response to this challenge, we present a novel method that combines two-stage sparse representation framework and the operator modulations (integral and derivative) to explore the temporal and spatial organizations underlying fMRI-derived activations in the brain. The two-stage sparse representation framework is designed to deal with big data and the functional operator is focused on finding the refined activation areas in the brain under task performances. Experiments demonstrated that diverse temporal and spatial organizations between activated regions exist and different functional operators may lead to different activation areas, thus significantly supplementing to the available principle of GLM that has been widely used in the human brain mapping field.",1.0,0.8102430701255798,True,0.3775406687981454,0.5938918694618627,True
Arterial input function and tracer kinetic model-driven network for rapid inference of kinetic maps in Dynamic Contrast-Enhanced MRI (AIF-TK-net),"We propose a patient-specific arterial input function (AIF) and tracer kinetic (TK) model-driven network to rapidly estimate the extended Tofts- Kety kinetic model parameters in DCE-MRI. We term our network as AIF-TK-net, which maps an input comprising of an image patch of the DCE-time series and the patient-specific AIF to the output image patch of the TK parameters. We leverage the open-source NEURO-RIDER database of brain tumor DCE-MRI scans to train our network. Once trained, our model rapidly infers the TK maps of unseen DCE-MRI images on the order of a 0.34 sec/slice for a 256x256x65 time series data on a NVIDIA GeForce GTX 1080 Ti GPU. We show its utility on high time resolution DCE-MRI datasets where significant variability in AIFs across patients exists. We demonstrate that the proposed AIF - TK net considerably improves the TK parameter estimation accuracy in comparison to a network, which does not utilize the patient AIF.",1.8,0.7753856778144836,True,0.574442516811659,0.6749140973130714,True
Functional Multi-Connectivity: A Novel Approach To Assess Multi-Way Entanglement Between Networks and Voxels,"The interactions among brain entities, commonly computed through pair-wise functional connectivity, are assumed to be manifestations of information processing which drive function. However, this focus on large-scale networks and their pair-wise temporal interactions is likely missing important information contained within fMRI data. We propose leveraging multi-connected features at both the voxel- and network-level to capture “multi-way entanglement” between networks and voxels, providing improved resolution of interconnected brain functional hierarchy. Entanglement refers to each brain network being heavily enmeshed with the activity of other networks. Under our multi-connectivity assumption, elements of a system simultaneously communicate and interact with each other through multiple pathways. As such we move beyond the typical pair-wise temporal partial or full correlation. We propose a framework to estimate functional multi-connectivity (FMC) by computing the relationship between system-wide connections of intrinsic connectivity networks (ICNs). Results show that FMC obtains information which is different from standard pair-wise analyses.",1.0,0.7314069271087646,True,0.3775406687981454,0.5544737979534551,True
"Architectural configurations, atlas granularity and functional connectivity with diagnostic value in Autism Spectrum Disorder","Currently, the diagnosis of Autism Spectrum Disorder (ASD) is dependent upon a subjective, time-consuming evaluation of behavioral tests by an expert clinician. Non-invasive functional MRI (fMRI) characterizes brain connectivity and may be used to inform diagnoses and democratize medicine. However, successful construction of predictive models, such as deep learning models, from fMRI requires addressing key choices about the model's architecture, including the number of layers and number of neurons per layer. Meanwhile, deriving functional connectivity (FC) features from fMRI requires choosing an atlas with an appropriate level of granularity. Once an accurate diagnostic model has been built, it is vital to determine which features are predictive of ASD and if similar features are learned across atlas granularity levels. Identifying new important features extends our understanding of the biological underpinnings of ASD, while identifying features that corroborate past findings and extend across atlas levels instills model confidence. To identify aptly suited architectural configurations, probability distributions of the configurations of high versus low performing models are compared. To determine the effect of atlas granularity, connectivity features are derived from atlases with 3 levels of granularity and important features are ranked with permutation feature importance. Results show the highest performing models use between 2–4 hidden layers and 16–64 neurons per layer, granularity dependent. Connectivity features identified as important across all 3 atlas granularity levels include FC to the supplementary motor gyrus and language association cortex, regions whose abnormal development are associated with deficits in social and sensory processing common in ASD. Importantly, the cerebellum, often not included in functional analyses, is also identified as a region whose abnormal connectivity is highly predictive of ASD. Results of this study identify important regions to include in future studies of ASD, help assist in the selection of network architectures, and help identify appropriate levels of granularity to facilitate the development of accurate diagnostic models of ASD.",1.0,0.7621087431907654,True,0.3775406687981454,0.5698247059944554,True
Learning to Segment Vessels from Poorly Illuminated Fundus Images,"Segmentation of retinal vessels is important for determining various disease conditions, but deep learning approaches have been limited by the unavailability of large, publicly available, and annotated datasets. The paper addresses this problem and analyses the performance of U-Net architecture on DRIVE and RIM-ONE datasets. A different approach for data augmentation using vignetting masks is presented to create more annotated fundus data. Unlike most prior efforts that attempt transforming poor images to match the images in a training set, our approach takes better quality images (which have good expert labels) and transforms them to resemble poor quality target images. We apply substantial vignetting masks to the DRIVE dataset and then train a U-net on the resulting lower quality images (using the corresponding expert label data). We quantitatively show that our approach leads to better generalized networks, and we show qualitative performance improvements in RIM-ONE images (which lack expert labels).",1.0,0.7281147837638855,True,0.3775406687981454,0.5528277262810155,True
Dual-Term Loss Function For Shape-Aware Medical Image Segmentation,"Besides network architecture, researchers have recently focused their attention on the loss function for the Convolutional Neural Network-based medical image segmentation. The loss function is used to evaluate the pixel-wise similarity in the whole image to reflect the correctness of the segmentation, which lacks awareness of the object boundaries. In this work, we propose a novel dual-term loss function with a region-based term and a shape-aware term, which forces the network to learn more boundary details by maximizing the probability difference between the two sides of the boundary. Our method adjusts the output probability appropriately according to the shape. We evaluated our approach on three datasets, and the results show that the proposed loss function outperforms other mainstream loss functions.",1.0,0.7413355708122253,True,0.3775406687981454,0.5594381198051854,True
Tree-loss function for training neural networks on weakly-labelled datasets,"Neural networks are powerful tools for medical image classification and segmentation. However, existing network structures and training procedures assume that the output classes are mutually exclusive and equally important. Many datasets of medical images do not satisfy these conditions. For example, some skin disease datasets have images labelled as coarse-grained class (such as Benign) in addition to images with fine-grained labels (such as a Benign subclass called Blue Nevus), and conventional neural network can not leverage such additional data for training. Also, in the clinical decision making, some classes (such as skin cancer or Melanoma) often carry more importance than other lesion types. We propose a novel Tree-Loss function for training and fine-tuning a neural network classifier using all available labelled images. The key step is the definition of the class taxonomy tree, which is used to describe the relations between labels. The tree can be also adjusted to reflect the desired importance of each class. These steps can be performed by a domain expert without detailed knowledge of machine learning techniques. The experiments demonstrate the improved performance compared with the conventional approach even without using additional data.",1.0,0.7433317303657532,True,0.3775406687981454,0.5604361995819493,True
Dynamic Functional Connectivity For The Classification Of Multiple Sclerosis Phenotype: A Hidden Markov Model Approach,"We present a pipeline for the classification of subjects according to multiple sclerosis phenotype. The approach is based on a hidden Markov model built on dynamic functional connectivity. More in detail, a sequence of correlation matrices is built from the fMRI time slices, then projected on the tangent Euclidean space. The number of considered dimensions is reduced through PCA, then dominant set clustering is applied to group similar correlation matrices in a limited number of ”mental” states, which are then used as the hidden states of the Markov model. Subjects in the test set are then classified according to the likelihood of their sequence of observations with the obtained class-wise Markov models. We demonstrate that our approach is capable of discriminating multiple sclerosis phenotypes and that the persistence of some of the identified states is a possible neurohpyisiological marker of disease severity.",1.0,0.7260926365852356,True,0.3775406687981454,0.5518166526916906,True
Exploring heritability of functional brain networks with inexact graph matching,"Data-driven brain parcellations aim to provide a more accurate representation of an individual's functional connectivity, since they are able to capture individual variability that arises due to development or disease. This renders comparisons between the emerging brain connectivity networks more challenging, since correspondences between their elements are not preserved. Unveiling these correspondences is of major importance to keep track of local functional connectivity changes. We propose a novel method based on graph edit distance for the comparison of brain graphs directly in their domain, that can accurately reflect similarities between individual networks while providing the network element correspondences. This method is validated on a dataset of 116 twin subjects provided by the Human Connectome Project.",1.0,0.7734531760215759,True,0.3775406687981454,0.5754969224098607,True
Dynamic Imaging Using Deep Bilinear Unsupervised Learning (Deblur),"Bilinear models such as low-rank and compressed sensing, which decompose the dynamic data to spatial and temporal factors, are powerful and memory efficient tools for the recovery of dynamic MRI data. These methods rely on sparsity and energy compaction priors on the factors to regularize the recovery. Motivated by deep image prior, we introduce a novel bilinear model, whose factors are regularized using convolutional neural networks. To reduce the run time, we initialize the CNN parameters by pre-training them on pre-acquired data with longer acquistion time. Since fully sampled data is not available, pretraining is performed on undersampled data in an unsupervised fashion. We use sparsity regularization of the network parameters to minimize the over-fitting of the network to measurement noise. Our experiments on free-breathing and ungated cardiac CINE data acquired using a navigated golden-angle gradient-echo radial sequence show the ability of our method to provide reduced spatial blurring as compared to low-rank and SToRM reconstructions.",0.8,0.7709888815879822,True,0.3318122278318339,0.551400554709908,True
Structural And Functional Interplay In Anxiety Related Classification: A Graph Signal Processing Approach,"Anxiety disorders are one of the most common mental health conditions with a high rate of everyday life disability. Connectivity is steadily gaining relevance to increase our knowledge of psychiatric diseases. Graph signal processing (GSP) is a new framework to integrate structural connectivity and brain function. We propose here a graph-based analysis using GSP metrics and classification procedure, to identify anxiety biomarkers. Results suggest that the joint consideration of structure-function features improves their discriminatory accuracy, and our understanding of the pathophysiology of anxiety.",1.0,0.7247133851051331,True,0.3775406687981454,0.5511270269516393,True
A Multimodal Learning Framework to Study Varying Information Complexity in Structural and Functional Sub-Domains in Schizophrenia,"Approaches involving the use of learning architectures on multimodal neuroimaging data tend to assume uniformity in the way information is stored in various sub-domains of the brain, thus not catering to the differences across functional and structural sub-domains. We introduce a learning framework to effectively incorporate multimodal features using structural and functional MRI data from a dataset of schizophrenia patients and controls, accounting for and exploiting the heterogeneity in the sub-domains of the brain. We analyze these sub-domains in terms of their functional interactions (i.e. within and between network connectivity) and structural properties (gray matter volume). By using Bayesian optimization on a search space of flexible multimodal architectures with multiple branches, we demonstrate that the discriminatory information from structural and functional sub-domains can be better recovered if the complexity of subspace structure in the model can be tuned to reflect the extent of non-linearity with which each sub-domain encodes the information. Our repeated cross-validated results from a schizophrenia classification problem show that for better classification and interpretation, sub-domains known for their role or disruption in Schizophrenia require more sophisticated subspace structure in the model compared to others. Our work emphasizes on the requirement to create multimodal frameworks that can adapt based on differences in the way various sub-domains of the brain encode discriminatory information. This is important to not only have better-performing prediction models but also to reveal sub-domains associated with the outcome at hand.",1.0,0.7962390780448914,True,0.3775406687981454,0.5868898734215184,True
Diagnosing Colorectal Polyps in the Wild with Capsule Networks,"Colorectal cancer, largely arising from precursor lesions called polyps, remains one of the leading causes of cancer-related death worldwide. Current clinical standards require the resection and histopathological analysis of polyps due to test accuracy and sensitivity of optical biopsy methods falling substantially below recommended levels. In this study, we design a novel capsule network architecture (D-Caps) to improve the viability of optical biopsy of colorectal polyps. Our proposed method introduces several technical novelties including a novel capsule architecture with a capsule-average pooling (CAP) method to improve efficiency in large-scale image classification. We demonstrate improved results over the previous state-of-the-art convolutional neural network (CNN) approach by as much as 43%. This work provides an important benchmark on the new Mayo Polyp dataset, a significantly more challenging and larger dataset than previous polyp studies, with results stratified across all available categories, imaging devices and modalities, and focus modes to promote future direction into AI-driven colorectal cancer screening systems. Code is publicly available at https://github.com/lalonderodney/D-Caps.",1.0,0.8122706413269043,True,0.3775406687981454,0.5949056550625249,True
Two-Stage Spatial Temporal Deep Learning Framework For Functional Brain Network Modeling,"Resting state functional magnetic resonance imaging (rsfMRI) data provides a unique window for the investigation of the human brain’s intrinsic functional mechanism. However, it is still an open question how to analyze and model functional brain connectivity networks via rsfMRI data due to the variability of different individual brains, noisy signals from rsfMRI data, and technical limitations of current rsfMRI data decomposition methods. In this work, we proposed a two-stage deep learning framework for both temporal and spatial analysis of functional brain networks with an application on autism spectrum disorder (ASD) rsfMRI data. This framework tackled the abovementioned challenges in these aspects: reducing noises in rsfMRI raw data, establishing functional network correspondence across various individual brains, and composing multiple functional networks into a compact representation. In general, our proposed framework offers a novel scheme for comprehensive and systematic spatial-temporal resting state network modeling. Our experimental results on the ABIDE ASD dataset showed promising results in discovering discriminative functional networks compared with traditional analysis. Furthermore, our work provided a new insight into ASD that ASD’s functional activity abnormalities tend to be more composite and systematic, other than being localized.",1.0,0.7751764059066772,True,0.3775406687981454,0.5763585373524114,True
Multiple Deep Learning Architectures Achieve Superior Performance Diagnosing Autism Spectrum Disorder Using Features Previously Extracted From Structural And Functional Mri,"The diagnosis of Autism Spectrum Disorder (ASD) is a subjective process requiring clinical expertise in neurodevelopmental disorders. Since such expertise is not available at many clinics, automated diagnosis using machine learning (ML) algorithms would be of great value to both clinicians and the imaging community to increase the diagnoses’ availability and reproducibility while reducing subjectivity. This research systematically compares the performance of classifiers using over 900 subjects from the IMPAC database [1], using the database’s derived anatomical and functional features to diagnose a subject as autistic or healthy. In total 12 classifiers are compared from 3 categories including: 6 nonlinear shallow ML models, 3 linear shallow models, and 3 deep learning models. When evaluated with an AUC ROC performance metric, results include: (1) amongst the shallow learning methods, linear models outperformed nonlinear models, agreeing with [2]. (2) Deep learning models outperformed shallow ML models. (3) The best model was a dense feedforward network, achieving 0.80 AUC which compares to the recently reported $0.79 \pm 0.01$ AUC average of the top 10 methods from the IMPAC challenge [3]. These results demonstrate that even when using features derived from imaging data, deep learning methods can provide additional predictive accuracy over classical methods.",1.0,0.7439943552017212,True,0.3775406687981454,0.5607675119999334,True
Super-resolution/segmentation of 3D trabecular bone images with total variation and nonconvex Cahn-Hilliard functional,"The analysis of trabecular bone micro structure from in-vivo CT images is still limited due to insufficient spatial resolution. In a previous work, we have investigated the use of super resolution techniques to improve image quality based on a TV based approach. However, the method is limited to recover the bimodal nature of the image. In this work, we investigate the use of a double well non convex constraint to solve the joint super resolution/segmentation problem. Two different minimization schemes are proposed to obtain a critical point of the non convex functional. The two methods improve the reconstruction results on real data.",1.0,0.7364642024040222,True,0.3775406687981454,0.5570024356010839,True
Generalize Ultrasound Image Segmentation Via Instant And Plug & Play Style Transfer,"Deep segmentation models that generalize to images with unknown appearance are important for real-world medical image analysis. Retraining models leads to high latency and complex pipelines, which are impractical in clinical settings. The situation becomes more severe for ultrasound image analysis because of their large appearance shifts. In this paper, we propose a novel method for robust segmentation under unknown appearance shifts. Our contribution is three-fold. First, we advance a one-stage plug-and-play solution by embedding hierarchical style transfer units into a segmentation architecture. Our solution can remove appearance shifts and perform segmentation simultaneously. Second, we adopt Dynamic Instance Normalization to conduct precise and dynamic style transfer in a learnable manner, rather than previously fixed style normalization. Third, our solution is fast and lightweight for routine clinical adoption. Given $400\times 400$ image input, our solution only needs an additional 0.2 ms and 1.92M FLOPs to handle appearance shifts compared to the baseline pipeline. Extensive experiments are conducted on a large dataset from three vendors demonstrate our proposed method enhances the robustness of deep segmentation models.",0.8,0.8657686114311218,True,0.3318122278318339,0.5987904196314778,True
Local Sequential Features Coupling Global Representation of Dynamic Functional Connectivity Network for Brain Disease Classification,"Recently, studies have applied advanced machine learning methods, e.g., convolutional neural network (CNN) and transformer architecture, to extract features from functional connectivity networks (FCNs) for brain disease analysis and classification. However, CNN based methods usually extract local features from FCN, ignoring global representation of FCN. Transformer based methods typically extract global features of FCN but are challenging to capture local information of the brain network. To address this problem, in this paper we propose Con-Trans, a novel learning framework that integrates both convolutional operation and transformer for brain disease classification, with functional magnetic resonance imaging (fMRI) data. Experimental results on 174 subjects with resting-state fMRI (rs-fMRI) data from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) demonstrate the effectiveness of the proposed Con-Trans method.",1.0,0.7654847502708435,True,0.3775406687981454,0.5715127095344945,True
Unsupervised Domain Adaption With Adversarial Learning (UDAA) for Emphysema Subtyping on Cardiac CT Scans: The Mesa Study,"Emphysema quantification and sub-typing is actively studied on cohorts of full-lung high-resolution CT (HRCT) scans, with promising results. Transfer of quantification and classification tools to cardiac CT scans, which involve 70% of the lungs, is challenging due to lower image resolution and degradation of textural patterns. In this study, we propose an original deep-learning domain-adaptation framework to use a pre-existing dictionary of lung texture patterns (LTP), learned on gold-standard full-lung HRCT scans, to label emphysema regions on cardiac CT scans. The method exploits convolutional neural networks (CNNs) trained for: 1) supervised lung texture classification on synthetic cardiac images, and 2) adversarial learning to discriminate between real and synthetic cardiac images. Combination of the classification and adversarial tasks enables to label real cardiac CT scans, and is evaluated on the MESA cohort (N = 15,357 scans). Our results show that image features derived from the adversarial training preserve the labeling accuracy on synthetic scans. LTP histogram signatures generated on 4,315 longitudinal pairs of cardiac CT scans, show high level of consistency over time and scanner generations. The ability to robustly label emphysema texture patterns on cardiac CT scans will enable large-scale longitudinal studies over 10 years of follow-up, for better understanding of the disease progression.",0.8,0.8018947243690491,True,0.3318122278318339,0.5668534761004415,True
"Who’s Watching Me?: Exploring the Impact of Audience Familiarity on Player Performance, Experience, and Exertion in Virtual Reality Exergames","Familiarity with audiences plays a significant role in shaping individual performance and experience across various activities in everyday life. This study delves into the impact of familiarity with non-playable character (NPC) audiences on player performance and experience in virtual reality (VR) exergames. By manipulating of NPC appearance (face and body shape) and voice familiarity, we explored their effect on game performance, experience, and exertion. The findings reveal that familiar NPC audiences have a positive impact on performance, creating a more enjoyable gaming experience, and leading players to perceive less exertion. Moreover, individuals with higher levels of self-consciousness exhibit heightened sensitivity to the familiarity with NPC audiences. Our results shed light on the role of familiar NPC audiences in enhancing player experiences and provide insights for designing more engaging and personalized VR exergame environments.",1.1,0.9288831353187561,True,0.401312339887548,0.665097737603152,True
"OpenRDW: A Redirected Walking Library and Benchmark with Multi-User, Learning-based Functionalities and State-of-the-art Algorithms","Redirected walking (RDW) is a locomotion technique that guides users on virtual paths, which might vary from the paths they physically walk in the real world. Thereby, RDW enables users to explore a virtual space that is larger than the physical counterpart with near-natural walking experiences. Several approaches have been proposed and developed; each using individual platforms and evaluated on a custom dataset, making it challenging to compare between methods. However, there are seldom public toolkits and recognized benchmarks in this field. In this paper, we introduce OpenRDW, an open-source library and benchmark for developing, deploying and evaluating a variety of methods for walking path redirection. The OpenRDW library provides application program interfaces to access the attributes of scenes, to customize the RDW controllers, to simulate and visualize the navigation process, to export multiple formats of the results, and to evaluate RDW techniques. It also supports the deployment of multi-user real walking, as well as reinforcement learning-based models exported from TensorFlow or PyTorch. The OpenRDW benchmark includes multiple testing conditions, such as walking in size varied tracking spaces or shape varied tracking spaces with obstacles, multiple user walking, etc. On the other hand, procedurally generated paths and walking paths collected from user experiments are provided for a comprehensive evaluation. It also contains several classic and state-of-the-art RDW techniques, which include the above mentioned functionalities.",1.0,0.7992579340934753,True,0.3775406687981454,0.5883993014458104,True
ABOVE & BELOW: Investigating Ceiling and Floor for Augmented Reality Content Placement,"Augmented Reality (AR) interfaces support users by providing access to digital content within real-world environments. However, displaying content at the users’ eye level might result in the occlusion of the real world. Therefore, it requires finding AR content placement areas that free the users’ field of vision. In this work, we systematically investigate two content placement areas beyond the users’ eye level: the ceiling and floor. To understand how potential users perceive virtual content on the ceiling and floor and how the content should be placed on these areas, we conducted two user studies. While the first exploratory study showed the general usefulness of either area, the second quantitative study allowed us to define optimal placement parameters regarding visibility and comfort. With insights from our studies, we provide design recommendations for future AR applications that support 2D content presentation on the ceiling and the floor.",0.8,0.8881199359893799,True,0.3318122278318339,0.6099660819106069,True
"Safety, Power Imbalances, Ethics and Proxy Sex: Surveying In-The-Wild Interactions Between VR Users and Bystanders","VR users and bystanders must sometimes interact, but our understanding of these interactions - their purpose, how they are accomplished, attitudes toward them, and where they break down - is limited. This current gap inhibits research into managing or supporting these interactions, and preventing unwanted or abusive activity. We present the results of the first survey (N=100) that investigates stories of actual emergent in-the-wild interactions between VR users and bystanders. Our analysis indicates VR user and bystander interactions can be categorised into one of three categories: coexisting, demoing, and interrupting. We highlight common interaction patterns and impediments encountered during these interactions. Bystanders play an important role in moderating the VR user’s experience, for example intervening to save the VR user from potential harm. However, our stories also suggest that the occlusive nature of VR introduces the potential for bystanders to exploit the vulnerable state of the VR user; and for the VR user to exploit the bystander for enhanced immersion, introducing significant ethical concerns.",1.0,0.9169778823852539,True,0.3775406687981454,0.6472592755916997,True
SiTAR: Situated Trajectory Analysis for In-the-Wild Pose Error Estimation,"Virtual content instability caused by device pose tracking error remains a prevalent issue in markerless augmented reality (AR), especially on smartphones and tablets. However, when examining environments which will host AR experiences, it is challenging to determine where those instability artifacts will occur; we rarely have access to ground truth pose to measure pose error, and even if pose error is available, traditional visualizations do not connect that data with the real environment, limiting their usefulness. To address these issues we present SiTAR (Situated Trajectory Analysis for Augmented Reality), the first situated trajectory analysis system for AR that incorporates estimates of pose tracking error. We start by developing the first uncertainty-based pose error estimation method for visual-inertial simultaneous localization and mapping (VI-SLAM), which allows us to obtain pose error estimates without ground truth; we achieve an average accuracy of up to 96.1% and an average FI score of up to 0.77 in our evaluations on four VI-SLAM datasets. Next, we present our SiTAR system, implemented for ARCore devices, combining a backend that supplies uncertainty-based pose error estimates with a frontend that generates situated trajectory visualizations. Finally, we evaluate the efficacy of SiTAR in realistic conditions by testing three visualization techniques in an in-the-wild study with 15 users and 13 diverse environments; this study reveals the impact both environment scale and the properties of surfaces present can have on user experience and task performance.",1.0,0.7295500040054321,True,0.3775406687981454,0.5535453364017888,True
Varying user agency and interaction opportunities in a home mobile augmented virtuality story,"New opportunities for immersive storytelling experiences have arrived through the technology in mobile phones, including the ability to overlay or register digital content on a user’s real world surroundings, to greater immerse the user in the world of the story. This raises questions around the methods and freedom to interact with the digital elements, that will lead to a more immersive and engaging experience. To investigate these areas the Augmented Virtuality (AV) mobile phone application Home Story was developed for iOS devices. It allows a user to move and interact with objects in a virtual environment displayed on their phone, by physically moving in the real world, completing particular actions to progress a story. A mixed methods study with Home Story either guided participants to the next interaction, or offered them increased agency to choose what object to interact with next. Virtual objects could also be interacted with in one of three ways; imagining the interaction, an embodied interaction using the user’s free hand, or a virtual interaction performed on the phone’s touchscreen. Similar levels of immersion were recorded across both study conditions suggesting both can be effective, though highlighting different issues in each case. The embodied free hand interactions proved particularly memorable, though further work is required to improve their implementation, arising from their novelty and lack of familiarity.",1.0,0.822632908821106,True,0.3775406687981454,0.6000867888096257,True
Using Identification with AR Face Filters to Predict Explicit & Implicit Gender Bias,"Augmented Reality (AR) filters, such as those used by social media platforms like Snapchat and Instagram, are perhaps the most commonly used AR technology. As with fully immersive Virtual Reality (VR) systems, individuals can use AR to embody different people. This experience in VR has been able to influence real world biases such as sexism. However, there is little to no comparative research on AR embodiment’s impact on societal biases. This study aims to set groundwork by examining possible connections between using gender changing Snapchat AR face filters and a person’s predicted implicit and explicit gender biases. We discovered that participants who experienced identification with gender manipulated versions of themselves showed both greater and lesser amounts of bias against men and women. These results depended the user’s gender, the filter applied, and the level of identification users reported with their AR manipulated selves. The results were similar to past VR findings but offered unique AR observations that could be useful for future bias intervention efforts.",0.8,0.8580749034881592,True,0.3318122278318339,0.5949435656599965,True
Scan&Paint: Image-based Projection Painting,"We present a pop-up projection painting system that projects onto an unknown three-dimensional surface, while the user creates the projection content on the fly. The digital paint is projected immediately and follows the object if it is moved. If unexplored surface areas are thereby exposed, an automated trigger system issues new depth recordings that expand and refine the surface estimate. By intertwining scanning and projection painting we scan the exposed surface at the appropriate time and only if needed. Like image-based rendering, multiple automatically recorded depth maps are fused in screen space to synthesize novel views of the object, making projection poses independent from the scan positions. Since the user’s digital paint is also stored in images, we eliminate the need to reconstruct and parametrize a single full mesh, which makes geometry and color updates simple and fast.",0.8,0.7763959169387817,True,0.3318122278318339,0.5541040723853078,True
Assessing Upper Extremity Motor Dysfunction Using an Augmented Reality Game,"Advances in technology offer new opportunities for a better understanding of how different disorders affect motor function. In this paper, we explore the potential of an augmented reality (AR) game implemented using free hand and body tracking to develop a uniform, cost-effective and objective methods for evaluation of upper extremity motor dysfunction in different patient groups. We conducted a study with 20 patients (10 Parkinson's Disease patients and 10 stroke patients) who performed hand/arm movement tasks in four different conditions in AR and one condition in real world. Despite usability issues mainly due to non-robust hand tracking, the patients were moderately engaged while playing the AR game. Our findings show that moving virtual objects was less targeted, took more time and was associated with larger trunk displacement and a lower variability of elbow angle and upper arm angle than moving real objects. No significant correlations were observed between characteristics of movements in AR and movements in the real world. Still, our findings suggest that the AR game may be suitable for assessing the hand and arm function of mildly affected patients if usability can be further improved.",1.0,0.8128793835639954,True,0.3775406687981454,0.5952100261810704,True
Exploring the Functional Difference of Gyri/Sulci via Hierarchical Interpretable Autoencoder,,1.0,0.783710241317749,True,0.3775406687981454,0.5806254550579473,True
Exploring Brain Function-Structure Connectome Skeleton via Self-supervised Graph-Transformer Approach,,1.0,0.799592912197113,True,0.3775406687981454,0.5885667904976293,True
Robust Segmentation of Brain MRI in the Wild with Hierarchical CNNs and no Retraining,"Retrospective analysis of brain MRI scans acquired in the clinic has the potential to enable neuroimaging studies with sample sizes much larger than those found in research datasets. However, analysing such clinical images""in the wild""is challenging, since subjects are scanned with highly variable protocols (MR contrast, resolution, orientation, etc.). Nevertheless, recent advances in convolutional neural networks (CNNs) and domain randomisation for image segmentation, best represented by the publicly available method SynthSeg, may enable morphometry of clinical MRI at scale. In this work, we first evaluate SynthSeg on an uncurated, heterogeneous dataset of more than 10,000 scans acquired at Massachusetts General Hospital. We show that SynthSeg is generally robust, but frequently falters on scans with low signal-to-noise ratio or poor tissue contrast. Next, we propose SynthSeg+, a novel method that greatly mitigates these problems using a hierarchy of conditional segmentation and denoising CNNs. We show that this method is considerably more robust than SynthSeg, while also outperforming cascaded networks and state-of-the-art segmentation denoising methods. Finally, we apply our approach to a proof-of-concept volumetric study of ageing, where it closely replicates atrophy patterns observed in research studies conducted on high-quality, 1mm, T1-weighted scans. The code and trained model are publicly available at https://github.com/BBillot/SynthSeg.",1.0,0.8281969428062439,True,0.3775406687981454,0.6028688058021947,True
Modularity-Constrained Dynamic Representation Learning for Interpretable Brain Disorder Analysis with Functional MRI,,1.0,0.7863336205482483,True,0.3775406687981454,0.5819371446731969,True
Exploring Fiber Skeletons via Joint Representation of Functional Networks and Structural Connectivity,,1.0,0.8768423199653625,True,0.3775406687981454,0.627191494381754,True
Integrating Neural Networks and Dictionary Learning for Multidimensional Clinical Characterizations from Functional Connectomics Data,"We propose a unified optimization framework that combines neural networks with dictionary learning to model complex interactions between resting state functional MRI and behavioral data. The dictionary learning objective decomposes patient correlation matrices into a collection of shared basis networks and subject-specific loadings. These subject-specific features are simultaneously input into a neural network that predicts multidimensional clinical information. Our novel optimization framework combines the gradient information from the neural network with that of a conventional matrix factorization objective. This procedure collectively estimates the basis networks, subject loadings, and neural network weights most informative of clinical severity. We evaluate our combined model on a multi-score prediction task using 52 patients diagnosed with Autism Spectrum Disorder (ASD). Our integrated framework outperforms state-of-the-art methods in a ten-fold cross validated setting to predict three different measures of clinical severity.",1.0,0.8022724986076355,True,0.3775406687981454,0.5899065837028905,True
"Robust Non-negative Tensor Factorization, Diffeomorphic Motion Correction, and Functional Statistics to Understand Fixation in Fluorescence Microscopy","Fixation is essential for preserving cellular morphology in biomedical research. However, it may also affect spectra captured in multispectral fluorescence microscopy, impacting molecular interpretations. To investigate fixation effects on tissue, multispectral fluorescence microscopy images of pairs of samples with and without fixation are captured. Each pixel might exhibit overlapping spectra, creating a blind source separation problem approachable with linear unmixing. With multiple excitation wavelengths, unmixing is intuitively extended to tensor factorizations. Yet these approaches are limited by nonlinear effects like attenuation. Further, light exposure during image acquisition introduces subtle Brownian motion between image channels of non-fixed tissue. Finally, hypothesis testing for spectral differences due to fixation is nontrivial as retrieved spectra are paired sequential samples. To these ends, we present three contributions, (1) a novel robust non-negative tensor factorization using the β-divergence and L 2,1 -norm, which decomposes the data into a low-rank multilinear and group-sparse non-multilinear tensor without making any explicit nonlinear modeling choices or assumptions on noise statistics; (2) a diffeomorphic atlas-based strategy for motion correction; (3) a non-parametric hypothesis testing framework for paired sequential data using functional principal component analysis.",1.0,0.7577340602874756,True,0.3775406687981454,0.5676373645428106,True
Multi-Input and Dataset-Invariant Adversarial Learning (MDAL) for Left and Right-Ventricular Coverage Estimation in Cardiac MRI,invariant adversarial learning (MDAL) for left and right-ventricular coverage estimation in cardiac MRI.,0.8,0.7934674620628357,True,0.3318122278318339,0.5626398449473348,True
Revolutionizing Space Health (Swin-FSR): Advancing Super-Resolution of Fundus Images for SANS Visual Assessment Technology,"The rapid accessibility of portable and affordable retinal imaging devices has made early differential diagnosis easier. For example, color funduscopy imaging is readily available in remote villages, which can help to identify diseases like age-related macular degeneration (AMD), glaucoma, or pathological myopia (PM). On the other hand, astronauts at the International Space Station utilize this camera for identifying spaceflight-associated neuro-ocular syndrome (SANS). However, due to the unavailability of experts in these locations, the data has to be transferred to an urban healthcare facility (AMD and glaucoma) or a terrestrial station (e.g, SANS) for more precise disease identification. Moreover, due to low bandwidth limits, the imaging data has to be compressed for transfer between these two places. Different super-resolution algorithms have been proposed throughout the years to address this. Furthermore, with the advent of deep learning, the field has advanced so much that x2 and x4 compressed images can be decompressed to their original form without losing spatial information. In this paper, we introduce a novel model called Swin-FSR that utilizes Swin Transformer with spatial and depth-wise attention for fundus image super-resolution. Our architecture achieves Peak signal-to-noise-ratio (PSNR) of 47.89, 49.00 and 45.32 on three public datasets, namely iChallenge-AMD, iChallenge-PM, and G1020. Additionally, we tested the model's effectiveness on a privately held dataset for SANS provided by NASA and achieved comparable results against previous architectures.",1.8,0.7878720760345459,True,0.574442516811659,0.6811572964231025,True
"Spatial-And-Context aware (SpACe) ""virtual biopsy"" radiogenomic maps to target tumor mutational status on structural MRI","With growing emphasis on personalized cancer-therapies, radiogenomics has shown promise in identifying target tumor mutational status on routine imaging (i.e. MRI) scans. These approaches largely fall into two categories: (1) deep-learning/radiomics (context-based) that employ image features from the entire tumor to identify the gene mutation status, or (2) atlas (spatial)-based to obtain likelihood of gene mutation status based on population statistics. While many genes (i.e. EGFR, MGMT) are spatially variant, a significant challenge in reliable assessment of gene mutation status on imaging is the lack of available co-localized ground truth for training the models. We present Spatial-And-Context aware (SpACe) ""virtual biopsy"" maps that incorporate context-features from co-localized biopsy site along with spatial-priors from population atlases, within a Least Absolute Shrinkage and Selection Operator (LASSO) regression model, to obtain a per-voxel probability of the presence of a mutation status (M + vs M -). We then use probabilistic pair-wise Markov model to improve the voxel-wise prediction probability. We evaluate the efficacy of SpACe maps on MRI scans with co-localized ground truth obtained from biopsy, to predict the mutation status of 2 driver genes in Glioblastoma (GBM): (1) EGF R + versus EGF R -, (n=91), and (2) M GM T + versus M GM T -, (n=81). When compared against state-of-the-art deep-learning (DL) and radiomic models, SpACe maps obtained training and testing accuracies of 90% (n=71) and 90.48% (n=21) in identifying EGFR amplification status, compared to 80% and 71.4% via radiomics, and 74.28% and 65.5% via DL. For MGMT methylation status, training and testing accuracies using SpACe were 88.3% (n=61) and 71.5% (n=20), compared to 52.4% and 66.7% using radiomics, and 79.3% and 68.4% using DL. Following validation, SpACe maps could provide surgical navigation to improve localization of sampling sites for targeting of specific driver genes in cancer.",0.8,0.8229040503501892,True,0.3318122278318339,0.5773581390910115,True
Spatiotemporal Attention Autoencoder (STAAE) for ADHD Classification,,0.8,0.7968887090682983,True,0.3318122278318339,0.5643504684500661,True
Inter-regional High-Level Relation Learning from Functional Connectivity via Self-supervision,,1.0,0.7372220754623413,True,0.3775406687981454,0.5573813721302434,True
Poincaré Embedding Reveals Edge-Based Functional Networks of the Brain,,1.0,0.7926114797592163,True,0.3775406687981454,0.5850760742786809,True
Phase Angle Spatial Embedding (PhASE) - A Kernel Method for Studying the Topology of the Human Functional Connectome,"Modern resting-state functional magnetic resonance imaging (rs-fMRI) provides a wealth of information about the inherent functional connectivity of the human brain. However, understanding the role of negative correlations and the nonlinear topology of rs-fMRI remains a challenge. To address these challenges, we propose a novel graph embedding technique, phase angle spatial embedding (PhASE), to study the ""intrinsic geometry"" of the functional connectome. PhASE both incorporates negative correlations as well as reformulates the connectome modularity problem as a kernel two-sample test, using a kernel method that induces a maximum mean discrepancy (MMD) in a reproducing kernel Hilbert space (RKHS). By solving a graph partition that maximizes this MMD, PhASE identifies the most functionally distinct brain modules. As a test case, we analyzed a public rs-fMRI dataset to compare male and female connectomes using PhASE and minimum spanning tree inferential statistics. These results show statistically significant differences between male and female resting-state brain networks, demonstrating PhASE to be a robust tool for connectome analysis.",1.8,0.5761075615882874,False,0.574442516811659,0.5752750391999732,True
Punctate White Matter Lesion Segmentation in Preterm Infants Powered by Counterfactually Generative Learning,"Accurate segmentation of punctate white matter lesions (PWMLs) are fundamental for the timely diagnosis and treatment of related developmental disorders. Automated PWMLs segmentation from infant brain MR images is challenging, considering that the lesions are typically small and low-contrast, and the number of lesions may dramatically change across subjects. Existing learning-based methods directly apply general network architectures to this challenging task, which may fail to capture detailed positional information of PWMLs, potentially leading to severe under-segmentations. In this paper, we propose to leverage the idea of counterfactual reasoning coupled with the auxiliary task of brain tissue segmentation to learn fine-grained positional and morphological representations of PWMLs for accurate localization and segmentation. A simple and easy-to-implement deep-learning framework (i.e., DeepPWML) is accordingly designed. It combines the lesion counterfactual map with the tissue probability map to train a lightweight PWML segmentation network, demonstrating state-of-the-art performance on a real-clinical dataset of infant T1w MR images. The code is available at \href{https://github.com/ladderlab-xjtu/DeepPWML}{https://github.com/ladderlab-xjtu/DeepPWML}.",1.0,0.8721209764480591,True,0.3775406687981454,0.6248308226231023,True
Embedding Human Brain Function via Transformer,,1.0,0.8398959636688232,True,0.3775406687981454,0.6087183162334844,True
Contrastive Masked Transformers for Forecasting Renal Transplant Function,"à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.",1.0,0.9695096611976624,True,0.3775406687981454,0.6735251649979039,True
Learnable Subdivision Graph Neural Network for Functional Brain Network Analysis and Interpretable Cognitive Disorder Diagnosis,,1.0,0.8681822419166565,True,0.3775406687981454,0.622861455357401,True
Image2SSM: Reimagining Statistical Shape Models from Images with Radial Basis Functions,"Statistical shape modeling (SSM) is an essential tool for analyzing variations in anatomical morphology. In a typical SSM pipeline, 3D anatomical images, gone through segmentation and rigid registration, are represented using lower-dimensional shape features, on which statistical analysis can be performed. Various methods for constructing compact shape representations have been proposed, but they involve laborious and costly steps. We propose Image2SSM, a novel deep-learning-based approach for SSM that leverages image-segmentation pairs to learn a radial-basis-function (RBF)-based representation of shapes directly from images. This RBF-based shape representation offers a rich self-supervised signal for the network to estimate a continuous, yet compact representation of the underlying surface that can adapt to complex geometries in a data-driven manner. Image2SSM can characterize populations of biological structures of interest by constructing statistical landmark-based shape models of ensembles of anatomical shapes while requiring minimal parameter tuning and no user assistance. Once trained, Image2SSM can be used to infer low-dimensional shape representations from new unsegmented images, paving the way toward scalable approaches for SSM, especially when dealing with large cohorts. Experiments on synthetic and real datasets show the efficacy of the proposed method compared to the state-of-art correspondence-based method for SSM.",1.0,0.7398660778999329,True,0.3775406687981454,0.5587033733490392,True
Multi-head Attention-Based Masked Sequence Model for Mapping Functional Brain Networks,,1.0,0.7554211020469666,True,0.3775406687981454,0.566480885422556,True
M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector,"Deep-learning-based object detection methods show promise for improving screening mammography, but high rates of false positives can hinder their effectiveness in clinical practice. To reduce false positives, we identify three challenges: (1) unlike natural images, a malignant mammogram typically contains only one malignant finding; (2) mammography exams contain two views of each breast, and both views ought to be considered to make a correct assessment; (3) most mammograms are negative and do not contain any findings. In this work, we tackle the three aforementioned challenges by: (1) leveraging Sparse R-CNN and showing that sparse detectors are more appropriate than dense detectors for mammography; (2) including a multi-view cross-attention module to synthesize information from different views; (3) incorporating multi-instance learning (MIL) to train with unannotated images and perform breast-level classification. The resulting model, M&M, is a Multi-view and Multi-instance learning system that can both localize malignant findings and provide breast-level predictions. We validate M&M's detection and classification performance using five mammography datasets. In addition, we demonstrate the effectiveness of each proposed component through comprehensive ablation studies.",0.8,0.9367680549621582,True,0.3318122278318339,0.634290141396996,True
Lesion-based Contrastive Learning for Diabetic Retinopathy Grading from Fundus Images,"Manually annotating medical images is extremely expensive, especially for large-scale datasets. Self-supervised contrastive learning has been explored to learn feature representations from unlabeled images. However, unlike natural images, the application of contrastive learning to medical images is relatively limited. In this work, we propose a self-supervised framework, namely lesion-based contrastive learning for automated diabetic retinopathy (DR) grading. Instead of taking entire images as the input in the common contrastive learning scheme, lesion patches are employed to encourage the feature extractor to learn representations that are highly discriminative for DR grading. We also investigate different data augmentation operations in defining our contrastive prediction task. Extensive experiments are conducted on the publicly-accessible dataset EyePACS, demonstrating that our proposed framework performs outstandingly on DR grading in terms of both linear evaluation and transfer capacity evaluation.",1.0,0.7506508827209473,True,0.3775406687981454,0.5640957757595464,True
Context-Aware Pseudo-Label Refinement for Source-Free Domain Adaptive Fundus Image Segmentation,"In the domain adaptation problem, source data may be unavailable to the target client side due to privacy or intellectual property issues. Source-free unsupervised domain adaptation (SF-UDA) aims at adapting a model trained on the source side to align the target distribution with only the source model and unlabeled target data. The source model usually produces noisy and context-inconsistent pseudo-labels on the target domain, i.e., neighbouring regions that have a similar visual appearance are annotated with different pseudo-labels. This observation motivates us to refine pseudo-labels with context relations. Another observation is that features of the same class tend to form a cluster despite the domain gap, which implies context relations can be readily calculated from feature distances. To this end, we propose a context-aware pseudo-label refinement method for SF-UDA. Specifically, a context-similarity learning module is developed to learn context relations. Next, pseudo-label revision is designed utilizing the learned context relations. Further, we propose calibrating the revised pseudo-labels to compensate for wrong revision caused by inaccurate context relations. Additionally, we adopt a pixel-level and class-level denoising scheme to select reliable pseudo-labels for domain adaptation. Experiments on cross-domain fundus images indicate that our approach yields the state-of-the-art results. Code is available at https://github.com/xmed-lab/CPR.",1.0,0.8557977676391602,True,0.3775406687981454,0.6166692182186528,True
Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks,"Fully convolutional neural networks (F-CNNs) have set the state-of-the-art in image segmentation for a plethora of applications. Architectural innovations within F-CNNs have mainly focused on improving spatial encoding or network connectivity to aid gradient flow. In this paper, we explore an alternate direction of recalibrating the feature maps adaptively, to boost meaningful features, while suppressing weak ones. We draw inspiration from the recently proposed squeeze & excitation (SE) module for channel recalibration of feature maps for image classification. Towards this end, we introduce three variants of SE modules for image segmentation, (i) squeezing spatially and exciting channel-wise (cSE), (ii) squeezing channel-wise and exciting spatially (sSE) and (iii) concurrent spatial and channel squeeze & excitation (scSE). We effectively incorporate these SE modules within three different state-of-theart F-CNNs (DenseNet, SD-Net, U-Net) and observe consistent improvement of performance across all architectures, while minimally effecting model complexity. Evaluations are performed on two challenging applications: whole brain segmentation on MRI scans and organ segmentation on whole body contrast enhanced CT scans.",0.8,0.8971550464630127,True,0.3318122278318339,0.6144836371474233,True
A Multitask Learning Architecture for Simultaneous Segmentation of Bright and Red Lesions in Fundus Images,,1.0,0.8021859526634216,True,0.3775406687981454,0.5898633107307836,True
Degradation-Invariant Enhancement of Fundus Images via Pyramid Constraint Network,"As an economical and efficient fundus imaging modality, retinal fundus images have been widely adopted in clinical fundus examination. Unfortunately, fundus images often suffer from quality degradation caused by imaging interferences, leading to misdiagnosis. Despite impressive enhancement performances that state-of-the-art methods have achieved, challenges remain in clinical scenarios. For boosting the clinical deployment of fundus image enhancement, this paper proposes the pyramid constraint to develop a degradation-invariant enhancement network (PCE-Net), which mitigates the demand for clinical data and stably enhances unknown data. Firstly, high-quality images are randomly degraded to form sequences of low-quality ones sharing the same content (SeqLCs). Then individual low-quality images are decomposed to Laplacian pyramid features (LPF) as the multi-level input for the enhancement. Subsequently, a feature pyramid constraint (FPC) for the sequence is introduced to enforce the PCE-Net to learn a degradation-invariant model. Extensive experiments have been conducted under the evaluation metrics of enhancement and segmentation. The effectiveness of the PCE-Net was demonstrated in comparison with state-of-the-art methods and the ablation study. The source code of this study is publicly available at https://github.com/HeverLaw/PCENet-Image-Enhancement.",1.0,0.7636511921882629,True,0.3775406687981454,0.5705959304932042,True
Enhanced Cycle-Consistent Generative Adversarial Network for Color Normalization of H&E Stained Images,,0.8,0.839938223361969,True,0.3318122278318339,0.5858752255969014,True
Maximum Entropy on Erroneous Predictions (MEEP): Improving model calibration for medical image segmentation,,0.8,0.8759014010429382,True,0.3318122278318339,0.603856814437386,True
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,,0.8,0.7955878973007202,True,0.3318122278318339,0.563700062566277,True
RADIomic Spatial TexturAl descripTor (RADISTAT): Characterizing Intra-tumoral Heterogeneity for Response and Outcome Prediction,,0.8,0.8822961449623108,True,0.3318122278318339,0.6070541863970723,True
Improving Automatic Fetal Biometry Measurement with Swoosh Activation Function,,1.0,0.7652931809425354,True,0.3775406687981454,0.5714169248703405,True
Swin Deformable Attention U-Net Transformer (SDAUT) for Explainable Fast MRI,". Fast MRI aims to reconstruct a high ﬁdelity image from partially observed measurements. Exuberant development in fast MRI using deep learning has been witnessed recently. Meanwhile, novel deep learning paradigms, e.g., Transformer based models, are fast-growing in natural language processing and promptly developed for computer vision and medical image analysis due to their prominent performance. Nevertheless, due to the complexity of the Transformer, the application of fast MRI may not be straightforward. The main obstacle is the computational cost of the self-attention layer, which is the core part of the Transformer, can be expensive for high resolution MRI inputs. In this study, we propose a new Transformer architecture for solving fast MRI that coupled Shifted Windows Transformer with U-Net to reduce the network complexity. We incorporate deformable attention to construe the explainability of our reconstruction model. We empirically demonstrate that our method achieves consistently superior performance on the fast MRI task. Besides, compared to state-of-the-art Transformer models, our method has fewer network parameters while revealing explainability. The code is publicly available at https://github.com/ayanglab/SDAUT.",0.8,0.7947849631309509,True,0.3318122278318339,0.5632985954813924,True
MAGIC: Multi-scale Heterogeneity Analysis and Clustering for Brain Diseases,"There is a growing amount of clinical, anatomical and functional evidence for the heterogeneous presentation of neuropsychiatric and neurodegenerative diseases such as schizophrenia and Alzheimer's Disease (AD). Elucidating distinct subtypes of diseases allows a better understanding of neuropathogenesis and enables the possibility of developing targeted treatment programs. Recent semi-supervised clustering techniques have provided a data-driven way to understand disease heterogeneity. However, existing methods do not take into account that subtypes of the disease might present themselves at different spatial scales across the brain. Here, we introduce a novel method, MAGIC, to uncover disease heterogeneity by leveraging multi-scale clustering. We first extract multi-scale patterns of structural covariance (PSCs) followed by a semi-supervised clustering with double cyclic block-wise optimization across different scales of PSCs. We validate MAGIC using simulated heterogeneous neuroanatomical data and demonstrate its clinical potential by exploring the heterogeneity of AD using T1 MRI scans of 228 cognitively normal (CN) and 191 patients. Our results indicate two main subtypes of AD with distinct atrophy patterns that consist of both fine-scale atrophy in the hippocampus as well as large-scale atrophy in cortical regions. The evidence for the heterogeneity is further corroborated by the clinical evaluation of two subtypes, which indicates that there is a subpopulation of AD patients that tend to be younger and decline faster in cognitive performance relative to the other subpopulation, which tends to be older and maintains a relatively steady decline in cognitive abilities.",1.0,0.8809646964073181,True,0.3775406687981454,0.6292526826027318,True
Multi-head GAGNN: A Multi-head Guided Attention Graph Neural Network for Modeling Spatio-temporal Patterns of Holistic Brain Functional Networks,,1.0,0.8017401695251465,True,0.3775406687981454,0.589640419161646,True
Opinions Vary? Diagnosis First!,"With the advancement of deep learning techniques, an increasing number of methods have been proposed for optic disc and cup (OD/OC) segmentation from the fundus images. Clinically, OD/OC segmentation is often annotated by multiple clinical experts to mitigate the personal bias. However, it is hard to train the automated deep learning models on multiple labels. A common practice to tackle the issue is majority vote, e.g., taking the average of multiple labels. However such a strategy ignores the different expertness of medical experts. Motivated by the observation that OD/OC segmentation is often used for the glaucoma diagnosis clinically, in this paper, we propose a novel strategy to fuse the multi-rater OD/OC segmentation labels via the glaucoma diagnosis performance. Specifically, we assess the expertness of each rater through an attentive glaucoma diagnosis network. For each rater, its contribution for the diagnosis will be reflected as an expertness map. To ensure the expertness maps are general for different glaucoma diagnosis models, we further propose an Expertness Generator (ExpG) to eliminate the high-frequency components in the optimization process. Based on the obtained expertness maps, the multi-rater labels can be fused as a single ground-truth which we dubbed as Diagnosis First Ground-truth (DiagF irstGT). Experimental results show that by using DiagF irstGT as ground-truth, OD/OC segmentation networks will predict the masks with superior glaucoma diagnosis performance.",0.8,0.9271887540817261,True,0.3318122278318339,0.62950049095678,True
Dynamic Functional Connectome Harmonics,,1.0,0.8816014528274536,True,0.3775406687981454,0.6295710608127996,True
Reinforcement Learning of Musculoskeletal Control from Functional Simulations,"To diagnose, plan, and treat musculoskeletal pathologies, understanding and reproducing muscle recruitment for complex movements is essential. With muscle activations for movements often being highly redundant, nonlinear, and time dependent, machine learning can provide a solution for their modeling and control for anatomy-specific musculoskeletal simulations. Sophisticated biomechanical simulations often require specialized computational environments, being numerically complex and slow, hindering their integration with typical deep learning frameworks. In this work, a deep reinforcement learning (DRL) based inverse dynamics controller is trained to control muscle activations of a biomechanical model of the human shoulder. In a generalizable end-toend fashion, muscle activations are learned given current and desired position-velocity pairs. A customized reward functions for trajectory control is introduced, enabling straightforward extension to additional muscles and higher degrees of freedom. Using the biomechanical model, multiple episodes are simulated on a cluster simultaneously using the evolving neural models of the DRL being trained. Results are presented for a single-axis motion control of shoulder abduction for the task of following randomly generated angular trajectories.",1.0,0.723674476146698,True,0.3775406687981454,0.5506075724724218,True
Contrastive Re-localization and History Distillation in Federated CMR Segmentation,,1.0,0.7935672998428345,True,0.3775406687981454,0.58555398432049,True
Combining Fundus Images and Fluorescein Angiography for Artery/Vein Classification Using the Hierarchical Vessel Graph Network,,1.0,0.7337859272956848,True,0.3775406687981454,0.5556632980469152,True
Discovering Functional Brain Networks with 3D Residual Autoencoder (ResAE),,1.8,0.6712476015090942,True,0.574442516811659,0.6228450591603767,True
'Project & Excite' Modules for Segmentation of Volumetric Medical Scans,,0.8,0.9805981516838074,True,0.3318122278318339,0.6562051897578206,True
Deep Random Walk for Drusen Segmentation from Fundus Images,,1.0,0.8259618878364563,True,0.3775406687981454,0.6017512783173009,True
Boundary and Entropy-driven Adversarial Learning for Fundus Image Segmentation,"Accurate segmentation of the optic disc (OD) and cup (OC) in fundus images from different datasets is critical for glaucoma disease screening. The cross-domain discrepancy (domain shift) hinders the generalization of deep neural networks to work on different domain datasets. In this work, we present an unsupervised domain adaptation framework, called Boundary and Entropy-driven Adversarial Learning (BEAL), to improve the OD and OC segmentation performance, especially on the ambiguous boundary regions. In particular, our proposed BEAL framework utilizes the adversarial learning to encourage the boundary prediction and mask probability entropy map (uncertainty map) of the target domain to be similar to the source ones, generating more accurate boundaries and suppressing the high uncertainty predictions of OD and OC segmentation. We evaluate the proposed BEAL framework on two public retinal fundus image datasets (Drishti-GS and RIM-ONE-r3), and the experiment results demonstrate that our method outperforms the state-of-the-art unsupervised domain adaptation methods. Our code is available at https://github.com/EmmaW8/BEAL.",1.0,0.8855772018432617,True,0.3775406687981454,0.6315589353207036,True
FE-STGNN: Spatio-Temporal Graph Neural Network with Functional and Effective Connectivity Fusion for MCI Diagnosis,,1.0,0.724785566329956,True,0.3775406687981454,0.5511631175640508,True
I-SECRET: Importance-Guided Fundus Image Enhancement via Semi-supervised Contrastive Constraining,,1.0,0.7987393736839294,True,0.3775406687981454,0.5881400212410375,True
Effect of Functionalized CdSSe Quantum Dots in the CYP450 Activity of HEPG2 Cells,"Quantum dots (QDs) have different properties: high electron density, magnetic moment, phosphorescence, photoluminescence (fluorescence), and strong optical absorption. The layer or ligands on the QDs surface has a vital role because they allow the stabilization and practical uses on different matrixes. Ligand exchange is a commonly carried out methodology to incorporate functional groups that alter the solubility, introduce electron transfer partners, integrate biological receptors, or improve the properties of the QDs surface. CdSSe QDs were synthesized using a microwave system using thioglycolic acid (TGA) as a sulfur source and cover agent. The TGA ligand was interchanged with cysteine (Cys), glutamic acid (GA), glutathione (GTO), glutaraldehyde (GLT), and lysine (Lys). The viability and response of the CYP1A1, CYP1A2, and CYP3A4 isoenzymes were directly measured in HEP-G2 cells after exposure to CdSSe-TGA, CdSSe-Cys, CdSSe-GA, CdSSe-GTO, CdSSe-GLT, and CdSSe-Lys. CdSSe and CdSSe-GTO (10 mg/L) decrease viability by around 65%. The response of the cytochrome isoenzymes is based on the organic ligand on the surface of the CdSSe QDs. Changes in CYP 1A1 could be related to carcinogenic xenobiotics. Fluorescence microscopy shows CdSSe QDs on and inside HEPG2 cells. The results confirm that apoptosis and necrosis are the principal mechanisms of decreased viability.",1.0,0.7596006393432617,True,0.3775406687981454,0.5685706540707036,True
Utopia: Fast and Efficient Address Translation via Hybrid Restrictive & Flexible Virtual-to-Physical Address Mappings,"Conventional virtual memory (VM) frameworks enable a virtual address to flexibly map to any physical address. This flexibility necessitates large data structures to store virtual-to-physical mappings, which leads to high address translation latency and large translation-induced interference in the memory hierarchy, especially in data-intensive workloads. On the other hand, restricting the address mapping so that a virtual address can only map to a specific set of physical addresses can significantly reduce address translation overheads by making use of compact and efficient translation structures. However, restricting the address mapping flexibility across the entire main memory severely limits data sharing across different processes and increases data accesses to the swap space of the storage device even in the presence of free memory.We propose Utopia, a new hybrid virtual-to-physical address mapping scheme that allows both flexible and restrictive hash-based address mapping schemes to harmoniously co-exist in the system. The key idea of Utopia is to manage physical memory using two types of physical memory segments: restrictive segments and flexible segments. A restrictive segment uses a restrictive, hash-based address mapping scheme that maps virtual addresses to only a specific set of physical addresses and enables faster address translation using compact translation structures. A flexible segment employs the conventional fully-flexible address mapping scheme. By mapping data to a restrictive segment, Utopia enables faster address translation with lower translation-induced interference. At the same time, Utopia retains the ability to use the flexible address mapping to (i) support conventional VM features such as data sharing and (ii) avoid storing data in the swap space of the storage device when program data does not fit inside a restrictive segment.Our evaluation using 11 diverse data-intensive workloads shows that Utopia improves performance by 24% in a single-core system over the baseline conventional four-level radix-tree page table design, whereas the best prior state-of-the-art contiguity-aware translation scheme improves performance by 13%. Utopia provides 95% of the performance benefits of an ideal address translation scheme where every translation request hits in the first-level TLB. All of Utopia’s benefits come at a modest cost of 0.64% area overhead and 0.72% power overhead compared to a modern high-end CPU. The source code of Utopia is freely available at https://github.com/CMU-SAFARI/Utopia.CCS CONCEPTS• Hardware → Memory and dense storage; • Software and its engineering → Virtual memory.",0.8,0.7867904901504517,True,0.3318122278318339,0.5593013589911427,True
Magic-State Functional Units: Mapping and Scheduling Multi-Level Distillation Circuits for Fault-Tolerant Quantum Architectures,"Quantum computers have recently made great strides and are on a long-term path towards useful fault-tolerant computation. A dominant overhead in fault-tolerant quantum computation is the production of high-fidelity encoded qubits, called magic states, which enable reliable error-corrected computation. We present the first detailed designs of hardware functional units that implement space-time optimized magic-state factories for surface code error-corrected machines. Interactions among distant qubits require surface code braids (physical pathways on chip) which must be routed. Magic-state factories are circuits comprised of a complex set of braids that is more difficult to route than quantum circuits considered in previous work [1]. This paper explores the impact of scheduling techniques, such as gate reordering and qubit renaming, and we propose two novel mapping techniques: braid repulsion and dipole moment braid rotation. We combine these techniques with graph partitioning and community detection algorithms, and further introduce a stitching algorithm for mapping subgraphs onto a physical machine. Our results show a factor of 5.64 reduction in space-time volume compared to the best-known previous designs for magic-state factories.",2.0,0.8534145355224609,True,0.6224593312018546,0.7379369333621577,True
Photochromic Responses and Stability of Functional Inks Applied on Sustainable Packaging Materials,"Photochromism refers to a reversible colour change induced by the irradiation of photochromic materials with ultraviolet (UV) or visible light that reverts to the original colour after the light source is removed. This effect arises from chemical transformations between two isomers with different absorption spectra, involving processes like proton transfer, chemical-bond formation, and isomerisation. These photochromic inks, appearing as crystalline powders with micro-sized particles, require dissolution in a suitable matrix to achieve the colour change. Photochromic inks are used in security, as functional coatings for paper and packaging, in the fabric industry, and in other ways. This study examines the influence of varying concentrations of micro-sized photochromic pigments and different ink-coating thicknesses on the photochromic effect on sustainable paperboard substrates. Artificial ageing was performed to assess the photochromic response and lightfastness in relation to pigment concentration, ink-coating thickness, and the influence of the paperboard substrates. The results of this research could contribute to enhancing knowledge on employing photochromic inks for diverse packaging applications.",1.0,0.8452320098876953,True,0.3775406687981454,0.6113863393429204,True
Active Textile Glove for Cooling and Personal Protection,"Conventional gloves partially insulate against heat transfer from a hot external environment. They also prevent metabolic heat generated by the human body from escaping. Thus, gloves are a source of heat buildup and heat stress in workers. Heat stress can lead to hyperthermia. Described herein is a glove that cools using a carbon nanotube (CNT) fabric micro-liner and forced convection from a fan. A cold sink is assumed to be located in the glove to cool the convection air. This glove is called an active textile glove. CNT fabric has high thermal conductivity in the plane of the fabric, low thermal conductivity through its thickness, and a large surface area for convection cooling. Thus, the active textile glove can transfer heat from the hand to cooler air in the environment. This paper simulates the performance of a CNT-cooled glove using simple theoretical heat transfer models. Cooling was also demonstrated by testing the glove using a hot plate. Forced convection was found to provide the greatest cooling effect, with it working in synergy with the CNT fabric which aids in spreading heat. CNT fabric also acts as a shield from environmental dangers. The fabric is flame resistant, attenuates radio frequency waves, and prevents smoke particles and toxic chemicals from entering the glove. Testing illustrates the shielding properties of CNT fabric.",1.0,0.7491759061813354,True,0.3775406687981454,0.5633582874897405,True
"Tackling Computer Security Issues Through Lazy, Stackless Functional Programming Architectures","As transistor scaling hits its limits, a new challenge for general purpose computing arises: the need for efficient structures both in architecture and microarchitecture levels. Until recently, gains in transistor performance justified complex architectures, while computer systems security and safety has been dealt with as a software-only problem. The result is that current computer architectures are plagued with security vulnerabilities, intentional and unintentional backdoors. As a response to this, we propose a fresh look on functional programming architectures, based on combinatory logic. A functional processor has been designed, enabling the development of safe, purely functional operational systems and device drivers.",1.0,0.7867897152900696,True,0.3775406687981454,0.5821651920441075,True
Bit-Exact ECC Recovery (BEER): Determining DRAM On-Die ECC Functions by Exploiting DRAM Data Retention Characteristics,"Increasing single-cell DRAM error rates have pushed DRAM manufacturers to adopt on-die error-correction coding (ECC), which operates entirely within a DRAM chip to improve factory yield. The on-die ECC function and its effects on DRAM reliability are considered trade secrets, so only the manufacturer knows precisely how on-die ECC alters the externally-visible reliability characteristics. Consequently, on-die ECC obstructs third-party DRAM customers (e.g., test engineers, experimental researchers), who typically design, test, and validate systems based on these characteristicsTo give third parties insight into precisely how on-die ECC transforms DRAM error patterns during error correction, we introduce Bit-Exact ECC Recovery (BEER), a new methodology for determining the full DRAM on-die ECC function (i.e., its parity-check matrix) without hardware tools, prerequisite knowledge about the DRAM chip or on-die ECC mechanism, or access to ECC metadata (e.g., error syndromes, parity information). BEER exploits the key insight that non-intrusively inducing data-retention errors with carefully-crafted test pat-terns reveals behavior that is unique to a specific ECC functionWe use BEER to identify the ECC functions of 80 real LPDDR4 DRAM chips with on-die ECC from three major DRAM manufacturers. We evaluate BEER’s correctness in simulation and performance on a real system to show that BEER is effective and practical across a wide range of on-die ECC functions. To demonstrate BEER’s value, we propose and discuss several ways that third parties can use BEER to improve their design and testing practices. As a concrete example, we introduce and evaluate BEEP, the first error profiling method-ology that uses the known on-die ECC function to recover the number and bit-exact locations of unobservable raw bit errors responsible for observable post-correction errors.",1.8,0.7731627225875854,True,0.574442516811659,0.6738026196996223,True
Non-Destructive Characterization of Selected Types of Films and Other Layers via White Light Reflectance Spectroscopy (WLRS),"In this work, we consider White Light Reflectance Spectroscopy (WLRS) as an optical methodology for the accurate, fast and non-destructive measurement of film thickness in the 1 nm to the 1 mm range and for applications that include microelectronics, photonics, bioanalysis and packaging. Films to which WLRS is applicable can be either homogeneous or layered-composite ones, while thickness and composition might be fixed or varying with time; in the latter case, real-time monitoring of the kinetics of processes such as certain transitions, film dissolution and bioreactions is possible. We present the basic principles of WLRS and a selection of characteristic application examples of current interest, and we also briefly compare WLRS with alternative methods for film measurement.",0.8,0.9184523224830627,True,0.3318122278318339,0.6251322751574483,True
Race-To-Sleep + Content Caching + Display Caching: A Recipe for Energy-efficient Video Streaming on Handhelds,"Video streaming has become the most common application in handhelds and this trend is expected to grow in future to account for about 75% of all mobile data traffic by 2021. Thus, optimizing the performance and energy consumption of video processing in mobile devices is critical for sustaining the handheld market growth. In this paper, we propose three complementary techniques, race-to-sleep, content caching and display caching, to minimize the energy consumption of the video processing flows. Unlike the state-of-the-art frame-by-frame processing of a video decoder, the first scheme, race-to-sleep, uses two approaches, called batching of frames and frequency boosting to prolong its sleep state for saving energy, while avoiding any frame drops. The second scheme, content caching, exploits the content similarity of smaller video blocks, called macroblocks, to design a novel cache organization for reducing the memory pressure. The third scheme, in turn, takes advantage of content similarity at the display controller to facilitate display caching further improving energy efficiency. We integrate these three schemes for developing an end-to-end video processing framework and evaluate our design on a comprehensive mobile system design platform with a variety of video processing workloads. Our evaluations show that the proposed three techniques complement each other in improving performance by avoiding frame drops and reducing the energy consumption of video streaming applications by 21%, on average, compared to the current baseline design.CCS CONCEPTS• Human-centered computing $ \rightarrow$ Mobile computing;• Computer systems organization $ \rightarrow$ Architectures; Embedded hardware;",1.0,0.9871019124984741,True,0.3775406687981454,0.6823212906483098,True
Architectural Opportunities for Novel Dynamic EMI Shifting(DEMIS),"Processors emit non-trivial amounts of electromagnetic radiation, creating interference in frequency bands used by wireless communication technologies such as cellular, WiFi and Bluetooth. We introduce the problem of in-band radio frequency noise as a form of electromagnetic interference (EMI) to the computer architecture community as a technical challenge to be addressed. This paper proposes the new idea of Dynamic EMI Shifting (DEMIS) where architectural and/or compiler changes allow the EMI to be shifted at runtime. DEMIS processors dynamically move the interference from bands used during communication to other unused frequencies. Unlike previous works that leverage static techniques, DEMIS dynamically targets specific frequency bands; the type of techniques used here are only possible from an architectural perspective. This paper is also the first to provide insights in the new area of dynamic EMI shifting by evaluating several platforms and showing the EMI is sensitive to many architectural and compilation parameters. Our evaluation over real systems shows a decrease of in-band EMI ranging from 3 to 15 dB with less than a 10% average performance impact. A 15dB EMI reduction for LTE can represent over 3x bandwidth improvement for EMI bound communication. CCS CONCEPTS • Hardware → Noise reduction; Wireless devices; Signal integrity and noise analysis;",0.8,0.8107901811599731,True,0.3318122278318339,0.5713012044959035,True
Micro-Armed Bandit: Lightweight & Reusable Reinforcement Learning for Microarchitecture Decision-Making,"Online Reinforcement Learning (RL) has been adopted as an effective mechanism in various decision-making problems in microarchitecture. Its high adaptability and the ability to learn at runtime are attractive characteristics in microarchitecture settings. However, although hardware RL agents are effective, they suffer from two main problems. First, they have high complexity and storage overhead. This complexity stems from decomposing the environment into a large number of states and then, for each of these states, bookkeeping many action values. Second, many RL agents are engineered for a specific application and are not reusable.In this work, we tackle both of these shortcomings by designing an RL agent that is both lightweight and reusable across different microarchitecture decision-making problems. We find that, in some of these problems, only a small fraction of the action space is useful in a given time window. We refer to this property as temporal homogeneity in the action space. Motivated by this property, we design an RL agent based on Multi-Armed Bandit algorithms, the simplest form of RL. We call our agent Micro-Armed Bandit.We showcase our agent in two use cases: data prefetching and instruction fetch in simultaneous multithreaded (SMT) processors. For prefetching, our agent outperforms non-RL prefetchers Bingo and MLOP by 2.6% and 2.3% (geometric mean), respectively, and attains similar performance as the state-of-the-art RL prefetcher Pythia–with the dramatically lower storage requirement of only 100 bytes. For SMT instruction fetch, our agent outperforms the Hill Climbing method by 2.2% (geometric mean).CCS CONCEPTS• Computer systems organization; • Computing methodologies → Reinforcement learning;",0.8,0.9789191484451294,True,0.3318122278318339,0.6553656881384816,True
Dadu-RBD: Robot Rigid Body Dynamics Accelerator with Multifunctional Pipelines,"Rigid body dynamics is a core technology in the robotics field. In trajectory optimization and model predictive control algorithms, there are usually a large number of rigid body dynamics computing tasks. Using CPUs to process these tasks consumes a lot of time, which will affect the real-time performance of robots. To this end, we propose a multifunctional robot rigid body dynamics accelerator, named Dadu-RBD, to address the performance bottleneck. By analyzing different functions commonly used in robot dynamics calculations, we summarize their relationships and characteristics, then optimize them according to the hardware. Based on this, Dadu-RBD can fully reuse common hardware modules when processing different computing tasks. By dynamically switching the dataflow path, Dadu-RBD can accelerate various dynamics functions without reconfiguring the hardware. We design the Round-Trip Pipeline and Structure-Adaptive Pipelines for Dadu-RBD, which can greatly improve the throughput of the accelerator. Robots with different structures and parameters can be optimized specifically. Compared with the state-of-the-art CPU, GPU dynamics libraries and FPGA accelerator, Dadu-RBD can significantly improve the performance.CCS CONCEPTS• Computer systems organization → Data flow architectures; Reconfigurable computing; • Hardware → Application specific processors.",1.0,0.824853241443634,True,0.3775406687981454,0.6011969551208898,True
Pressure-Driven Sample Flow through an Electrospun Membrane Increases the Analyte Adsorption,"Electrospun polymer membranes are regarded as prospective biosensor components due to their large specific surface area and diverse opportunities for chemical modifications. However, their intricate porous structure can impede diffusion and render some analyte-binding sites inaccessible. To overcome these diffusion limitations and improve analyte adsorption onto the polymer, a pressure-driven sample flow through the membrane can be employed. To date, the efficiency of pressure-driven analyte delivery into these membranes has not been quantified. Here, we compare forced flow and passive sample diffusion through poly(dioxanone) electrospun membranes. We examine two model analytes, BSA and interleukin-1 beta (IL1b), to address both non-specific and specific binding. Following exposure of the membranes to the test solutions, we measured the residual concentrations of the analytes using fluorometry and enzyme-linked immunosorbent assay (ELISA) techniques. The pressure-driven sample loading was superior to passive diffusion, with a 2.8–11.5-fold change for physical adsorption and a 2.4–3.4-fold difference for specific binding. Our data can be useful for the development of immunoassays and microfluidic devices.",1.0,0.7280872464179993,True,0.3775406687981454,0.5528139576080724,True
Speculative Privacy Tracking (SPT): Leaking Information From Speculative Execution Without Compromising Privacy,"Speculative execution attacks put a dangerous new twist on information leakage through microarchitectural side channels. Ordinarily, programmers can reason about leakage based on the program’s semantics, and prevent said leakage by carefully writing the program to not pass secrets to covert channel-creating “transmitter” instructions, such as branches and loads. Speculative execution breaks this defense, because a transmitter might mis-speculatively execute with a secret operand even if it can never execute with said operand in valid executions. This paper proposes a new security definition that enables hardware to provide comprehensive, low-overhead and transparent-to-software protection against these attacks. The key idea is that it is safe to speculatively execute a transmitter without any protection if its operands were already leaked by the non-speculative execution. Based on this definition we design Speculative Privacy Tracking (SPT), a hardware protection that delays execution of every transmitter until it can prove that the transmitter’s operands leak during the program’s non-speculative execution. Using a novel dynamic information flow analysis microarchitecture, SPT efficiently proves when such an operand declassification implies that other data becomes declassified, which enables other delayed transmitters to be executed safely. We evaluate SPT on SPEC2017 and constant-time code benchmarks, and find that it adds only 45%/11% overhead on average (depending on the attack model) relative to an insecure processor. Compared to a secure baseline with the same protection scope, SPT reduces overhead by an average 3.6 × /3 ×.",0.8,0.8833557963371277,True,0.3318122278318339,0.6075840120844808,True
HiMA: A Fast and Scalable History-based Memory Access Engine for Differentiable Neural Computer,"Memory-augmented neural networks (MANNs) provide better inference performance in many tasks with the help of an external memory. The recently developed differentiable neural computer (DNC) is a MANN that has been shown to outperform in representing complicated data structures and learning long-term dependencies. DNC’s higher performance is derived from new history-based attention mechanisms in addition to the previously used content-based attention mechanisms. History-based mechanisms require a variety of new compute primitives and state memories, which are not supported by existing neural network (NN) or MANN accelerators. We present HiMA, a tiled, history-based memory access engine with distributed memories in tiles. HiMA incorporates a multi-mode network-on-chip (NoC) to reduce the communication latency and improve scalability. An optimal submatrix-wise memory partition strategy is applied to reduce the amount of NoC traffic; and a two-stage usage sort method leverages distributed tiles to improve computation speed. To make HiMA fundamentally scalable, we create a distributed version of DNC called DNC-D to allow almost all memory operations to be applied to local memories with trainable weighted summation to produce the global memory output. Two approximation techniques, usage skimming and softmax approximation, are proposed to further enhance hardware efficiency. HiMA prototypes are created in RTL and synthesized in a 40nm technology. By simulations, HiMA running DNC and DNC-D demonstrates 6.47 × and 39.1 × higher speed, 22.8 × and 164.3 × better area efficiency, and 6.1 × and 61.2 × better energy efficiency over the state-of-the-art MANN accelerator. Compared to an Nvidia 3080Ti GPU, HiMA demonstrates speedup by up to 437 × and 2,646 × when running DNC and DNC-D, respectively.",1.0,0.7253498435020447,True,0.3775406687981454,0.5514452561500951,True
"Multifunctional Carbon-Based Hybrid Foams for Shape-Stabilization of Phase Change Materials, Thermal Energy Storage, and Electromagnetic Interference Shielding Functions","Carbon-red mud foam/paraffin hybrid materials were prepared and studied for their thermal energy storage and electromagnetic interference (EMI) shielding properties. The host matrices were prepared utilizing the polymeric foam replication method, with a polyurethane sponge as a template, resin as a carbon source, and red mud as a filler. The paraffins, n-octadecane (OD) and the commercial RT18HC, were used as organic encapsulant phase change materials (PCMs) into the open pore structure of the foams. The foams’ morphological and structural study revealed a highly porous structure (bulk density, apparent porosity P > 65%), which exhibits elliptical and spherical pores, sized from 50 up to 500 μm, and cell walls composed of partially graphitized carbon and various oxide phases. The hybrid foams showed a remarkable encapsulation efficiency as shape stabilizers for paraffins: 48.8% (OD), 37.8% (RT18HC), while their melting enthalpies (ΔHm) were found to be 126.9 J/g and 115.5 J/g, respectively. The investigated hybrids showed efficient electromagnetic shielding performance in frequency range of 3.5–9.0 GHz reaching the entry-level value of ~20 dB required for commercial applications, when filled with PCMs. Their excellent thermal and EMI shielding performance places the as-prepared samples as promising candidates for use in thermal management and EMI shielding of electronic devices as well.",1.0,0.7590141296386719,True,0.3775406687981454,0.5682773992184087,True
"Hey Alexa, is this Skill Safe?: Taking a Closer Look at the Alexa Skill Ecosystem","—Amazon’s voice-based assistant, Alexa, enables users to directly interact with various web services through natural language dialogues. It provides developers with the option to create third-party applications (known as Skills ) to run on top of Alexa. While such applications ease users’ interaction with smart devices and bolster a number of additional services, they also raise security and privacy concerns due to the personal setting they operate in. This paper aims to perform a systematic analysis of the Alexa skill ecosystem. We perform the ﬁrst large-scale analysis of Alexa skills, obtained from seven different skill stores totaling to 90,194 unique skills. Our analysis reveals several limitations that exist in the current skill vetting process. We show that not only can a malicious user publish a skill under any arbitrary developer/company name, but she can also make backend code changes after approval to coax users into revealing unwanted information. We, next, formalize the different skill-squatting techniques and evaluate the efﬁcacy of such techniques. We ﬁnd that while certain approaches are more favorable than others, there is no substantial abuse of skill squatting in the real world. Lastly, we study the prevalence of privacy policies across different categories of skill, and more importantly the policy content of skills that use the Alexa permission model to access sensitive user data. We ﬁnd that around 23.3% of such skills do not fully disclose the data types associated with the permissions requested. We conclude by providing some suggestions for strengthening the overall ecosystem, and thereby enhance transparency for end-users.",1.1,0.757908821105957,True,0.401312339887548,0.5796105804967525,True
POP and PUSH: Demystifying and Defending against (Mach) Port-oriented Programming,"—Apple devices (e.g., iPhone, MacBook, iPad, and Apple Watch) are high value targets for attackers. Although these devices use different operating systems (e.g., iOS, macOS, iPadOS, watchOS, and tvOS), they are all based on a hybrid kernel called XNU. Existing attacks demonstrated that vulnerabilities in XNU could be exploited to escalate privileges and jailbreak devices. To mitigate these threats, multiple security mechanisms have been deployed in latest systems. In this paper, we ﬁrst perform a systematic assessment of deployed mitigations by Apple, and demonstrate that most of them can be bypassed through corrupting a special type of kernel objects, i.e., Mach port objects. We summarize this type of attack as (Mach) Port Object-Oriented Programming (POP). Accordingly, we deﬁne multiple attack primitives to launch the attack and demonstrate realistic scenarios to achieve full memory manipulation on recently released systems (i.e., iOS 13 and macOS 10.15). To defend against POP, we propose the Port Ultra-SHield (PUSH) system to reduce the number of unprotected Mach port objects. Speciﬁcally, PUSH automatically locates potential POP primitives and instruments related system calls to enforce the integrity of Mach port kernel objects. It does not require system modiﬁcations and only introduces 2% runtime overhead. The PUSH framework has been deployed on more than 40,000 macOS devices in a leading company. The evaluation of 18 public exploits and one zero-day exploit detected by our system demonstrated the effectiveness of PUSH. We believe that the proposed framework will facilitate the design and implementation of a more secure XNU kernel.",0.8,0.9304503202438354,True,0.3318122278318339,0.6311312740378346,True
Don't Trust The Locals: Investigating the Prevalence of Persistent Client-Side Cross-Site Scripting in the Wild,"The Web has become highly interactive and an 
important driver for modern life, enabling information retrieval, 
social exchange, and online shopping. From the security perspective, Cross-Site Scripting (XSS) is one of the most nefarious 
attacks against Web clients. Research has long since focused 
on three categories of XSS: Reflected, Persistent, and DOMbased XSS. In this paper, we argue that our community must 
consider at least four important classes of XSS, and present 
the first systematic study of the threat of Persistent Client-Side 
XSS, caused by the insecure use of client-side storage. While 
the existence of this class has been acknowledged, especially by 
the non-academic community like OWASP, prior works have 
either only found such flaws as side effects of other analyses or 
focused on a limited set of applications to analyze. Therefore, the 
community lacks in-depth knowledge about the actual prevalence 
of Persistent Client-Side XSS in the wild. 
To close this research gap, we leverage taint tracking to 
identify suspicious flows from client-side persistent storage (Web 
Storage, cookies) to dangerous sinks (HTML, JavaScript, and 
script.src). We discuss two attacker models capable of 
injecting malicious payloads into storage, i.e., a Network Attacker 
capable of temporarily hijacking HTTP communication (e.g., in 
a public WiFi), and a Web Attacker who can leverage flows into 
storage or an existing reflected XSS flaw to persist their payload. 
With our taint-aware browser and these models in mind, we 
study the prevalence of Persistent Client-Side XSS in the Alexa 
Top 5,000 domains. We find that more than 8% of them have 
unfiltered data flows from persistent storage to a dangerous sink, 
which showcases the developers’ inherent trust in the integrity 
of storage content. Even worse, if we only consider sites that 
make use of data originating from storage, 21% of the sites are 
vulnerable. For those sites with vulnerable flows from storage 
to sink, we find that at least 70% are directly exploitable by 
our attacker models. Finally, investigating the vulnerable flows 
originating from storage allows us to categorize them into four 
disjoint categories and propose appropriate mitigations.",1.0,0.7890148162841797,True,0.3775406687981454,0.5832777425411626,True
Subverting Stateful Firewalls with Protocol States (Extended Version),"We analyzed the generation of protocol header fields in the implementations of multiple TCP/IP network stacks and found new ways to leak information about global protocol states. We then demonstrated new covert channels by remotely observing and modifying the system's global state via these protocol fields. Unlike earlier works, our research focuses on hosts that reside in firewalled networks (including source address validation -- SAV), which is a very common scenario nowadays. Our attacks are designed to be non-disruptive -- in the exfiltration scenario, this makes the attacks stealthier and thus extends their longevity, and in case of host alias resolution and similar techniques -- this ensures the techniques are ethical. We focused on ICMP, which is commonly served by firewalls, and on UDP, which is forecasted to take a more prominent share of the Internet traffic with the advent of HTTP/3 and QUIC, though we report results for TCP as well. The information leakage scenarios we discovered enable the construction of practical covert channels which directly pierce firewalls, or indirectly establish communication via hosts in firewalled networks that also employ SAV. We describe and test three novel attacks in this context: exfiltration via the firewall itself, exfiltration via a DMZ host, and exfiltration via co-resident containers. These are three generic, new use cases for covert channels that work around firewalling and enable devices that are not allowed direct communication with the Internet, to still exfiltrate data out of the network. In other words, we exfiltrate data from isolated networks to the Internet. We also explain how to mount known attacks such as host alias resolution, de-NATting and container co-residence detection, using the new information leakage techniques.",0.8,0.8830792307853699,True,0.3318122278318339,0.6074457293086019,True
Constant Round Maliciously Secure 2PC with Function-independent Preprocessing using LEGO,"Secure two-party computation (S2PC) allows two parties to compute a function on their joint inputs while leaking only the output of the function. At TCC 2009 Orlandi and Nielsen proposed the LEGO protocol for maliciously secure 2PC based on cut-and-choose of Yao’s garbled circuits at the gate level and showed that this is asymptotically more efficient than on the circuit level. Since then the LEGO approach has been improved upon in several theoretical works, but never implemented. In this paper we describe further concrete improvements and provide the first implementation of a protocol from the LEGO family. Our protocol has a constant number of rounds and is optimized for the offline/online setting with function-independent preprocessing. We have benchmarked our prototype and find that our protocol can compete with all existing implementations and that it is often more efficient. As an example, in a LAN setting we can evaluate an AES-128 circuit with online latency down to 1.13ms, while if evaluating 128 AES-128 circuits in parallel the amortized cost is 0.09ms per AES-128. This online performance does not come at the price of offline inefficiency as we achieve comparable performance to previous, less general protocols, and significantly better if we ignore the cost of the function-independent preprocessing. Also, as our protocol has an optimal 2-round online phase it is significantly more efficient than previous protocols when considering a high latency network. Keywords—Secure Two-party Computation, Implementation, LEGO, XOR-Homomorphic Commitments, Selective OT-Attack",1.0,0.8800489902496338,True,0.3775406687981454,0.6287948295238897,True
Please Forget Where I Was Last Summer: The Privacy Risks of Public Location (Meta)Data,"The exposure of location data constitutes a significant privacy risk to users as it can lead to de-anonymization, the inference of sensitive information, and even physical threats. In this paper we present LPAuditor, a tool that conducts a comprehensive evaluation of the privacy loss caused by publicly available location metadata. First, we demonstrate how our system can pinpoint users' key locations at an unprecedented granularity by identifying their actual postal addresses. Our experimental evaluation on Twitter data highlights the effectiveness of our techniques which outperform prior approaches by 18.9%-91.6% for homes and 8.7%-21.8% for workplaces. Next we present a novel exploration of automated private information inference that uncovers ""sensitive"" locations that users have visited (pertaining to health, religion, and sex/nightlife). We find that location metadata can provide additional context to tweets and thus lead to the exposure of private information that might not match the users' intentions. 
We further explore the mismatch between user actions and information exposure and find that older versions of the official Twitter apps follow a privacy-invasive policy of including precise GPS coordinates in the metadata of tweets that users have geotagged at a coarse-grained level (e.g., city). The implications of this exposure are further exacerbated by our finding that users are considerably privacy-cautious in regards to exposing precise location data. When users can explicitly select what location data is published, there is a 94.6% reduction in tweets with GPS coordinates. As part of current efforts to give users more control over their data, LPAuditor can be adopted by major services and offered as an auditing tool that informs users about sensitive information they (indirectly) expose through location metadata.",0.8,0.8062557578086853,True,0.3318122278318339,0.5690339928202596,True
Tales of Favicons and Caches: Persistent Tracking in Modern Browsers,,1.0,0.9673300385475159,True,0.3775406687981454,0.6724353536728307,True
Cross-Origin State Inference (COSI) Attacks: Leaking Web Site States through XS-Leaks,"In a Cross-Origin State Inference (COSI) attack, an attacker convinces a victim into visiting an attack web page, which leverages the cross-origin interaction features of the victim's web browser to infer the victim's state at a target web site. Multiple instances of COSI attacks have been found in the past under different names such as login detection or access detection attacks. But, those attacks only consider two states (e.g., logged in or not) and focus on a specific browser leak method (or XS-Leak). This work shows that mounting more complex COSI attacks such as deanonymizing the owner of an account, determining if the victim owns sensitive content, and determining the victim's account type often requires considering more than two states. Furthermore, robust attacks require supporting a variety of browsers since the victim's browser cannot be predicted apriori. To address these issues, we present a novel approach to identify and build complex COSI attacks that differentiate more than two states and support multiple browsers by combining multiple attack vectors, possibly using different XS-Leaks. To enable our approach, we introduce the concept of a COSI attack class. We propose two novel techniques to generalize existing COSI attack instances into COSI attack classes and to discover new COSI attack classes. We systematically apply our techniques to existing attacks, identifying 40 COSI attack classes. As part of this process, we discover a novel XS-Leak based on window.postMessage. We implement our approach into Basta-COSI, a tool to find COSI attacks in a target web site. We apply Basta-COSI to test four stand-alone web applications and 58 popular web sites, finding COSI attacks against each of them.",0.8,0.8190743923187256,True,0.3318122278318339,0.5754433100752797,True
FBS-Radar: Uncovering Fake Base Stations at Scale in the Wild,"Base stations constitute the basic infrastructure of today’s cellular networks. Unfortunately, vulnerabilities in the GSM (2G) network protocol enable the creation of fake base stations (FBSes) that are not authorized by network operators. Criminal gangs are using FBSes to directly attack users by sending spam and fraud SMS messages, even if the users have access to 3G/4G networks. In this paper, we present the design, deployment, and evolution of an FBS detection system called FBS-Radar, based on crowdsourced data of nearly 100M users. In particular, we evaluate five different metrics for identifying FBSes in the wild, and find that FBSes can be precisely identified without sacrificing user privacy. Additionally, we present a novel method for accurately geolocating FBSes while incurring negligible impact on end-user devices. Our system protects users from millions of spam and fraud SMS messages per day, and has helped the authorities arrest hundreds of FBS operators.",1.0,0.789729654788971,True,0.3775406687981454,0.5836351617935582,True
Zoom on the Keystrokes: Exploiting Video Calls for Keystroke Inference Attacks,"Due to recent world events, video calls have become the new norm for both personal and professional remote communication. However, if a participant in a video call is not careful, he/she can reveal his/her private information to others in the call. In this paper, we design and evaluate an attack framework to infer one type of such private information from the video stream of a call -- keystrokes, i.e., text typed during the call. We evaluate our video-based keystroke inference framework using different experimental settings and parameters, including different webcams, video resolutions, keyboards, clothing, and backgrounds. Our relatively high keystroke inference accuracies under commonly occurring and realistic settings highlight the need for awareness and countermeasures against such attacks. Consequently, we also propose and evaluate effective mitigation techniques that can automatically protect users when they type during a video call.",1.0,0.935005784034729,True,0.3775406687981454,0.6562732264164373,True
Dachshund: Digging for and Securing (Non-)Blinded Constants in JIT Code,"Modern browsers such as Chrome and Edge deploy 
constant blinding to remove attacker-controlled constants from 
the JIT-compiled code. Without such a defense, attackers can 
encode arbitrary shellcode in constants that get compiled to 
executable code. In this paper, we review the security and 
completeness of current constant blinding implementations. We 
develop DACHSHUND, a fuzzing-driven framework to find user-specified constants in JIT-compiled code. 
DACHSHUND reveals several cases in which JIT compilers of modern browsers fail 
to blind constants, ranging from constants passed as function 
parameters to blinded constants that second-stage code optimizers 
revert to a non-protected form. To tackle this problem, we 
then propose a JavaScript rewriting mechanism that removes 
all constants from JavaScript code. We prototype this cross- 
browser methodology as part of a Web proxy and show that 
it can successfully remove all constants from JavaScript code.",0.8,0.9124720096588135,True,0.3318122278318339,0.6221421187453237,True
ProvTalk: Towards Interpretable Multi-level Provenance Analysis in Networking Functions Virtualization (NFV),"—Network functions virtualization (NFV) enables agile deployment of network services on top of clouds. However, as NFV involves multiple levels of abstraction representing the same components, pinpointing the root cause of security incidents can become challenging. For instance, a security incident may be detected at a different level from where its root cause operations were conducted with no obvious link between the two. Moreover, existing provenance analysis techniques may produce results that are impractically large for human analysts to interpret due to the inherent complexity of NFV. In this paper, we propose ProvTalk, a provenance analysis system that handles the unique multi-level nature of NFV and assists the analyst to identify the root cause of security incidents. Specifically, we first define a multi-level provenance model to capture the dependencies between NFV levels. Next, we improve the interpretability through three novel techniques, i.e., multi-level pruning, mining-based aggregation, and rule-based natural language translation. We implement ProvTalk on a Tacker-OpenStack NFV platform and validate its effectiveness based on real-world security incidents. We demonstrate that ProvTalk captures management API calls issued to all NFV services, and produces more interpretable results by significantly reducing the size of the provenance graphs (about 3.6 times reduction via the multi-level pruning scheme and two times reduction via the aggregation scheme). Our user studies show that ProvTalk facilitates the analysis task of real-world users by generating more interpretable results.",1.8,0.8058626651763916,True,0.574442516811659,0.6901525909940254,True
Do Not Give a Dog Bread Every Time He Wags His Tail: Stealing Passwords through Content Queries (CONQUER) Attacks,"—Android accessibility service was designed to assist individuals with disabilities in using Android devices. However, it has been exploited by attackers to steal user passwords due to design shortcomings. Google has implemented various countermeasures to make it difficult for these types of attacks to be successful on modern Android devices. In this paper, we present a new type of side channel attack called content queries (C ONQUER ) that can bypass these defenses. We discovered that Android does not prevent the content of passwords from being queried by the accessibility service, allowing malware with this service enabled to enumerate the combinations of content to brute force the password. While this attack seems simple to execute, there are several challenges that must be addressed in order to successfully launch it against real-world apps. These include the use of lazy query to differentiate targeted password strings, active query to determine the right timing for the attack, and timing-and state-based side channels to infer case-sensitive passwords. Our evaluation results demonstrate that the C ONQUER attack is effective at stealing passwords, with an average one-time success rate of 64.91%. This attack also poses a threat to all Android versions from 4.1 to 12, and can be used against tens of thousands of apps. In addition, we analyzed the root cause of the C ONQUER attack and discussed several countermeasures to mitigate the potential security risks it poses.",0.8,0.8941296339035034,True,0.3318122278318339,0.6129709308676686,True
DefRec: Establishing Physical Function Virtualization to Disrupt Reconnaissance of Power Grids' Cyber-Physical Infrastructures,"—Reconnaissance is critical for adversaries to prepare attacks causing physical damage in industrial control systems (ICS) like smart power grids. Disrupting reconnaissance is challenging. The state-of-the-art moving target defense (MTD) techniques based on mimicking and simulating system behaviors do not consider the physical infrastructure of power grids and can be easily identiﬁed. To overcome these challenges, we propose physical function virtualization (PFV) that “hooks” network interactions with real physical devices and uses these real devices to build lightweight virtual nodes that follow the actual implementation of network stacks, system invariants, and physical state variations in the real devices. On top of PFV, we propose DefRec, a defense mechanism that signiﬁcantly increases the effort required for an adversary to infer the knowledge of power grids’ cyber-physical infrastructures. By randomizing communications and crafting decoy data for virtual nodes, DefRec can mislead adversaries into designing damage-free attacks. We implement PFV and DefRec in the ONOS network operating system and evaluate them in a cyber-physical testbed, using real devices from different vendors and HP physical switches to simulate six power grids. The experimental results show that with negligible overhead, PFV can accurately follow the behavior of real devices. DefRec can delay adversaries’ reconnaissance for more than 100 years by adding a number of virtual nodes less than or equal to 20% of the number of real devices.",1.0,0.8080601692199707,True,0.3775406687981454,0.5928004190090581,True
K-means++ vs. Behavioral Biometrics: One Loop to Rule Them All,"Behavioral biometrics, a field that studies patterns in an individual’s unique behavior, has been researched actively as a means of authentication for decades. Recently, it has even been adopted in many real world scenarios. In this paper, we study keystroke dynamics, the most researched of such behavioral biometrics, from the perspective of an adversary. We designed two adversarial agents with a standard accuracy convenience tradeoff: Targeted K-means++, which is an expensive, but extremely effective adversarial agent, and Indiscriminate K-means++, which is slightly less powerful, but adds no overhead cost to the attacker. With Targeted K-means++ we could compromise the security of 40-70% of users within ten tries. In contrast, with Indiscriminate K-means++, the security of 30-50% of users was compromised. Therefore, we conclude that while keystroke dynamics has potential, it is not ready for security critical applications yet. Future keystroke dynamics research should use such adversaries to benchmark the performance of the detection algorithms, and design better algorithms to foil these. Finally, we show that the K-means++ adversarial agent generalizes well to even other types of behavioral biometrics data by applying it on a dataset of touchscreen swipes.",1.8,0.9224356412887573,True,0.574442516811659,0.7484390790502082,True
Neural Machine Translation Inspired Binary Code Similarity Comparison beyond Function Pairs,"Binary code analysis allows analyzing binary code without having access to the corresponding source code. A binary, after disassembly, is expressed in an assembly language. This inspires us to approach binary analysis by leveraging ideas and techniques from Natural Language Processing (NLP), a rich area focused on processing text of various natural languages. We notice that binary code analysis and NLP share a lot of analogical topics, such as semantics extraction, summarization, and classification. This work utilizes these ideas to address two important code similarity comparison problems. (I) Given a pair of basic blocks for different instruction set architectures (ISAs), determining whether their semantics is similar or not; and (II) given a piece of code of interest, determining if it is contained in another piece of assembly code for a different ISA. The solutions to these two problems have many applications, such as cross-architecture vulnerability discovery and code plagiarism detection. We implement a prototype system INNEREYE and perform a comprehensive evaluation. A comparison between our approach and existing approaches to Problem I shows that our system outperforms them in terms of accuracy, efficiency and scalability. And the case studies utilizing the system demonstrate that our solution to Problem II is effective. Moreover, this research showcases how to apply ideas and techniques from NLP to large-scale binary code analysis.",1.0,0.7363601922988892,True,0.3775406687981454,0.5569504305485173,True
"Nearly Linear-Time, Deterministic Algorithm for Maximizing (Non-Monotone) Submodular Functions Under Cardinality Constraint","A deterministic, nearly linear-time, approximation algorithm FastInterlaceGreedy is developed, for the maximization of non-monotone submodular functions under cardinality constraint. The approximation ratio of $1/4 - \varepsilon$ is an improvement over the next fastest deterministic algorithm for this problem, which requires quadratic time to achieve ratio $1/6 - \varepsilon$. The algorithm FastInterlaceGreedy is a novel interlacing of multiple greedy procedures and is validated in the context of two applications, on which FastInterlaceGreedy outperforms the fastest deterministic and randomized algorithms in prior literature.",1.8,0.6142914891242981,True,0.574442516811659,0.5943670029679786,True
Functional Ensemble Distillation,"Bayesian models have many desirable properties, most notable is their ability to generalize from limited data and to properly estimate the uncertainty in their predictions. However, these benefits come at a steep computational cost as Bayesian inference, in most cases, is computationally intractable. One popular approach to alleviate this problem is using a Monte-Carlo estimation with an ensemble of models sampled from the posterior. However, this approach still comes at a significant computational cost, as one needs to store and run multiple models at test time. In this work, we investigate how to best distill an ensemble's predictions using an efficient model. First, we argue that current approaches that simply return distribution over predictions cannot compute important properties, such as the covariance between predictions, which can be valuable for further processing. Second, in many limited data settings, all ensemble members achieve nearly zero training loss, namely, they produce near-identical predictions on the training set which results in sub-optimal distilled models. To address both problems, we propose a novel and general distillation approach, named Functional Ensemble Distillation (FED), and we investigate how to best distill an ensemble in this setting. We find that learning the distilled model via a simple augmentation scheme in the form of mixup augmentation significantly boosts the performance. We evaluated our method on several tasks and showed that it achieves superior results in both accuracy and uncertainty estimation compared to current approaches.",1.0,0.7742382884025574,True,0.3775406687981454,0.5758894786003514,True
Meta-Learning Reliable Priors in the Function Space,"When data are scarce meta-learning can improve a learner's accuracy by harnessing previous experience from related learning tasks. However, existing methods have unreliable uncertainty estimates which are often overconfident. Addressing these shortcomings, we introduce a novel meta-learning framework, called F-PACOH, that treats meta-learned priors as stochastic processes and performs meta-level regularization directly in the function space. This allows us to directly steer the probabilistic predictions of the meta-learner towards high epistemic uncertainty in regions of insufficient meta-training data and, thus, obtain well-calibrated uncertainty estimates. Finally, we showcase how our approach can be integrated with sequential decision making, where reliable uncertainty quantification is imperative. In our benchmark study on meta-learning for Bayesian Optimization (BO), F-PACOH significantly outperforms all other meta-learners and standard baselines.",1.0,0.7413367033004761,True,0.3775406687981454,0.5594386860493108,True
GumBolt: Extending Gumbel trick to Boltzmann priors,"Boltzmann machines (BMs) are appealing candidates for powerful priors in variational autoencoders (VAEs), as they are capable of capturing nontrivial and multi-modal distributions over discrete variables. However, non-differentiability of the discrete units prohibits using the reparameterization trick, essential for low-noise back propagation. The Gumbel trick resolves this problem in a consistent way by relaxing the variables and distributions, but it is incompatible with BM priors. Here, we propose the GumBolt, a model that extends the Gumbel trick to BM priors in VAEs. GumBolt is significantly simpler than the recently proposed methods with BM prior and outperforms them by a considerable margin. It achieves state-of-the-art performance on permutation invariant MNIST and OMNIGLOT datasets in the scope of models with only discrete latent variables. Moreover, the performance can be further improved by allowing multi-sampled (importance-weighted) estimation of log-likelihood in training, which was not possible with previous models.",1.0,0.9755879044532776,True,0.3775406687981454,0.6765642866257116,True
Matrix Multiplicative Weights Updates in Quantum Zero-Sum Games: Conservation Laws & Recurrence,"Recent advances in quantum computing and in particular, the introduction of quantum GANs, have led to increased interest in quantum zero-sum game theory, extending the scope of learning algorithms for classical games into the quantum realm. In this paper, we focus on learning in quantum zero-sum games under Matrix Multiplicative Weights Update (a generalization of the multiplicative weights update method) and its continuous analogue, Quantum Replicator Dynamics. When each player selects their state according to quantum replicator dynamics, we show that the system exhibits conservation laws in a quantum-information theoretic sense. Moreover, we show that the system exhibits Poincare recurrence, meaning that almost all orbits return arbitrarily close to their initial conditions infinitely often. Our analysis generalizes previous results in the case of classical games.",0.8,0.7961118817329407,True,0.3318122278318339,0.5639620547823873,True
The Surprising Simplicity of the Early-Time Learning Dynamics of Neural Networks,"Modern neural networks are often regarded as complex black-box functions whose behavior is difficult to understand owing to their nonlinear dependence on the data and the nonconvexity in their loss landscapes. In this work, we show that these common perceptions can be completely false in the early phase of learning. In particular, we formally prove that, for a class of well-behaved input distributions, the early-time learning dynamics of a two-layer fully-connected neural network can be mimicked by training a simple linear model on the inputs. We additionally argue that this surprising simplicity can persist in networks with more layers and with convolutional architecture, which we verify empirically. Key to our analysis is to bound the spectral norm of the difference between the Neural Tangent Kernel (NTK) at initialization and an affine transform of the data kernel; however, unlike many previous results utilizing the NTK, we do not require the network to have disproportionately large width, and the network is allowed to escape the kernel regime later in training.",1.0,0.761537492275238,True,0.3775406687981454,0.5695390805366918,True
Exploring through Random Curiosity with General Value Functions,"Efficient exploration in reinforcement learning is a challenging problem commonly addressed through intrinsic rewards. Recent prominent approaches are based on state novelty or variants of artificial curiosity. However, directly applying them to partially observable environments can be ineffective and lead to premature dissipation of intrinsic rewards. Here we propose random curiosity with general value functions (RC-GVF), a novel intrinsic reward function that draws upon connections between these distinct approaches. Instead of using only the current observation's novelty or a curiosity bonus for failing to predict precise environment dynamics, RC-GVF derives intrinsic rewards through predicting temporally extended general value functions. We demonstrate that this improves exploration in a hard-exploration diabolical lock problem. Furthermore, RC-GVF significantly outperforms previous methods in the absence of ground-truth episodic counts in the partially observable MiniGrid environments. Panoramic observations on MiniGrid further boost RC-GVF's performance such that it is competitive to baselines exploiting privileged information in form of episodic counts.",1.0,0.9708883762359619,True,0.3775406687981454,0.6742145225170537,True
Dynamic Regret of Convex and Smooth Functions,"We investigate online convex optimization in non-stationary environments and choose the dynamic regret as the performance measure, defined as the difference between cumulative loss incurred by the online algorithm and that of any feasible comparator sequence. Let $T$ be the time horizon and $P_T$ be the path-length that essentially reflects the non-stationarity of environments, the state-of-the-art dynamic regret is $\mathcal{O}(\sqrt{T(1+P_T)})$. Although this bound is proved to be minimax optimal for convex functions, in this paper, we demonstrate that it is possible to further enhance the dynamic regret by exploiting the smoothness condition. Specifically, we propose novel online algorithms that are capable of leveraging smoothness and replace the dependence on $T$ in the dynamic regret by problem-dependent quantities: the variation in gradients of loss functions, and the cumulative loss of the comparator sequence. These quantities are at most $\mathcal{O}(T)$ while could be much smaller in benign environments. Therefore, our results are adaptive to the intrinsic difficulty of the problem, since the bounds are tighter than existing results for easy problems and meanwhile guarantee the same rate in the worst case.",1.0,0.897050678730011,True,0.3775406687981454,0.6372956737640783,True
Gradient Estimation with Stochastic Softmax Tricks,"The Gumbel-Max trick is the basis of many relaxed gradient estimators. These estimators are easy to implement and low variance, but the goal of scaling them comprehensively to large combinatorial distributions is still outstanding. Working within the perturbation model framework, we introduce stochastic softmax tricks, which generalize the Gumbel-Softmax trick to combinatorial spaces. Our framework is a unified perspective on existing relaxed estimators for perturbation models, and it contains many novel relaxations. We design structured relaxations for subset selection, spanning trees, arborescences, and others. When compared to less structured baselines, we find that stochastic softmax tricks can be used to train latent variable models that perform better and discover more latent structure.",1.0,0.8064698576927185,True,0.3775406687981454,0.592005263245432,True
A framework for Multi-A(rmed)/B(andit) Testing with Online FDR Control,"We propose an alternative framework to existing setups for controlling false alarms when multiple A/B tests are run over time. This setup arises in many practical applications, e.g. when pharmaceutical companies test new treatment options against control pills for different diseases, or when internet companies test their default webpages versus various alternatives over time. Our framework proposes to replace a sequence of A/B tests by a sequence of best-arm MAB instances, which can be continuously monitored by the data scientist. When interleaving the MAB tests with an an online false discovery rate (FDR) algorithm, we can obtain the best of both worlds: low sample complexity and any time online FDR control. Our main contributions are: (i) to propose reasonable definitions of a null hypothesis for MAB instances; (ii) to demonstrate how one can derive an always-valid sequential p-value that allows continuous monitoring of each MAB test; and (iii) to show that using rejection thresholds of online-FDR algorithms as the confidence levels for the MAB algorithms results in both sample-optimality, high power and low FDR at any point in time. We run extensive simulations to verify our claims, and also report results on real data collected from the New Yorker Cartoon Caption contest.",0.8,0.7795770764350891,True,0.3318122278318339,0.5556946521334615,True
"Baby Intuitions Benchmark (BIB): Discerning the goals, preferences, and actions of others","To achieve human-like common sense about everyday life, machine learning systems must understand and reason about the goals, preferences, and actions of other agents in the environment. By the end of their first year of life, human infants intuitively achieve such common sense, and these cognitive achievements lay the foundation for humans' rich and complex understanding of the mental states of others. Can machines achieve generalizable, commonsense reasoning about other agents like human infants? The Baby Intuitions Benchmark (BIB) challenges machines to predict the plausibility of an agent's behavior based on the underlying causes of its actions. Because BIB's content and paradigm are adopted from developmental cognitive science, BIB allows for direct comparison between human and machine performance. Nevertheless, recently proposed, deep-learning-based agency reasoning models fail to show infant-like reasoning, leaving BIB an open challenge.",0.8,0.8567519187927246,True,0.3318122278318339,0.5942820733122792,True
Model Zoos: A Dataset of Diverse Populations of Neural Network Models,"In the last years, neural networks (NN) have evolved from laboratory environments to the state-of-the-art for many real-world problems. It was shown that NN models (i.e., their weights and biases) evolve on unique trajectories in weight space during training. Following, a population of such neural network models (referred to as model zoo) would form structures in weight space. We think that the geometry, curvature and smoothness of these structures contain information about the state of training and can reveal latent properties of individual models. With such model zoos, one could investigate novel approaches for (i) model analysis, (ii) discover unknown learning dynamics, (iii) learn rich representations of such populations, or (iv) exploit the model zoos for generative modelling of NN weights and biases. Unfortunately, the lack of standardized model zoos and available benchmarks significantly increases the friction for further research about populations of NNs. With this work, we publish a novel dataset of model zoos containing systematically generated and diverse populations of NN models for further research. In total the proposed model zoo dataset is based on eight image datasets, consists of 27 model zoos trained with varying hyperparameter combinations and includes 50'360 unique NN models as well as their sparsified twins, resulting in over 3'844'360 collected model states. Additionally, to the model zoo data we provide an in-depth analysis of the zoos and provide benchmarks for multiple downstream tasks. The dataset can be found at www.modelzoos.cc.",1.0,0.7421265244483948,True,0.3775406687981454,0.5598335966232701,True
Look Beneath the Surface: Exploiting Fundamental Symmetry for Sample-Efficient Offline RL,"Offline reinforcement learning (RL) offers an appealing approach to real-world tasks by learning policies from pre-collected datasets without interacting with the environment. However, the performance of existing offline RL algorithms heavily depends on the scale and state-action space coverage of datasets. Real-world data collection is often expensive and uncontrollable, leading to small and narrowly covered datasets and posing significant challenges for practical deployments of offline RL. In this paper, we provide a new insight that leveraging the fundamental symmetry of system dynamics can substantially enhance offline RL performance under small datasets. Specifically, we propose a Time-reversal symmetry (T-symmetry) enforced Dynamics Model (TDM), which establishes consistency between a pair of forward and reverse latent dynamics. TDM provides both well-behaved representations for small datasets and a new reliability measure for OOD samples based on compliance with the T-symmetry. These can be readily used to construct a new offline RL algorithm (TSRL) with less conservative policy constraints and a reliable latent space data augmentation procedure. Based on extensive experiments, we find TSRL achieves great performance on small benchmark datasets with as few as 1% of the original samples, which significantly outperforms the recent offline RL algorithms in terms of data efficiency and generalizability.Code is available at: https://github.com/pcheng2/TSRL",1.0,0.7545384764671326,True,0.3775406687981454,0.566039572632639,True
Dr Jekyll & Mr Hyde: the strange case of off-policy policy updates,,0.8,0.9800275564193726,True,0.3318122278318339,0.6559198921256032,True
Shape Non-rigid Kinematics (SNK): A Zero-Shot Method for Non-Rigid Shape Matching via Unsupervised Functional Map Regularized Reconstruction,"We present Shape Non-rigid Kinematics (SNK), a novel zero-shot method for non-rigid shape matching that eliminates the need for extensive training or ground truth data. SNK operates on a single pair of shapes, and employs a reconstruction-based strategy using an encoder-decoder architecture, which deforms the source shape to closely match the target shape. During the process, an unsupervised functional map is predicted and converted into a point-to-point map, serving as a supervisory mechanism for the reconstruction. To aid in training, we have designed a new decoder architecture that generates smooth, realistic deformations. SNK demonstrates competitive results on traditional benchmarks, simplifying the shape-matching process without compromising accuracy. Our code can be found online: https://github.com/pvnieo/SNK",1.8,0.5519108176231384,False,0.574442516811659,0.5631766672173988,True
"Heavy-tailed Representations, Text Polarity Classification & Data Augmentation","The dominant approaches to text representation in natural language rely on learning embeddings on massive corpora which have convenient properties such as compositionality and distance preservation. In this paper, we develop a novel method to learn a heavy-tailed embedding with desirable regularity properties regarding the distributional tails, which allows to analyze the points far away from the distribution bulk using the framework of multivariate extreme value theory. In particular, a classifier dedicated to the tails of the proposed embedding is obtained which performance outperforms the baseline. This classifier exhibits a scale invariance property which we leverage by introducing a novel text generation method for label preserving dataset augmentation. Numerical experiments on synthetic and real text data demonstrate the relevance of the proposed framework and confirm that this method generates meaningful sentences with controllable attribute, e.g. positive or negative sentiment.",0.8,0.8512514233589172,True,0.3318122278318339,0.5915318255953755,True
Three iterations of (d-1)-WL test distinguish non isometric clouds of d-dimensional points,"The Weisfeiler-Lehman (WL) test is a fundamental iterative algorithm for checking isomorphism of graphs. It has also been observed that it underlies the design of several graph neural network architectures, whose capabilities and performance can be understood in terms of the expressive power of this test. Motivated by recent developments in machine learning applications to datasets involving three-dimensional objects, we study when the WL test is complete for clouds of euclidean points represented by complete distance graphs, i.e., when it can distinguish, up to isometry, any arbitrary such cloud.",0.8,0.7820545434951782,True,0.3318122278318339,0.556933385663506,True
Will Bilevel Optimizers Benefit from Loops,"Bilevel optimization has arisen as a powerful tool for solving a variety of machine learning problems. Two current popular bilevel optimizers AID-BiO and ITD-BiO naturally involve solving one or two sub-problems, and consequently, whether we solve these problems with loops (that take many iterations) or without loops (that take only a few iterations) can significantly affect the overall computational efficiency. Existing studies in the literature cover only some of those implementation choices, and the complexity bounds available are not refined enough to enable rigorous comparison among different implementations. In this paper, we first establish unified convergence analysis for both AID-BiO and ITD-BiO that are applicable to all implementation choices of loops. We then specialize our results to characterize the computational complexity for all implementations, which enable an explicit comparison among them. Our result indicates that for AID-BiO, the loop for estimating the optimal point of the inner function is beneficial for overall efficiency, although it causes higher complexity for each update step, and the loop for approximating the outer-level Hessian-inverse-vector product reduces the gradient complexity. For ITD-BiO, the two loops always coexist, and our convergence upper and lower bounds show that such loops are necessary to guarantee a vanishing convergence error, whereas the no-loop scheme suffers from an unavoidable non-vanishing convergence error. Our numerical experiments further corroborate our theoretical results.",1.0,0.8645790219306946,True,0.3775406687981454,0.62105984536442,True
Agnostic $Q$-learning with Function Approximation in Deterministic Systems: Near-Optimal Bounds on Approximation Error and Sample Complexity,,1.0,0.7990825772285461,True,0.3775406687981454,0.5883116230133458,True
Online learning in MDPs with linear function approximation and bandit feedback,"We consider an online learning problem where the learner interacts with a Markov decision process in a sequence of episodes, where the reward function is allowed to change between episodes in an adversarial manner and the learner only gets to observe the rewards associated with its actions. We allow the state space to be arbitrarily large, but we assume that all action-value functions can be represented as linear functions in terms of a known low-dimensional feature map, and that the learner has access to a simulator of the environment that allows generating trajectories from the true MDP dynamics. Our main contribution is developing a computationally efficient algorithm that we call MDP-LinExp3, and prove that its regret is bounded by $\widetilde{\mathcal{O}}\big(H^2 T^{2/3} (dK)^{1/3}\big)$, where $T$ is the number of episodes, $H$ is the number of steps in each episode, $K$ is the number of actions, and $d$ is the dimension of the feature map. We also show that the regret can be improved to $\widetilde{\mathcal{O}}\big(H^2 \sqrt{TdK}\big)$ under much stronger assumptions on the MDP dynamics. To our knowledge, MDP-LinExp3 is the first provably efficient algorithm for this problem setting.",1.0,0.8953511118888855,True,0.3775406687981454,0.6364458903435155,True
The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games,"Proximal Policy Optimization (PPO) is a ubiquitous on-policy reinforcement learning algorithm but is significantly less utilized than off-policy learning algorithms in multi-agent settings. This is often due to the belief that PPO is significantly less sample efficient than off-policy methods in multi-agent systems. In this work, we carefully study the performance of PPO in cooperative multi-agent settings. We show that PPO-based multi-agent algorithms achieve surprisingly strong performance in four popular multi-agent testbeds: the particle-world environments, the StarCraft multi-agent challenge, Google Research Football, and the Hanabi challenge, with minimal hyperparameter tuning and without any domain-specific algorithmic modifications or architectures. Importantly, compared to competitive off-policy methods, PPO often achieves competitive or superior results in both final returns and sample efficiency. Finally, through ablation studies, we analyze implementation and hyperparameter factors that are critical to PPO's empirical performance, and give concrete practical suggestions regarding these factors. Our results show that when using these practices, simple PPO-based methods can be a strong baseline in cooperative multi-agent reinforcement learning. Source code is released at \url{https://github.com/marlbenchmark/on-policy}.",1.0,0.87284255027771,True,0.3775406687981454,0.6251916095379277,True
DISCO: Adversarial Defense with Local Implicit Functions,"The problem of adversarial defenses for image classification, where the goal is to robustify a classifier against adversarial examples, is considered. Inspired by the hypothesis that these examples lie beyond the natural image manifold, a novel aDversarIal defenSe with local impliCit functiOns (DISCO) is proposed to remove adversarial perturbations by localized manifold projections. DISCO consumes an adversarial image and a query pixel location and outputs a clean RGB value at the location. It is implemented with an encoder and a local implicit module, where the former produces per-pixel deep features and the latter uses the features in the neighborhood of query pixel for predicting the clean RGB value. Extensive experiments demonstrate that both DISCO and its cascade version outperform prior defenses, regardless of whether the defense is known to the attacker. DISCO is also shown to be data and parameter efficient and to mount defenses that transfers across datasets, classifiers and attacks.",1.0,0.8313568830490112,True,0.3775406687981454,0.6044487759235784,True
Beyond the Best: Distribution Functional Estimation in Infinite-Armed Bandits,"In the infinite-armed bandit problem, each arm’s average reward is sampled from an unknown distribution, and each arm can be sampled further to obtain noisy estimates of the average reward of that arm. Prior work focuses on the best arm, i.e., estimating the maximum of the average reward distribution. We consider a general class of distribution functionals beyond the maximum and obtain optimal sample complexities in both the offline and online settings. We show that online estimation, where the learner can sequentially choose whether to sample a new or existing arm, offers no advantage over the offline setting for estimating the mean functional, but significantly reduces the sample complexity for other functionals such as the median, maximum, and trimmed mean. We propose unified meta algorithms for the online and offline settings and derive matching lower bounds using different Wasserstein distances. For the special case of median estimation, we identify a curious thresholding phenomenon on the indistinguishability between Gaussian convolutions with respect to the noise level, which may be of independent interest.",1.0,0.8262414336204529,True,0.3775406687981454,0.6018910512092992,True
Learning compositional functions via multiplicative weight updates,"Compositionality is a basic structural feature of both biological and artificial neural networks. Learning compositional functions via gradient descent incurs well known problems like vanishing and exploding gradients, making careful learning rate tuning essential for real-world applications. This paper proves that multiplicative weight updates satisfy a descent lemma tailored to compositional functions. Based on this lemma, we derive Madam---a multiplicative version of the Adam optimiser---and show that it can train state of the art neural network architectures without learning rate tuning. We further show that Madam is easily adapted to train natively compressed neural networks by representing their weights in a logarithmic number system. We conclude by drawing connections between multiplicative weight updates and recent findings about synapses in biology.",1.0,0.8106184601783752,True,0.3775406687981454,0.5940795644882604,True
Fully Dynamic k-Clustering in Õ(k) Update Time,,0.8,0.8427326679229736,True,0.3318122278318339,0.5872724478774037,True
Leveraging Recursive Gumbel-Max Trick for Approximate Inference in Combinatorial Spaces,"Structured latent variables allow incorporating meaningful prior knowledge into deep learning models. However, learning with such variables remains challenging because of their discrete nature. Nowadays, the standard learning approach is to define a latent variable as a perturbed algorithm output and to use a differentiable surrogate for training. In general, the surrogate puts additional constraints on the model and inevitably leads to biased gradients. To alleviate these shortcomings, we extend the Gumbel-Max trick to define distributions over structured domains. We avoid the differentiable surrogates by leveraging the score function estimators for optimization. In particular, we highlight a family of recursive algorithms with a common feature we call stochastic invariant. The feature allows us to construct reliable gradient estimates and control variates without additional constraints on the model. In our experiments, we consider various structured latent variable models and achieve results competitive with relaxation-based counterparts.",1.0,0.7463864088058472,True,0.3775406687981454,0.5619635388019963,True
How do Minimum-Norm Shallow Denoisers Look in Function Space?,"Neural network (NN) denoisers are an essential building block in many common tasks, ranging from image reconstruction to image generation. However, the success of these models is not well understood from a theoretical perspective. In this paper, we aim to characterize the functions realized by shallow ReLU NN denoisers -- in the common theoretical setting of interpolation (i.e., zero training loss) with a minimal representation cost (i.e., minimal $\ell^2$ norm weights). First, for univariate data, we derive a closed form for the NN denoiser function, find it is contractive toward the clean data points, and prove it generalizes better than the empirical MMSE estimator at a low noise level. Next, for multivariate data, we find the NN denoiser functions in a closed form under various geometric assumptions on the training data: data contained in a low-dimensional subspace, data contained in a union of one-sided rays, or several types of simplexes. These functions decompose into a sum of simple rank-one piecewise linear interpolations aligned with edges and/or faces connecting training samples. We empirically verify this alignment phenomenon on synthetic data and real images.",1.3,0.8018832802772522,True,0.45016600268752216,0.6260246414823871,True
"Recipe for a General, Powerful, Scalable Graph Transformer","We propose a recipe on how to build a general, powerful, scalable (GPS) graph Transformer with linear complexity and state-of-the-art results on a diverse set of benchmarks. Graph Transformers (GTs) have gained popularity in the field of graph representation learning with a variety of recent publications but they lack a common foundation about what constitutes a good positional or structural encoding, and what differentiates them. In this paper, we summarize the different types of encodings with a clearer definition and categorize them as being $\textit{local}$, $\textit{global}$ or $\textit{relative}$. The prior GTs are constrained to small graphs with a few hundred nodes, here we propose the first architecture with a complexity linear in the number of nodes and edges $O(N+E)$ by decoupling the local real-edge aggregation from the fully-connected Transformer. We argue that this decoupling does not negatively affect the expressivity, with our architecture being a universal function approximator on graphs. Our GPS recipe consists of choosing 3 main ingredients: (i) positional/structural encoding, (ii) local message-passing mechanism, and (iii) global attention mechanism. We provide a modular framework $\textit{GraphGPS}$ that supports multiple types of encodings and that provides efficiency and scalability both in small and large graphs. We test our architecture on 16 benchmarks and show highly competitive results in all of them, show-casing the empirical benefits gained by the modularity and the combination of different strategies.",1.0,0.8195387125015259,True,0.3775406687981454,0.5985396906498357,True
Online (Multinomial) Logistic Bandit: Improved Regret and Constant Computation Cost,,0.8,0.9404177069664001,True,0.3318122278318339,0.636114967399117,True
"(Provable) Adversarial Robustness for Group Equivariant Tasks: Graphs, Point Clouds, Molecules, and More","A machine learning model is traditionally considered robust if its prediction remains (almost) constant under input perturbations with small norm. However, real-world tasks like molecular property prediction or point cloud segmentation have inherent equivariances, such as rotation or permutation equivariance. In such tasks, even perturbations with large norm do not necessarily change an input's semantic content. Furthermore, there are perturbations for which a model's prediction explicitly needs to change. For the first time, we propose a sound notion of adversarial robustness that accounts for task equivariance. We then demonstrate that provable robustness can be achieved by (1) choosing a model that matches the task's equivariances (2) certifying traditional adversarial robustness. Certification methods are, however, unavailable for many models, such as those with continuous equivariances. We close this gap by developing the framework of equivariance-preserving randomized smoothing, which enables architecture-agnostic certification. We additionally derive the first architecture-specific graph edit distance certificates, i.e. sound robustness guarantees for isomorphism equivariant tasks like node classification. Overall, a sound notion of robustness is an important prerequisite for future work at the intersection of robust and geometric machine learning.",0.8,0.8887571096420288,True,0.3318122278318339,0.6102846687369313,True
"Not too little, not too much: a theoretical analysis of graph (over)smoothing","We analyze graph smoothing with \emph{mean aggregation}, where each node successively receives the average of the features of its neighbors. Indeed, it has quickly been observed that Graph Neural Networks (GNNs), which generally follow some variant of Message-Passing (MP) with repeated aggregation, may be subject to the oversmoothing phenomenon: by performing too many rounds of MP, the node features tend to converge to a non-informative limit. In the case of mean aggregation, for connected graphs, the node features become constant across the whole graph. At the other end of the spectrum, it is intuitively obvious that some MP rounds are necessary, but existing analyses do not exhibit both phenomena at once: beneficial ``finite'' smoothing and oversmoothing in the limit. In this paper, we consider simplified linear GNNs, and rigorously analyze two examples for which a finite number of mean aggregation steps provably improves the learning performance, before oversmoothing kicks in. We consider a latent space random graph model, where node features are partial observations of the latent variables and the graph contains pairwise relationships between them. We show that graph smoothing restores some of the lost information, up to a certain point, by two phenomenon: graph smoothing shrinks non-principal directions in the data faster than principal ones, which is useful for regression, and shrinks nodes within communities faster than they collapse together, which improves classification.",0.8,0.944943904876709,True,0.3318122278318339,0.6383780663542714,True
A Guide Through the Zoo of Biased SGD,"Stochastic Gradient Descent (SGD) is arguably the most important single algorithm in modern machine learning. Although SGD with unbiased gradient estimators has been studied extensively over at least half a century, SGD variants relying on biased estimators are rare. Nevertheless, there has been an increased interest in this topic in recent years. However, existing literature on SGD with biased estimators (BiasedSGD) lacks coherence since each new paper relies on a different set of assumptions, without any clear understanding of how they are connected, which may lead to confusion. We address this gap by establishing connections among the existing assumptions, and presenting a comprehensive map of the underlying relationships. Additionally, we introduce a new set of assumptions that is provably weaker than all previous assumptions, and use it to present a thorough analysis of BiasedSGD in both convex and non-convex settings, offering advantages over previous results. We also provide examples where biased estimators outperform their unbiased counterparts or where unbiased versions are simply not available. Finally, we demonstrate the effectiveness of our framework through experimental results that validate our theoretical findings.",1.0,0.8276593685150146,True,0.3775406687981454,0.6026000186565801,True
Reconstruct & Crush Network,"This article introduces an energy-based model that is adversarial regarding data: it minimizes the energy for a given data distribution (the positive samples) while maximizing the energy for another given data distribution (the negative or unlabeled samples). The model is especially instantiated with autoencoders where the energy, represented by the reconstruction error, provides a general distance measure for unknown data. The resulting neural network thus learns to reconstruct data from the first distribution while crushing data from the second distribution. This solution can handle different problems such as Positive and Unlabeled (PU) learning or covariate shift, especially with imbalanced data. Using autoencoders allows handling a large variety of data, such as images, text or even dialogues. Our experiments show the flexibility of the proposed approach in dealing with different types of data in different settings: images with CIFAR-10 and CIFAR-100 (not-in-training setting), text with Amazon reviews (PU learning) and dialogues with Facebook bAbI (next response classification and dialogue completion).",0.8,0.8677740097045898,True,0.3318122278318339,0.5997931187682118,True
Morié Attack (MA): A New Potential Risk of Screen Photos,,0.8,0.9602962732315063,True,0.3318122278318339,0.6460542505316701,True
Learning Positive Functions with Pseudo Mirror Descent,"The nonparametric learning of positive-valued functions appears widely in machine learning, especially in the context of estimating intensity functions of point processes. Yet, existing approaches either require computing expensive projections or semidefinite relaxations, or lack convexity and theoretical guarantees after introducing nonlinear link functions. In this paper, we propose a novel algorithm, pseudo mirror descent, that performs efficient estimation of positive functions within a Hilbert space without expensive projections. The algorithm guarantees positivity by performing mirror descent with an appropriately selected Bregman divergence, and a pseudo-gradient is adopted to speed up the gradient evaluation procedure in practice. We analyze both asymptotic and nonasymptotic convergence of the algorithm. Through simulations, we show that pseudo mirror descent outperforms the state-of-the-art benchmarks for learning intensities of Poisson and multivariate Hawkes processes, in terms of both computational efficiency and accuracy.",1.0,0.8862377405166626,True,0.3775406687981454,0.6318892046574041,True
Responsible AI (RAI) Games and Ensembles,"Several recent works have studied the societal effects of AI; these include issues such as fairness, robustness, and safety. In many of these objectives, a learner seeks to minimize its worst-case loss over a set of predefined distributions (known as uncertainty sets), with usual examples being perturbed versions of the empirical distribution. In other words, aforementioned problems can be written as min-max problems over these uncertainty sets. In this work, we provide a general framework for studying these problems, which we refer to as Responsible AI (RAI) games. We provide two classes of algorithms for solving these games: (a) game-play based algorithms, and (b) greedy stagewise estimation algorithms. The former class is motivated by online learning and game theory, whereas the latter class is motivated by the classical statistical literature on boosting, and regression. We empirically demonstrate the applicability and competitive performance of our techniques for solving several RAI problems, particularly around subpopulation shift.",0.8,0.8947499990463257,True,0.3318122278318339,0.6132811134390798,True
One Risk to Rule Them All: A Risk-Sensitive Perspective on Model-Based Offline Reinforcement Learning,"Offline reinforcement learning (RL) is suitable for safety-critical domains where online exploration is too costly or dangerous. In such safety-critical settings, decision-making should take into consideration the risk of catastrophic outcomes. In other words, decision-making should be risk-sensitive. Previous works on risk in offline RL combine together offline RL techniques, to avoid distributional shift, with risk-sensitive RL algorithms, to achieve risk-sensitivity. In this work, we propose risk-sensitivity as a mechanism to jointly address both of these issues. Our model-based approach is risk-averse to both epistemic and aleatoric uncertainty. Risk-aversion to epistemic uncertainty prevents distributional shift, as areas not covered by the dataset have high epistemic uncertainty. Risk-aversion to aleatoric uncertainty discourages actions that may result in poor outcomes due to environment stochasticity. Our experiments show that our algorithm achieves competitive performance on deterministic benchmarks, and outperforms existing approaches for risk-sensitive objectives in stochastic domains.",1.8,0.6399505734443665,True,0.574442516811659,0.6071965451280128,True
"ConfLab: A Data Collection Concept, Dataset, and Benchmark for Machine Analysis of Free-Standing Social Interactions in the Wild","Recording the dynamics of unscripted human interactions in the wild is challenging due to the delicate trade-offs between several factors: participant privacy, ecological validity, data fidelity, and logistical overheads. To address these, following a 'datasets for the community by the community' ethos, we propose the Conference Living Lab (ConfLab): a new concept for multimodal multisensor data collection of in-the-wild free-standing social conversations. For the first instantiation of ConfLab described here, we organized a real-life professional networking event at a major international conference. Involving 48 conference attendees, the dataset captures a diverse mix of status, acquaintance, and networking motivations. Our capture setup improves upon the data fidelity of prior in-the-wild datasets while retaining privacy sensitivity: 8 videos (1920x1080, 60 fps) from a non-invasive overhead view, and custom wearable sensors with onboard recording of body motion (full 9-axis IMU), privacy-preserving low-frequency audio (1250 Hz), and Bluetooth-based proximity. Additionally, we developed custom solutions for distributed hardware synchronization at acquisition and time-efficient continuous annotation of body keypoints and actions at high sampling rates. Our benchmarks showcase some of the open research tasks related to in-the-wild privacy-preserving social data analysis: keypoints detection from overhead camera views, skeleton-based no-audio speaker detection, and F-formation detection.",1.0,0.850162148475647,True,0.3775406687981454,0.6138514086368962,True
Influence Maximization with $\varepsilon$-Almost Submodular Threshold Functions,"Influence maximization is the problem of selecting $k$ nodes in a social network to maximize their influence spread. The problem has been extensively studied but most works focus on the submodular influence diffusion models. In this paper, motivated by empirical evidences, we explore influence maximization in the non-submodular regime. In particular, we study the general threshold model in which a fraction of nodes have non-submodular threshold functions, but their threshold functions are closely upper- and lower-bounded by some submodular functions (we call them $\varepsilon$-almost submodular). We first show a strong hardness result: there is no $1/n^{\gamma/c}$ approximation for influence maximization (unless P = NP) for all networks with up to $n^{\gamma}$ $\varepsilon$-almost submodular nodes, where $\gamma$ is in (0,1) and $c$ is a parameter depending on $\varepsilon$. This indicates that influence maximization is still hard to approximate even though threshold functions are close to submodular. We then provide $(1-\varepsilon)^{\ell}(1-1/e)$ approximation algorithms when the number of $\varepsilon$-almost submodular nodes is $\ell$. Finally, we conduct experiments on a number of real-world datasets, and the results demonstrate that our approximation algorithms outperform other baseline algorithms.",1.0,0.7429698705673218,True,0.3775406687981454,0.5602552696827336,True
Tame a Wild Camera: In-the-Wild Monocular Camera Calibration,"3D sensing for monocular in-the-wild images, e.g., depth estimation and 3D object detection, has become increasingly important. However, the unknown intrinsic parameter hinders their development and deployment. Previous methods for the monocular camera calibration rely on specific 3D objects or strong geometry prior, such as using a checkerboard or imposing a Manhattan World assumption. This work solves the problem from the other perspective by exploiting the monocular 3D prior. Our method is assumption-free and calibrates the complete $4$ Degree-of-Freedom (DoF) intrinsic parameters. First, we demonstrate intrinsic is solved from two well-studied monocular priors, i.e., monocular depthmap, and surface normal map. However, this solution imposes a low-bias and low-variance requirement for depth estimation. Alternatively, we introduce a novel monocular 3D prior, the incidence field, defined as the incidence rays between points in 3D space and pixels in the 2D imaging plane. The incidence field is a pixel-wise parametrization of the intrinsic invariant to image cropping and resizing. With the estimated incidence field, a robust RANSAC algorithm recovers intrinsic. We demonstrate the effectiveness of our method by showing superior performance on synthetic and zero-shot testing datasets. Beyond calibration, we demonstrate downstream applications in image manipulation detection&restoration, uncalibrated two-view pose estimation, and 3D sensing. Codes, models, and data will be held in https://github.com/ShngJZ/WildCamera.",1.0,0.8968156576156616,True,0.3775406687981454,0.6371781632069036,True
Should We Learn Most Likely Functions or Parameters?,"Standard regularized training procedures correspond to maximizing a posterior distribution over parameters, known as maximum a posteriori (MAP) estimation. However, model parameters are of interest only insomuch as they combine with the functional form of a model to provide a function that can make good predictions. Moreover, the most likely parameters under the parameter posterior do not generally correspond to the most likely function induced by the parameter posterior. In fact, we can re-parametrize a model such that any setting of parameters can maximize the parameter posterior. As an alternative, we investigate the benefits and drawbacks of directly estimating the most likely function implied by the model and the data. We show that this procedure leads to pathological solutions when using neural networks and prove conditions under which the procedure is well-behaved, as well as a scalable approximation. Under these conditions, we find that function-space MAP estimation can lead to flatter minima, better generalization, and improved robustness to overfitting.",1.3,0.6997752785682678,True,0.45016600268752216,0.5749706406278949,True
Streaming Kernel PCA with \tilde{O}(\sqrt{n}) Random Features,,0.8,0.8390735387802124,True,0.3318122278318339,0.5854428833060231,True
Katakomba: Tools and Benchmarks for Data-Driven NetHack,"NetHack is known as the frontier of reinforcement learning research where learning-based methods still need to catch up to rule-based solutions. One of the promising directions for a breakthrough is using pre-collected datasets similar to recent developments in robotics, recommender systems, and more under the umbrella of offline reinforcement learning (ORL). Recently, a large-scale NetHack dataset was released; while it was a necessary step forward, it has yet to gain wide adoption in the ORL community. In this work, we argue that there are three major obstacles for adoption: resource-wise, implementation-wise, and benchmark-wise. To address them, we develop an open-source library that provides workflow fundamentals familiar to the ORL community: pre-defined D4RL-style tasks, uncluttered baseline implementations, and reliable evaluation tools with accompanying configs and logs synced to the cloud.",1.0,0.8430863618850708,True,0.3775406687981454,0.6103135153416082,True
$O(n)$ Connections are Expressive Enough: Universal Approximability of Sparse Transformers,"Transformer networks use pairwise attention to compute contextual embeddings of inputs, and have redefined the state of the art in many NLP tasks. However, these models suffer from quadratic computational cost in the input sequence length $n$ to compute attention in each layer. This has prompted recent research into faster attention models, with a predominant approach involving sparsifying the connections in the attention layers. While empirically promising for long sequences, fundamental questions remain unanswered: Can sparse transformers approximate any arbitrary sequence-to-sequence function, similar to their dense counterparts? How does the sparsity pattern and the sparsity level affect their performance? In this paper, we address these questions and provide a unifying framework that captures existing sparse attention models. Our analysis proposes sufficient conditions under which we prove that a sparse attention model can universally approximate any sequence-to-sequence function. Surprisingly, our results show the existence of models with only $O(n)$ connections per attention layer that can approximate the same function class as the dense model with $n^2$ connections. Lastly, we present experiments comparing different patterns/levels of sparsity on standard NLP tasks.",0.8,0.8445398211479187,True,0.3318122278318339,0.5881760244898763,True
Detecting Hands and Recognizing Physical Contact in the Wild,"We investigate a new problem of detecting hands and recognizing their physical contact state in unconstrained conditions. This is a challenging inference task given the need to reason beyond the local appearance of hands. The lack of training annotations indicating which object or parts of an object the hand is in contact with further complicates the task. We propose a novel convolutional network based on Mask-RCNN that can jointly learn to localize hands and predict their physical contact to address this problem. The network uses outputs from another object detector to obtain locations of objects present in the scene. It uses these outputs and hand locations to recognize the hand's contact state using two attention mechanisms. The first attention mechanism is based on the hand and a region's affinity, enclosing the hand and the object, and densely pools features from this region to the hand region. The second attention module adaptively selects salient features from this plausible region of contact. To develop and evaluate our method's performance, we introduce a large-scale dataset called ContactHands, containing unconstrained images annotated with hand locations and contact states. The proposed network, including the parameters of attention modules, is end-to-end trainable. This network achieves approximately 7\% relative improvement over a baseline network that was built on the vanilla Mask-RCNN architecture and trained for recognizing hand contact states.",1.0,0.7390158176422119,True,0.3775406687981454,0.5582782432201787,True
Provably Adversarially Robust Detection of Out-of-Distribution Data (Almost) for Free,"The application of machine learning in safety-critical systems requires a reliable assessment of uncertainty. However, deep neural networks are known to produce highly overconfident predictions on out-of-distribution (OOD) data. Even if trained to be non-confident on OOD data, one can still adversarially manipulate OOD data so that the classifier again assigns high confidence to the manipulated samples. We show that two previously published defenses can be broken by better adapted attacks, highlighting the importance of robustness guarantees around OOD data. Since the existing method for this task is hard to train and significantly limits accuracy, we construct a classifier that can simultaneously achieve provably adversarially robust OOD detection and high clean accuracy. Moreover, by slightly modifying the classifier's architecture our method provably avoids the asymptotic overconfidence problem of standard neural networks. We provide code for all our experiments.",0.8,0.8337805867195129,True,0.3318122278318339,0.5827964072756734,True
When Adversarial Training Meets Vision Transformers: Recipes from Training to Architecture,"Vision Transformers (ViTs) have recently achieved competitive performance in broad vision tasks. Unfortunately, on popular threat models, naturally trained ViTs are shown to provide no more adversarial robustness than convolutional neural networks (CNNs). Adversarial training is still required for ViTs to defend against such adversarial attacks. In this paper, we provide the first and comprehensive study on the adversarial training recipe of ViTs via extensive evaluation of various training techniques across benchmark datasets. We find that pre-training and SGD optimizer are necessary for ViTs' adversarial training. Further considering ViT as a new type of model architecture, we investigate its adversarial robustness from the perspective of its unique architectural components. We find, when randomly masking gradients from some attention blocks or masking perturbations on some patches during adversarial training, the adversarial robustness of ViTs can be remarkably improved, which may potentially open up a line of work to explore the architectural information inside the newly designed models like ViTs. Our code is available at https://github.com/mo666666/When-Adversarial-Training-Meets-Vision-Transformers.",1.0,0.9706767201423645,True,0.3775406687981454,0.674108694470255,True
LambdaBeam: Neural Program Search with Higher-Order Functions and Lambdas,"Search is an important technique in program synthesis that allows for adaptive strategies such as focusing on particular search directions based on execution results. Several prior works have demonstrated that neural models are effective at guiding program synthesis searches. However, a common drawback of those approaches is the inability to handle iterative loops, higher-order functions, or lambda functions, thus limiting prior neural searches from synthesizing longer and more general programs. We address this gap by designing a search algorithm called LambdaBeam that can construct arbitrary lambda functions that compose operations within a given DSL. We create semantic vector representations of the execution behavior of the lambda functions and train a neural policy network to choose which lambdas to construct during search, and pass them as arguments to higher-order functions to perform looping computations. Our experiments show that LambdaBeam outperforms neural, symbolic, and LLM-based techniques in an integer list manipulation domain.",1.0,0.8028526306152344,True,0.3775406687981454,0.59019664970669,True
Dynamic Importance Sampling for Anytime Bounds of the Partition Function,"Computing the partition function is a key inference task in many graphical models. In this paper, we propose a dynamic importance sampling scheme that provides anytime finite-sample bounds for the partition function. Our algorithm balances the advantages of the three major inference strategies, heuristic search, variational bounds, and Monte Carlo methods, blending sampling with search to refine a variationally defined proposal. Our algorithm combines and generalizes recent work on anytime search and probabilistic bounds of the partition function. By using an intelligently chosen weighted average over the samples, we construct an unbiased estimator of the partition function with strong finite-sample confidence intervals that inherit both the rapid early improvement rate of sampling and the long-term benefits of an improved proposal from search. This gives significantly improved anytime behavior, and more flexible trade-offs between memory, time, and solution quality. We demonstrate the effectiveness of our approach empirically on real-world problem instances taken from recent UAI competitions.",1.0,0.8035105466842651,True,0.3775406687981454,0.5905256077412053,True
Experiment Planning with Function Approximation,,1.0,0.8382909893989563,True,0.3775406687981454,0.6079158290985509,True
Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing,"With the success of language pretraining, it is highly desirable to develop more efficient architectures of good scalability that can exploit the abundant unlabeled data at a lower cost. To improve the efficiency, we examine the much-overlooked redundancy in maintaining a full-length token-level presentation, especially for tasks that only require a single-vector presentation of the sequence. With this intuition, we propose Funnel-Transformer which gradually compresses the sequence of hidden states to a shorter one and hence reduces the computation cost. More importantly, by re-investing the saved FLOPs from length reduction in constructing a deeper or wider model, we further improve the model capacity. In addition, to perform token-level predictions as required by common pretraining objectives, Funnel-Transformer is able to recover a deep representation for each token from the reduced hidden sequence via a decoder. Empirically, with comparable or fewer FLOPs, Funnel-Transformer outperforms the standard Transformer on a wide variety of sequence-level prediction tasks, including text classification, language understanding, and reading comprehension. The code and pretrained checkpoints are available at this https URL.",1.0,0.8877869844436646,True,0.3775406687981454,0.632663826620905,True
Finite-Time Analysis of Whittle Index based Q-Learning for Restless Multi-Armed Bandits with Neural Network Function Approximation,"Whittle index policy is a heuristic to the intractable restless multi-armed bandits (RMAB) problem. Although it is provably asymptotically optimal, finding Whittle indices remains difficult. In this paper, we present Neural-Q-Whittle, a Whittle index based Q-learning algorithm for RMAB with neural network function approximation, which is an example of nonlinear two-timescale stochastic approximation with Q-function values updated on a faster timescale and Whittle indices on a slower timescale. Despite the empirical success of deep Q-learning, the non-asymptotic convergence rate of Neural-Q-Whittle, which couples neural networks with two-timescale Q-learning largely remains unclear. This paper provides a finite-time analysis of Neural-Q-Whittle, where data are generated from a Markov chain, and Q-function is approximated by a ReLU neural network. Our analysis leverages a Lyapunov drift approach to capture the evolution of two coupled parameters, and the nonlinearity in value function approximation further requires us to characterize the approximation error. Combing these provide Neural-Q-Whittle with $\mathcal{O}(1/k^{2/3})$ convergence rate, where $k$ is the number of iterations.",1.0,0.7901843190193176,True,0.3775406687981454,0.5838624939087316,True
Neural Unsigned Distance Fields for Implicit Function Learning,"In this work we target a learnable output representation that allows continuous, high resolution outputs of arbitrary shape. Recent works represent 3D surfaces implicitly with a Neural Network, thereby breaking previous barriers in resolution, and ability to represent diverse topologies. However, neural implicit representations are limited to closed surfaces, which divide the space into inside and outside. Many real world objects such as walls of a scene scanned by a sensor, clothing, or a car with inner structures are not closed. This constitutes a significant barrier, in terms of data pre-processing (objects need to be artificially closed creating artifacts), and the ability to output open surfaces. In this work, we propose Neural Distance Fields (NDF), a neural network based model which predicts the unsigned distance field for arbitrary 3D shapes given sparse point clouds. NDF represent surfaces at high resolutions as prior implicit models, but do not require closed surface data, and significantly broaden the class of representable shapes in the output. NDF allow to extract the surface as very dense point clouds and as meshes. We also show that NDF allow for surface normal calculation and can be rendered using a slight modification of sphere tracing. We find NDF can be used for multi-target regression (multiple outputs for one input) with techniques that have been exclusively used for rendering in graphics. Experiments on ShapeNet show that NDF, while simple, is the state-of-the art, and allows to reconstruct shapes with inner structures, such as the chairs inside a bus. Notably, we show that NDF are not restricted to 3D shapes, and can approximate more general open surfaces such as curves, manifolds, and functions. Code is available for research at this https URL.",1.0,0.7431278228759766,True,0.3775406687981454,0.560334245837061,True
Teacher Forcing Recovers Reward Functions for Text Generation,"Reinforcement learning (RL) has been widely used in text generation to alleviate the exposure bias issue or to utilize non-parallel datasets. The reward function plays an important role in making RL training successful. However, previous reward functions are typically task-specific and sparse, restricting the use of RL. In our work, we propose a task-agnostic approach that derives a step-wise reward function directly from a model trained with teacher forcing. We additionally propose a simple modification to stabilize the RL training on non-parallel datasets with our induced reward function. Empirical results show that our method outperforms self-training and reward regression methods on several text generation tasks, confirming the effectiveness of our reward function.",1.0,0.7804054021835327,True,0.3775406687981454,0.5789730354908391,True
Partially Encrypted Machine Learning using Functional Encryption,"Machine learning on encrypted data has received a lot of attention thanks to recent breakthroughs in homomorphic encryption and secure multi-party computation. It allows outsourcing computation to untrusted servers without sacrificing privacy of sensitive data. We propose a practical framework to perform partially encrypted and privacy-preserving predictions which combines adversarial training and functional encryption. We first present a new functional encryption scheme to efficiently compute quadratic functions so that the data owner controls what can be computed but is not involved in the calculation: it provides a decryption key which allows one to learn a specific function evaluation of some encrypted data. We then show how to use it in machine learning to partially encrypt neural networks with quadratic activation functions at evaluation time, and we provide a thorough analysis of the information leaks based on indistinguishability of data items of the same label. Last, since most encryption schemes cannot deal with the last thresholding operation used for classification, we propose a training method to prevent selected sensitive features from leaking, which adversarially optimizes the network against an adversary trying to identify these features. This is interesting for several existing works using partially encrypted machine learning as it comes with little reduction on the model's accuracy and significantly improves data privacy.",1.0,0.7518285512924194,True,0.3775406687981454,0.5646846100452825,True
Rewriting History with Inverse RL: Hindsight Inference for Policy Improvement,"Multi-task reinforcement learning (RL) aims to simultaneously learn policies for solving many tasks. Several prior works have found that relabeling past experience with different reward functions can improve sample efficiency. Relabeling methods typically ask: if, in hindsight, we assume that our experience was optimal for some task, for what task was it optimal? In this paper, we show that hindsight relabeling is inverse RL, an observation that suggests that we can use inverse RL in tandem for RL algorithms to efficiently solve many tasks. We use this idea to generalize goal-relabeling techniques from prior work to arbitrary classes of tasks. Our experiments confirm that relabeling data using inverse RL accelerates learning in general multi-task settings, including goal-reaching, domains with discrete sets of rewards, and those with linear reward functions.",1.0,0.7746724486351013,True,0.3775406687981454,0.5761065587166234,True
How degenerate is the parametrization of neural networks with the ReLU activation function?,"Neural network training is usually accomplished by solving a non-convex optimization problem using stochastic gradient descent. Although one optimizes over the networks parameters, the main loss function generally only depends on the realization of the neural network, i.e. the function it computes. Studying the optimization problem over the space of realizations opens up new ways to understand neural network training. In particular, usual loss functions like mean squared error and categorical cross entropy are convex on spaces of neural network realizations, which themselves are non-convex. Approximation capabilities of neural networks can be used to deal with the latter non-convexity, which allows us to establish that for sufficiently large networks local minima of a regularized optimization problem on the realization space are almost optimal. Note, however, that each realization has many different, possibly degenerate, parametrizations. In particular, a local minimum in the parametrization space needs not correspond to a local minimum in the realization space. To establish such a connection, inverse stability of the realization map is required, meaning that proximity of realizations must imply proximity of corresponding parametrizations. We present pathologies which prevent inverse stability in general, and, for shallow networks, proceed to establish a restricted space of parametrizations on which we have inverse stability w.r.t. to a Sobolev norm. Furthermore, we show that by optimizing over such restricted sets, it is still possible to learn any function which can be learned by optimization over unrestricted sets.",1.3,0.8895554542541504,True,0.45016600268752216,0.6698607284708362,True
Learning on Random Balls is Sufficient for Estimating (Some) Graph Parameters,"Theoretical analyses for graph learning methods often assume a complete observation of the input graph. Such an assumption might not be useful for handling any-size graphs due to the scalability issues in practice. In this work, we develop a theoretical framework for graph classification problems in the partial observation setting (i.e., subgraph samplings). Equipped with insights from graph limit theory, we propose a new graph classification model that works on a randomly sampled subgraph and a novel topology to characterize the representability of the model. Our theoretical framework contributes a theoretical validation of mini-batch learning on graphs and leads to new learning-theoretic results on generalization bounds as well as size-generalizability without assumptions on the input.",0.8,0.8532475233078003,True,0.3318122278318339,0.5925298755698171,True
Word2Fun: Modelling Words as Functions for Diachronic Word Representation,"Word meaning may change over time as a reﬂection of changes in human society. Therefore, modeling time in word representation is necessary for some diachronic tasks. Most existing diachronic word representation approaches train the embeddings separately for each pre-grouped time-stamped corpus and align these embeddings, e.g., by orthogonal projections, vector initialization, temporal referencing, and compass. However, not only does word meaning change in a short time, word meaning may also be subject to evolution over long timespans, thus resulting in a uniﬁed continuous process. A recent approach called ‘Diff-Time’ models semantic evolution as functions parameterized by multiple-layer nonlinear neural networks over time. In this paper, we will carry on this line of work by learning explicit functions over time for each word. Our approach, called ‘Word2Fun’, reduces the space complexity from O ( TV D ) to O ( kV D ) where k is a small constant ( k (cid:28) T ). In particular, a speciﬁc instance based on polynomial functions could provably approximate any function modeling word evolution with a given negligible error thanks to the Weierstrass Approximation Theorem. The effectiveness of the proposed approach is evaluated in diverse tasks including time-aware word clustering, temporal analogy, and semantic change detection. Code at: https://github.com/wabyking/Word2Fun.git .",1.0,0.9869166612625122,True,0.3775406687981454,0.6822286650303289,True
MBW: Multi-view Bootstrapping in the Wild,"Labeling articulated objects in unconstrained settings have a wide variety of applications including entertainment, neuroscience, psychology, ethology, and many fields of medicine. Large offline labeled datasets do not exist for all but the most common articulated object categories (e.g., humans). Hand labeling these landmarks within a video sequence is a laborious task. Learned landmark detectors can help, but can be error-prone when trained from only a few examples. Multi-camera systems that train fine-grained detectors have shown significant promise in detecting such errors, allowing for self-supervised solutions that only need a small percentage of the video sequence to be hand-labeled. The approach, however, is based on calibrated cameras and rigid geometry, making it expensive, difficult to manage, and impractical in real-world scenarios. In this paper, we address these bottlenecks by combining a non-rigid 3D neural prior with deep flow to obtain high-fidelity landmark estimates from videos with only two or three uncalibrated, handheld cameras. With just a few annotations (representing 1-2% of the frames), we are able to produce 2D results comparable to state-of-the-art fully supervised methods, along with 3D reconstructions that are impossible with other existing approaches. Our Multi-view Bootstrapping in the Wild (MBW) approach demonstrates impressive results on standard human datasets, as well as tigers, cheetahs, fish, colobus monkeys, chimpanzees, and flamingos from videos captured casually in a zoo. We release the codebase for MBW as well as this challenging zoo dataset consisting image frames of tail-end distribution categories with their corresponding 2D, 3D labels generated from minimal human intervention.",1.0,0.9024302363395691,True,0.3775406687981454,0.6399854525688573,True
Mitigating Over-smoothing in Transformers via Regularized Nonlocal Functionals,"Transformers have achieved remarkable success in a wide range of natural language processing and computer vision applications. However, the representation capacity of a deep transformer model is degraded due to the over-smoothing issue in which the token representations become identical when the model's depth grows. In this work, we show that self-attention layers in transformers minimize a functional which promotes smoothness, thereby causing token uniformity. We then propose a novel regularizer that penalizes the norm of the difference between the smooth output tokens from self-attention and the input tokens to preserve the fidelity of the tokens. Minimizing the resulting regularized energy functional, we derive the Neural Transformer with a Regularized Nonlocal Functional (NeuTRENO), a novel class of transformer models that can mitigate the over-smoothing issue. We empirically demonstrate the advantages of NeuTRENO over the baseline transformers and state-of-the-art methods in reducing the over-smoothing of token representations on various practical tasks, including object classification, image segmentation, and language modeling.",1.0,0.8144656419754028,True,0.3775406687981454,0.5960031553867742,True
Active Negative Loss Functions for Learning with Noisy Labels,,1.0,0.950258731842041,True,0.3775406687981454,0.6638997003200933,True
"Revisiting (ε, γ, τ)-similarity learning for domain adaptation","Similarity learning is an active research area in machine learning that tackles the problem of finding a similarity function tailored to an observable data sample in order to achieve efficient classification. This learning scenario has been generally formalized by the means of a (, γ, τ)−good similarity learning framework in the context of supervised classification and has been shown to have important theoretical guarantees. In this paper , we propose to extend the theoretical analysis of similarity learning to the domain adaptation setting, a particular situation occurring when the similarity is learned and then deployed on samples following different probability distributions. We give a new definition of an (, γ)−good similarity for domain adaptation and prove several results quantifying the performance of a similarity function on a target domain after it has been trained on a source domain. We particularly show that if the source domain support contains that of the target then a notable improvement of the adaptation is achievable.",0.8,0.7813136577606201,True,0.3318122278318339,0.556562942796227,True
SE(3)-Transformers: 3D Roto-Translation Equivariant Attention Networks,"We introduce the SE(3)-Transformer, a variant of the self-attention module for 3D point clouds, which is equivariant under continuous 3D roto-translations. Equivariance is important to ensure stable and predictable performance in the presence of nuisance transformations of the data input. A positive corollary of equivariance is increased weight-tying within the model, leading to fewer trainable parameters and thus decreased sample complexity (i.e. we need less training data). The SE(3)-Transformer leverages the benefits of self-attention to operate on large point clouds with varying number of points, while guaranteeing SE(3)-equivariance for robustness. We evaluate our model on a toy $N$-body particle simulation dataset, showcasing the robustness of the predictions under rotations of the input. We further achieve competitive performance on two real-world datasets, ScanObjectNN and QM9. In all cases, our model outperforms a strong, non-equivariant attention baseline and an equivariant model without attention.",0.8,0.7871015071868896,True,0.3318122278318339,0.5594568675093617,True
Reinforcement Learning with General Value Function Approximation: Provably Efficient Approach via Bounded Eluder Dimension,"Value function approximation has demonstrated phenomenal empirical success in reinforcement learning (RL). Nevertheless, despite a handful of recent progress on developing theory for RL with linear function approximation, the understanding of general function approximation schemes largely remains missing. In this paper, we establish a provably efficient RL algorithm with general value function approximation. We show that if the value functions admit an approximation with a function class $\mathcal{F}$, our algorithm achieves a regret bound of $\widetilde{O}(\mathrm{poly}(dH)\sqrt{T})$ where $d$ is a complexity measure of $\mathcal{F}$ that depends on the eluder dimension [Russo and Van Roy, 2013] and log-covering numbers, $H$ is the planning horizon, and $T$ is the number interactions with the environment. Our theory generalizes recent progress on RL with linear value function approximation and does not make explicit assumptions on the model of the environment. Moreover, our algorithm is model-free and provides a framework to justify the effectiveness of algorithms used in practice.",1.0,0.7364635467529297,True,0.3775406687981454,0.5570021077755376,True
ZooD: Exploiting Model Zoo for Out-of-Distribution Generalization,"Recent advances on large-scale pre-training have shown great potentials of leveraging a large set of Pre-Trained Models (PTMs) for improving Out-of-Distribution (OoD) generalization, for which the goal is to perform well on possible unseen domains after fine-tuning on multiple training domains. However, maximally exploiting a zoo of PTMs is challenging since fine-tuning all possible combinations of PTMs is computationally prohibitive while accurate selection of PTMs requires tackling the possible data distribution shift for OoD tasks. In this work, we propose ZooD, a paradigm for PTMs ranking and ensemble with feature selection. Our proposed metric ranks PTMs by quantifying inter-class discriminability and inter-domain stability of the features extracted by the PTMs in a leave-one-domain-out cross-validation manner. The top-K ranked models are then aggregated for the target OoD task. To avoid accumulating noise induced by model ensemble, we propose an efficient variational EM algorithm to select informative features. We evaluate our paradigm on a diverse model zoo consisting of 35 models for various OoD tasks and demonstrate: (i) model ranking is better correlated with fine-tuning ranking than previous methods and up to 9859x faster than brute-force fine-tuning; (ii) OoD generalization after model ensemble with feature selection outperforms the state-of-the-art methods and the accuracy on most challenging task DomainNet is improved from 46.5\% to 50.6\%. Furthermore, we provide the fine-tuning results of 35 PTMs on 7 OoD datasets, hoping to help the research of model zoo and OoD generalization. Code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/zood.",1.0,0.7669737339019775,True,0.3775406687981454,0.5722572013500615,True
Learning New Tricks From Old Dogs: Multi-Source Transfer Learning From Pre-Trained Networks,"The advent of deep learning algorithms for mobile devices and sensors has led to a dramatic expansion in the availability and number of systems trained on a wide range of machine learning tasks, creating a host of opportunities and challenges in the realm of transfer learning. Currently, most transfer learning methods require some kind of control over the systems learned, either by enforcing constraints during the source training, or through the use of a joint optimization objective between tasks that requires all data be co-located for training. However, for practical, privacy, or other reasons, in a variety of applications we may have no control over the individual source task training, nor access to source training samples. Instead we only have access to features pre-trained on such data as the output of ""black-boxes.'' For such scenarios, we consider the multi-source learning problem of training a classifier using an ensemble of pre-trained neural networks for a set of classes that have not been observed by any of the source networks, and for which we have very few training samples. We show that by using these distributed networks as feature extractors, we can train an effective classifier in a computationally-efficient manner using tools from (nonlinear) maximal correlation analysis. In particular, we develop a method we refer to as maximal correlation weighting (MCW) to build the required target classifier from an appropriate weighting of the feature functions from the source networks. We illustrate the effectiveness of the resulting classifier on datasets derived from the CIFAR-100, Stanford Dogs, and Tiny ImageNet datasets, and, in addition, use the methodology to characterize the relative value of different source tasks in learning a target task.",1.0,0.8562377691268921,True,0.3775406687981454,0.6168892189625188,True
Most Activation Functions Can Win the Lottery Without Excessive Depth,"The strong lottery ticket hypothesis has highlighted the potential for training deep neural networks by pruning, which has inspired interesting practical and theoretical insights into how neural networks can represent functions. For networks with ReLU activation functions, it has been proven that a target network with depth $L$ can be approximated by the subnetwork of a randomly initialized neural network that has double the target's depth $2L$ and is wider by a logarithmic factor. We show that a depth $L+1$ network is sufficient. This result indicates that we can expect to find lottery tickets at realistic, commonly used depths while only requiring logarithmic overparametrization. Our novel construction approach applies to a large class of activation functions and is not limited to ReLUs.",1.0,0.9577013254165649,True,0.3775406687981454,0.6676209971073552,True
Optimistic Regret Minimization for Extensive-Form Games via Dilated Distance-Generating Functions,"We study the performance of optimistic regret-minimization algorithms for both minimizing regret in, and computing Nash equilibria of, zero-sum extensive-form games. In order to apply these algorithms to extensive-form games, a distance-generating function is needed. We study the use of the dilated entropy and dilated Euclidean distance functions. For the dilated Euclidean distance function we prove the first explicit bounds on the strong-convexity parameter for general treeplexes. Furthermore, we show that the use of dilated distance-generating functions enable us to decompose the mirror descent algorithm, and its optimistic variant, into local mirror descent algorithms at each information set. This decomposition mirrors the structure of the counterfactual regret minimization framework, and enables important techniques in practice, such as distributed updates and pruning of cold parts of the game tree. Our algorithms provably converge at a rate of $T^{-1}$, which is superior to prior counterfactual regret minimization algorithms. We experimentally compare to the popular algorithm CFR+, which has a theoretical convergence rate of $T^{-0.5}$ in theory, but is known to often converge at a rate of $T^{-1}$, or better, in practice. We give an example matrix game where CFR+ experimentally converges at a relatively slow rate of $T^{-0.74}$, whereas our optimistic methods converge faster than $T^{-1}$. We go on to show that our fast rate also holds in the Kuhn poker game, which is an extensive-form game. For games with deeper game trees however, we find that CFR+ is still faster. Finally we show that when the goal is minimizing regret, rather than computing a Nash equilibrium, our optimistic methods can outperform CFR+, even in deep game trees.",1.0,0.768547773361206,True,0.3775406687981454,0.5730442210796758,True
Scaling MLPs: A Tale of Inductive Bias,"In this work we revisit the most fundamental building block in deep learning, the multi-layer perceptron (MLP), and study the limits of its performance on vision tasks. Empirical insights into MLPs are important for multiple reasons. (1) Given the recent narrative""less inductive bias is better"", popularized due to transformers eclipsing convolutional models, it is natural to explore the limits of this hypothesis. To that end, MLPs offer an ideal test bed, as they lack any vision-specific inductive bias. (2) MLPs have almost exclusively been the main protagonist in the deep learning theory literature due to their mathematical simplicity, serving as a proxy to explain empirical phenomena observed for more complex architectures. Surprisingly, experimental datapoints for MLPs are very difficult to find in the literature, especially when coupled with large pre-training protocols. This discrepancy between practice and theory is worrying: Do MLPs reflect the empirical advances exhibited by practical models? Or do theorists need to rethink the role of MLPs as a proxy? We provide insights into both these aspects. We show that the performance of MLPs drastically improves with scale (95% on CIFAR10, 82% on CIFAR100, 58% on ImageNet ReaL), highlighting that lack of inductive bias can indeed be compensated. We observe that MLPs mimic the behaviour of their modern counterparts faithfully, with some components in the learning setting however exhibiting stronger or unexpected behaviours. Due to their inherent computational efficiency, large pre-training experiments become more accessible for academic researchers. All of our experiments were run on a single GPU.",0.8,0.8752779364585876,True,0.3318122278318339,0.6035450821452107,True
Wild-Time: A Benchmark of in-the-Wild Distribution Shift over Time,"Distribution shift occurs when the test distribution differs from the training distribution, and it can considerably degrade performance of machine learning models deployed in the real world. Temporal shifts -- distribution shifts arising from the passage of time -- often occur gradually and have the additional structure of timestamp metadata. By leveraging timestamp metadata, models can potentially learn from trends in past distribution shifts and extrapolate into the future. While recent works have studied distribution shifts, temporal shifts remain underexplored. To address this gap, we curate Wild-Time, a benchmark of 5 datasets that reflect temporal distribution shifts arising in a variety of real-world applications, including patient prognosis and news classification. On these datasets, we systematically benchmark 13 prior approaches, including methods in domain generalization, continual learning, self-supervised learning, and ensemble learning. We use two evaluation strategies: evaluation with a fixed time split (Eval-Fix) and evaluation with a data stream (Eval-Stream). Eval-Fix, our primary evaluation strategy, aims to provide a simple evaluation protocol, while Eval-Stream is more realistic for certain real-world applications. Under both evaluation strategies, we observe an average performance drop of 20% from in-distribution to out-of-distribution data. Existing methods are unable to close this gap. Code is available at https://wild-time.github.io/.",1.0,0.8480769395828247,True,0.3775406687981454,0.6128088041904851,True
Why Do Better Loss Functions Lead to Less Transferable Features?,"Previous work has proposed many new loss functions and regularizers that improve test accuracy on image classification tasks. However, it is not clear whether these loss functions learn better representations for downstream tasks. This paper studies how the choice of training objective affects the transferability of the hidden representations of convolutional neural networks trained on ImageNet. We show that many objectives lead to statistically significant improvements in ImageNet accuracy over vanilla softmax cross-entropy, but the resulting fixed feature extractors transfer substantially worse to downstream tasks, and the choice of loss has little effect when networks are fully fine-tuned on the new tasks. Using centered kernel alignment to measure similarity between hidden representations of networks, we find that differences among loss functions are apparent only in the last few layers of the network. We delve deeper into representations of the penultimate layer, finding that different objectives and hyperparameter combinations lead to dramatically different levels of class separation. Representations with higher class separation obtain higher accuracy on the original task, but their features are less useful for downstream tasks. Our results suggest there exists a trade-off between learning invariant features for the original task and features relevant for transfer tasks.",1.3,0.7434777617454529,True,0.45016600268752216,0.5968218822164875,True
Branch & Learn for Recursively and Iteratively Solvable Problems in Predict+Optimize,"This paper proposes Branch&Learn, a framework for Predict+Optimize to tackle optimization problems containing parameters that are unknown at the time of solving. Given an optimization problem solvable by a recursive algorithm satisfying simple conditions, we show how a corresponding learning algorithm can be constructed directly and methodically from the recursive algorithm. Our framework applies also to iterative algorithms by viewing them as a degenerate form of recursion. Extensive experimentation shows better performance for our proposal over classical and state-of-the-art approaches.",0.8,0.7826448678970337,True,0.3318122278318339,0.5572285478644338,True
Wibergian Learning of Continuous Energy Functions,,1.0,0.7351661920547485,True,0.3775406687981454,0.556353430426447,True
Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function Approximation: Minimax Optimal and Instance-Dependent Regret Bounds,"While numerous works have focused on devising efficient algorithms for reinforcement learning (RL) with uniformly bounded rewards, it remains an open question whether sample or time-efficient algorithms for RL with large state-action space exist when the rewards are \emph{heavy-tailed}, i.e., with only finite $(1+\epsilon)$-th moments for some $\epsilon\in(0,1]$. In this work, we address the challenge of such rewards in RL with linear function approximation. We first design an algorithm, \textsc{Heavy-OFUL}, for heavy-tailed linear bandits, achieving an \emph{instance-dependent} $T$-round regret of $\tilde{O}\big(d T^{\frac{1-\epsilon}{2(1+\epsilon)}} \sqrt{\sum_{t=1}^T \nu_t^2} + d T^{\frac{1-\epsilon}{2(1+\epsilon)}}\big)$, the \emph{first} of this kind. Here, $d$ is the feature dimension, and $\nu_t^{1+\epsilon}$ is the $(1+\epsilon)$-th central moment of the reward at the $t$-th round. We further show the above bound is minimax optimal when applied to the worst-case instances in stochastic and deterministic linear bandits. We then extend this algorithm to the RL settings with linear function approximation. Our algorithm, termed as \textsc{Heavy-LSVI-UCB}, achieves the \emph{first} computationally efficient \emph{instance-dependent} $K$-episode regret of $\tilde{O}(d \sqrt{H \mathcal{U}^*} K^\frac{1}{1+\epsilon} + d \sqrt{H \mathcal{V}^* K})$. Here, $H$ is length of the episode, and $\mathcal{U}^*, \mathcal{V}^*$ are instance-dependent quantities scaling with the central moment of reward and value functions, respectively. We also provide a matching minimax lower bound $\Omega(d H K^{\frac{1}{1+\epsilon}} + d \sqrt{H^3 K})$ to demonstrate the optimality of our algorithm in the worst case. Our result is achieved via a novel robust self-normalized concentration inequality that may be of independent interest in handling heavy-tailed noise in general online regression problems.",1.0,0.7342888712882996,True,0.3775406687981454,0.5559147700432225,True
Reciprocal Adversarial Learning via Characteristic Functions,"Generative adversarial nets (GANs) have become a preferred tool for accommodating complicated distributions, and to stabilise the training and reduce the mode collapse of GANs, one of their main variants employs the integral probability metric (IPM) as the loss function. Although theoretically supported, extensive IPM-GANs are basically comparing moments in an embedded domain of the \textit{critic}. We generalise this by comparing the distributions rather than the moments via a powerful tool, i.e., the characteristic function (CF), which uniquely and universally contains all the information about a distribution. For rigour, we first establish the physical meaning of the phase and amplitude in CFs. This provides a feasible way of manipulating the generation. We then develop an efficient sampling way to calculate the CFs. Within this framework, we further prove an equivalence between the embedded and data domains when a reciprocal exists, which allows us to develop the GAN in an auto-encoder way, by using only two modules to achieve bi-directionally generating clear images. We refer to this efficient structure as the reciprocal CF GAN (RCF-GAN). Experimental results show the superior performances of the proposed RCF-GAN in terms of both generation and reconstruction.",1.0,0.9048070907592773,True,0.3775406687981454,0.6411738797787114,True
Exploiting a Zoo of Checkpoints for Unseen Tasks,"There are so many models in the literature that it is difficult for practitioners to decide which combinations are likely to be effective for a new task. This paper attempts to address this question by capturing relationships among checkpoints published on the web. We model the space of tasks as a Gaussian process. The covariance can be estimated from checkpoints and unlabeled probing data. With the Gaussian process, we can identify representative checkpoints by a maximum mutual information criterion. This objective is submodular. A greedy method identifies representatives that are likely to""cover""the task space. These representatives generalize to new tasks with superior performance. Empirical evidence is provided for applications from both computational linguistics as well as computer vision.",1.0,0.9844129085540771,True,0.3775406687981454,0.6809767886761113,True
One Ring to Rule Them All: Certifiably Robust Geometric Perception with Outliers,"We propose a general and practical framework to design certifiable algorithms for robust geometric perception in the presence of a large amount of outliers. We investigate the use of a truncated least squares (TLS) cost function, which is known to be robust to outliers, but leads to hard, nonconvex, and nonsmooth optimization problems. Our first contribution is to show that -for a broad class of geometric perception problems- TLS estimation can be reformulated as an optimization over the ring of polynomials and Lasserre's hierarchy of convex moment relaxations is empirically tight at the minimum relaxation order (i.e., certifiably obtains the global minimum of the nonconvex TLS problem). Our second contribution is to exploit the structural sparsity of the objective and constraint polynomials and leverage basis reduction to significantly reduce the size of the semidefinite program (SDP) resulting from the moment relaxation, without compromising its tightness. Our third contribution is to develop scalable dual optimality certifiers from the lens of sums-of-squares (SOS) relaxation, that can compute the suboptimality gap and possibly certify global optimality of any candidate solution (e.g., returned by fast heuristics such as RANSAC or graduated non-convexity). Our dual certifiers leverage Douglas-Rachford Splitting to solve a convex feasibility SDP. Numerical experiments across different perception problems, including high-integrity satellite pose estimation, demonstrate the tightness of our relaxations, the correctness of the certification, and the scalability of the proposed dual certifiers to large problems, beyond the reach of current SDP solvers.",1.8,0.7076523303985596,True,0.574442516811659,0.6410474236051094,True
Data-Efficient GAN Training Beyond (Just) Augmentations: A Lottery Ticket Perspective,"Training generative adversarial networks (GANs) with limited real image data generally results in deteriorated performance and collapsed models. To conquer this challenge, we are inspired by the latest observation, that one can discover independently trainable and highly sparse subnetworks (a.k.a., lottery tickets) from GANs. Treating this as an inductive prior, we suggest a brand-new angle towards data-efficient GAN training: by first identifying the lottery ticket from the original GAN using the small training set of real images; and then focusing on training that sparse subnetwork by re-using the same set. We find our coordinated framework to offer orthogonal gains to existing real image data augmentation methods, and we additionally present a new feature-level augmentation that can be applied together with them. Comprehensive experiments endorse the effectiveness of our proposed framework, across various GAN architectures (SNGAN, BigGAN, and StyleGAN-V2) and diverse datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet, ImageNet, and multiple few-shot generation datasets). Codes are available at: https://github.com/VITA-Group/Ultra-Data-Efficient-GAN-Training.",0.8,0.9478592276573181,True,0.3318122278318339,0.639835727744576,True
An Image is Worth More Than a Thousand Words: Towards Disentanglement in the Wild,"Unsupervised disentanglement has been shown to be theoretically impossible without inductive biases on the models and the data. As an alternative approach, recent methods rely on limited supervision to disentangle the factors of variation and allow their identifiability. While annotating the true generative factors is only required for a limited number of observations, we argue that it is infeasible to enumerate all the factors of variation that describe a real-world image distribution. To this end, we propose a method for disentangling a set of factors which are only partially labeled, as well as separating the complementary set of residual factors that are never explicitly specified. Our success in this challenging setting, demonstrated on synthetic benchmarks, gives rise to leveraging off-the-shelf image descriptors to partially annotate a subset of attributes in real image domains (e.g. of human faces) with minimal manual effort. Specifically, we use a recent language-image embedding model (CLIP) to annotate a set of attributes of interest in a zero-shot manner and demonstrate state-of-the-art disentangled image manipulation results.",1.0,0.7340010404586792,True,0.3775406687981454,0.5557708546284124,True
2021 BEETL Competition: Advancing Transfer Learning for Subject Independence & Heterogenous EEG Data Sets,"Transfer learning and meta-learning offer some of the most promising avenues to unlock the scalability of healthcare and consumer technologies driven by biosignal data. This is because current methods cannot generalise well across human subjects' data and handle learning from different heterogeneously collected data sets, thus limiting the scale of training data. On the other side, developments in transfer learning would benefit significantly from a real-world benchmark with immediate practical application. Therefore, we pick electroencephalography (EEG) as an exemplar for what makes biosignal machine learning hard. We design two transfer learning challenges around diagnostics and Brain-Computer-Interfacing (BCI), that have to be solved in the face of low signal-to-noise ratios, major variability among subjects, differences in the data recording sessions and techniques, and even between the specific BCI tasks recorded in the dataset. Task 1 is centred on the field of medical diagnostics, addressing automatic sleep stage annotation across subjects. Task 2 is centred on Brain-Computer Interfacing (BCI), addressing motor imagery decoding across both subjects and data sets. The BEETL competition with its over 30 competing teams and its 3 winning entries brought attention to the potential of deep transfer learning and combinations of set theory and conventional machine learning techniques to overcome the challenges. The results set a new state-of-the-art for the real-world BEETL benchmark.",0.8,0.8361157178878784,True,0.3318122278318339,0.5839639728598561,True
Fully Parameterized Quantile Function for Distributional Reinforcement Learning,"Distributional Reinforcement Learning (RL) differs from traditional RL in that, rather than the expectation of total returns, it estimates distributions and has achieved state-of-the-art performance on Atari Games. The key challenge in practical distributional RL algorithms lies in how to parameterize estimated distributions so as to better approximate the true continuous distribution. Existing distributional RL algorithms parameterize either the probability side or the return value side of the distribution function, leaving the other side uniformly fixed as in C51, QR-DQN or randomly sampled as in IQN. In this paper, we propose fully parameterized quantile function that parameterizes both the quantile fraction axis (i.e., the x-axis) and the value axis (i.e., y-axis) for distributional RL. Our algorithm contains a fraction proposal network that generates a discrete set of quantile fractions and a quantile value network that gives corresponding quantile values. The two networks are jointly trained to find the best approximation of the true distribution. Experiments on 55 Atari Games show that our algorithm significantly outperforms existing distributional RL algorithms and creates a new record for the Atari Learning Environment for non-distributed agents.",1.0,0.7233926653862,True,0.3775406687981454,0.5504666670921727,True
Understanding Deep Neural Function Approximation in Reinforcement Learning via ε-Greedy Exploration,"This paper provides a theoretical study of deep neural function approximation in reinforcement learning (RL) with the $\epsilon$-greedy exploration under the online setting. This problem setting is motivated by the successful deep Q-networks (DQN) framework that falls in this regime. In this work, we provide an initial attempt on theoretical understanding deep RL from the perspective of function class and neural networks architectures (e.g., width and depth) beyond the ``linear'' regime. To be specific, we focus on the value based algorithm with the $\epsilon$-greedy exploration via deep (and two-layer) neural networks endowed by Besov (and Barron) function spaces, respectively, which aims at approximating an $\alpha$-smooth Q-function in a $d$-dimensional feature space. We prove that, with $T$ episodes, scaling the width $m = \widetilde{\mathcal{O}}(T^{\frac{d}{2\alpha + d}})$ and the depth $L=\mathcal{O}(\log T)$ of the neural network for deep RL is sufficient for learning with sublinear regret in Besov spaces. Moreover, for a two layer neural network endowed by the Barron space, scaling the width $\Omega(\sqrt{T})$ is sufficient. To achieve this, the key issue in our analysis is how to estimate the temporal difference error under deep neural function approximation as the $\epsilon$-greedy exploration is not enough to ensure ``optimism''. Our analysis reformulates the temporal difference error in an $L^2(\mathrm{d}\mu)$-integrable space over a certain averaged measure $\mu$, and transforms it to a generalization problem under the non-iid setting. This might have its own interest in RL theory for better understanding $\epsilon$-greedy exploration in deep RL.",1.0,0.7737446427345276,True,0.3775406687981454,0.5756426557663366,True
Diversify & Conquer: Outcome-directed Curriculum RL via Out-of-Distribution Disagreement,"Reinforcement learning (RL) often faces the challenges of uninformed search problems where the agent should explore without access to the domain knowledge such as characteristics of the environment or external rewards. To tackle these challenges, this work proposes a new approach for curriculum RL called Diversify for Disagreement&Conquer (D2C). Unlike previous curriculum learning methods, D2C requires only a few examples of desired outcomes and works in any environment, regardless of its geometry or the distribution of the desired outcome examples. The proposed method performs diversification of the goal-conditional classifiers to identify similarities between visited and desired outcome states and ensures that the classifiers disagree on states from out-of-distribution, which enables quantifying the unexplored region and designing an arbitrary goal-conditioned intrinsic reward signal in a simple and intuitive way. The proposed method then employs bipartite matching to define a curriculum learning objective that produces a sequence of well-adjusted intermediate goals, which enable the agent to automatically explore and conquer the unexplored region. We present experimental results demonstrating that D2C outperforms prior curriculum RL methods in both quantitative and qualitative aspects, even with the arbitrarily distributed desired outcome examples.",0.8,0.894500732421875,True,0.3318122278318339,0.6131564801268544,True
RecursiveMix: Mixed Learning with History,"Mix-based augmentation has been proven fundamental to the generalization of deep vision models. However, current augmentations only mix samples at the current data batch during training, which ignores the possible knowledge accumulated in the learning history. In this paper, we propose a recursive mixed-sample learning paradigm, termed""RecursiveMix""(RM), by exploring a novel training strategy that leverages the historical input-prediction-label triplets. More specifically, we iteratively resize the input image batch from the previous iteration and paste it into the current batch while their labels are fused proportionally to the area of the operated patches. Further, a consistency loss is introduced to align the identical image semantics across the iterations, which helps the learning of scale-invariant feature representations. Based on ResNet-50, RM largely improves classification accuracy by $\sim$3.2\% on CIFAR100 and $\sim$2.8\% on ImageNet with negligible extra computation/storage costs. In the downstream object detection task, the RM pretrained model outperforms the baseline by 2.1 AP points and surpasses CutMix by 1.4 AP points under the ATSS detector on COCO. In semantic segmentation, RM also surpasses the baseline and CutMix by 1.9 and 1.1 mIoU points under UperNet on ADE20K, respectively. Codes and pretrained models are available at \url{https://github.com/megvii-research/RecursiveMix}.",1.0,0.8871669173240662,True,0.3775406687981454,0.6323537930611058,True
The Limit Points of (Optimistic) Gradient Descent in Min-Max Optimization,"Motivated by applications in Optimization, Game Theory, and the training of Generative Adversarial Networks, the convergence properties of first order methods in min-max problems have received extensive study. It has been recognized that they may cycle, and there is no good understanding of their limit points when they do not. When they converge, do they converge to local min-max solutions? We characterize the limit points of two basic first order methods, namely Gradient Descent/Ascent (GDA) and Optimistic Gradient Descent Ascent (OGDA). We show that both dynamics avoid unstable critical points for almost all initializations. Moreover, for small step sizes and under mild assumptions, the set of \{OGDA\}-stable critical points is a superset of \{GDA\}-stable critical points, which is a superset of local min-max solutions (strict in some cases). The connecting thread is that the behavior of these dynamics can be studied from a dynamical systems perspective.",0.8,0.8491001725196838,True,0.3318122278318339,0.5904562001757588,True
The Bayesian Stability Zoo,"We show that many definitions of stability found in the learning theory literature are equivalent to one another. We distinguish between two families of definitions of stability: distribution-dependent and distribution-independent Bayesian stability. Within each family, we establish equivalences between various definitions, encompassing approximate differential privacy, pure differential privacy, replicability, global stability, perfect generalization, TV stability, mutual information stability, KL-divergence stability, and R\'enyi-divergence stability. Along the way, we prove boosting results that enable the amplification of the stability of a learning rule. This work is a step towards a more systematic taxonomy of stability notions in learning theory, which can promote clarity and an improved understanding of an array of stability concepts that have emerged in recent years.",1.0,0.7840651273727417,True,0.3775406687981454,0.5808028980854436,True
Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias,"Large language models (LLMs) have been recently leveraged as training data generators for various natural language processing (NLP) tasks. While previous research has explored different approaches to training models using generated data, they generally rely on simple class-conditional prompts, which may limit the diversity of the generated data and inherit systematic biases of LLM. Thus, we investigate training data generation with diversely attributed prompts (e.g., specifying attributes like length and style), which have the potential to yield diverse and attributed generated data. Our investigation focuses on datasets with high cardinality and diverse domains, wherein we demonstrate that attributed prompts outperform simple class-conditional prompts in terms of the resulting model's performance. Additionally, we present a comprehensive empirical study on data generation encompassing vital aspects like bias, diversity, and efficiency, and highlight three key observations: firstly, synthetic datasets generated by simple prompts exhibit significant biases, such as regional bias; secondly, attribute diversity plays a pivotal role in enhancing model performance; lastly, attributed prompts achieve the performance of simple class-conditional prompts while utilizing only 5\% of the querying cost of ChatGPT associated with the latter. The data and code are available on \url{https://github.com/yueyu1030/AttrPrompt}.",0.8,0.7742162346839905,True,0.3318122278318339,0.5530142312579122,True
A Damped Newton Method Achieves Global $\mathcal O \left(\frac{1}{k^2}\right)$ and Local Quadratic Convergence Rate,,0.8,0.7698522806167603,True,0.3318122278318339,0.550832254224297,True
Submodular Function Minimization with Noisy Evaluation Oracle,"This paper considers submodular function minimization with \textit{noisy evaluation oracles} that return the function value of a submodular objective with zero-mean additive noise. For this problem, we provide an algorithm that returns an $O(n^{3/2}/\sqrt{T})$-additive approximate solution in expectation, where $n$ and $T$ stand for the size of the problem and the number of oracle calls, respectively. There is no room for reducing this error bound by a factor smaller than $O(1/\sqrt{n})$. Indeed, we show that any algorithm will suffer additive errors of $\Omega(n/\sqrt{T})$ in the worst case. Further, we consider an extended problem setting with \textit{multiple-point feedback} in which we can get the feedback of $k$ function values with each oracle call. Under the additional assumption that each noisy oracle is submodular and that $2 \leq k = O(1)$, we provide an algorithm with an $O(n/\sqrt{T})$-additive error bound as well as a worst-case analysis including a lower bound of $\Omega(n/\sqrt{T})$, which together imply that the algorithm achieves an optimal error bound up to a constant.",1.0,0.7715083360671997,True,0.3775406687981454,0.5745245024326726,True
SE(3)-equivariant prediction of molecular wavefunctions and electronic densities,"Machine learning has enabled the prediction of quantum chemical properties with high accuracy and efficiency, allowing to bypass computationally costly ab initio calculations. Instead of training on a fixed set of properties, more recent approaches attempt to learn the electronic wavefunction (or density) as a central quantity of atomistic systems, from which all other observables can be derived. This is complicated by the fact that wavefunctions transform non-trivially under molecular rotations, which makes them a challenging prediction target. To solve this issue, we introduce general SE(3)-equivariant operations and building blocks for constructing deep learning architectures for geometric point cloud data and apply them to reconstruct wavefunctions of atomistic systems with unprecedented accuracy. Our model achieves speedups of over three orders of magnitude compared to ab initio methods and reduces prediction errors by up to two orders of magnitude compared to the previous state-of-the-art. This accuracy makes it possible to derive properties such as energies and forces directly from the wavefunction in an end-to-end manner. We demonstrate the potential of our approach in a transfer learning application, where a model trained on low accuracy reference wavefunctions implicitly learns to correct for electronic many-body interactions from observables computed at a higher level of theory. Such machine-learned wavefunction surrogates pave the way towards novel semi-empirical methods, offering resolution at an electronic level while drastically decreasing computational cost. Additionally, the predicted wavefunctions can serve as initial guess in conventional ab initio methods, decreasing the number of iterations required to arrive at a converged solution, thus leading to significant speedups without any loss of accuracy or robustness.",1.8,0.6216692924499512,True,0.574442516811659,0.5980559046308052,True
Extracting Reward Functions from Diffusion Models,"Diffusion models have achieved remarkable results in image generation, and have similarly been used to learn high-performing policies in sequential decision-making tasks. Decision-making diffusion models can be trained on lower-quality data, and then be steered with a reward function to generate near-optimal trajectories. We consider the problem of extracting a reward function by comparing a decision-making diffusion model that models low-reward behavior and one that models high-reward behavior; a setting related to inverse reinforcement learning. We first define the notion of a relative reward function of two diffusion models and show conditions under which it exists and is unique. We then devise a practical learning algorithm for extracting it by aligning the gradients of a reward function -- parametrized by a neural network -- to the difference in outputs of both diffusion models. Our method finds correct reward functions in navigation environments, and we demonstrate that steering the base model with the learned reward functions results in significantly increased performance in standard locomotion benchmarks. Finally, we demonstrate that our approach generalizes beyond sequential decision-making by learning a reward-like function from two large-scale image generation diffusion models. The extracted reward function successfully assigns lower rewards to harmful images.",1.0,0.7862774133682251,True,0.3775406687981454,0.5819090410831853,True
Neural Functional Transformers,"The recent success of neural networks as implicit representation of data has driven growing interest in neural functionals: models that can process other neural networks as input by operating directly over their weight spaces. Nevertheless, constructing expressive and efficient neural functional architectures that can handle high-dimensional weight-space objects remains challenging. This paper uses the attention mechanism to define a novel set of permutation equivariant weight-space layers and composes them into deep equivariant models called neural functional Transformers (NFTs). NFTs respect weight-space permutation symmetries while incorporating the advantages of attention, which have exhibited remarkable success across multiple domains. In experiments processing the weights of feedforward MLPs and CNNs, we find that NFTs match or exceed the performance of prior weight-space methods. We also leverage NFTs to develop Inr2Array, a novel method for computing permutation invariant latent representations from the weights of implicit neural representations (INRs). Our proposed method improves INR classification accuracy by up to $+17\%$ over existing methods. We provide an implementation of our layers at https://github.com/AllanYangZhou/nfn.",1.0,0.8205315470695496,True,0.3775406687981454,0.5990361079338475,True
Black-Box Certification with Randomized Smoothing: A Functional Optimization Based Framework,"Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design new families of non-Gaussian smoothing distributions that work more efficiently for different $\ell_p$ settings, including $\ell_1$, $\ell_2$ and $\ell_\infty$ attacks. Our proposed methods achieve better certification results than previous works and provide a new perspective on randomized smoothing certification.",1.0,0.7844161987304688,True,0.3775406687981454,0.5809784337643071,True
Which Explanation Should I Choose? A Function Approximation Perspective to Characterizing Post hoc Explanations,"A critical problem in the field of post hoc explainability is the lack of a common foundational goal among methods. For example, some methods are motivated by function approximation, some by game theoretic notions, and some by obtaining clean visualizations. This fragmentation of goals causes not only an inconsistent conceptual understanding of explanations but also the practical challenge of not knowing which method to use when. In this work, we begin to address these challenges by unifying eight popular post hoc explanation methods (LIME, C-LIME, KernelSHAP, Occlusion, Vanilla Gradients, Gradients x Input, SmoothGrad, and Integrated Gradients). We show that these methods all perform local function approximation of the black-box model, differing only in the neighbourhood and loss function used to perform the approximation. This unification enables us to (1) state a no free lunch theorem for explanation methods, demonstrating that no method can perform optimally across all neighbourhoods, and (2) provide a guiding principle to choose among methods based on faithfulness to the black-box model. We empirically validate these theoretical results using various real-world datasets, model classes, and prediction tasks. By bringing diverse explanation methods into a common framework, this work (1) advances the conceptual understanding of these methods, revealing their shared local function approximation objective, properties, and relation to one another, and (2) guides the use of these methods in practice, providing a principled approach to choose among methods and paving the way for the creation of new ones.",1.3,0.7160390615463257,True,0.45016600268752216,0.5831025321169239,True
The NetHack Learning Environment,"Progress in Reinforcement Learning (RL) algorithms goes hand-in-hand with the development of challenging environments that test the limits of current methods. While existing RL environments are either sufficiently complex or based on fast simulation, they are rarely both. Here, we present the NetHack Learning Environment (NLE), a scalable, procedurally generated, stochastic, rich, and challenging environment for RL research based on the popular single-player terminal-based roguelike game, NetHack. We argue that NetHack is sufficiently complex to drive long-term research on problems such as exploration, planning, skill acquisition, and language-conditioned RL, while dramatically reducing the computational resources required to gather a large amount of experience. We compare NLE and its task suite to existing alternatives, and discuss why it is an ideal medium for testing the robustness and systematic generalization of RL agents. We demonstrate empirical success for early stages of the game using a distributed Deep RL baseline and Random Network Distillation exploration, alongside qualitative analysis of various agents trained in the environment. NLE is open source at this https URL.",1.0,0.7767288088798523,True,0.3775406687981454,0.5771347388389989,True
Re-Think and Re-Design Graph Neural Networks in Spaces of Continuous Graph Diffusion Functionals,"Graph neural networks (GNNs) are widely used in domains like social networks and biological systems. However, the locality assumption of GNNs, which limits information exchange to neighboring nodes, hampers their ability to capture long-range dependencies and global patterns in graphs. To address this, we propose a new inductive bias based on variational analysis, drawing inspiration from the Brachistochrone problem. Our framework establishes a mapping between discrete GNN models and continuous diffusion functionals. This enables the design of application-specific objective functions in the continuous domain and the construction of discrete deep models with mathematical guarantees. To tackle over-smoothing in GNNs, we analyze the existing layer-by-layer graph embedding models and identify that they are equivalent to l2-norm integral functionals of graph gradients, which cause over-smoothing. Similar to edge-preserving filters in image denoising, we introduce total variation (TV) to align the graph diffusion pattern with global community topologies. Additionally, we devise a selective mechanism to address the trade-off between model depth and over-smoothing, which can be easily integrated into existing GNNs. Furthermore, we propose a novel generative adversarial network (GAN) that predicts spreading flows in graphs through a neural transport equation. To mitigate vanishing flows, we customize the objective function to minimize transportation within each community while maximizing inter-community flows. Our GNN models achieve state-of-the-art (SOTA) performance on popular graph learning benchmarks such as Cora, Citeseer, and Pubmed.",1.0,0.8220716714859009,True,0.3775406687981454,0.5998061701420232,True
The Surprising Effectiveness of Diffusion Models for Optical Flow and Monocular Depth Estimation,"Denoising diffusion probabilistic models have transformed image generation with their impressive fidelity and diversity. We show that they also excel in estimating optical flow and monocular depth, surprisingly, without task-specific architectures and loss functions that are predominant for these tasks. Compared to the point estimates of conventional regression-based methods, diffusion models also enable Monte Carlo inference, e.g., capturing uncertainty and ambiguity in flow and depth. With self-supervised pre-training, the combined use of synthetic and real data for supervised training, and technical innovations (infilling and step-unrolled denoising diffusion training) to handle noisy-incomplete training data, and a simple form of coarse-to-fine refinement, one can train state-of-the-art diffusion models for depth and optical flow estimation. Extensive experiments focus on quantitative performance against benchmarks, ablations, and the model's ability to capture uncertainty and multimodality, and impute missing values. Our model, DDVM (Denoising Diffusion Vision Model), obtains a state-of-the-art relative depth error of 0.074 on the indoor NYU benchmark and an Fl-all outlier rate of 3.26\% on the KITTI optical flow benchmark, about 25\% better than the best published method. For an overview see https://diffusion-vision.github.io.",1.0,0.7910463213920593,True,0.3775406687981454,0.5842934950951024,True
The Grand Illusion: The Myth of Software Portability and Implications for ML Progress,"Pushing the boundaries of machine learning often requires exploring different hardware and software combinations. However, the freedom to experiment across different tooling stacks can be at odds with the drive for efficiency, which has produced increasingly specialized AI hardware and incentivized consolidation around a narrow set of ML frameworks. Exploratory research can be restricted if software and hardware are co-evolving, making it even harder to stray away from mainstream ideas that work well with popular tooling stacks. While this friction increasingly impacts the rate of innovation in machine learning, to our knowledge the lack of portability in tooling has not been quantified. In this work, we ask: How portable are popular ML software frameworks? We conduct a large-scale study of the portability of mainstream ML frameworks across different hardware types. Our findings paint an uncomfortable picture -- frameworks can lose more than 40% of their key functions when ported to other hardware. Worse, even when functions are portable, the slowdown in their performance can be extreme and render performance untenable. Collectively, our results reveal how costly straying from a narrow set of hardware-software combinations can be - and suggest that specialization of hardware impedes innovation in machine learning research.",1.0,0.7982895970344543,True,0.3775406687981454,0.5879151329162999,True
Bayes Consistency vs. H-Consistency: The Interplay between Surrogate Loss Functions and the Scoring Function Class,"A fundamental question in multiclass classification concerns understanding the consistency properties of surrogate risk minimization algorithms, which minimize a (often convex) surrogate to the multiclass 0-1 loss. In particular, the framework of calibrated surrogates has played an important role in analyzing Bayes consistency of such algorithms, i.e. in studying convergence to a Bayes optimal classifier (Zhang, 2004; Tewari and Bartlett, 2007). However, follow-up work has suggested this framework can be of limited value when studying H -consistency; in particular, concerns have been raised that even when the data comes from an underlying linear model, minimizing certain convex calibrated surrogates over linear scoring functions fails to recover the true model (Long and Servedio, 2013). In this paper, we investigate this apparent conundrum. We find that while some calibrated surrogates can indeed fail to provide H -consistency when minimized over a naturallooking but naïvely chosen scoring function class F , the situation can potentially be remedied by minimizing them over a more carefully chosen class of scoring functions F . In particular, for the popular one-vs-all hinge and logistic surrogates, both of which are calibrated (and therefore provide Bayes consistency) under realizable models, but were previously shown to pose problems for realizable H -consistency, we derive a form of scoring function class F that enables Hconsistency. When H is the class of linear models, the class F consists of certain piecewise linear scoring functions that are characterized by the same number of parameters as in the linear case, and minimization over which can be performed using an adaptation of the min-pooling idea from neural network training. Our experiments confirm that the one-vs-all surrogates, when trained over this class of nonlinear scoring functions F , yield better linear multiclass classifiers than when trained over standard linear scoring functions.",1.0,0.8111106157302856,True,0.3775406687981454,0.5943256422642156,True
A Direct tilde{O}(1/epsilon) Iteration Parallel Algorithm for Optimal Transport,"Optimal transportation, or computing the Wasserstein or ``earth mover's'' distance between two $n$-dimensional distributions, is a fundamental primitive which arises in many learning and statistical settings. We give an algorithm which solves the problem to additive $\epsilon$ accuracy with $\tilde{O}(1/\epsilon)$ parallel depth and $\tilde{O}\left(n^2/\epsilon\right)$ work. \cite{BlanchetJKS18, Quanrud19} obtained this runtime through reductions to positive linear programming and matrix scaling. However, these reduction-based algorithms use subroutines which may be impractical due to requiring solvers for second-order iterations (matrix scaling) or non-parallelizability (positive LP). Our methods match the previous-best work bounds by \cite{BlanchetJKS18, Quanrud19} while either improving parallelization or removing the need for linear system solves, and improve upon the previous best first-order methods running in time $\tilde{O}(\min(n^2 / \epsilon^2, n^{2.5} / \epsilon))$ \cite{DvurechenskyGK18, LinHJ19}. We obtain our results by a primal-dual extragradient method, motivated by recent theoretical improvements to maximum flow \cite{Sherman17}.",0.8,0.8524275422096252,True,0.3318122278318339,0.5921198850207295,True
Minigrid & Miniworld: Modular & Customizable Reinforcement Learning Environments for Goal-Oriented Tasks,"We present the Minigrid and Miniworld libraries which provide a suite of goal-oriented 2D and 3D environments. The libraries were explicitly created with a minimalistic design paradigm to allow users to rapidly develop new environments for a wide range of research-specific needs. As a result, both have received widescale adoption by the RL community, facilitating research in a wide range of areas. In this paper, we outline the design philosophy, environment details, and their world generation API. We also showcase the additional capabilities brought by the unified API between Minigrid and Miniworld through case studies on transfer learning (for both RL agents and humans) between the different observation spaces. The source code of Minigrid and Miniworld can be found at https://github.com/Farama-Foundation/{Minigrid, Miniworld} along with their documentation at https://{minigrid, miniworld}.farama.org/.",0.8,0.9385424256324768,True,0.3318122278318339,0.6351773267321553,True
"If Influence Functions are the Answer, Then What is the Question?","Influence functions efficiently estimate the effect of removing a single training data point on a model's learned parameters. While influence estimates align well with leave-one-out retraining for linear models, recent works have shown this alignment is often poor in neural networks. In this work, we investigate the specific factors that cause this discrepancy by decomposing it into five separate terms. We study the contributions of each term on a variety of architectures and datasets and how they vary with factors such as network width and training time. While practical influence function estimates may be a poor match to leave-one-out retraining for nonlinear networks, we show they are often a good approximation to a different object we term the proximal Bregman response function (PBRF). Since the PBRF can still be used to answer many of the questions motivating influence functions, such as identifying influential or mislabeled examples, our results suggest that current algorithms for influence function estimation give more informative results than previous error analyses would suggest.",1.3,0.8860623240470886,True,0.45016600268752216,0.6681141633673053,True
Multi-Objective Maximization of Monotone Submodular Functions with Cardinality Constraint,"We consider the problem of multiobjective maximization of monotone submodular functions subject to cardinality constraint, often formulated as [Formula: see text]. Although it is widely known that greedy methods work well for a single objective, the problem becomes much harder with multiple objectives. In fact, it is known that when the number of objectives m grows as the cardinality k, that is, [Formula: see text], the problem is inapproximable (unless P = NP). On the other hand, when m is constant, there exists a a randomized [Formula: see text] approximation with runtime (number of queries to function oracle) the scales as [Formula: see text]. We focus on finding a fast algorithm that has (asymptotic) approximation guarantees even when m is super constant. First, through a continuous greedy based algorithm we give a [Formula: see text] approximation for [Formula: see text]. This demonstrates a steep transition from constant factor approximability to inapproximability around [Formula: see text]. Then using multiplicative-weight-updates (MWUs), we find a much faster [Formula: see text] time asymptotic [Formula: see text] approximation. Although these results are all randomized, we also give a simple deterministic [Formula: see text] approximation with runtime [Formula: see text]. Finally, we run synthetic experiments using Kronecker graphs and find that our MWU inspired heuristic outperforms existing heuristics.",1.0,0.7416087985038757,True,0.3775406687981454,0.5595747336510106,True
Kantorovich Strikes Back! Wasserstein GANs are not Optimal Transport?,"Wasserstein Generative Adversarial Networks (WGANs) are the popular generative models built on the theory of Optimal Transport (OT) and the Kantorovich duality. Despite the success of WGANs, it is still unclear how well the underlying OT dual solvers approximate the OT cost (Wasserstein-1 distance, $\mathbb{W}_{1}$) and the OT gradient needed to update the generator. In this paper, we address these questions. We construct 1-Lipschitz functions and use them to build ray monotone transport plans. This strategy yields pairs of continuous benchmark distributions with the analytically known OT plan, OT cost and OT gradient in high-dimensional spaces such as spaces of images. We thoroughly evaluate popular WGAN dual form solvers (gradient penalty, spectral normalization, entropic regularization, etc.) using these benchmark pairs. Even though these solvers perform well in WGANs, none of them faithfully compute $\mathbb{W}_{1}$ in high dimensions. Nevertheless, many provide a meaningful approximation of the OT gradient. These observations suggest that these solvers should not be treated as good estimators of $\mathbb{W}_{1}$, but to some extent they indeed can be used in variational problems requiring the minimization of $\mathbb{W}_{1}$.",0.8,0.9471793174743652,True,0.3318122278318339,0.6394957726530995,True
Bucks for Buckets (B4B): Active Defenses Against Stealing Encoders,"Machine Learning as a Service (MLaaS) APIs provide ready-to-use and high-utility encoders that generate vector representations for given inputs. Since these encoders are very costly to train, they become lucrative targets for model stealing attacks during which an adversary leverages query access to the API to replicate the encoder locally at a fraction of the original training costs. We propose Bucks for Buckets (B4B), the first active defense that prevents stealing while the attack is happening without degrading representation quality for legitimate API users. Our defense relies on the observation that the representations returned to adversaries who try to steal the encoder's functionality cover a significantly larger fraction of the embedding space than representations of legitimate users who utilize the encoder to solve a particular downstream task.vB4B leverages this to adaptively adjust the utility of the returned representations according to a user's coverage of the embedding space. To prevent adaptive adversaries from eluding our defense by simply creating multiple user accounts (sybils), B4B also individually transforms each user's representations. This prevents the adversary from directly aggregating representations over multiple accounts to create their stolen encoder copy. Our active defense opens a new path towards securely sharing and democratizing encoders over public APIs.",0.8,0.7988736033439636,True,0.3318122278318339,0.5653429155878987,True
Pre-training Contextualized World Models with In-the-wild Videos for Reinforcement Learning,"Unsupervised pre-training methods utilizing large and diverse datasets have achieved tremendous success across a range of domains. Recent work has investigated such unsupervised pre-training methods for model-based reinforcement learning (MBRL) but is limited to domain-specific or simulated data. In this paper, we study the problem of pre-training world models with abundant in-the-wild videos for efficient learning of downstream visual control tasks. However, in-the-wild videos are complicated with various contextual factors, such as intricate backgrounds and textured appearance, which precludes a world model from extracting shared world knowledge to generalize better. To tackle this issue, we introduce Contextualized World Models (ContextWM) that explicitly separate context and dynamics modeling to overcome the complexity and diversity of in-the-wild videos and facilitate knowledge transfer between distinct scenes. Specifically, a contextualized extension of the latent dynamics model is elaborately realized by incorporating a context encoder to retain contextual information and empower the image decoder, which encourages the latent dynamics model to concentrate on essential temporal variations. Our experiments show that in-the-wild video pre-training equipped with ContextWM can significantly improve the sample efficiency of MBRL in various domains, including robotic manipulation, locomotion, and autonomous driving. Code is available at this repository: https://github.com/thuml/ContextWM.",1.0,0.8399606943130493,True,0.3775406687981454,0.6087506815555974,True
Change-point Detection for Sparse and Dense Functional Data in General Dimensions,"We study the problem of change-point detection and localisation for functional data sequentially observed on a general d-dimensional space, where we allow the functional curves to be either sparsely or densely sampled. Data of this form naturally arise in a wide range of applications such as biology, neuroscience, climatology, and finance. To achieve such a task, we propose a kernel-based algorithm named functional seeded binary segmentation (FSBS). FSBS is computationally efficient, can handle discretely observed functional data, and is theoretically sound for heavy-tailed and temporally-dependent observations. Moreover, FSBS works for a general d-dimensional domain, which is the first in the literature of change-point estimation for functional data. We show the consistency of FSBS for multiple change-point estimations and further provide a sharp localisation error rate, which reveals an interesting phase transition phenomenon depending on the number of functional curves observed and the sampling frequency for each curve. Extensive numerical experiments illustrate the effectiveness of FSBS and its advantage over existing methods in the literature under various settings. A real data application is further conducted, where FSBS localises change-points of sea surface temperature patterns in the south Pacific attributed to El Nino.",1.0,0.765504777431488,True,0.3775406687981454,0.5715227231148168,True
Geo-PIFu: Geometry and Pixel Aligned Implicit Functions for Single-view Human Reconstruction,"We propose Geo-PIFu, a method to recover a 3D mesh from a monocular color image of a clothed person. Our method is based on a deep implicit function-based representation to learn latent voxel features using a structure-aware 3D U-Net, to constrain the model in two ways: first, to resolve feature ambiguities in query point encoding, second, to serve as a coarse human shape proxy to regularize the high-resolution mesh and encourage global shape regularity. We show that, by both encoding query points and constraining global shape using latent voxel features, the reconstruction we obtain for clothed human meshes exhibits less shape distortion and improved surface details compared to competing methods. We evaluate Geo-PIFu on a recent human mesh public dataset that is $10 \times$ larger than the private commercial dataset used in PIFu and previous derivative work. On average, we exceed the state of the art by $42.7\%$ reduction in Chamfer and Point-to-Surface Distances, and $19.4\%$ reduction in normal estimation errors.",1.0,0.7413903474807739,True,0.3775406687981454,0.5594655081394597,True
Punctuation-level Attack: Single-shot and Single Punctuation Can Fool Text Models,,1.0,0.9427191019058228,True,0.3775406687981454,0.6601298853519841,True
Robust Quantization: One Model to Rule Them All,"Neural network quantization methods often involve simulating the quantization process during training, making the trained model highly dependent on the target bit-width and precise way quantization is performed. Robust quantization offers an alternative approach with improved tolerance to different classes of data-types and quantization policies. It opens up new exciting applications where the quantization process is not static and can vary to meet different circumstances and implementations. To address this issue, we propose a method that provides intrinsic robustness to the model against a broad range of quantization processes. Our method is motivated by theoretical arguments and enables us to store a single generic model capable of operating at various bit-widths and quantization policies. We validate our method's effectiveness on different ImageNet models.",1.8,0.6082527041435242,True,0.574442516811659,0.5913476104775917,True
Oracle Complexity of Single-Loop Switching Subgradient Methods for Non-Smooth Weakly Convex Functional Constrained Optimization,"We consider a non-convex constrained optimization problem, where the objective function is weakly convex and the constraint function is either convex or weakly convex. To solve this problem, we consider the classical switching subgradient method, which is an intuitive and easily implementable first-order method whose oracle complexity was only known for convex problems. This paper provides the first analysis on the oracle complexity of the switching subgradient method for finding a nearly stationary point of non-convex problems. Our results are derived separately for convex and weakly convex constraints. Compared to existing approaches, especially the double-loop methods, the switching gradient method can be applied to non-smooth problems and achieves the same complexity using only a single loop, which saves the effort on tuning the number of inner iterations.",1.0,0.8017866015434265,True,0.3775406687981454,0.589663635170786,True
Labeling Trick: A Theory of Using Graph Neural Networks for Multi-Node Representation Learning,"In this paper, we provide a theory of using graph neural networks (GNNs) for multi-node representation learning (where we are interested in learning a representation for a set of more than one node, such as link). We know that GNN is designed to learn single-node representations. When we want to learn a node set representation involving multiple nodes, a common practice in previous works is to directly aggregate the single-node representations obtained by a GNN into a joint node set representation. In this paper, we show a fundamental constraint of such an approach, namely the inability to capture the dependence between nodes in the node set, and argue that directly aggregating individual node representations does not lead to an effective joint representation for multiple nodes. Then, we notice that a few previous successful works for multi-node representation learning, including SEAL, Distance Encoding, and ID-GNN, all used node labeling. These methods first label nodes in the graph according to their relationships with the target node set before applying a GNN. Then, the node representations obtained in the labeled graph are aggregated into a node set representation. By investigating their inner mechanisms, we unify these node labeling techniques into a single and most general form -- labeling trick. We prove that with labeling trick a sufficiently expressive GNN learns the most expressive node set representations, thus in principle solves any joint learning tasks over node sets. Experiments on one important two-node representation learning task, link prediction, verified our theory. Our work explains the superior performance of previous node-labeling-based methods, and establishes a theoretical foundation of using GNNs for multi-node representation learning.",1.0,0.8678485155105591,True,0.3775406687981454,0.6226945921543523,True
Does Localization Inform Editing? Surprising Differences in Causality-Based Localization vs. Knowledge Editing in Language Models,"Language models learn a great quantity of factual information during pretraining, and recent work localizes this information to specific model weights like mid-layer MLP weights. In this paper, we find that we can change how a fact is stored in a model by editing weights that are in a different location than where existing methods suggest that the fact is stored. This is surprising because we would expect that localizing facts to specific model parameters would tell us where to manipulate knowledge in models, and this assumption has motivated past work on model editing methods. Specifically, we show that localization conclusions from representation denoising (also known as Causal Tracing) do not provide any insight into which model MLP layer would be best to edit in order to override an existing stored fact with a new one. This finding raises questions about how past work relies on Causal Tracing to select which model layers to edit. Next, we consider several variants of the editing problem, including erasing and amplifying facts. For one of our editing problems, editing performance does relate to localization results from representation denoising, but we find that which layer we edit is a far better predictor of performance. Our results suggest, counterintuitively, that better mechanistic understanding of how pretrained language models work may not always translate to insights about how to best change their behavior. Our code is available at https://github.com/google/belief-localization",1.3,0.8080262541770935,True,0.45016600268752216,0.6290961284323078,True
Quantum Speedups of Optimizing Approximately Convex Functions with Applications to Logarithmic Regret Stochastic Convex Bandits,"We initiate the study of quantum algorithms for optimizing approximately convex functions. Given a convex set ${\cal K}\subseteq\mathbb{R}^{n}$ and a function $F\colon\mathbb{R}^{n}\to\mathbb{R}$ such that there exists a convex function $f\colon\mathcal{K}\to\mathbb{R}$ satisfying $\sup_{x\in{\cal K}}|F(x)-f(x)|\leq \epsilon/n$, our quantum algorithm finds an $x^{*}\in{\cal K}$ such that $F(x^{*})-\min_{x\in{\cal K}} F(x)\leq\epsilon$ using $\tilde{O}(n^{3})$ quantum evaluation queries to $F$. This achieves a polynomial quantum speedup compared to the best-known classical algorithms. As an application, we give a quantum algorithm for zeroth-order stochastic convex bandits with $\tilde{O}(n^{5}\log^{2} T)$ regret, an exponential speedup in $T$ compared to the classical $\Omega(\sqrt{T})$ lower bound. Technically, we achieve quantum speedup in $n$ by exploiting a quantum framework of simulated annealing and adopting a quantum version of the hit-and-run walk. Our speedup in $T$ for zeroth-order stochastic convex bandits is due to a quadratic quantum speedup in multiplicative error of mean estimation.",1.0,0.8239286541938782,True,0.3775406687981454,0.6007346614960118,True
Graph Scattering beyond Wavelet Shackles,"This work develops a flexible and mathematically sound framework for the design and analysis of graph scattering networks with variable branching ratios and generic functional calculus filters. Spectrally-agnostic stability guarantees for node- and graph-level perturbations are derived; the vertex-set non-preserving case is treated by utilizing recently developed mathematical-physics based tools. Energy propagation through the network layers is investigated and related to truncation stability. New methods of graph-level feature aggregation are introduced and stability of the resulting composite scattering architectures is established. Finally, scattering transforms are extended to edge- and higher order tensorial input. Theoretical results are complemented by numerical investigations: Suitably chosen cattering networks conforming to the developed theory perform better than traditional graph-wavelet based scattering approaches in social network graph classification tasks and significantly outperform other graph-based learning approaches to regression of quantum-chemical energies on QM7.",1.0,0.8349952697753906,True,0.3775406687981454,0.6062679692867681,True
Faster and Non-ergodic O(1/K) Stochastic Alternating Direction Method of Multipliers,"We study stochastic convex optimization subjected to linear equality constraints. Traditional Stochastic Alternating Direction Method of Multipliers and its Nesterov's acceleration scheme can only achieve ergodic O(1/\sqrt{K}) convergence rates, where K is the number of iteration. By introducing Variance Reduction (VR) techniques, the convergence rates improve to ergodic O(1/K). In this paper, we propose a new stochastic ADMM which elaborately integrates Nesterov's extrapolation and VR techniques. We prove that our algorithm can achieve a non-ergodic O(1/K) convergence rate which is optimal for separable linearly constrained non-smooth convex problems, while the convergence rates of VR based ADMM methods are actually tight O(1/\sqrt{K}) in non-ergodic sense. To the best of our knowledge, this is the first work that achieves a truly accelerated, stochastic convergence rate for constrained convex problems. The experimental results demonstrate that our algorithm is significantly faster than the existing state-of-the-art stochastic ADMM methods.",0.8,0.820939838886261,True,0.3318122278318339,0.5763760333590474,True
Breaking the Activation Function Bottleneck through Adaptive Parameterization,"Standard neural network architectures are non-linear only by virtue of a simple element-wise activation function, making them both brittle and excessively large. In this paper, we consider methods for making the feed-forward layer more flexible while preserving its basic structure. We develop simple drop-in replacements that learn to adapt their parameterization conditional on the input, thereby increasing statistical efficiency significantly. We present an adaptive LSTM that advances the state of the art for the Penn Treebank and WikiText-2 word-modeling tasks while using fewer parameters and converging in less than half as many iterations.",1.0,0.7422487139701843,True,0.3775406687981454,0.5598946913841649,True
Fully Understanding the Hashing Trick,"Feature hashing, also known as {\em the hashing trick}, introduced by Weinberger et al. (2009), is one of the key techniques used in scaling-up machine learning algorithms. Loosely speaking, feature hashing uses a random sparse projection matrix $A : \mathbb{R}^n \to \mathbb{R}^m$ (where $m \ll n$) in order to reduce the dimension of the data from $n$ to $m$ while approximately preserving the Euclidean norm. Every column of $A$ contains exactly one non-zero entry, equals to either $-1$ or $1$. 
Weinberger et al. showed tail bounds on $\|Ax\|_2^2$. Specifically they showed that for every $\varepsilon, \delta$, if $\|x\|_{\infty} / \|x\|_2$ is sufficiently small, and $m$ is sufficiently large, then $$\Pr[ \; | \;\|Ax\|_2^2 - \|x\|_2^2\; | < \varepsilon \|x\|_2^2 \;] \ge 1 - \delta \;.$$ These bounds were later extended by Dasgupta \etal (2010) and most recently refined by Dahlgaard et al. (2017), however, the true nature of the performance of this key technique, and specifically the correct tradeoff between the pivotal parameters $\|x\|_{\infty} / \|x\|_2, m, \varepsilon, \delta$ remained an open question. 
We settle this question by giving tight asymptotic bounds on the exact tradeoff between the central parameters, thus providing a complete understanding of the performance of feature hashing. We complement the asymptotic bound with empirical data, which shows that the constants ""hiding"" in the asymptotic notation are, in fact, very close to $1$, thus further illustrating the tightness of the presented bounds in practice.",1.0,0.7301528453826904,True,0.3775406687981454,0.553846757090418,True
Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains,"We show that passing input points through a simple Fourier feature mapping enables a multilayer perceptron (MLP) to learn high-frequency functions in low-dimensional problem domains. These results shed light on recent advances in computer vision and graphics that achieve state-of-the-art results by using MLPs to represent complex 3D objects and scenes. Using tools from the neural tangent kernel (NTK) literature, we show that a standard MLP fails to learn high frequencies both in theory and in practice. To overcome this spectral bias, we use a Fourier feature mapping to transform the effective NTK into a stationary kernel with a tunable bandwidth. We suggest an approach for selecting problem-specific Fourier features that greatly improves the performance of MLPs for low-dimensional regression tasks relevant to the computer vision and graphics communities.",1.0,0.7914406657218933,True,0.3775406687981454,0.5844906672600194,True
Corruption-Robust Offline Reinforcement Learning with General Function Approximation,"We investigate the problem of corruption robustness in offline reinforcement learning (RL) with general function approximation, where an adversary can corrupt each sample in the offline dataset, and the corruption level $\zeta\geq0$ quantifies the cumulative corruption amount over $n$ episodes and $H$ steps. Our goal is to find a policy that is robust to such corruption and minimizes the suboptimality gap with respect to the optimal policy for the uncorrupted Markov decision processes (MDPs). Drawing inspiration from the uncertainty-weighting technique from the robust online RL setting \citep{he2022nearly,ye2022corruptionrobust}, we design a new uncertainty weight iteration procedure to efficiently compute on batched samples and propose a corruption-robust algorithm for offline RL. Notably, under the assumption of single policy coverage and the knowledge of $\zeta$, our proposed algorithm achieves a suboptimality bound that is worsened by an additive factor of $\mathcal{O}(\zeta (C(\widehat{\mathcal{F}},\mu)n)^{-1})$ due to the corruption. Here $\widehat{\mathcal{F}}$ is the confidence set, and the dataset $\mathcal{Z}_n^H$, and $C(\widehat{\mathcal{F}},\mu)$ is a coefficient that depends on $\widehat{\mathcal{F}}$ and the underlying data distribution $\mu$. When specialized to linear MDPs, the corruption-dependent error term reduces to $\mathcal{O}(\zeta d n^{-1})$ with $d$ being the dimension of the feature map, which matches the existing lower bound for corrupted linear MDPs. This suggests that our analysis is tight in terms of the corruption-dependent term.",1.0,0.8633378744125366,True,0.3775406687981454,0.6204392716053411,True
Sample Complexity of Learning Heuristic Functions for Greedy-Best-First and A* Search,"Greedy best-first search (GBFS) and A* search (A*) are popular algorithms for path-finding on large graphs. Both use so-called heuristic functions, which estimate how close a vertex is to the goal. While heuristic functions have been handcrafted using domain knowledge, recent studies demonstrate that learning heuristic functions from data is effective in many applications. Motivated by this emerging approach, we study the sample complexity of learning heuristic functions for GBFS and A*. We build on a recent framework called \textit{data-driven algorithm design} and evaluate the \textit{pseudo-dimension} of a class of utility functions that measure the performance of parameterized algorithms. Assuming that a vertex set of size $n$ is fixed, we present $\mathrm{O}(n\lg n)$ and $\mathrm{O}(n^2\lg n)$ upper bounds on the pseudo-dimensions for GBFS and A*, respectively, parameterized by heuristic function values. The upper bound for A* can be improved to $\mathrm{O}(n^2\lg d)$ if every vertex has a degree of at most $d$ and to $\mathrm{O}(n \lg n)$ if edge weights are integers bounded by $\mathrm{poly}(n)$. We also give $\Omega(n)$ lower bounds for GBFS and A*, which imply that our bounds for GBFS and A* under the integer-weight condition are tight up to a $\lg n$ factor. Finally, we discuss a case where the performance of A* is measured by the suboptimality and show that we can sometimes obtain a better guarantee by combining a parameter-dependent worst-case bound with a sample complexity bound.",1.0,0.8428757190704346,True,0.3775406687981454,0.61020819393429,True
Function Space Bayesian Pseudocoreset for Bayesian Neural Networks,"A Bayesian pseudocoreset is a compact synthetic dataset summarizing essential information of a large-scale dataset and thus can be used as a proxy dataset for scalable Bayesian inference. Typically, a Bayesian pseudocoreset is constructed by minimizing a divergence measure between the posterior conditioning on the pseudocoreset and the posterior conditioning on the full dataset. However, evaluating the divergence can be challenging, particularly for the models like deep neural networks having high-dimensional parameters. In this paper, we propose a novel Bayesian pseudocoreset construction method that operates on a function space. Unlike previous methods, which construct and match the coreset and full data posteriors in the space of model parameters (weights), our method constructs variational approximations to the coreset posterior on a function space and matches it to the full data posterior in the function space. By working directly on the function space, our method could bypass several challenges that may arise when working on a weight space, including limited scalability and multi-modality issue. Through various experiments, we demonstrate that the Bayesian pseudocoresets constructed from our method enjoys enhanced uncertainty quantification and better robustness across various model architectures.",1.0,0.7820892333984375,True,0.3775406687981454,0.5798149510982915,True
Dungeons and Data: A Large-Scale NetHack Dataset,"Recent breakthroughs in the development of agents to solve challenging sequential decision making problems such as Go, StarCraft, or DOTA, have relied on both simulated environments and large-scale datasets. However, progress on this research has been hindered by the scarcity of open-sourced datasets and the prohibitive computational cost to work with them. Here we present the NetHack Learning Dataset (NLD), a large and highly-scalable dataset of trajectories from the popular game of NetHack, which is both extremely challenging for current methods and very fast to run. NLD consists of three parts: 10 billion state transitions from 1.5 million human trajectories collected on the NAO public NetHack server from 2009 to 2020; 3 billion state-action-score transitions from 100,000 trajectories collected from the symbolic bot winner of the NetHack Challenge 2021; and, accompanying code for users to record, load and stream any collection of such trajectories in a highly compressed form. We evaluate a wide range of existing algorithms including online and offline RL, as well as learning from demonstrations, showing that significant research advances are needed to fully leverage large-scale datasets for challenging sequential decision making tasks.",1.0,0.9309070110321045,True,0.3775406687981454,0.654223839915125,True
What functions can Graph Neural Networks compute on random graphs? The role of Positional Encoding,"We aim to deepen the theoretical understanding of Graph Neural Networks (GNNs) on large graphs, with a focus on their expressive power. Existing analyses relate this notion to the graph isomorphism problem, which is mostly relevant for graphs of small sizes, or studied graph classification or regression tasks, while prediction tasks on nodes are far more relevant on large graphs. Recently, several works showed that, on very general random graphs models, GNNs converge to certains functions as the number of nodes grows. In this paper, we provide a more complete and intuitive description of the function space generated by equivariant GNNs for node-tasks, through general notions of convergence that encompass several previous examples. We emphasize the role of input node features, and study the impact of node Positional Encodings (PEs), a recent line of work that has been shown to yield state-of-the-art results in practice. Through the study of several examples of PEs on large random graphs, we extend previously known universality results to significantly more general models. Our theoretical results hint at some normalization tricks, which is shown numerically to have a positive impact on GNN generalization on synthetic and real data. Our proofs contain new concentration inequalities of independent interest.",1.3,0.8490005731582642,True,0.45016600268752216,0.6495832879228931,True
Learning to Teach with Dynamic Loss Functions,"Teaching is critical to human society: it is with teaching that prospective students are educated and human civilization can be inherited and advanced. A good teacher not only provides his/her students with qualified teaching materials (e.g., textbooks), but also sets up appropriate learning objectives (e.g., course projects and exams) considering different situations of a student. When it comes to artificial intelligence, treating machine learning models as students, the loss functions that are optimized act as perfect counterparts of the learning objective set by the teacher. In this work, we explore the possibility of imitating human teaching behaviors by dynamically and automatically outputting appropriate loss functions to train machine learning models. Different from typical learning settings in which the loss function of a machine learning model is predefined and fixed, in our framework, the loss function of a machine learning model (we call it student) is defined by another machine learning model (we call it teacher). The ultimate goal of teacher model is cultivating the student to have better performance measured on development dataset. Towards that end, similar to human teaching, the teacher, a parametric model, dynamically outputs different loss functions that will be used and optimized by its student model at different training stages. We develop an efficient learning method for the teacher model that makes gradient based optimization possible, exempt of the ineffective solutions such as policy optimization. We name our method as ""learning to teach with dynamic loss functions"" (L2T-DLF for short). Extensive experiments on real world tasks including image classification and neural machine translation demonstrate that our method significantly improves the quality of various student models.",1.0,0.759966254234314,True,0.3775406687981454,0.5687534615162297,True
Connected Superlevel Set in (Deep) Reinforcement Learning and its Application to Minimax Theorems,"The aim of this paper is to improve the understanding of the optimization landscape for policy optimization problems in reinforcement learning. Specifically, we show that the superlevel set of the objective function with respect to the policy parameter is always a connected set both in the tabular setting and under policies represented by a class of neural networks. In addition, we show that the optimization objective as a function of the policy parameter and reward satisfies a stronger""equiconnectedness""property. To our best knowledge, these are novel and previously unknown discoveries. We present an application of the connectedness of these superlevel sets to the derivation of minimax theorems for robust reinforcement learning. We show that any minimax optimization program which is convex on one side and is equiconnected on the other side observes the minimax equality (i.e. has a Nash equilibrium). We find that this exact structure is exhibited by an interesting robust reinforcement learning problem under an adversarial reward attack, and the validity of its minimax equality immediately follows. This is the first time such a result is established in the literature.",0.8,0.7969099283218384,True,0.3318122278318339,0.5643610780768361,True
Active Learning Polynomial Threshold Functions,"We initiate the study of active learning polynomial threshold functions (PTFs). While traditional lower bounds imply that even univariate quadratics cannot be non-trivially actively learned, we show that allowing the learner basic access to the derivatives of the underlying classifier circumvents this issue and leads to a computationally efficient algorithm for active learning degree-$d$ univariate PTFs in $\tilde{O}(d^3\log(1/\varepsilon\delta))$ queries. We also provide near-optimal algorithms and analyses for active learning PTFs in several average case settings. Finally, we prove that access to derivatives is insufficient for active learning multivariate PTFs, even those of just two variables.",1.0,0.9116050601005554,True,0.3775406687981454,0.6445728644493505,True
How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model,"Pre-trained language models can be surprisingly adept at tasks they were not explicitly trained on, but how they implement these capabilities is poorly understood. In this paper, we investigate the basic mathematical abilities often acquired by pre-trained language models. Concretely, we use mechanistic interpretability techniques to explain the (limited) mathematical abilities of GPT-2 small. As a case study, we examine its ability to take in sentences such as""The war lasted from the year 1732 to the year 17"", and predict valid two-digit end years (years>32). We first identify a circuit, a small subset of GPT-2 small's computational graph that computes this task's output. Then, we explain the role of each circuit component, showing that GPT-2 small's final multi-layer perceptrons boost the probability of end years greater than the start year. Finally, we find related tasks that activate our circuit. Our results suggest that GPT-2 small computes greater-than using a complex but general mechanism that activates across diverse contexts.",1.1,0.7723569869995117,True,0.401312339887548,0.5868346634435299,True
Where Do You Feel? Neuroanatomical and Functional Insights into Interoception and Embodiment,,1.3,0.7234089970588684,True,0.45016600268752216,0.5867874998731952,True
Cross-Scale MAE: A Tale of Multiscale Exploitation in Remote Sensing,,0.8,0.8148459196090698,True,0.3318122278318339,0.5733290737204518,True
Approximating two value functions instead of one: towards characterizing a new family of Deep Reinforcement Learning algorithms,"This paper makes one step forward towards characterizing a new family of \textit{model-free} Deep Reinforcement Learning (DRL) algorithms. The aim of these algorithms is to jointly learn an approximation of the state-value function ($V$), alongside an approximation of the state-action value function ($Q$). Our analysis starts with a thorough study of the Deep Quality-Value Learning (DQV) algorithm, a DRL algorithm which has been shown to outperform popular techniques such as Deep-Q-Learning (DQN) and Double-Deep-Q-Learning (DDQN) \cite{sabatelli2018deep}. Intending to investigate why DQV's learning dynamics allow this algorithm to perform so well, we formulate a set of research questions which help us characterize a new family of DRL algorithms. Among our results, we present some specific cases in which DQV's performance can get harmed and introduce a novel \textit{off-policy} DRL algorithm, called DQV-Max, which can outperform DQV. We then study the behavior of the $V$ and $Q$ functions that are learned by DQV and DQV-Max and show that both algorithms might perform so well on several DRL test-beds because they are less prone to suffer from the overestimation bias of the $Q$ function.",1.0,0.7392820715904236,True,0.3775406687981454,0.5584113701942846,True
Fast and Regret Optimal Best Arm Identification: Fundamental Limits and Low-Complexity Algorithms,"This paper considers a stochastic Multi-Armed Bandit (MAB) problem with dual objectives: (i) quick identification and commitment to the optimal arm, and (ii) reward maximization throughout a sequence of $T$ consecutive rounds. Though each objective has been individually well-studied, i.e., best arm identification for (i) and regret minimization for (ii), the simultaneous realization of both objectives remains an open problem, despite its practical importance. This paper introduces \emph{Regret Optimal Best Arm Identification} (ROBAI) which aims to achieve these dual objectives. To solve ROBAI with both pre-determined stopping time and adaptive stopping time requirements, we present an algorithm called EOCP and its variants respectively, which not only achieve asymptotic optimal regret in both Gaussian and general bandits, but also commit to the optimal arm in $\mathcal{O}(\log T)$ rounds with pre-determined stopping time and $\mathcal{O}(\log^2 T)$ rounds with adaptive stopping time. We further characterize lower bounds on the commitment time (equivalent to the sample complexity) of ROBAI, showing that EOCP and its variants are sample optimal with pre-determined stopping time, and almost sample optimal with adaptive stopping time. Numerical results confirm our theoretical analysis and reveal an interesting""over-exploration""phenomenon carried by classic UCB algorithms, such that EOCP has smaller regret even though it stops exploration much earlier than UCB, i.e., $\mathcal{O}(\log T)$ versus $\mathcal{O}(T)$, which suggests over-exploration is unnecessary and potentially harmful to system performance.",1.0,0.8159530758857727,True,0.3775406687981454,0.5967468723419591,True
GPT3.int8(): 8-bit Matrix Multiplication for Transformers at Scale,,0.8,0.7965841293334961,True,0.3318122278318339,0.564198178582665,True
Comparing Apples to Oranges: Learning Similarity Functions for Data Produced by Different Distributions,"Similarity functions measure how comparable pairs of elements are, and play a key role in a wide variety of applications, e.g., notions of Individual Fairness abiding by the seminal paradigm of Dwork et al., as well as Clustering problems. However, access to an accurate similarity function should not always be considered guaranteed, and this point was even raised by Dwork et al. For instance, it is reasonable to assume that when the elements to be compared are produced by different distributions, or in other words belong to different ``demographic'' groups, knowledge of their true similarity might be very difficult to obtain. In this work, we present an efficient sampling framework that learns these across-groups similarity functions, using only a limited amount of experts' feedback. We show analytical results with rigorous theoretical bounds, and empirically validate our algorithms via a large suite of experiments.",1.0,0.8051890730857849,True,0.3775406687981454,0.5913648709419652,True
Insights From the NeurIPS 2021 NetHack Challenge,"In this report, we summarize the takeaways from the first NeurIPS 2021 NetHack Challenge. Participants were tasked with developing a program or agent that can win (i.e., 'ascend' in) the popular dungeon-crawler game of NetHack by interacting with the NetHack Learning Environment (NLE), a scalable, procedurally generated, and challenging Gym environment for reinforcement learning (RL). The challenge showcased community-driven progress in AI with many diverse approaches significantly beating the previously best results on NetHack. Furthermore, it served as a direct comparison between neural (e.g., deep RL) and symbolic AI, as well as hybrid systems, demonstrating that on NetHack symbolic bots currently outperform deep RL by a large margin. Lastly, no agent got close to winning the game, illustrating NetHack's suitability as a long-term benchmark for AI research.",1.0,0.7479574680328369,True,0.3775406687981454,0.5627490684154912,True
The Machine Learning for Combinatorial Optimization Competition (ML4CO): Results and Insights,"Combinatorial optimization is a well-established area in operations research and computer science. Until recently, its methods have focused on solving problem instances in isolation, ignoring that they often stem from related data distributions in practice. However, recent years have seen a surge of interest in using machine learning as a new approach for solving combinatorial problems, either directly as solvers or by enhancing exact solvers. Based on this context, the ML4CO aims at improving state-of-the-art combinatorial optimization solvers by replacing key heuristic components. The competition featured three challenging tasks: finding the best feasible solution, producing the tightest optimality certificate, and giving an appropriate solver configuration. Three realistic datasets were considered: balanced item placement, workload apportionment, and maritime inventory routing. This last dataset was kept anonymous for the contestants.",0.8,0.7910093069076538,True,0.3318122278318339,0.5614107673697438,True
Provable General Function Class Representation Learning in Multitask Bandits and MDPs,"While multitask representation learning has become a popular approach in reinforcement learning (RL) to boost the sample efficiency, the theoretical understanding of why and how it works is still limited. Most previous analytical works could only assume that the representation function is already known to the agent or from linear function class, since analyzing general function class representation encounters non-trivial technical obstacles such as generalization guarantee, formulation of confidence bound in abstract function space, etc. However, linear-case analysis heavily relies on the particularity of linear function class, while real-world practice usually adopts general non-linear representation functions like neural networks. This significantly reduces its applicability. In this work, we extend the analysis to general function class representations. Specifically, we consider an agent playing $M$ contextual bandits (or MDPs) concurrently and extracting a shared representation function $\phi$ from a specific function class $\Phi$ using our proposed Generalized Functional Upper Confidence Bound algorithm (GFUCB). We theoretically validate the benefit of multitask representation learning within general function class for bandits and linear MDP for the first time. Lastly, we conduct experiments to demonstrate the effectiveness of our algorithm with neural net representation.",1.0,0.7379345893859863,True,0.3775406687981454,0.5577376290920659,True
Training Your Image Restoration Network Better with Random Weight Network as Optimization Function,,1.0,0.7492444515228271,True,0.3775406687981454,0.5633925601604863,True
Non-parametric Models for Non-negative Functions,"Linear models have shown great effectiveness and flexibility in many fields such as machine learning, signal processing and statistics. They can represent rich spaces of functions while preserving the convexity of the optimization problems where they are used, and are simple to evaluate, differentiate and integrate. However, for modeling non-negative functions, which are crucial for unsupervised learning, density estimation, or non-parametric Bayesian methods, linear models are not applicable directly. Moreover, current state-of-the-art models like generalized linear models either lead to non-convex optimization problems, or cannot be easily integrated. In this paper we provide the first model for non-negative functions which benefits from the same good properties of linear models. In particular, we prove that it admits a representer theorem and provide an efficient dual formulation for convex problems. We study its representation power, showing that the resulting space of functions is strictly richer than that of generalized linear models. Finally we extend the model and the theoretical results to functions with outputs in convex cones. The paper is complemented by an experimental evaluation of the model showing its effectiveness in terms of formulation, algorithmic derivation and practical results on the problems of density estimation, regression with heteroscedastic errors, and multiple quantile regression.",1.0,0.8380966782569885,True,0.3775406687981454,0.607818673527567,True
Locally Differentially Private (Contextual) Bandits Learning,"We study locally differentially private (LDP) bandits learning in this paper. First, we propose simple black-box reduction frameworks that can solve a large family of context-free bandits learning problems with LDP guarantee. Based on our frameworks, we can improve previous best results for private bandits learning with one-point feedback, such as private Bandits Convex Optimization etc, and obtain the first results for Bandits Convex Optimization (BCO) with multi-point feedback under LDP. LDP guarantee and black-box nature make our frameworks more attractive in real applications compared with previous specifically designed and relatively weaker differentially private (DP) context-free bandits algorithms. Further, we also extend our algorithm to Generalized Linear Bandits with regret bound $\tilde{\mathcal{O}}(T^{3/4}/\varepsilon)$ under $(\varepsilon, \delta)$-LDP which is conjectured to be optimal. Note given existing $\Omega(T)$ lower bound for DP contextual linear bandits (Shariff&Sheffe,NeurIPS2018), our result shows a fundamental difference between LDP and DP contextual bandits learning.",0.8,0.9580050706863403,True,0.3318122278318339,0.6449086492590871,True
Using Mixup as a Regularizer Can Surprisingly Improve Accuracy & Out-of-Distribution Robustness,,1.8,0.8990756273269653,True,0.574442516811659,0.7367590720693122,True
Recurrent Hypernetworks are Surprisingly Strong in Meta-RL,"Deep reinforcement learning (RL) is notoriously impractical to deploy due to sample inefficiency. Meta-RL directly addresses this sample inefficiency by learning to perform few-shot learning when a distribution of related tasks is available for meta-training. While many specialized meta-RL methods have been proposed, recent work suggests that end-to-end learning in conjunction with an off-the-shelf sequential model, such as a recurrent network, is a surprisingly strong baseline. However, such claims have been controversial due to limited supporting evidence, particularly in the face of prior work establishing precisely the opposite. In this paper, we conduct an empirical investigation. While we likewise find that a recurrent network can achieve strong performance, we demonstrate that the use of hypernetworks is crucial to maximizing their potential. Surprisingly, when combined with hypernetworks, the recurrent baselines that are far simpler than existing specialized methods actually achieve the strongest performance of all methods evaluated. We provide code at https://github.com/jacooba/hyper.",1.0,0.7867404222488403,True,0.3775406687981454,0.5821405455234929,True
GANs for All: Supporting Fun and Intuitive Exploration of GAN Latent Spaces,"We have developed a new tool 1 that makes it possible for people with zero programming experience to intentionally and meaningfully explore the latent space of a GAN. We combine a number of methods from the literature into a single system that includes multiple functionalities: uploading and locating images in the latent space, image generation with text, visual style mixing, and intentional and intuitive latent space exploration. This tool was developed to provide a means for designers to explore the ”design space” of their domains. Our goal was to create a system to support novices in gaining a more complete, expert understanding of their domain’s design space by lowering the barrier of entry to using deep generative models in creative practice.",1.0,0.9541019201278687,True,0.3775406687981454,0.6658212944630071,True
BIOT: Biosignal Transformer for Cross-data Learning in the Wild,,1.0,0.8043270707130432,True,0.3775406687981454,0.5909338697555944,True
PettingZoo: Gym for Multi-Agent Reinforcement Learning,"This paper introduces the PettingZoo library and the accompanying Agent Environment Cycle (“AEC”) games model. PettingZoo is a library of diverse sets of multi-agent environments with a universal, elegant Python API. PettingZoo was developed with the goal of accelerating research in Multi-Agent Reinforcement Learning (“MARL”), by making work more interchangeable, accessible and re-producible akin to what OpenAI’s Gym library did for single-agent reinforcement learning. PettingZoo’s API, while inheriting many features of Gym, is unique amongst MARL APIs in that it’s based around the novel AEC games model. We argue, in part through case studies on major problems in popular MARL environments, that the popular game models are poor conceptual models of the games commonly used with MARL, that they promote severe bugs that are hard to detect, and that the AEC games model addresses these problems.",1.0,0.9487465023994446,True,0.3775406687981454,0.663143585598795,True
Differentiable Sampling of Categorical Distributions Using the CatLog-Derivative Trick,"Categorical random variables can faithfully represent the discrete and uncertain aspects of data as part of a discrete latent variable model. Learning in such models necessitates taking gradients with respect to the parameters of the categorical probability distributions, which is often intractable due to their combinatorial nature. A popular technique to estimate these otherwise intractable gradients is the Log-Derivative trick. This trick forms the basis of the well-known REINFORCE gradient estimator and its many extensions. While the Log-Derivative trick allows us to differentiate through samples drawn from categorical distributions, it does not take into account the discrete nature of the distribution itself. Our first contribution addresses this shortcoming by introducing the CatLog-Derivative trick - a variation of the Log-Derivative trick tailored towards categorical distributions. Secondly, we use the CatLog-Derivative trick to introduce IndeCateR, a novel and unbiased gradient estimator for the important case of products of independent categorical distributions with provably lower variance than REINFORCE. Thirdly, we empirically show that IndeCateR can be efficiently implemented and that its gradient estimates have significantly lower bias and variance for the same number of samples compared to the state of the art.",1.0,0.8547241687774658,True,0.3775406687981454,0.6161324187878057,True
NeuroMLR: Robust & Reliable Route Recommendation on Road Networks,"Predicting the most likely route from a source location to a destination is a core functionality in mapping services. Although the problem has been studied in the literature, two key limitations remain to be addressed. First, our study reveals that a signiﬁcant portion of the routes recommended by existing methods fail to reach the destination. Second, existing techniques are transductive in nature; hence, they fail to recommend routes if unseen roads are encountered at inference time. In this paper, we address these limitations through an inductive algorithm called N EURO MLR. N EURO MLR learns a generative model from historical trajectories by conditioning on three explanatory factors: the current location, the destination, and real-time trafﬁc conditions. The conditional distributions are learned through a novel combination of Lipschitz embeddings with Graph Convolutional Networks (GCN) using historical trajectory data. Through in-depth experiments on real-world datasets, we establish that N EURO MLR imparts signiﬁcant improvement in accuracy over the state of the art. More importantly, N EURO MLR generalizes dramatically better to unseen data and the recommended routes reach the destination with much higher likelihood than existing techniques.",0.8,0.8443160653114319,True,0.3318122278318339,0.5880641465716329,True
Multi-modal Queried Object Detection in the Wild,"We introduce MQ-Det, an efficient architecture and pre-training strategy design to utilize both textual description with open-set generalization and visual exemplars with rich description granularity as category queries, namely, Multi-modal Queried object Detection, for real-world detection with both open-vocabulary categories and various granularity. MQ-Det incorporates vision queries into existing well-established language-queried-only detectors. A plug-and-play gated class-scalable perceiver module upon the frozen detector is proposed to augment category text with class-wise visual information. To address the learning inertia problem brought by the frozen detector, a vision conditioned masked language prediction strategy is proposed. MQ-Det's simple yet effective architecture and training strategy design is compatible with most language-queried object detectors, thus yielding versatile applications. Experimental results demonstrate that multi-modal queries largely boost open-world detection. For instance, MQ-Det significantly improves the state-of-the-art open-set detector GLIP by +7.8% AP on the LVIS benchmark via multi-modal queries without any downstream finetuning, and averagely +6.3% AP on 13 few-shot downstream tasks, with merely additional 3% modulating time required by GLIP. Code is available at https://github.com/YifanXu74/MQ-Det.",1.0,0.7904599905014038,True,0.3775406687981454,0.5840003296497747,True
What Can Transformers Learn In-Context? A Case Study of Simple Function Classes,"In-context learning refers to the ability of a model to condition on a prompt sequence consisting of in-context examples (input-output pairs corresponding to some task) along with a new query input, and generate the corresponding output. Crucially, in-context learning happens only at inference time without any parameter updates to the model. While large language models such as GPT-3 exhibit some ability to perform in-context learning, it is unclear what the relationship is between tasks on which this succeeds and what is present in the training data. To make progress towards understanding in-context learning, we consider the well-defined problem of training a model to in-context learn a function class (e.g., linear functions): that is, given data derived from some functions in the class, can we train a model to in-context learn""most""functions from this class? We show empirically that standard Transformers can be trained from scratch to perform in-context learning of linear functions -- that is, the trained model is able to learn unseen linear functions from in-context examples with performance comparable to the optimal least squares estimator. In fact, in-context learning is possible even under two forms of distribution shift: (i) between the training data of the model and inference-time prompts, and (ii) between the in-context examples and the query input during inference. We also show that we can train Transformers to in-context learn more complex function classes -- namely sparse linear functions, two-layer neural networks, and decision trees -- with performance that matches or exceeds task-specific learning algorithms. Our code and models are available at https://github.com/dtsip/in-context-learning .",1.3,0.8897310495376587,True,0.45016600268752216,0.6699485261125904,True
SugarCrepe: Fixing Hackable Benchmarks for Vision-Language Compositionality,"In the last year alone, a surge of new benchmarks to measure compositional understanding of vision-language models have permeated the machine learning ecosystem. Given an image, these benchmarks probe a model's ability to identify its associated caption amongst a set of compositional distractors. Surprisingly, we find significant biases in all these benchmarks rendering them hackable. This hackability is so dire that blind models with no access to the image outperform state-of-the-art vision-language models. To remedy this rampant vulnerability, we introduce SugarCrepe, a new benchmark for vision-language compositionality evaluation. We employ large language models, instead of rule-based templates used in previous benchmarks, to generate fluent and sensical hard negatives, and utilize an adversarial refinement mechanism to maximally reduce biases. We re-evaluate state-of-the-art models and recently proposed compositionality inducing strategies, and find that their improvements were hugely overestimated, suggesting that more innovation is needed in this important direction. We release SugarCrepe and the code for evaluation at: https://github.com/RAIVNLab/sugar-crepe.",1.0,0.9230161905288696,True,0.3775406687981454,0.6502784296635076,True
The MAGICAL Benchmark for Robust Imitation,"Imitation Learning (IL) algorithms are typically evaluated in the same environment that was used to create demonstrations. This rewards precise reproduction of demonstrations in one particular environment, but provides little information about how robustly an algorithm can generalise the demonstrator's intent to substantially different deployment settings. This paper presents the MAGICAL benchmark suite, which permits systematic evaluation of generalisation by quantifying robustness to different kinds of distribution shift that an IL algorithm is likely to encounter in practice. Using the MAGICAL suite, we confirm that existing IL algorithms overfit significantly to the context in which demonstrations are provided. We also show that standard methods for reducing overfitting are effective at creating narrow perceptual invariances, but are not sufficient to enable transfer to contexts that require substantially different behaviour, which suggests that new approaches will be needed in order to robustly generalise demonstrator intent. Code and data for the MAGICAL suite is available at https://github.com/qxcv/magical/.",1.0,0.956919252872467,True,0.3775406687981454,0.6672299608353063,True
"Robustness in deep learning: The good (width), the bad (depth), and the ugly (initialization)","We study the average robustness notion in deep neural networks in (selected) wide and narrow, deep and shallow, as well as lazy and non-lazy training settings. We prove that in the under-parameterized setting, width has a negative effect while it improves robustness in the over-parameterized setting. The effect of depth closely depends on the initialization and the training mode. In particular, when initialized with LeCun initialization, depth helps robustness with the lazy training regime. In contrast, when initialized with Neural Tangent Kernel (NTK) and He-initialization, depth hurts the robustness. Moreover, under the non-lazy training regime, we demonstrate how the width of a two-layer ReLU network benefits robustness. Our theoretical developments improve the results by [Huang et al. NeurIPS21; Wu et al. NeurIPS21] and are consistent with [Bubeck and Sellke NeurIPS21; Bubeck et al. COLT21].",0.8,0.8274998068809509,True,0.3318122278318339,0.5796560173563924,True
History Filtering in Imperfect Information Games: Algorithms and Complexity,"Historically applied exclusively to perfect information games, depth-limited search with value functions has been key to recent advances in AI for imperfect information games. Most prominent approaches with strong theoretical guarantees require subgame decomposition - a process in which a subgame is computed from public information and player beliefs. However, subgame decomposition can itself require non-trivial computations, and its tractability depends on the existence of efficient algorithms for either full enumeration or generation of the histories that form the root of the subgame. Despite this, no formal analysis of the tractability of such computations has been established in prior work, and application domains have often consisted of games, such as poker, for which enumeration is trivial on modern hardware. Applying these ideas to more complex domains requires understanding their cost. In this work, we introduce and analyze the computational aspects and tractability of filtering histories for subgame decomposition. We show that constructing a single history from the root of the subgame is generally intractable, and then provide a necessary and sufficient condition for efficient enumeration. We also introduce a novel Markov Chain Monte Carlo-based generation algorithm for trick-taking card games - a domain where enumeration is often prohibitively expensive. Our experiments demonstrate its improved scalability in the trick-taking card game Oh Hell. These contributions clarify when and how depth-limited search via subgame decomposition can be an effective tool for sequential decision-making in imperfect information settings.",1.0,0.9305955767631531,True,0.3775406687981454,0.6540681227806493,True
Online Stochastic Shortest Path with Bandit Feedback and Unknown Transition Function,"We consider online learning in episodic loop-free Markov decision processes (MDPs), where the loss function can change arbitrarily between episodes. The transition function is fixed but unknown to the learner, and the learner only observes bandit feedback (not the entire loss function). For this problem we develop no-regret algorithms that perform asymptotically as well as the best stationary policy in hindsight. Assuming that all states are reachable with probability $\beta > 0$ under any policy, we give a regret bound of $\tilde{O} ( L|X|\sqrt{|A|T} / \beta )$, where $T$ is the number of episodes, $X$ is the state space, $A$ is the action space, and $L$ is the length of each episode. When this assumption is removed we give a regret bound of $\tilde{O} ( L^{3/2} |X| |A|^{1/4} T^{3/4})$, that holds for an arbitrary transition function. To our knowledge these are the first algorithms that in our setting handle both bandit feedback and an unknown transition function.",1.0,0.8904086947441101,True,0.3775406687981454,0.6339746817711278,True
Decorate3D: Text-Driven High-Quality Texture Generation for Mesh Decoration in the Wild,,1.0,0.9000721573829651,True,0.3775406687981454,0.6388064130905553,True
The surprising efficiency of framing geo-spatial time series forecasting as a video prediction task - Insights from the IARAI Traffic4cast Competition at NeurIPS 2019,"Deep Neural Networks models are state-of-the-art solutions in accurately forecasting future video frames in a movie. A successful video prediction model needs to extract and encode semantic features that describe the complex spatio-temporal correlations within image sequences of the real world. The IARAI Traﬃc4cast Challenge of the NeurIPS Competition Track 2019 for the ﬁrst time introduced the novel argument that this is also highly relevant for urban traﬃc. By framing traﬃc prediction as a movie completion task, the challenge requires models to take advantage of complex geo-spatial and temporal patterns of the underlying process. We here report on the success and insights",1.0,0.7799132466316223,True,0.3775406687981454,0.5787269577148839,True
Where Do You Think You're Going?: Inferring Beliefs about Dynamics from Behavior,"Inferring intent from observed behavior has been studied extensively within the frameworks of Bayesian inverse planning and inverse reinforcement learning. These methods infer a goal or reward function that best explains the actions of the observed agent, typically a human demonstrator. Another agent can use this inferred intent to predict, imitate, or assist the human user. However, a central assumption in inverse reinforcement learning is that the demonstrator is close to optimal. While models of suboptimal behavior exist, they typically assume that suboptimal actions are the result of some type of random noise or a known cognitive bias, like temporal inconsistency. In this paper, we take an alternative approach, and model suboptimal behavior as the result of internal model misspecification: the reason that user actions might deviate from near-optimal actions is that the user has an incorrect set of beliefs about the rules -- the dynamics -- governing how actions affect the environment. Our insight is that while demonstrated actions may be suboptimal in the real world, they may actually be near-optimal with respect to the user's internal model of the dynamics. By estimating these internal beliefs from observed behavior, we arrive at a new method for inferring intent. We demonstrate in simulation and in a user study with 12 participants that this approach enables us to more accurately model human intent, and can be used in a variety of applications, including offering assistance in a shared autonomy framework and inferring human preferences.",1.1,0.7912288308143616,True,0.401312339887548,0.5962705853509548,True
Directed Cyclic Graph for Causal Discovery from Multivariate Functional Data,"Discovering causal relationship using multivariate functional data has received a significant amount of attention very recently. In this article, we introduce a functional linear structural equation model for causal structure learning when the underlying graph involving the multivariate functions may have cycles. To enhance interpretability, our model involves a low-dimensional causal embedded space such that all the relevant causal information in the multivariate functional data is preserved in this lower-dimensional subspace. We prove that the proposed model is causally identifiable under standard assumptions that are often made in the causal discovery literature. To carry out inference of our model, we develop a fully Bayesian framework with suitable prior specifications and uncertainty quantification through posterior summaries. We illustrate the superior performance of our method over existing methods in terms of causal graph estimation through extensive simulation studies. We also demonstrate the proposed method using a brain EEG dataset.",1.0,0.7225881218910217,True,0.3775406687981454,0.5500643953445836,True
Surprising Instabilities in Training Deep Networks and a Theoretical Analysis,"We discover restrained numerical instabilities in current training practices of deep networks with stochastic gradient descent (SGD). We show numerical error (on the order of the smallest floating point bit) induced from floating point arithmetic in training deep nets can be amplified significantly and result in significant test accuracy variance, comparable to the test accuracy variance due to stochasticity in SGD. We show how this is likely traced to instabilities of the optimization dynamics that are restrained, i.e., localized over iterations and regions of the weight tensor space. We do this by presenting a theoretical framework using numerical analysis of partial differential equations (PDE), and analyzing the gradient descent PDE of convolutional neural networks (CNNs). We show that it is stable only under certain conditions on the learning rate and weight decay. We show that rather than blowing up when the conditions are violated, the instability can be restrained. We show this is a consequence of the non-linear PDE associated with the gradient descent of the CNN, whose local linearization changes when over-driving the step size of the discretization, resulting in a stabilizing effect. We link restrained instabilities to the recently discovered Edge of Stability (EoS) phenomena, in which the stable step size predicted by classical theory is exceeded while continuing to optimize the loss and still converging. Because restrained instabilities occur at the EoS, our theory provides new predictions about the EoS, in particular, the role of regularization and the dependence on the network complexity.",1.0,0.8164539337158203,True,0.3775406687981454,0.5969973012569829,True
MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image Editing,"Text-guided image editing is widely needed in daily life, ranging from personal use to professional applications such as Photoshop. However, existing methods are either zero-shot or trained on an automatically synthesized dataset, which contains a high volume of noise. Thus, they still require lots of manual tuning to produce desirable outcomes in practice. To address this issue, we introduce MagicBrush (https://osu-nlp-group.github.io/MagicBrush/), the first large-scale, manually annotated dataset for instruction-guided real image editing that covers diverse scenarios: single-turn, multi-turn, mask-provided, and mask-free editing. MagicBrush comprises over 10K manually annotated triplets (source image, instruction, target image), which supports trainining large-scale text-guided image editing models. We fine-tune InstructPix2Pix on MagicBrush and show that the new model can produce much better images according to human evaluation. We further conduct extensive experiments to evaluate current image editing baselines from multiple dimensions including quantitative, qualitative, and human evaluations. The results reveal the challenging nature of our dataset and the gap between current baselines and real-world editing needs.",1.0,0.8137611746788025,True,0.3775406687981454,0.595650921738474,True
Reward Scale Robustness for Proximal Policy Optimization via DreamerV3 Tricks,"Most reinforcement learning methods rely heavily on dense, well-normalized environment rewards. DreamerV3 recently introduced a model-based method with a number of tricks that mitigate these limitations, achieving state-of-the-art on a wide range of benchmarks with a single set of hyperparameters. This result sparked discussion about the generality of the tricks, since they appear to be applicable to other reinforcement learning algorithms. Our work applies DreamerV3's tricks to PPO and is the first such empirical study outside of the original work. Surprisingly, we find that the tricks presented do not transfer as general improvements to PPO. We use a high quality PPO reference implementation and present extensive ablation studies totaling over 10,000 A100 hours on the Arcade Learning Environment and the DeepMind Control Suite. Though our experiments demonstrate that these tricks do not generally outperform PPO, we identify cases where they succeed and offer insight into the relationship between the implementation tricks. In particular, PPO with these tricks performs comparably to PPO on Atari games with reward clipping and significantly outperforms PPO without reward clipping.",1.0,0.9168097376823425,True,0.3775406687981454,0.647175203240244,True
BEER: Fast O(1/T) Rate for Decentralized Nonconvex Optimization with Communication Compression,"Communication efficiency has been widely recognized as the bottleneck for large-scale decentralized machine learning applications in multi-agent or federated environments. To tackle the communication bottleneck, there have been many efforts to design communication-compressed algorithms for decentralized nonconvex optimization, where the clients are only allowed to communicate a small amount of quantized information (aka bits) with their neighbors over a predefined graph topology. Despite significant efforts, the state-of-the-art algorithm in the nonconvex setting still suffers from a slower rate of convergence $O((G/T)^{2/3})$ compared with their uncompressed counterpart, where $G$ measures the data heterogeneity across different clients, and $T$ is the number of communication rounds. This paper proposes BEER, which adopts communication compression with gradient tracking, and shows it converges at a faster rate of $O(1/T)$. This significantly improves over the state-of-the-art rate, by matching the rate without compression even under arbitrary data heterogeneity. Numerical experiments are also provided to corroborate our theory and confirm the practical superiority of BEER in the data heterogeneous regime.",0.8,0.8409945368766785,True,0.3318122278318339,0.5864033823542562,True
Stochastic $L^\natural$-convex Function Minimization,,1.0,0.7754596471786499,True,0.3775406687981454,0.5765001579883977,True
Differentially Private Learning Needs Hidden State (Or Much Faster Convergence),"Prior work on differential privacy analysis of randomized SGD algorithms relies on composition theorems, where the implicit (unrealistic) assumption is that the internal state of the iterative algorithm is revealed to the adversary. As a result, the R\'enyi DP bounds derived by such composition-based analyses linearly grow with the number of training epochs. When the internal state of the algorithm is hidden, we prove a converging privacy bound for noisy stochastic gradient descent (on strongly convex smooth loss functions). We show how to take advantage of privacy amplification by sub-sampling and randomized post-processing, and prove the dynamics of privacy bound for""shuffle and partition""and""sample without replacement""stochastic mini-batch gradient descent schemes. We prove that, in these settings, our privacy bound converges exponentially fast and is substantially smaller than the composition bounds, notably after a few number of training epochs. Thus, unless the DP algorithm converges fast, our privacy analysis shows that hidden state analysis can significantly amplify differential privacy.",0.8,0.7988603711128235,True,0.3318122278318339,0.5653362994723287,True
Bridging the Gap from Asymmetry Tricks to Decorrelation Principles in Non-contrastive Self-supervised Learning,,1.0,0.7963898181915283,True,0.3775406687981454,0.5869652434948369,True
A Mean-Field Game Approach to Cloud Resource Management with Function Approximation,,1.0,0.9371917843818665,True,0.3775406687981454,0.657366226590006,True
Combinatorial Pure Exploration with Bottleneck Reward Function and its Extension to General Reward Functions,"In this paper, we study the Combinatorial Pure Exploration problem with the Bottleneck reward function (CPE-B) under the fixed-confidence (FC) and fixed-budget (FB) settings. In CPE-B, given a set of base arms and a collection of subsets of base arms (super arms) following a certain combinatorial constraint, a learner sequentially plays a base arm and observes its random reward, with the objective of finding the optimal super arm with the maximum bottleneck value, defined as the minimum expected reward of the base arms contained in the super arm. CPE-B captures a variety of practical scenarios such as network routing in communication networks, and its \emph{unique challenges} fall on how to utilize the bottleneck property to save samples and achieve the statistical optimality. None of the existing CPE studies (most of them assume linear rewards) can be adapted to solve such challenges, and thus we develop brand-new techniques to handle them. For the FC setting, we propose novel algorithms with optimal sample complexity for a broad family of instances and establish a matching lower bound to demonstrate the optimality (within a logarithmic factor). For the FB setting, we design an algorithm which achieves the state-of-the-art error probability guarantee and is the first to run efficiently on fixed-budget path instances, compared to existing CPE algorithms. Our experimental results on the top-$k$, path and matching instances validate the empirical superiority of the proposed algorithms over their baselines.",1.0,0.8553215265274048,True,0.3775406687981454,0.6164310976627752,True
Multi-Stage Influence Function,"Multi-stage training and knowledge transfer, from a large-scale pretraining task to various finetuning tasks, have revolutionized natural language processing and computer vision resulting in state-of-the-art performance improvements. In this paper, we develop a multi-stage influence function score to track predictions from a finetuned model all the way back to the pretraining data. With this score, we can identify the pretraining examples in the pretraining task that contribute most to a prediction in the finetuning task. The proposed multi-stage influence function generalizes the original influence function for a single model in (Koh & Liang, 2017), thereby enabling influence computation through both pretrained and finetuned models. We study two different scenarios with the pretrained embeddings fixed or updated in the finetuning tasks. We test our proposed method in various experiments to show its effectiveness and potential applications.",1.0,0.8803098797798157,True,0.3775406687981454,0.6289252742889806,True
Making a (Counterfactual) Difference One Rationale at a Time,"Rationales, snippets of extracted text that explain an inference, have emerged as a popular framework for interpretable natural language processing (NLP). Rationale models typically consist of two cooperating modules: a selector and a classifier with the goal of maximizing the mutual information (MMI) between the""selected""text and the document label. Despite their promises, MMI-based methods often pick up on spurious text patterns and result in models with nonsensical behaviors. In this work, we investigate whether counterfactual data augmentation (CDA), without human assistance, can improve the performance of the selector by lowering the mutual information between spurious signals and the document label. Our counterfactuals are produced in an unsupervised fashion using class-dependent generative models. From an information theoretic lens, we derive properties of the unaugmented dataset for which our CDA approach would succeed. The effectiveness of CDA is empirically evaluated by comparing against several baselines including an improved MMI-based rationale schema on two multi aspect datasets. Our results show that CDA produces rationales that better capture the signal of interest.",0.8,0.9397920966148376,True,0.3318122278318339,0.6358021622233357,True
Time-Reversed Dissipation Induces Duality Between Minimizing Gradient Norm and Function Value,"In convex optimization, first-order optimization methods efficiently minimizing function values have been a central subject study since Nesterov's seminal work of 1983. Recently, however, Kim and Fessler's OGM-G and Lee et al.'s FISTA-G have been presented as alternatives that efficiently minimize the gradient magnitude instead. In this paper, we present H-duality, which represents a surprising one-to-one correspondence between methods efficiently minimizing function values and methods efficiently minimizing gradient magnitude. In continuous-time formulations, H-duality corresponds to reversing the time dependence of the dissipation/friction term. To the best of our knowledge, H-duality is different from Lagrange/Fenchel duality and is distinct from any previously known duality or symmetry relations. Using H-duality, we obtain a clearer understanding of the symmetry between Nesterov's method and OGM-G, derive a new class of methods efficiently reducing gradient magnitudes of smooth convex functions, and find a new composite minimization method that is simpler and faster than FISTA-G.",1.0,0.8949483633041382,True,0.3775406687981454,0.6362445160511419,True
Functional Adversarial Attacks,"We propose functional adversarial attacks, a novel class of threat models for crafting adversarial examples to fool machine learning models. Unlike a standard $\ell_p$-ball threat model, a functional adversarial threat model allows only a single function to be used to perturb input features to produce an adversarial example. For example, a functional adversarial attack applied on colors of an image can change all red pixels simultaneously to light red. Such global uniform changes in images can be less perceptible than perturbing pixels of the image individually. For simplicity, we refer to functional adversarial attacks on image colors as ReColorAdv, which is the main focus of our experiments. We show that functional threat models can be combined with existing additive ($\ell_p$) threat models to generate stronger threat models that allow both small, individual perturbations and large, uniform changes to an input. Moreover, we prove that such combinations encompass perturbations that would not be allowed in either constituent threat model. In practice, ReColorAdv can significantly reduce the accuracy of a ResNet-32 trained on CIFAR-10. Furthermore, to the best of our knowledge, combining ReColorAdv with other attacks leads to the strongest existing attack even after adversarial training. An implementation of ReColorAdv is available at this https URL .",1.0,0.9106373190879822,True,0.3775406687981454,0.6440889939430638,True
StEik: Stabilizing the Optimization of Neural Signed Distance Functions and Finer Shape Representation,"We present new insights and a novel paradigm (StEik) for learning implicit neural representations (INR) of shapes. In particular, we shed light on the popular eikonal loss used for imposing a signed distance function constraint in INR. We show analytically that as the representation power of the network increases, the optimization approaches a partial differential equation (PDE) in the continuum limit that is unstable. We show that this instability can manifest in existing network optimization, leading to irregularities in the reconstructed surface and/or convergence to sub-optimal local minima, and thus fails to capture fine geometric and topological structure. We show analytically how other terms added to the loss, currently used in the literature for other purposes, can actually eliminate these instabilities. However, such terms can over-regularize the surface, preventing the representation of fine shape detail. Based on a similar PDE theory for the continuum limit, we introduce a new regularization term that still counteracts the eikonal instability but without over-regularizing. Furthermore, since stability is now guaranteed in the continuum limit, this stabilization also allows for considering new network structures that are able to represent finer shape detail. We introduce such a structure based on quadratic layers. Experiments on multiple benchmark data sets show that our new regularization and network are able to capture more precise shape details and more accurate topology than existing state-of-the-art.",1.0,0.7334545850753784,True,0.3775406687981454,0.555497626936762,True
HOGWILD!-Gibbs can be PanAccurate,"Asynchronous Gibbs sampling has been recently shown to be fast-mixing and an accurate method for estimating probabilities of events on a small number of variables of a graphical model satisfying Dobrushin's condition~\cite{DeSaOR16}. We investigate whether it can be used to accurately estimate expectations of functions of {\em all the variables} of the model. Under the same condition, we show that the synchronous (sequential) and asynchronous Gibbs samplers can be coupled so that the expected Hamming distance between their (multivariate) samples remains bounded by $O(\tau \log n),$ where $n$ is the number of variables in the graphical model, and $\tau$ is a measure of the asynchronicity. A similar bound holds for any constant power of the Hamming distance. Hence, the expectation of any function that is Lipschitz with respect to a power of the Hamming distance, can be estimated with a bias that grows logarithmically in $n$. Going beyond Lipschitz functions, we consider the bias arising from asynchronicity in estimating the expectation of polynomial functions of all variables in the model. Using recent concentration of measure results~\cite{DaskalakisDK17,GheissariLP17,GotzeSS18}, we show that the bias introduced by the asynchronicity is of smaller order than the standard deviation of the function value already present in the true model. We perform experiments on a multi-processor machine to empirically illustrate our theoretical findings.",1.5,0.9162537455558777,True,0.5,0.7081268727779388,True
(Amplified) Banded Matrix Factorization: A unified approach to private training,"Matrix factorization (MF) mechanisms for differential privacy (DP) have substantially improved the state-of-the-art in privacy-utility-computation tradeoffs for ML applications in a variety of scenarios, but in both the centralized and federated settings there remain instances where either MF cannot be easily applied, or other algorithms provide better tradeoffs (typically, as $\epsilon$ becomes small). In this work, we show how MF can subsume prior state-of-the-art algorithms in both federated and centralized training settings, across all privacy budgets. The key technique throughout is the construction of MF mechanisms with banded matrices (lower-triangular matrices with at most $\hat{b}$ nonzero bands including the main diagonal). For cross-device federated learning (FL), this enables multiple-participations with a relaxed device participation schema compatible with practical FL infrastructure (as demonstrated by a production deployment). In the centralized setting, we prove that banded matrices enjoy the same privacy amplification results as the ubiquitous DP-SGD algorithm, but can provide strictly better performance in most scenarios -- this lets us always at least match DP-SGD, and often outperform it.",0.8,0.7836773991584778,True,0.3318122278318339,0.5577448134951558,True
Zap Q-Learning With Nonlinear Function Approximation,"The Zap stochastic approximation (SA) algorithm was introduced recently as a means to accelerate convergence in reinforcement learning algorithms. While numerical results were impressive, stability (in the sense of boundedness of parameter estimates) was established in only a few special cases. This class of algorithms is generalized in this paper, and stability is established under very general conditions. This general result can be applied to a wide range of algorithms found in reinforcement learning. Two classes are considered in this paper: (i)The natural generalization of Watkins' algorithm is not always stable in function approximation settings. Parameter estimates may diverge to infinity even in the \textit{linear} function approximation setting with a simple finite state-action MDP. Under mild conditions, the Zap SA algorithm provides a stable algorithm, even in the case of \textit{nonlinear} function approximation. (ii) The GQ algorithm of Maei et.~al.~2010 is designed to address the stability challenge. Analysis is provided to explain why the algorithm may be very slow to converge in practice. The new Zap GQ algorithm is stable even for nonlinear function approximation.",1.0,0.878334105014801,True,0.3775406687981454,0.6279373869064733,True
Zippy LL(1) parsing with derivatives,"In this paper, we present an efficient, functional, and formally verified parsing algorithm for LL(1) context-free expressions based on the concept of derivatives of formal languages. Parsing with derivatives is an elegant parsing technique, which, in the general case, suffers from cubic worst-case time complexity and slow performance in practice. We specialise the parsing with derivatives algorithm to LL(1) context-free expressions, where alternatives can be chosen given a single token of lookahead. We formalise the notion of LL(1) expressions and show how to efficiently check the LL(1) property. Next, we present a novel linear-time parsing with derivatives algorithm for LL(1) expressions operating on a zipper-inspired data structure. We prove the algorithm correct in Coq and present an implementation as a part of Scallion, a parser combinators framework in Scala with enumeration and pretty printing capabilities.",0.8,0.9789995551109314,True,0.3318122278318339,0.6554058914713826,True
HipHop.js: (A)Synchronous reactive web programming,"We present HipHop.js, a synchronous reactive language that adds synchronous concurrency and preemption to JavaScript. Inspired from Esterel, HipHop.js simplifies the programming of non-trivial temporal behaviors as found in complex web interfaces or IoT controllers and the cooperation between synchronous and asynchronous activities. HipHop.js is compiled into plain sequential JavaScript and executes on unmodified runtime environments. We use three examples to present and discuss HipHop.js: a simple web login form to introduce the language and show how it differs from JavaScript, and two real life examples, a medical prescription pillbox and an interactive music system that show why concurrency and preemption help programming such temporal applications.",0.8,0.9465538859367371,True,0.3318122278318339,0.6391830568842854,True
"Composable, sound transformations of nested recursion and loops","Scheduling transformations reorder a program’s operations to improve locality and/or parallelism. The polyhedral model is a general framework for composing and applying instance-wise scheduling transformations for loop-based programs, but there is no analogous framework for recursive programs. This paper presents an approach for composing and applying scheduling transformations—like inlining, interchange, and code motion—to nested recursive programs. This paper describes the phases of the approach—representing dynamic instances, composing and applying transformations, reasoning about correctness—and shows that these techniques can verify the soundness of composed transformations.",1.0,0.9278043508529663,True,0.3775406687981454,0.6526725098255559,True
Instruction punning: lightweight instrumentation for x86-64,"Existing techniques for injecting probes into running applications are limited; they either fail to support probing arbitrary locations, or to support scalable, rapid toggling of probes. We introduce a new technique on x86-64, called instruction punning, which allows scalable probes at any instruction. The key idea is that when we inject a jump instruction, the relative address of the jump serves simultaneously as data and as an instruction sequence. We show that this approach achieves probe invocation overheads of only a few dozen cycles, and probe activation/deactivation costs that are cheaper than a system call, even when all threads in the system are both invoking probes and toggling them.",1.0,0.9720528721809387,True,0.3775406687981454,0.6747967704895421,True
Modular divide-and-conquer parallelization of nested loops,"We propose a methodology for automatic generation of divide-and-conquer parallel implementations of sequential nested loops. We focus on a class of loops that traverse read-only multidimensional collections (lists or arrays) and compute a function over these collections. Our approach is modular, in that, the inner loop nest is abstracted away to produce a simpler loop nest for parallelization. The summarized version of the loop nest is then parallelized. The main challenge addressed by this paper is that to perform the code transformations necessary in each step, the loop nest may have to be augmented (automatically) with extra computation to make possible the abstraction and/or the parallelization tasks. We present theoretical results to justify the correctness of our modular approach, and algorithmic solutions for automation. Experimental results demonstrate that our approach can parallelize highly non-trivial loop nests efficiently.",1.0,0.7233281135559082,True,0.3775406687981454,0.5504343911770269,True
To-many or to-one? all-in-one! efficient purely functional multi-maps with type-heterogeneous hash-tries,"An immutable multi-map is a many-to-many map data structure with expected fast insert and lookup operations. This data structure is used for applications processing graphs or many-to-many relations as applied in compilers, runtimes of programming languages, or in static analysis of object-oriented systems. Collection data structures are assumed to carefully balance execution time of operations with memory consumption characteristics and need to scale gracefully from a few elements to multiple gigabytes at least. When processing larger in-memory data sets the overhead of the data structure encoding itself becomes a memory usage bottleneck, dominating the overall performance. In this paper we propose AXIOM, a novel hash-trie data structure that allows for a highly efficient and type-safe multi-map encoding by distinguishing inlined values of singleton sets from nested sets of multi-mappings. AXIOM strictly generalizes over previous hash-trie data structures by supporting the processing of fine-grained type-heterogeneous content on the implementation level (while API and language support for type-heterogeneity are not scope of this paper). We detail the design and optimizations of AXIOM and further compare it against state-of-the-art immutable maps and multi-maps in Java, Scala and Clojure. We isolate key differences using microbenchmarks and validate the resulting conclusions on a case study in static analysis. AXIOM reduces the key-value storage overhead by 1.87x; with specializing and inlining across collection boundaries it improves by 5.1x.",1.8,0.8998991250991821,True,0.574442516811659,0.7371708209554206,True
Scooter & Sidecar: a domain-specific approach to writing secure database migrations,"Web applications often handle large amounts of sensitive user data. Modern secure web frameworks protect this data by (1) using declarative languages to specify security policies alongside database schemas and (2) automatically enforcing these policies at runtime. Unfortunately, these frameworks do not handle the very common situation in which the schemas or the policies need to evolve over time---and updates to schemas and policies need to be performed in a carefully coordinated way. Mistakes during schema or policy migrations can unintentionally leak sensitive data or introduce privilege escalation bugs. In this work, we present a domain-specific language (Scooter) for expressing schema and policy migrations, and an associated SMT-based verifier (Sidecar) which ensures that migrations are secure as the application evolves. We describe the design of Scooter and Sidecar and show that our framework can be used to express realistic schemas, policies, and migrations, without giving up on runtime or verification performance.",0.8,0.978452205657959,True,0.3318122278318339,0.6551322167448964,True
Synthesis of divide and conquer parallelism for loops,"Divide-and-conquer is a common parallel programming skeleton supported by many cross-platform multithreaded libraries, and most commonly used by programmers for parallelization. The challenges of producing (manually or automatically) a correct divide-and-conquer parallel program from a given sequential code are two-fold: (1) assuming that a good solution exists where individual worker threads execute a code identical to the sequential one, the programmer has to provide the extra code for dividing the tasks and combining the partial results (i.e. joins), and (2) the sequential code may not be suitable for divide-and-conquer parallelization as is, and may need to be modified to become a part of a good solution. We address both challenges in this paper. We present an automated synthesis technique to synthesize correct joins and an algorithm for modifying the sequential code to make it suitable for parallelization when necessary. This paper focuses on class of loops that traverse a read-only collection and compute a scalar function over that collection. We present theoretical results for when the necessary modifications to sequential code are possible, theoretical guarantees for the algorithmic solutions presented here, and experimental evaluation of the approach's success in practice and the quality of the produced parallel programs.",1.0,0.970143735408783,True,0.3775406687981454,0.6738422021034642,True
FunTAL: reasonably mixing a functional language with assembly,"We present FunTAL, the first multi-language system to formalize safe interoperability between a high-level functional language and low-level assembly code while supporting compositional reasoning about the mix. A central challenge in developing such a multi-language is bridging the gap between assembly, which is staged into jumps to continuations, and high-level code, where subterms return a result. We present a compositional stack-based typed assembly language that supports components, comprised of one or more basic blocks, that may be embedded in high-level contexts. We also present a logical relation for FunTAL that supports reasoning about equivalence of high-level components and their assembly replacements, mixed-language programs with callbacks between languages, and assembly components comprised of different numbers of basic blocks.",1.0,0.9814826846122742,True,0.3775406687981454,0.6795116767052098,True
Futhark: purely functional GPU-programming with nested parallelism and in-place array updates,"Futhark is a purely functional data-parallel array language that offers a machine-neutral programming model and an optimising compiler that generates OpenCL code for GPUs. This paper presents the design and implementation of three key features of Futhark that seek a suitable middle ground with imperative approaches. First, in order to express efficient code inside the parallel constructs, we introduce a simple type system for in-place updates that ensures referential transparency and supports equational reasoning. Second, we furnish Futhark with parallel operators capable of expressing efficient strength-reduced code, along with their fusion rules. Third, we present a flattening transformation aimed at enhancing the degree of parallelism that (i) builds on loop interchange and distribution but uses higher-order reasoning rather than array-dependence analysis, and (ii) still allows further locality-of-reference optimisations. Finally, an evaluation on 16 benchmarks demonstrates the impact of the language and compiler features and shows application-level performance competitive with hand-written GPU code.",1.0,0.8638232350349426,True,0.3775406687981454,0.6206819519165441,True
Randomized Functions with High Round Complexity,,1.0,0.8185396790504456,True,0.3775406687981454,0.5980401739242955,True
On One-Way Functions and Sparse Languages,,1.0,0.7692633271217346,True,0.3775406687981454,0.5734019979599401,True
(Pseudo) Random Quantum States with Binary Phase,"We prove a quantum information-theoretic conjecture due to Ji, Liu and Song (CRYPTO  2018)  which suggested that a uniform superposition with random binary phase is statistically indistinguishable from a Haar random state. That is, any polynomial number of copies of the aforementioned state is within exponentially small trace distance from the same number of copies of a Haar random state.",0.8,0.918642520904541,True,0.3318122278318339,0.6252273743681874,True
Private Constrained PRFs (and More) from LWE,,0.8,0.7703753709793091,True,0.3318122278318339,0.5510937994055715,True
When Does Functional Encryption Imply Obfuscation?,,1.3,0.8810023069381714,True,0.45016600268752216,0.6655841548128467,True
Serverless in the Wild: Characterizing and Optimizing the Serverless Workload at a Large Cloud Provider,"Function as a Service (FaaS) has been gaining popularity as a way to deploy computations to serverless backends in the cloud. This paradigm shifts the complexity of allocating and provisioning resources to the cloud provider, which has to provide the illusion of always-available resources (i.e., fast function invocations without cold starts) at the lowest possible resource cost. Doing so requires the provider to deeply understand the characteristics of the FaaS workload. Unfortunately, there has been little to no public information on these characteristics. Thus, in this paper, we first characterize the entire production FaaS workload of Azure Functions. We show for example that most functions are invoked very infrequently, but there is an 8-order-of-magnitude range of invocation frequencies. Using observations from our characterization, we then propose a practical resource management policy that significantly reduces the number of function coldstarts,while spending fewerresources than state-of-the-practice policies.",1.0,0.7364234924316406,True,0.3775406687981454,0.5569820806148931,True
ClickNF: a Modular Stack for Custom Network Functions,"Network function virtualization has recently allowed specialized equipment to be replaced with equivalent software implementation. The Click router was a first step in this direction, defining a modular platform for generalized packet processing. Despite its major impact, however, Click does not provides native L4 implementation and only uses nonblocking I/O, limiting its scope to L2-L3 network functions. To overcome these limitations we introduce ClickNF, which provides modular transport and application-layer building blocks for the development of middleboxes and server-side network functions. We evaluate ClickNF to highlight its state-of-theart performance and showcase its modularity by composing complex functions from simple elements. ClickNF is open source and publicly available.",1.0,0.7677527070045471,True,0.3775406687981454,0.5726466879013463,True
Faastlane: Accelerating Function-as-a-Service Workflows,"In FaaS workﬂows, a set of functions implement application logic by interacting and exchanging data among themselves. Contemporary FaaS platforms execute each function of a workﬂow in separate containers. When functions in a workﬂow interact, the resulting latency slows execution. Faastlane minimizes function interaction latency by striving to execute functions of a workﬂow as threads within a single process of a container instance, which eases data sharing via simple load / store instructions. For FaaS workﬂows that operate on sensitive data, Faastlane provides lightweight thread-level isolation domains using Intel Memory Protection Keys (MPK). While threads ease sharing, implementations of languages such as Python and Node.js (widely used in FaaS applications) disallow concurrent execution of threads. Faastlane dynamically identiﬁes opportunities for parallelism in FaaS workﬂows and fork processes (instead of threads) or spawns new container instances to concurrently execute parallel functions of a workﬂow. We implemented Faastlane atop Apache OpenWhisk and show that it accelerates work-ﬂow instances by up to 15 × , and reduces function interaction latency by up to 99 . 95% compared to OpenWhisk.",1.0,0.8897495269775391,True,0.3775406687981454,0.6336450978878423,True
HetPipe: Enabling Large DNN Training on (Whimpy) Heterogeneous GPU Clusters through Integration of Pipelined Model Parallelism and Data Parallelism,"Deep Neural Network (DNN) models have continuously been growing in size in order to improve the accuracy and quality of the models. Moreover, for training of large DNN models, the use of heterogeneous GPUs is inevitable due to the short release cycle of new GPU architectures. In this paper, we investigate how to enable training of large DNN models on a heterogeneous GPU cluster that possibly includes whimpy GPUs that, as a standalone, could not be used for training. We present a DNN training system, HetPipe (Heterogeneous Pipeline), that integrates pipelined model parallelism (PMP) with data parallelism (DP). In HetPipe, a group of multiple GPUs, called a virtual worker, processes minibatches in a pipelined manner, and multiple such virtual workers employ data parallelism for higher performance. We also propose a novel parameter synchronization model, which we refer to as Wave Synchronous Parallel (WSP) to accommodate both PMP and DP for virtual workers, and provide convergence proof of WSP. Our experimental results on a given heterogeneous setting show that with HetPipe, DNN models converge up to 49% faster compared to the state-of-the-art DP technique.",0.8,0.8707380890846252,True,0.3318122278318339,0.6012751584582295,True
From Laptop to Lambda: Outsourcing Everyday Jobs to Thousands of Transient Functional Containers,"We present gg, a framework and a set of command-line tools that helps people execute everyday applications--e.g., software compilation, unit tests, video encoding, or object recognition--using thousands of parallel threads on a cloud-functions service to achieve near-interactive completion times. In the future, instead of running these tasks on a laptop, or keeping a warm cluster running in the cloud, users might push a button that spawns 10,000 parallel cloud functions to execute a large job in a few seconds from start. gg is designed to make this practical and easy. 
 
With gg, applications express a job as a composition of lightweight OS containers that are individually transient (lifetimes of 1-60 seconds) and functional (each container is hermetically sealed and deterministic). gg takes care of instantiating these containers on cloud functions, loading dependencies, minimizing data movement, moving data between containers, and dealing with failure and stragglers. 
 
We ported several latency-sensitive applications to run on gg and evaluated its performance. In the best case, a distributed compiler built on gg outperformed a conventional tool (icecc) by 2-5×, without requiring a warm cluster running continuously. In the worst case, gg was within 20% of the hand-tuned performance of an existing tool for video encoding (ExCamera).",1.0,0.8115145564079285,True,0.3775406687981454,0.594527612603037,True
Your Coflow has Many Flows: Sampling them for Fun and Speed,"Coflow scheduling improves data-intensive application performance by improving their networking performance. State-of-the-art online coflow schedulers in essence approximate the classic Shortest-Job-First (SJF) scheduling by learning the coflow size online. In particular, they use multiple priority queues to simultaneously accomplish two goals: to sieve long coflows from short coflows, and to schedule short coflows with high priorities. Such a mechanism pays high overhead in learning the coflow size: moving a large coflow across the queues delays small and other large coflows, and moving similar-sized coflows across the queues results in inadvertent round-robin scheduling. 
 
We propose Philae, a new online coflow scheduler that exploits the spatial dimension of coflows, i.e., a coflow has many flows, to drastically reduce the overhead of coflow size learning. Philae pre-schedules sampled flows of each coflow and uses their sizes to estimate the average flow size of the coflow. It then resorts to Shortest Coflow First, where the notion of shortest is determined using the learned coflow sizes and coflow contention. We show that the sampling-based learning is robust to flow size skew and has the added benefit of much improved scalability from reduced coordinator-local agent interactions. Our evaluation using an Azure testbed, a publicly available production cluster trace from Facebook shows that compared to the prior art Aalo, Philae reduces the coflow completion time (CCT) in average (P90) cases by 1.50× (8.00×) on a 150-node testbed and 2.72× (9.78×) on a 900-node testbed. Evaluation using additional traces further demonstrates Philae's robustness to flow size skew.",1.0,0.9859867095947266,True,0.3775406687981454,0.681763689196436,True
Optimistic Concurrency Control for Real-world Go Programs (Extended Version with Appendix),"We present a source-to-source transformation framework, GOCC, that consumes lock-based pessimistic concurrency programs in the Go language and transforms them into optimistic concurrency programs that use Hardware Transactional Memory (HTM). The choice of the Go language is motivated by the fact that concurrency is a first-class citizen in Go, and it is widely used in Go programs. GOCC performs rich inter-procedural program analysis to detect and filter lock-protected regions and performs AST-level code transformation of the surrounding locks when profitable. Profitability is driven by both static analyses of critical sections and dynamic analysis via execution profiles. A custom HTM library, using perceptron, learns concurrency behavior and dynamically decides whether to use HTM in the rewritten lock/unlock points. Given the rich history of transactional memory research but its lack of adoption in any industrial setting, we believe this workflow, which ultimately produces source-code patches, is more apt for industry-scale adoption. Results on widely adopted Go libraries and applications demonstrate significant (up to 10x) and scalable performance gains resulting from our automated transformation while avoiding major performance regressions.",0.8,0.8112440705299377,True,0.3318122278318339,0.5715281491808858,True
"Graph Isomorphism for (H1, H2)-free Graphs: An Almost Complete Dichotomy","We resolve the computational complexity of Graph IsomorphIsm for classes of graphs characterized by two forbidden induced subgraphs H 1 and H 2 for all but six pairs (H 1 , H 2 ) . Schweitzer had previously shown that the number of open cases was finite, but without specifying the open cases. Grohe and Schweitzer proved that Graph IsomorphIsm is polynomial-time solvable on graph classes of bounded cliquewidth. Our work combines known results such as these with new results. By exploiting a relationship between Graph IsomorphIsm and clique-width, we simultaneously reduce the number of open cases for boundedness of clique-width for (H 1 , H 2 )-free graphs to five.",0.8,0.7958009243011475,True,0.3318122278318339,0.5638065760664907,True
Fast deterministic algorithms for computing all eccentricities in (hyperbolic) Helly graphs,"A graph is Helly if every family of pairwise intersecting balls has a nonempty common intersection. The class of Helly graphs is the discrete analogue of the class of hyperconvex metric spaces. It is also known that every graph isometrically embeds into a Helly graph, making the latter an important class of graphs in Metric Graph Theory. We study diameter, radius and all eccentricity computations within the Helly graphs. Under plausible complexity assumptions, neither the diameter nor the radius can be computed in truly subquadratic time on general graphs. In contrast to these negative results, it was recently shown that the radius and the diameter of an n-vertex m-edge Helly graph G can be computed with high probability in Õ(m √ n) time (i.e., subquadratic in n + m). In this paper, we improve that result by presenting a deterministic O(m √ n) time algorithm which computes not only the radius and the diameter but also all vertex eccentricities in a Helly graph. Furthermore, we give a parameterized linear-time algorithm for this problem on Helly graphs, with the parameter being the Gromov hyperbolicity δ. More specifically, we show that the radius and a central vertex of an m-edge δ-hyperbolic Helly graph G can be computed in O(δm) time and that all vertex eccentricities in G can be computed in O(δ 2 m) time. To show this more general result, we heavily use our new structural properties obtained for Helly graphs.",0.8,0.9063839316368103,True,0.3318122278318339,0.6190980797343221,True
Busy Time Scheduling on a Bounded Number of Machines (Extended Abstract),,0.8,0.7907811999320984,True,0.3318122278318339,0.5612967138819661,True
One Detector to Rule Them All: Towards a General Deepfake Attack Detection Framework,"Deep learning-based video manipulation methods have become widely accessible to the masses. With little to no effort, people can quickly learn how to generate deepfake (DF) videos. While deep learning-based detection methods have been proposed to identify specific types of DFs, their performance suffers for other types of deepfake methods, including real-world deepfakes, on which they are not sufficiently trained. In other words, most of the proposed deep learning-based detection methods lack transferability and generalizability. Beyond detecting a single type of DF from benchmark deepfake datasets, we focus on developing a generalized approach to detect multiple types of DFs, including deepfakes from unknown generation methods such as DeepFake-in-the-Wild (DFW) videos. To better cope with unknown and unseen deepfakes, we introduce a Convolutional LSTM-based Residual Network (CLRNet), which adopts a unique model training strategy and explores spatial as well as the temporal information in a deepfakes. Through extensive experiments, we show that existing defense methods are not ready for real-world deployment. Whereas our defense method (CLRNet) achieves far better generalization when detecting various benchmark deepfake methods (97.57% on average). Furthermore, we evaluate our approach with a high-quality DeepFake-in-the-Wild dataset, collected from the Internet containing numerous videos and having more than 150,000 frames. Our CLRNet model demonstrated that it generalizes well against high-quality DFW videos by achieving 93.86% detection accuracy, outperforming existing state-of-the-art defense methods by a considerable margin.",1.8,0.6301152110099792,True,0.574442516811659,0.6022788639108192,True
Exploring HTTP Header Manipulation In-The-Wild,"Headers are a critical part of HTTP, and it has been shown that they are increasingly subject to middlebox manipulation. Although this is well known, little is understood about the general regional and network trends that underpin these manipulations. In this paper, we collect data on thousands of networks to understand how they intercept HTTP headers in-the-wild. Our analysis reveals that 25% of measured ASes modify HTTP headers. Beyond this, we witness distinct trends among different regions and AS types; e.g., we observe high numbers of cache headers in poorly connected regions. Finally, we perform an in-depth analysis of the types of manipulations and how they differ across regions.",1.0,0.930749773979187,True,0.3775406687981454,0.6541452213886663,True
International Workshop on Modeling Social Media (MSM 2018) Chairs' Welcome & Organization,"Bienvenue! It is our great pleasure to welcome you to the WWW 2018 International Workshop on Modeling Social Media (MSM'2018) - Applying Machine Learning and AI for Modeling Social Media. This is our 9th edition of our workshop. Social networks such as Facebook, Twitter, and LinkedIn have paved the way for generating huge amount of diverse, streaming bit data in a short period of time. Such social media data require the application of big data analytics to produce meaningful information to both information consumers and data generators. Machine learning and AI techniques are particularly effective in situations where deep and predictive insights need to be uncovered from such social media data sets that are large, diverse and fast changing. The workshop aims to address machine learning and AI methods, frameworks, algorithms, and the applications and evaluation of these approaches on social media, big data and the web. We received 11 papers from all around the world covering a broad range of topics, and we accepted 8 papers resulting in a 72% acceptance rate. We evaluated them regarding relevance, quality, and novelty, selecting 4 full papers and 4 short papers. Each paper was reviewed by 3 reviewers and then decisions were made from the reviews and the workshop chairs.",1.6,0.7879325747489929,True,0.52497918747894,0.6564558811139665,True
iStory: Intelligent Storytelling with Social Data,"The production of knowledge from ever increasing amount of social data is seen by many organizations as an increasingly important capability that can complement the traditional analytics sources. Examples include extracting knowledge and deriving insights from social data to improve government services, predict intelligence activities, personalize the advertisements in elections and improve national security and public health. Understanding social data can be challenging as the analysis goal can be subjective. In this context, storytelling is considered as an appropriate metaphor as it facilitates understanding and surfacing insights which is embedded within the data. In this paper, we focus on the research problem of ‘understanding the social data’ in general and more particularly the curation, summarization and presentation of large amounts of social data. The goal is to enable intelligent narrative construction based on the important features (extracted and ranked automatically) and enable storytelling at multiple levels and from different views using novel summarization techniques. We implement an interactive storytelling dashboard, namely iStory, and focus on a motivating scenario for analyzing Urban Social Issues from Twitter as it relates to the Australian Government Budget, to highlight how storytelling can significantly facilitate understanding social data.",1.0,0.7804124355316162,True,0.3775406687981454,0.5789765521648809,True
Caught in the Game: On the History and Evolution of Web Browser Gaming,"Web browsers have come a long way since their inception, evolving from a simple means of displaying text documents over the network to complex software stacks with advanced graphics and network capabilities. As personal computers grew in popularity, developers jumped at the opportunity to deploy cross-platform games with centralized management and a low barrier to entry. Simply going to the right address is now enough to start a game. From text-based to GPU-powered 3D games, browser gaming has evolved to become a strong alternative to traditional console and mobile-based gaming, targeting both casual and advanced gamers. Browser technology has also evolved to accommodate more demanding applications, sometimes even supplanting functions typically left to the operating system. Today, websites display rich, computationally intensive, hardware-accelerated graphics, allowing developers to build ever-more impressive applications and games. In this paper, we present the evolution of browser gaming and the technologies that enabled it, from the release of the first text-based games in the early 1990s to current open-world and game-engine-powered browser games. We discuss the societal impact of browser gaming and how it has allowed a new target audience to access digital gaming. Finally, we review the potential future evolution of the browser gaming industry.",1.0,0.9630842804908752,True,0.3775406687981454,0.6703124746445104,True
Some Recipes Can Do More Than Spoil Your Appetite: Analyzing the Security and Privacy Risks of IFTTT Recipes,"The use of end-user programming, such as if-this-then-that (IFTTT), is becoming increasingly common. Services like IFTTT allow users to easily create new functionality by connecting arbitrary Internet-of-Things (IoT) devices and online services using simple if-then rules, commonly known as recipes. However, such convenience at times comes at the cost of security and privacy risks for end users. To gain an in-depth understanding of the potential security and privacy risks, we build an information-flow model to analyze how often IFTTT recipes involve potential integrity or secrecy violations. Our analysis finds that around 50% of the 19,323 unique recipes we examined are potentially unsafe, as they contain a secrecy violation, an integrity violation, or both. We next categorize the types of harm that these potentially unsafe recipes can cause to users. After manually examining a random selection of potentially unsafe recipes, we find that recipes can not only lead to harms such as personal embarrassment but can also be exploited by an attacker, e.g., to distribute malware or carry out denial-of-service attacks. The use of IoT devices and services like IFTTT is expected only to grow in the near future; our analysis suggests users need to be both informed about and protected from these emerging threats to which they could be unwittingly exposing themselves.",1.0,0.7503057718276978,True,0.3775406687981454,0.5639232203129216,True
"Friendly, Appealing or Both?: Characterising User Experience in Sponsored Search Landing Pages","Many of today's websites have recognised the importance of mobile friendly pages to keep users engaged and to provide a satisfying user experience. However, next to the experience provided by the sites themselves, advertisements, when clicked, present users with landing pages that are not necessarily mobile friendly. We explore what type of features are able to characterise the mobile friendliness of sponsored search ad landing pages. To have a complete understanding of the mobile ad experience in terms of layout and visual appearance, we also explore the notion of the ad page aesthetic appeal. We design and collect annotations for both dimensions on a large set of ads, and find that mobile friendliness and aesthetics represent different notions. We perform a comprehensive study of the effectiveness of over 120 features on the tasks of friendliness and aesthetics prediction. We find that next to general page size, HTML, and resource usage based features, several features based on the visual composition of landing pages are important to determine mobile friendliness and aesthetics. We demonstrate the additional benefit of these various types of features by comparing against the mobile friendliness guidelines provided by W3C. Finally, we use our models to determine the state of landing page mobile friendliness and aesthetics on a large sample of advertisements of a major internet company.",1.1,0.8581703305244446,True,0.401312339887548,0.6297413352059963,True
"The WWW (and an H) of Mobile Application Usage in the City: The What, Where, When, and How","People fulfill their informational needs through smartphones, however, little is known regarding how the urban fabric and the activities that take place in it affect the usage of mobile applications. In this regard, starting from an anonymized dataset of Deep Packet Inspection (DPI) data from the largest telecommunications operator in Chile, we focus on the following questions: What are the most popular applications used in the city Where are they spatially clustered When does an application is more frequently used And How does the urban context and the mobility patterns relate to application usage As a result, we observed that specific applications present high spatial clustering, while the most popular services are geographically dispersed throughout the entire city. Clusters appear in places of high floating population; however, hotspots vary in space depending on the application. Interestingly, we found that commuting plays an important role, both in terms of rush hours and transportation infrastructure. We present a discussion on these results, focusing on how the physical space and the daily commuting routine affect the pattern of data consumption and represent an important aspect in mobile users behavioral studies.",0.8,0.937537670135498,True,0.3318122278318339,0.6346749489836659,True
Lie to Me: Abusing the Mobile Content Sharing Service for Fun and Profit,"Online content sharing is a widely used feature in Android apps. In this paper, we observe a new Fake-Share attack that adversaries can abuse existing content sharing services to manipulate the displayed source of shared content to bypass the content review of targeted Online Social Apps (OSAs) and induce users to click on the shared fraudulent content. We show that seven popular content-sharing services (including WeChat, AliPay, and KakaoTalk) are vulnerable to such an attack. To detect this kind of attack and explore whether adversaries have leveraged it in the wild, we propose DeFash, a multi-granularity detection tool including static analysis and dynamic verification. The extensive in-the-lab and in-the-wild experiments demonstrate that DeFash is effective in detecting such attacks. We have identified 51 real-world apps involved in Fake-Share attacks. We have further harvested over 24K Sharing Identification Information (SIIs) that can be abused by attackers. It is hence urgent for our community to take actions to detect and mitigate this kind of attack.",1.0,0.9949333667755127,True,0.3775406687981454,0.6862370177868291,True
EMOFIEL: Mapping Emotions of Relationships in a Story,"We present EMOFIEL, a system that identifies characters and scenes in a story from a fictional narrative summary, generates appropriate scene descriptions, identifies the emotion flow between a given directed pair of story characters in each interaction, and organizes them along the story timeline. These emotions are identified using two emotion modelling approaches: categorical and dimensional emotion models. The generated plots show that in a particular scene, two characters can share multiple emotions together with different intensity. Furthermore, the directionality of the emotion can be captured as well, depending on which character is more dominant in each interaction. EMOFIEL provides a web-based GUI that allows users to query the annotated stories to explore the emotion mapping of a given character pair throughout a given story, and to explore scenes for which a certain emotion peaks.",1.0,0.7643783688545227,True,0.3775406687981454,0.5709595188263341,True
The Surprising Performance of Simple Baselines for Misinformation Detection,"As social media becomes increasingly prominent in our day to day lives, it is increasingly important to detect informative content and prevent the spread of disinformation and unverified rumours. While many sophisticated and successful models have been proposed in the literature, they are often compared with older NLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the performance of a broad set of modern transformer-based language models and show that with basic fine-tuning, these models are competitive with and can even significantly outperform recently proposed state-of-the-art methods. We present our framework as a baseline for creating and evaluating new methods for misinformation detection. We further study a comprehensive set of benchmark datasets, and discuss potential data leakage and the need for careful design of the experiments and understanding of datasets to account for confounding variables. As an extreme case example, we show that classifying only based on the first three digits of tweet ids, which contain information on the date, gives state-of-the-art performance on a commonly used benchmark dataset for fake news detection –Twitter16. We provide a simple tool to detect this problem and suggest steps to mitigate it in future datasets.",1.0,0.8647522926330566,True,0.3775406687981454,0.6211464807156011,True
Genre-Controllable Story Generation via Supervised Contrastive Learning,"While controllable text generation has received attention due to the recent advances in large-scale pre-trained language models, there is a lack of research that focuses on story-specific controllability. To address this, we present Story Control via Supervised Contrastive learning model (SCSC), to create a story conditioned on genre. For this, we design a supervised contrastive objective combined with log-likelihood objective, to capture the intrinsic differences among the stories in different genres. The results of our automated evaluation and user study demonstrate that the proposed method is effective in genre-controlled story generation.",1.0,0.7853795289993286,True,0.3775406687981454,0.5814600988987371,True
Why are Hyperlinks Blue?: A deep dive into browser hyperlink color history,"The internet has ingrained itself into every aspect of our lives, but there's one aspect of the digital world that some take for granted. Did you ever notice that many links, specifically hyperlinks, are blue? When a coworker casually asked me why links are blue, I was stumped. As a user experience designer who has created websites since 2001, I've always made my links blue. I have advocated for the specific shade of blue, and for the consistent application of blue, yes, but I've never stopped and wondered, why are links blue? It was just a fact of life. Grass is green and hyperlinks are blue. Culturally, we associate links with the color blue so much that in 2016, when Google changed its links to black, it created quite a disruption [1]. But now, I find myself all consumed by the question, WHY are links blue? WHO decided to make them blue? WHEN was this decision made, and HOW has this decision made such a lasting impact? Mosaic, an early browser released by Marc Andreessen and Eric Bina on January 23, 1993 [2], had blue hyperlinks. To truly understand the origin and evolution of hyperlinks, I took a journey through technology history and interfaces to explore how links were handled before color monitors, and how interfaces and hyperlinks rapidly evolved once color monitors became an option.",2.1,0.6138297319412231,True,0.6456563062257954,0.6297430190835093,True
GIF: A General Graph Unlearning Strategy via Influence Function,"With the greater emphasis on privacy and security in our society, the problem of graph unlearning — revoking the influence of specific data on the trained GNN model, is drawing increasing attention. However, ranging from machine unlearning to recently emerged graph unlearning methods, existing efforts either resort to retraining paradigm, or perform approximate erasure that fails to consider the inter-dependency between connected neighbors or imposes constraints on GNN structure, therefore hard to achieve satisfying performance-complexity trade-offs. In this work, we explore the influence function tailored for graph unlearning, so as to improve the unlearning efficacy and efficiency for graph unlearning. We first present a unified problem formulation of diverse graph unlearning tasks w.r.t. node, edge, and feature. Then, we recognize the crux to the inability of traditional influence function for graph unlearning, and devise Graph Influence Function (GIF), a model-agnostic unlearning method that can efficiently and accurately estimate parameter changes in response to a ϵ -mass perturbation in deleted data. The idea is to supplement the objective of the traditional influence function with an additional loss term of the influenced neighbors due to the structural dependency. Further deductions on the closed-form solution of parameter changes provide a better understanding of the unlearning mechanism. We conduct extensive experiments on four representative GNN models and three benchmark datasets to justify the superiority of GIF for diverse graph unlearning tasks in terms of unlearning efficacy, model utility, and unlearning efficiency. Our implementations are available at https://github.com/wujcan/GIF-torch/.",1.0,0.7986934185028076,True,0.3775406687981454,0.5881170436504766,True
REST: Robust and Efficient Neural Networks for Sleep Monitoring in the Wild,"In recent years, significant attention has been devoted towards integrating deep learning technologies in the healthcare domain. However, to safely and practically deploy deep learning models for home health monitoring, two significant challenges must be addressed: the models should be (1) robust against noise; and (2) compact and energy-efficient. We propose Rest , a new method that simultaneously tackles both issues via 1) adversarial training and controlling the Lipschitz constant of the neural network through spectral regularization while 2) enabling neural network compression through sparsity regularization. We demonstrate that Rest produces highly-robust and efficient models that substantially outperform the original full-sized models in the presence of noise. For the sleep staging task over single-channel electroencephalogram (EEG), the Rest model achieves a macro-F1 score of 0.67 vs. 0.39 achieved by a state-of-the-art model in the presence of Gaussian noise while obtaining 19 × parameter reduction and 15 × MFLOPS reduction on two large, real-world EEG datasets. By deploying these models to an Android application on a smartphone, we quantitatively observe that Rest allows models to achieve up to 17 × energy reduction and 9 × faster inference. We open source the code repository with this paper: https://github.com/duggalrahul/REST.",1.0,0.730644702911377,True,0.3775406687981454,0.5540926858547612,True
Hidden Indicators of Collective Intelligence in Crowdfunding,"Extensive literature argues that crowds possess essential collective intelligence benefits that allow superior decision-making by untrained individuals working in low-information environments. Classic wisdom of crowds theory is based on evidence gathered from studying large groups of diverse and independent decision-makers. Yet, most human decisions are reached in online settings of interconnected like-minded people that challenge these criteria. This observation raises a key question: Are there surprising expressions of collective intelligence online? Here, we explore whether crowds furnish collective intelligence benefits in crowdfunding systems. Crowdfunding has grown and diversified quickly over the past decade, expanding from funding aspirant creative works and supplying pro-social donations to enabling large citizen-funded urban projects and providing commercial interest-based unsecured loans. Using nearly 10 million loan contributions from a market-dominant lending platform, we find evidence for collective intelligence indicators in crowdfunding. Our results, which are based on a two-stage Heckman selection model, indicate that opinion diversity and the speed at which funds are contributed predict who gets funded and who repays, even after accounting for traditional measures of creditworthiness. Moreover, crowds work consistently well in correctly assessing the outcome of high-risk projects. Finally, diversity and speed serve as early warning signals when inferring fundraising based solely on the initial part of the campaign. Our findings broaden the field of crowd-aware system design and inform discussions about the augmentation of traditional financing systems with tech innovations.",1.0,0.7586978077888489,True,0.3775406687981454,0.5681192382934972,True
"A Triangle Framework among Subgraph Isomorphism, Pharmacophore and Structure-function Relationship","Coronavirus disease 2019 (COVID-19) has gained utmost attention in the current time from academic research and industrial practices because it continues to rage in many countries. Pharmacophore models exploit molecule topological similarity as well as functional compound similarity so that they can be reliable via the application of the concept of bioisosterism. In this work, we analyze the targets for coronavirus protein and the structure of RNA virus variation, thereby complete the safety and pharmacodynamic action evaluation of small-molecule anti-coronavirus oral drugs. Common pharmacophore identifications could be converted into subgraph querying problems, due to chemical structures can also be converted to graphs, which is a knotty problem pressing for a solution. We adopt simplified representation pharmacophore graphs by reducing complete molecular structures to abstracts to detect isomorphic topological patterns and further to improve the substructure retrieval efficiency. Our threefold architecture subgraph isomorphism-based method retrieves query subgraphs over large graphs. First, by means of extracting a sequence of subgraphs to be matched and then comparing the number of vertex and edge between the potential isomorphic subgraphs and the query graph, we lower the computational scaling markedly. Afterwards, the directed vertex and edge matrix recording vertex and edge positional relation, directional relation and distance relation has been created. Then, on the basis of permutation theorem, we calculate the row sum of vertex and edge adjacency matrix of query graph and potential sample. Finally, according to equinumerosity theorem, we check the eigenvalues of the vertex and edge adjacency matrices of the two graphs are equinumerous. The topological distance could be calculated based on the graph isomorphism and the subgraph isomorphism can be implemented after the combination of the subgraph. The proposed quantitative structure–function relationships (QSFR) approach can be effectively applied for pharmacophoric abstract patterns identification. The framework of new drug development for covid-19 has been established based on this triangle.",1.0,0.7731614708900452,True,0.3775406687981454,0.5753510698440953,True
How Public Is My Private Life?: Privacy in Online Dating,"Online dating services let users expand their dating pool beyond their social network and specify important characteristics of potential partners. To assess compatibility, users share personal information -- e.g., identifying details or sensitive opinions about sexual preferences or worldviews -- in profiles or in one-on-one communication. Thus, participating in online dating poses inherent privacy risks. How people reason about these privacy risks in modern online dating ecosystems has not been extensively studied. We present the results of a survey we designed to examine privacy-related risks, practices, and expectations of people who use or have used online dating, then delve deeper using semi-structured interviews. We additionally analyzed 400 Tinder profiles to explore how these issues manifest in practice. Our results reveal tensions between privacy and competing user values and goals, and we demonstrate how these results can inform future designs.",1.1,0.7467420697212219,True,0.401312339887548,0.574027204804385,True
Augmenting Intelligence with Humans-in-the-Loop (HumL@WWW2018) Chairs' Welcome & Organization,"It is our great pleasure to welcome you to the WWW 2018 Augmenting Intelligence with Humans-in-the-loop (HumL@WWW2018), http://w3id.org/huml/HumL-WWW2018/ The workshop program includes two invited talks. Praveen Paritosh (Google Research) explores the right incentives to motivate human contribution to create knowledge resources. Elena Simperl (University of Southampton) surveys how humans and bots contribute together to the development of the Wikidata knowledge graph. Seven full papers and one short paper were accepted, covering a wide range of topics related to the efficient and effective combination of the strong sides of both machine and crowd computation. Empirical results were provided and discussed with respect to (1) methods for data quality ensurance and labeling task efficiency, (2) the role of gamification elements for improving crowd performance as well as the role of quantum mathematics to simulate human behavior.",1.6,0.8448559045791626,True,0.52497918747894,0.6849175460290513,True
Almost (Weighted) Proportional Allocations for Indivisible Chores✱✱,"In this paper, we study how to fairly allocate a set of indivisible chores to a number of (asymmetric) agents with additive cost functions. We consider the fairness notion of (weighted) proportionality up to any item (PROPX), and show that a (weighted) PROPX allocation always exists and can be computed efficiently. We also consider the partial information setting, where the algorithms can only use agents’ ordinal preferences. We design algorithms that achieve 2-approximate (weighted) PROPX, and the approximation ratio is optimal. We complement the algorithmic results by investigating the relationship between (weighted) PROPX and other fairness notions such as maximin share and AnyPrice share, and bounding the social welfare loss by enforcing the allocations to be (weighted) PROPX.",0.8,0.8408032059669495,True,0.3318122278318339,0.5863077168993917,True
Human Dimensions of Animal Exploitation: Towards Understanding the International Wildlife Trade and Selfie-Tourism on Twitter,"This study investigates statements of participation in an exploitative animal activity on social media website Twitter. The data include social posts (tweets) related to two exploited species - the sloth (N=32,119), and the elephant (N=15,160). Tweets for each of these case studies were examined and labeled. The initial results reveal several features of interaction with exploited species. Namely, there are a high number of tweets indicating that individuals participated in exploited species activities during vacations in destinations that double as native countries for the exploited species. The data also indicate that a large number of exploited species activities take place at fairs, carnivals, and circuses. These initial results shed light on the trends in human participation in activities with exploited species. These findings will offer insight to stakeholders seeking to bolster education programs and quantify the level of animal exploitation.",1.0,0.918578565120697,True,0.3775406687981454,0.6480596169594213,True
Using Web Data to Reveal 22-Year History of Sneaker Designs,"Web data and computational models can play important roles in analyzing cultural trends. The current study presents an analysis of 23,492 sneaker images and metadata collected from a global reselling shop, StockX.com. Based on data encompassing 22 years from 1999 to 2020, we propose a sneaker design index that helps track changes in the design characteristics of sneakers using a contrastive learning method. Our data suggest that sneaker designs have been employing brighter colors and lower hue and saturation values over time. We also observe how popular brands have continued to build their unique identities in shape-related design space. The embedding analysis also predicts which sneakers will likely see a high premium in the reselling market, suggesting viable algorithm-driven investment and design strategies. The current work is one of the first publicly available studies to analyze product design evolution over a long historical period and has implications for the novel use of Web data to understand cultural patterns that are otherwise difficult to assess.",1.0,0.776032030582428,True,0.3775406687981454,0.5767863496902867,True
Hypermedea: A Framework for Web (of Things) Agents,"Hypermedea is an extension of the JaCaMo multi-agent programming framework to act on Web and Web of Things environments. In this demo, the performance of Hypermedea’s Linked Data navigation and planning components are evaluated, both encapsulating computation-intensive algorithms.",0.8,0.8033656477928162,True,0.3318122278318339,0.567588937812325,True
Re-coding Black Mirror Chairs' Welcome & Organization,"This volume of proceedings presents the papers from the 2nd edition of the interdisciplinary workshop Re-coding Black Mirror, held on April 24, 2018 in Lyon, France and co-located with The WEB Conference (WWW2018). Participating to the topical debate of data ethics and algorithmic governance, Re-coding Black Mirror offers the research community tools to reflect on its role in the construction of the technological future and the potential societal implications. The workshop becomes a venue for computer scientists, data scientists and social scientists to create bridges of knowledge. The complexity of the societal phenomena emerging from the development in web technologies urge for interdisciplinary collaboration. Following the slightly futuristic approach to technology of the British-made sci-fi series Black Mirror, we called scientists to create their dystopic scenarios developed from their own existing technologies. Through this thought experiment, researchers considered potential ethical and social risks of technological advancements offering in some cases possible solutions.",0.8,0.9697830677032471,True,0.3318122278318339,0.6507976477675405,True
A History of Diversity in The Web (Conference),"The Web has grown considerably since its inception and opened up a multitude of opportunities for people all around the world for work, leisure, and learning. These opportunities were limited to western audiences earlier on, but globalization has now put almost the entire world online. While there is a growing social understanding and acknowledgment of various gender and ethnic groups in society, we still have a long way to go toward achieving equity in gender and ethnic representations, especially in the workplace. In this paper, we attempt to quantify the diversity and evenness in terms of gender and ethnicity of The WebConference participants over its 30 year history. The choice is motivated by the monumental contribution of this conference to the evolution of the web. In particular, we study the gender and ethnicity of program committee members, authors and other speakers at the conference between 1994-2022. We also generate the co-speaker network over the three decades to study how closely the speakers work with each other. Our findings show that we still have a long way to go before achieving fair representation at The WebConference, especially for female participants and individuals from non-White, non-Asian ethnicities.",1.8,0.7444625496864319,True,0.574442516811659,0.6594525332490455,True
Facebook (A)Live?: Are Live Social Broadcasts Really Broadcasts?,"The era of live-broadcast is back but with two major changes. First, unlike traditional TV broadcasts, content is now streamed over the Internet enabling it to reach a wider audience. Second, due to various user-generated content platforms it has become possible for anyone to get involved, streaming their own content to the world. This emerging trend of going live usually happens via social platforms, where users perform live social broadcasts predominantly from their mobile devices, allowing their friends (and the general public) to engage with the stream in real-time. With the growing popularity of such platforms, the burden on the current Internet infrastructure is therefore expected to multiply. With this in mind, we explore one such prominent platform - Facebook Live. We gather 3TB of data, representing one month of global activity and explore the characteristics of live social broadcast. From this, we derive simple yet effective principles which can decrease the network burden. We then dissect global and hyper-local properties of the video while on-air, by capturing the geography of the broadcasters or the users who produce the video and the viewers or the users who interact with it. Finally, we study the social engagement while the video is live and distinguish the key aspects when the same video goes on-demand. A common theme throughout the paper is that, despite its name, many attributes of Facebook Live deviate from both the concepts of live and broadcast.",1.9,0.6589791178703308,True,0.598687660112452,0.6288333889913914,True
Stupify: A Hardware Countermeasure of KRACKs in WPA2 using Physically Unclonable Functions,"A digital communication network is typically the backbone of world wide web and web based applications. Security protocols, specifically in wireless network has undergone several rounds of modifications and upgrades in order to prevent supplicants (or clients) or authenticators (or access points) from attackers either sitting physically around the wireless coverage area or being hooked up to a wired network connected to wireless clients. The latest security protocol in the series is WPA2 (Wi-Fi Protected Access II) which has been implemented in most of the Wi-Fi stations (clients or access points) that are being used in traditional wireless networking as well as recent IoT and CPS devices. Recently a severe replay attack named Key Reinstallation AttaCK (KRACK) has shown that the handshake in WPA2 protocol suite can be compromised and enforce the stations to reuse an old set of initialization vectors (IVs). In this work, we propose to use an unconventional hardware security primitive named Physically Unclonable Functions (PUFs) to nullify the impact of KRACK attack by ensuring a mutual authentication before establishing the communication between the authenticators and the supplicants. In this demo, we show i) how the hardware intrinsic properties of a device can be leveraged to embed a PUF instance in each device, ii) a working prototype of PUF based authentication protocol using Z-Turn board integrated with dual-core ARM Cortex-A9 processor and Artix-7 FPGA, iii) how this protocol can be integrated with existing handshake protocol in WiFi network to resist against KRACK attacks.",1.0,0.9123892188072205,True,0.3775406687981454,0.644964943802683,True
HopRank: How Semantic Structure Influences Teleportation in PageRank (A Case Study on BioPortal),"This paper introduces HopRank, an algorithm for modeling human navigation on semantic networks. HopRank leverages the assumption that users know or can see the whole structure of the network. Therefore, besides following links, they also follow nodes at certain distances (i.e., k-hop neighborhoods), and not at random as suggested by PageRank, which assumes only links are known or visible. We observe such preference towards k-hop neighborhoods on BioPortal, one of the leading repositories of biomedical ontologies on the Web. In general, users navigate within the vicinity of a concept. But they also “jump” to distant concepts less frequently. We fit our model on 11 ontologies using the transition matrix of clickstreams, and show that semantic structure can influence teleportation in PageRank. This suggests that users-to some extent-utilize knowledge about the underlying structure of ontologies, and leverage it to reach certain pieces of information. Our results help the development and improvement of user interfaces for ontology exploration.",0.8,0.9226745963096619,True,0.3318122278318339,0.6272434120707479,True
SoBigData: Social Mining & Big Data Ecosystem,"One of the most pressing and fascinating challenges scientists face today, is understanding the complexity of our globally interconnected society. The big data arising from the digital breadcrumbs of human activities has the potential of providing a powerful social microscope, which can help us understand many complex and hidden socio-economic phenomena. Such challenge requires high-level analytics, modeling and reasoning across all the social dimensions above. There is a need to harness these opportunities for scientific advancement and for the social good, compared to the currently prevalent exploitation of big data for commercial purposes or, worse, social control and surveillance. The main obstacle to this accomplishment, besides the scarcity of data scientists, is the lack of a large-scale open ecosystem where big data and social mining research can be carried out. The SoBigData Research Infrastructure (RI) provides an integrated ecosystem for ethic-sensitive scientific discoveries and advanced applications of social data mining on the various dimensions of social life as recorded by ""big data"". The research community uses the SoBigData facilities as a ""secure digital wind-tunnel"" for large-scale social data analysis and simulation experiments. SoBigData promotes repeatable and open science and supports data science research projects by providing: (i) an ever-growing, distributed data ecosystem for procurement, access and curation and management of big social data, to underpin social data mining research within an ethic-sensitive context; (ii) an ever-growing, distributed platform of interoperable, social data mining methods and associated skills: tools, methodologies and services for mining, analysing, and visualising complex and massive datasets, harnessing the techno-legal barriers to the ethically safe deployment of big data for social mining; (iii) an ecosystem where protection of personal information and the respect for fundamental human rights can coexist with a safe use of the same information for scientific purposes of broad and central societal interest. SoBigData has a dedicated ethical and legal board, which is implementing a legal and ethical framework.",0.8,0.8710206151008606,True,0.3318122278318339,0.6014164214663472,True
First Workshop on Hypermedia Multi-Agent Systems (HyperAgents 2019) Workshop Chairs' Welcome & Organization Listing,"Hypermedia is increasingly used in Web service design, particularly in Web of Things and Linked Data systems: the dynamic and open nature of these systems requires components to be deployed and to evolve independently from one another, which makes the use of static Web APIs that are manually integrated by developers simply impractical (in any such systems). This evolution raises new challenges: to discover, consume, and integrate hypermedia APIs at runtime, clients have to become increasingly autonomous in pursuit of their design goals. Such autonomous systems have been studied to a large extent in research on multi-agent systems (MAS). To consolidate the evolution of hypermedia APIs, it is now necessary to have comprehensive discussions on integrating hypermedia systems and MAS, which we call Hypermedia MAS.",1.6,0.8509159684181213,True,0.52497918747894,0.6879475779485307,True
Hack for Hire: Exploring the Emerging Market for Account Hijacking,"Email accounts represent an enticing target for attackers, both for the information they contain and the root of trust they provide to other connected web services. While defense-in-depth approaches such as phishing detection, risk analysis, and two-factor authentication help to stem large-scale hijackings, targeted attacks remain a potent threat due to the customization and effort involved. In this paper, we study a segment of targeted attackers known as “hack for hire” services to understand the playbook that attackers use to gain access to victim accounts. Posing as buyers, we interacted with 27 English, Russian, and Chinese blackmarket services, only five of which succeeded in attacking synthetic (though realistic) identities we controlled. Attackers primarily relied on tailored phishing messages, with enough sophistication to bypass SMS two-factor authentication. However, despite the ability to successfully deliver account access, the market exhibited low volume, poor customer service, and had multiple scammers. As such, we surmise that retail email hijacking has yet to mature to the level of other criminal market segments.",1.0,0.9179791808128357,True,0.3775406687981454,0.6477599248054906,True
Self- and Cross-Excitation in Stack Exchange Question & Answer Communities,"In this paper, we quantify the impact of self- and cross-excitation on the temporal development of user activity in Stack Exchange Question & Answer (Q&A) communities. We study differences in user excitation between growing and declining Stack Exchange communities, and between those dedicated to STEM and humanities topics by leveraging Hawkes processes. We find that growing communities exhibit early stage, high cross-excitation by a small core of power users reacting to the community as a whole, and strong long-term self-excitation in general and cross-excitation by casual users in particular, suggesting community openness towards less active users. Further, we observe that communities in the humanities exhibit long-term power user cross-excitation, whereas in STEM communities activity is more evenly distributed towards casual user self-excitation. We validate our findings via permutation tests and quantify the impact of these excitation effects with a range of prediction experiments. Our work enables researchers to quantitatively assess the evolution and activity potential of Q&A communities.",0.8,0.9700385928153992,True,0.3318122278318339,0.6509254103236165,True
"(Mis)Information Dissemination in WhatsApp: Gathering, Analyzing and Countermeasures","WhatsApp has revolutionized the way people communicate and interact. It is not only cheaper than the traditional Short Message Service (SMS) communication but it also brings a new form of mobile communication: the group chats. Such groups are great forums for collective discussions on a variety of topics. In particular, in events of great social mobilization, such as strikes and electoral campaigns, WhatsApp group chats are very attractive as they facilitate information exchange among interested people. Yet, recent events have raised concerns about the spreading of misinformation in WhatsApp. In this work, we analyze information dissemination within WhatsApp, focusing on publicly accessible political-oriented groups, collecting all shared messages during major social events in Brazil: a national truck drivers' strike and the Brazilian presidential campaign. We analyze the types of content shared within such groups as well as the network structures that emerge from user interactions within and cross-groups. We then deepen our analysis by identifying the presence of misinformation among the shared images using labels provided by journalists and by a proposed automatic procedure based on Google searches. We identify the most important sources of the fake images and analyze how they propagate across WhatsApp groups and from/to other Web platforms.",0.8,0.9316867589950562,True,0.3318122278318339,0.631749493413445,True
I’m out of breath from laughing! I think? A dataset of COVID-19 Humor and its toxic variants,"Humor is a cognitive construct that predominantly evokes the feeling of mirth. During the COVID-19 pandemic, the situations that arouse out of the pandemic were so incongruous to the world we knew that even factual statements often had a humorous reaction. In this paper, we present a dataset of 2510 samples hand-annotated with labels such as humor style, type, theme, target and stereotypes formed or exploited while creating the humor in addition to 909 memes. Our dataset comprises Reddit posts, comments, Onion news headlines, real news headlines, and tweets. We evaluate the task of humor detection and maladaptive humor detection on state-of-the-art models namely RoBERTa and GPT-3. The finetuned models trained on our dataset show significant gains over zero-shot models including GPT-3 when detecting humor. Even though GPT-3 is good at generating meaningful explanations, we observed that it fails to detect maladaptive humor due to the absence of overt targets and profanities. We believe that the presented dataset will be helpful in designing computational methods for topical humor processing as it provides a unique sample set to study the theory of incongruity in a post-pandemic world. The data is available to research community at https://github.com/smritae01/Covid19_Humor.",0.8,0.9748302698135376,True,0.3318122278318339,0.6533212488226857,True
Dixit: Interactive Visual Storytelling via Term Manipulation,"In this paper, we introduce Dixit, an interactive visual storytelling system that the user interacts with iteratively to compose a short story for a photo sequence. The user initiates the process by uploading a sequence of photos. Dixit first extracts text terms from each photo which describe the objects (e.g., boy, bike) or actions (e.g., sleep) in the photo, and then allows the user to add new terms or remove existing terms. Dixit then generates a short story based on these terms. Behind the scenes, Dixit uses an LSTM-based model trained on image caption data and FrameNet to distill terms from each image, and utilizes a transformer decoder to compose a context-coherent story. Users change images or terms iteratively with Dixit to create the most ideal story. Dixit also allows users to manually edit and rate stories. The proposed procedure opens up possibilities for interpretable and controllable visual storytelling, allowing users to understand the story formation rationale and to intervene in the generation process.",1.0,0.974196195602417,True,0.3775406687981454,0.6758684322002813,True
No Silk Road for Online Gamers!: Using Social Network Analysis to Unveil Black Markets in Online Games,"Online game involves a very large number of users who are interconnected and interact with each other via the Internet. We studied the characteristics of exchanging virtual goods with real money through the processes called ""real money trading (RMT)"". This exchange might influence online game user behaviors and cause damage to the reputation of game companies. We examined in-game transactions to reveal RMT by constructing a social graph of virtual goods exchanges in an online game and identifying network communities of users. We analyzed approximately 6,000,000 transactions in a popular online game and inferred RMT transactions by comparing the RMT transactions crawled from an out-game market. Our findings are summarized as follows: (1) the size of the RMT market could be approximately estimated; (2) professional RMT providers typically form a specific network structure (either star-shape or chain) in the trading network, which can be used as a clue for tracing RMT transactions; and (3) the observed RMT market has evolved over time into a monopolized market with a small number of large-sized virtual goods providers.",1.3,0.8534865975379944,True,0.45016600268752216,0.6518263001127582,True
"Smaller, Faster & Lighter KNN Graph Constructions","We propose GoldFinger, a new compact and fast-to-compute binary representation of datasets to approximate Jaccard’s index. We illustrate the effectiveness of GoldFinger on the emblematic big data problem of K-Nearest-Neighbor (KNN) graph construction and show that GoldFinger can drastically accelerate a large range of existing KNN algorithms with little to no overhead. As a side effect, we also show that the compact representation of the data protects users’ privacy for free by providing k-anonymity and l-diversity. Our extensive evaluation of the resulting approach on several realistic datasets shows that our approach delivers speedups of up to 78.9% compared to the use of raw data while only incurring a negligible to moderate loss in terms of KNN quality. To convey the practical value of such a scheme, we apply it to item recommendation and show that the loss in recommendation quality is negligible.",0.8,0.7867555618286133,True,0.3318122278318339,0.5592838948302236,True
"How Do Mothers and Fathers Talk About Parenting to Different Audiences?: Stereotypes and Audience Effects: An Analysis of r/Daddit, r/Mommit, and r/Parenting Using Topic Modelling","While major strides have been made towards gender equality in public life, serious inequality remains in the domestic sphere, especially around parenting. The present study analyses discussions about parenting on Reddit (i.e., a content aggregation website) to explore audience effects and gender stereotypes. It suggests a novel method to study topical variation in individuals’ language when interacting with different audiences. Comments posted in 2020 were collected from three parenting subreddits (i.e., topical communities), described as being for fathers (r/Daddit), mothers (r/Mommit), and all parents (r/Parenting). Users posting on r/Parenting and r/Daddit or on r/Parenting and r/Mommit were assumed to identify as fathers or mothers, respectively, allowing gender comparison. Users’ comments on r/Parenting (to a mixed-gender audience) were compared with their comments to single-gender audiences on r/Daddit or r/Mommit using Latent Dirichlet Allocation (LDA) topic modelling. Results show that the most discussed topic among parents is about education and family advice, a topic mainly discussed in the mixed-gender subreddit and more by fathers than mothers. The topic model also indicates that, when it comes to the basic needs of children (sleep, food, and medical care), mothers seem to be more concerned regardless of the audience. In contrast, topics such as birth and pregnancy announcements and physical appearance are more discussed by fathers in the father-centric subreddit. Overall, findings seem to show that mothers are generally more concerned about the practical sides of parenting while fathers’ expressed concerns are more contextual: with other fathers, there seems to be a desire to show their fatherhood and be recognized for it while they discuss education with mothers. These results demonstrate that concerns expressed by parents on Reddit are context-sensitive but also consistent with gender stereotypes, potentially reflecting a persistent gendered and unequal division of labour in parenting.",1.1,0.759813129901886,True,0.401312339887548,0.580562734894717,True
Can You Spot the Fakes?: On the Limitations of User Feedback in Online Social Networks,"Online social networks (OSNs) are appealing platforms for spammers and fraudsters, who typically use fake or compromised accounts to connect with and defraud real users. To combat such abuse, OSNs allow users to report fraudulent profiles or activity. The OSN can then use reporting data to review and/or limit activity of reported accounts. Previous authors have suggested that an OSN can augment its takedown algorithms by identifying a ""trusted set"" of users whose reports are weighted more heavily in the disposition of flagged accounts. Such identification would allow the OSN to improve both speed and accuracy of fake account detection and thus reduce the impact of spam on users. In this work we provide the first public, data-driven assessment of whether the above assumption is true: are some users better at reporting than others? Specifically, is reporting skill both measurable, i.e., possible to distinguish from random guessing; and repeatable, i.e., persistent over repeated sampling? Our main contributions are to develop a statistical framework that describes these properties and to apply this framework to data from LinkedIn, the professional social network. Our data includes member reports of fake profiles as well as the more voluminous, albeit weaker, signal of member responses to connection requests. We find that members demonstrating measurable, repeatable skill in identifying fake profiles do exist but are rare: at most 2.4% of those reporting fakes and at most 1.3% of those rejecting connection requests. We conclude that any reliable ""trusted set"" of members will be too small to have noticeable impact on spam metrics.",1.1,0.9053757786750793,True,0.401312339887548,0.6533440592813137,True
SA-Fusion: Multimodal Fusion Approach for Web-based Human-Computer Interaction in the Wild,"Web-based AR technology has broadened human-computer interaction scenes from traditional mechanical devices and flat screens to the real world, resulting in unconstrained environmental challenges such as complex backgrounds, extreme illumination, depth range differences, and hand-object interaction. The previous hand detection and 3D hand pose estimation methods are usually based on single modality such as RGB or depth data, which are not available in some scenarios in unconstrained environments due to the differences between the two modalities. To address this problem, we propose a multimodal fusion approach, named Scene-Adapt Fusion (SA-Fusion), which can fully utilize the complementarity of RGB and depth modalities in web-based HCI tasks. SA-Fusion can be applied in existing hand detection and 3D hand pose estimation frameworks to boost their performance, and can be further integrated into the prototyping AR system to construct a web-based interactive AR application for unconstrained environments. To evaluate the proposed multimodal fusion method, we conduct two user studies on CUG Hand and DexYCB dataset, to demonstrate its effectiveness in terms of accurately detecting hand and estimating 3D hand pose in unconstrained environments and hand-object interaction.",1.0,0.8036614656448364,True,0.3775406687981454,0.590601067221491,True
Web Mail is not Dead!: It's Just Not Human Anymore,"Many have noticed that personal communications have slowly moved from mail to social media and instant messaging platforms, especially with younger generation [6]. Yet Web Mail traffic continues to steadily grow. A paradox? Not really. We have observed at Yahoo Research that the nature of email traffic has significantly changed in the last two decades, and it is now dominated by machine-generated messages. These messages include hotel newsletters, from which users forgot to unsubscribe, repeated, and often annoying, notifications from a social media site, or critical information such as a flight e-ticket, a purchase invoice, or a telephone bill. In this talk, I first share some elements of this journey that led us to this critical finding that 90% of today's Web Mail is sent by automatic scripts [1]. I then discuss the challenges and opportunities this drastic change offers. First the key challenge: namely, the need for Web mail services to revisit their usage assumptions and their traditional features in light of this change. An obvious example is the ""reply"" button being displayed by default below messages sent from a ""no-reply@"" sender. Another feature is mail classification, which has finally experienced some changes in the last few years, [4]. I then discuss the opportunities in this era of big data. One first insight is that messages that have been generated by a same script, share some semantic commonality. Being able to automatically cluster such messages, and map such clusters into ""templates"" brings great value for discovering meaning, for generalizing findings and predicting behaviors [5]. A second insight is that within this commonality, the differences bring even more value, which allows highlighting what makes individuals unique within a crowd. In particular we discuss extraction techniques that automatically identify these unique elements [2]. Yet, they also present a clear risk in terms of privacy and I describe the absolute need for guaranteeing k-anonymity in our mining techniques, [3]. I conclude by encouraging the research community to explore this new domain of Web mail search and data mining.",1.3,0.7351705431938171,True,0.45016600268752216,0.5926682729406696,True
A Model of Two Tales: Dual Transfer Learning Framework for Improved Long-tail Item Recommendation,"Highly skewed long-tail item distribution is very common in recommendation systems. It significantly hurts model performance on tail items. To improve tail-item recommendation, we conduct research to transfer knowledge from head items to tail items, leveraging the rich user feedback in head items and the semantic connections between head and tail items. Specifically, we propose a novel dual transfer learning framework that jointly learns the knowledge transfer from both model-level and item-level: 1. The model-level knowledge transfer builds a generic meta-mapping of model parameters from few-shot to many-shot model. It captures the implicit data augmentation on the model-level to improve the representation learning of tail items. 2. The item-level transfer connects head and tail items through item-level features, to ensure a smooth transfer of meta-mapping from head items to tail items. The two types of transfers are incorporated to ensure the learned knowledge from head items can be well applied for tail item representation learning in the long-tail distribution settings. Through extensive experiments on two benchmark datasets, results show that our proposed dual transfer learning framework significantly outperforms other state-of-the-art methods for tail item recommendation in hit ratio and NDCG. It is also very encouraging that our framework further improves head items and overall performance on top of the gains on tail items.",1.0,0.9008768200874329,True,0.3775406687981454,0.6392087444427892,True
GraphZoo: A Development Toolkit for Graph Neural Networks with Hyperbolic Geometries,"Hyperbolic spaces have recently gained prominence for representation learning in graph processing tasks such as link prediction and node classification. Several Euclidean graph models have been adapted to work in the hyperbolic space and the variants have shown a significant increase in performance. However, research and development in graph modeling currently involve several tedious tasks with a scope of standardization including data processing, parameter configuration, optimization tricks, and unavailability of public codebases. With the proliferation of new tasks such as knowledge graph reasoning and generation, there is a need in the community for a unified framework that eases the development and analysis of both Euclidean and hyperbolic graph networks, especially for new researchers in the field. To this end, we present a novel framework, GraphZoo, that makes learning, designing and applying graph processing pipelines/models systematic through abstraction over the redundant components. The framework contains a versatile library that supports several hyperbolic manifolds and an easy-to-use modular framework to perform graph processing tasks which aids researchers in different components, namely, (i) reproduce evaluation pipelines of state-of-the-art approaches, (ii) design new hyperbolic or Euclidean graph networks and compare them against the state-of-the-art approaches on standard benchmarks, (iii) add custom datasets for evaluation, (iv) add new tasks and evaluation criteria.",1.0,0.7495439648628235,True,0.3775406687981454,0.5635423168304845,True
With a Little Help from My Friends (and Their Friends): Influence Neighborhoods for Social Recommendations,"Social recommendations have been a very intriguing domain for researchers in the past decade. The main premise is that the social network of a user can be leveraged to enhance the rating-based recommendation process. This has been achieved in various ways, and under different assumptions about the network characteristics, structure, and availability of other information (such as trust, content, etc.) In this work, we create neighborhoods of influence leveraging only the social graph structure. These are in turn introduced in the recommendation process both as a pre-processing step and as a social regularization factor of the matrix factorization algorithm. Our experimental evaluation using real-life datasets demonstrates the effectiveness of the proposed technique.",0.8,0.8876402974128723,True,0.3318122278318339,0.6097262626223531,True
Modeling Dynamic Competition on Crowdfunding Markets,"The often fierce competition on crowdfunding markets can significantly affect project success. While various factors have been considered in predicting the success of crowdfunding projects, to the best knowledge of the authors, the phenomenon of competition has not been investigated. In this paper, we study the competition on crowdfunding markets through data analysis, and propose a probabilistic generative model, Dynamic Market Competition (DMC) model, to capture the competitiveness of projects in crowdfunding. Through an empirical evaluation using the pledging history of past crowdfunding projects, our approach has shown to capture the competitiveness of projects very well, and significantly outperforms several baseline approaches in predicting the daily collected funds of crowdfunding projects, reducing errors by 31.73% to 45.14%. In addition, our analyses on the correlations between project competitiveness, project design factors, and project success indicate that highly competitive projects, while being winners under various setting of project design factors, are particularly impressive with high pledging goals and high price rewards, comparing to medium and low competitive projects. Finally, the competitiveness of projects learned by DMC is shown to be very useful in applications of predicting final success and days taken to hit pledging goal, reaching 85% accuracy and error of less than 7 days, respectively, with limited information at early pledging stage.",1.0,0.8376036882400513,True,0.3775406687981454,0.6075721785190984,True
"Black Hat Trolling, White Hat Trolling, and Hacking the Attention Landscape","In this paper, we analogize the practice of trolling to the practice of hacking. Just as hacking often involves the discovery and exploitation of vulnerabilities in a computer security landscape, trolling frequently involves the discovery and exploitation of vulnerabilities in a media or attention landscape to amplify messages and direct attention. Also like with hacking, we consider the possibility for a range of trolling personas: from black hat trolls who push an agenda that is clearly counter to the interests of the target, to gray hat trolls who exploit vulnerabilities to draw critical attention to unaddressed issues, and white hat trolls who could help proactively disclose vulnerabilities so that attack surface can be reduced. We discuss a variety of trolling techniques from dogpiling to sockpuppetry and also a range of possible interventions.",1.0,0.9940283298492432,True,0.3775406687981454,0.6857844993236943,True
International Workshop on Modeling Social Media (MSM'2019) Chairs' Welcome,"Welcome to the TheWebConf 2019 International Workshop on Modeling Social Media (MSM'2019) Mining, Modeling and Learning from Social Media. We are celebrating our 10 edition (one decade) of our workshop. Social networks such as Facebook, Twitter, and LinkedIn generate huge amounts of data that require the application of big data analytics to produce meaningful information to both information consumers and data generators. Machine learning and AI techniques are particularly effective in situations where deep and predictive insights need to be uncovered from such social media data sets that are large, diverse and fast changing.",0.8,0.7739365696907043,True,0.3318122278318339,0.5528743987612691,True
Who Controls the Internet?: Analyzing Global Threats using Property Graph Traversals,"The Internet is built on top of intertwined network services, e.g., email, DNS, and content distribution networks operated by private or governmental organizations. Recent events have shown that these organizations may, knowingly or unknowingly, be part of global-scale security incidents including state-sponsored mass surveillance programs and large-scale DDoS attacks. For example, in March 2015 the Great Cannon attack has shown that an Internet service provider can weaponize millions of Web browsers and turn them into DDoS bots by injecting malicious JavaScript code into transiting TCP connections. While attack techniques and root cause vulnerabilities are routinely studied, we still lack models and algorithms to study the intricate dependencies between services and providers, reason on their abuse, and assess the attack impact. To close this gap, we present a technique that models services, providers, and dependencies as a property graph. Moreover, we present a taint-style propagation-based technique to query the model, and present an evaluation of our framework on the top 100k Alexa domains.",1.1,0.8086783289909363,True,0.401312339887548,0.6049953344392421,True
Identification of Homographic Pun Location for Pun Understanding,"This paper introduces a novel framework for homographic pun location identification. Two observations, the existence of the support term and the preferred positions of the pun in context, are considered as crucial hints for pun identification. We first nominate the pun candidates, and then select the most probable one based on various strategies. Experimental results show the effectiveness of our method.",1.0,0.9321978688240051,True,0.3775406687981454,0.6548692688110753,True
How New is the (RDF) News?,"Linked Open Data and the RDF format have become the premier method of publishing structured data representing entities and facts. Specifically, media organizations, such as the New York Times and the BBC, have embraced Linked Open Data as a way of providing structured access to traditional media content, including articles, images, and video. To ground RDF entities and predicates in existing Linked Open Data sources, dataset curators provide links for some entities to existing general purpose repositories, such as YAGO and DBpedia, using entity extraction and linking tools. However, these state-of-the-art tools rely on the entities to exist in the knowledge base. How much of the information is actually new and thus unable to be grounded is unclear. In this work, we empirically investigate the prevalence of new entities in news feeds with respect to both public and commercial knowledge graphs.",1.1,0.8084640502929688,True,0.401312339887548,0.6048881950902584,True
Toward An Interdisciplinary Methodology to Solve New (Old) Transportation Problems,"The rising availability of digital traces provides a fertile ground for new solutions to both, new and old problems in cities. Even though a massive data set analyzed with Data Science methods may provide a powerful solution to a problem, its adoption by relevant stakeholders is not guaranteed, due to adoption blockers such as lack of interpretability and transparency. In this context, this paper proposes a preliminary methodology toward bridging two disciplines, Data Science and Transportation, to solve urban problems with methods that are suitable for adoption. The methodology is defined by four steps where people from both disciplines go from algorithm and model definition to the building of a potentially adoptable solution. As case study, we describe how this methodology was applied to define a model to infer commuting trips with mode of transportation from mobile phone data.",0.8,0.7689034938812256,True,0.3318122278318339,0.5503578608565297,True
The Third Workshop on Women in Web Data Science (WinDS '19) Chairs' Welcome & Organization Listing,"It is our great pleasure to welcome you to the WWW 2019 Third Women in Web Data Science (WinDS’19) Workshop. This half-day workshop brings together female faculties, graduate students, research scientists, and industry researchers for an opportunity to connect, exchange ideas, and learn from each other in the field of Data Science. Underrepresented minorities, graduates, and undergraduates interested in pursuing data science and machine learning research are encouraged to participate. While most presenters are women, everybody is invited to attend.",1.6,0.7136201858520508,True,0.52497918747894,0.6192996866654954,True
Did You Really Just Have a Heart Attack?: Towards Robust Detection of Personal Health Mentions in Social Media,"Millions of users share their experiences on social media sites, such as Twitter, which in turn generate valuable data for public health monitoring, digital epidemiology, and other analyses of population health at global scale. The first, critical, task for these applications is classifying whether a personal health event was mentioned, which we call the (PHM) problem. This task is challenging for many reasons, including typically short length of social media posts, inventive spelling and lexicons, and figurative language, including hyperbole using diseases like ""heart attack»» or ""cancer»» for emphasis, and not as a health self-report. This problem is even more challenging for rarely reported, or frequent but ambiguously expressed conditions, such as ""stroke»». To address this problem, we propose a general, robust method for detecting PHMs in social media, which we call WESPAD, that combines lexical, syntactic, word embedding-based, and context-based features. WESPAD is able to generalize from few examples by automatically distorting the word embedding space to most effectively detect the true health mentions. Unlike previously proposed state-of-the-art supervised and deep-learning techniques, WESPAD requires relatively little training data, which makes it possible to adapt, with minimal effort, to each new disease and condition. We evaluate WESPAD on both an established publicly available Flu detection benchmark, and on a new dataset that we have constructed with mentions of multiple health conditions. Our experiments show that WESPAD outperforms the baselines and state-of-the-art methods, especially in cases when the number and proportion of true health mentions in the training data is small.",1.1,0.9266433119773865,True,0.401312339887548,0.6639778259324672,True
Political Polarization and Platform Migration:: A Study of Parler and Twitter Usage by United States of America Congress Members,"Growing dissatisfaction with platform governance decisions at major social media platforms like Twitter, Facebook, and Instagram has led to a number of substantial efforts, originating both on the political right and the political left, to shift to new platforms. In this paper, we examine one of the most impactful of these platform migration efforts, a recent effort primarily on the political right to shift from Twitter to Parler in response to Twitter's increased efforts to flag misinformation in the lead up to the 2020 election in the US. As a case study, we analyze the usage of Parler by all members of the United States Congress and compare that to their usage of Twitter. Even though usage of Parler, even at its peak, was only a small percentage of Twitter usage, Parler usage has been impactful. Specifically, it was linked to the planning of the January 6, 2021 attack on the United States Capitol building. Going forward, Parler itself may not have a large and lasting impact, but it offers important lessons about the relationship between political polarization, platform migration, and the real-world political impacts of platform governance decisions and the splintering of our media landscape.",0.8,0.8230965733528137,True,0.3318122278318339,0.5774544005923238,True
Metadata vs. Ground-truth: A Myth behind the Evolution of Community Detection Methods,"A community detection (CD) method is usually evaluated by what extent it is able to discover the 'ground-truth' community structure of a network. A certain 'node-centric metadata' is used to define the ground-truth partition. However, nodes in real networks often have multiple metadata types (e.g., occupation, location); each can potentially form a ground-truth partition. Our experiment with 10 CD methods on 5 datasets (having multiple metadata-based ground-truth partitions) show that the metadata-based evaluation is misleading because there is no single CD method that can outperform others by detecting all types of metadata-based partitions. We further show that the community structure obtained from the CD methods is usually topologically stronger than any metadata-based partitions. Finally, we suggest a new task-based evaluation framework for CD methods and show that a certain type of CD methods is useful for a certain type of task.",1.0,0.7938154339790344,True,0.3775406687981454,0.58567805138859,True
A Hybrid BitFunnel and Partitioned Elias-Fano Inverted Index,"Search engines encounter a time vs. space trade-off: search responsiveness (i.e., a short query response time) comes at the cost of increased index storage. We propose a hybrid method which uses both (a) the recently published mapping-matrix-style index BitFunnel (BF) for search efficiency, and (b) the state-of-the-art Partitioned Elias-Fano (PEF) inverted-index compression method. We use this proposed hybrid method to minimize time while satisfying a fixed space constraint, and to minimize space while satisfying a fixed time constraint. Each document is stored using either BF or PEF, and we use a local search strategy to find an approximately optimal BF-PEF partition. Since performing full experiments on each candidate BF-PEF partition is impractically slow, we use a regression model to predict the time and space costs resulting from candidate partitions (space accuracy 97.6%; time accuracy 95.2%). Compared with a hybrid mathematical index (Ottaviano et al., 2015), the time cost is reduced by up to 47% without significantly exceeding its size. Compared with three mathematical encoding methods, the hybrid BF-PEF index allows performing list intersection between around 16% to 76% faster (without significantly increasing the index size). Compared with BF, the index size is reduced by 45% while maintaining an intersection time comparable to that of BF.",1.0,0.9203122854232788,True,0.3775406687981454,0.6489264771107122,True
Heterographic Pun Recognition via Pronunciation and Spelling Understanding Gated Attention Network,"Heterographic pun plays a critical role in human writing and literature, which usually has a similar sounding or spelling structure. It is important and difficult research to recognize the heterographic pun because of the ambiguity. However, most existing methods for this task only focus on designing features with rule-based or machine learning methods. In this paper, we propose an end-to-end computational approach - Pronunciation Spelling Understanding Gated Attention (PSUGA) network. For pronunciation, we exploit the hierarchical attention model with phoneme embedding. While for spelling, we consider the character-level, word-level, tag-level, position-level and contextual-level embedding with attention model. To deal with the two parts, we present a gated attention mechanism to control the information integration. We have conducted extensive experiments on SemEval2017 task7 and Pun of the Day datasets. Experimental results show that our approach significantly outperforms state-of-the-art methods.",1.0,0.9173346757888794,True,0.3775406687981454,0.6474376722935125,True
Fighting Against Deepfake: Patch&Pair Convolutional Neural Networks (PPCNN),"In this paper, we propose a novel Patch&Pair Convolutional Neural Networks (PPCNN) to distinguish Deepfake videos or images from real ones. Through the comprehensive evaluations on public datasets, we demonstrate that our model performs better than existing detection methods and show better generalization.",1.6,0.6955892443656921,True,0.52497918747894,0.6102842159223161,True
Outguard: Detecting In-Browser Covert Cryptocurrency Mining in the Wild,"In-browser cryptojacking is a form of resource abuse that leverages end-users' machines to mine cryptocurrency without obtaining the users' consent. In this paper, we design, implement, and evaluate Outguard, an automated cryptojacking detection system. We construct a large ground-truth dataset, extract several features using an instrumented web browser, and ultimately select seven distinctive features that are used to build an SVM classification model. Outguardachieves a 97.9% TPR and 1.1% FPR and is reasonably tolerant to adversarial evasions. We utilized Outguardin the wild by deploying it across the Alexa Top 1M websites and found 6,302 cryptojacking sites, of which 3,600 are new detections that were absent from the training data. These cryptojacking sites paint a broad picture of the cryptojacking ecosystem, with particular emphasis on the prevalence of cryptojacking websites and the shared infrastructure that provides clues to the operators behind the cryptojacking phenomenon.",1.0,0.8094624876976013,True,0.3775406687981454,0.5935015782478734,True
"Rock, Rap, or Reggaeton?: Assessing Mexican Immigrants' Cultural Assimilation Using Facebook Data,","The degree to which Mexican immigrants in the U.S. are assimilating culturally has been widely debated. To examine this question, we focus on musical taste, a key symbolic resource that signals the social positions of individuals. We adapt an assimilation metric from earlier work to analyze self-reported musical interests among immigrants in Facebook. We use the relative levels of interest in musical genres, where a similarity to the host population in musical preferences is treated as evidence of cultural assimilation. Contrary to skeptics of Mexican assimilation, we find significant cultural convergence even among first-generation immigrants, which problematizes their use as assimilative “benchmarks” in the literature. Further, 2nd generation Mexican Americans show high cultural convergence vis-à-vis both Anglos and African-Americans, with the exception of those who speak Spanish. Rather than conforming to a single assimilation path, our findings reveal how Mexican immigrants defy simple unilinear theoretical expectations and illuminate their uniquely heterogeneous character.",1.1,0.8817911744117737,True,0.401312339887548,0.6415517571496608,True
OSNED 2018 Chairs' Welcome & Organization,,0.8,0.8573603630065918,True,0.3318122278318339,0.5945862954192128,True
Influence Function based Data Poisoning Attacks to Top-N Recommender Systems,"Recommender system is an essential component of web services to engage users. Popular recommender systems model user preferences and item properties using a large amount of crowdsourced user-item interaction data, e.g., rating scores; then top-N items that match the best with a user’s preference are recommended to the user. In this work, we show that an attacker can launch a data poisoning attack to a recommender system to make recommendations as the attacker desires via injecting fake users with carefully crafted user-item interaction data. Specifically, an attacker can trick a recommender system to recommend a target item to as many normal users as possible. We focus on matrix factorization based recommender systems because they have been widely deployed in industry. Given the number of fake users the attacker can inject, we formulate the crafting of rating scores for the fake users as an optimization problem. However, this optimization problem is challenging to solve as it is a non-convex integer programming problem. To address the challenge, we develop several techniques to approximately solve the optimization problem. For instance, we leverage influence function to select a subset of normal users who are influential to the recommendations and solve our formulated optimization problem based on these influential users. Our results show that our attacks are effective and outperform existing methods.",1.0,0.8297590017318726,True,0.3775406687981454,0.603649835265009,True
Is Tofu the Cheese of Asia?: Searching for Corresponding Objects across Geographical Areas,"Keyword-based search engines are widely used nowadays for content retrieval. Creating queries is relatively easy when users wish to retrieve content in familiar domains (e.g., information about things within their own country). However, they often struggle when searching in unfamiliar domains (e.g., searching for information related to a foreign country). In this paper, we approach the vocabulary gap problem by allowing users to search by analogical examples, that is, by letting them utilize information in familiar domains to perform search in domains unfamiliar to them. In particular, we focus on geographical domains. We propose to build connections between two different spaces (e.g., USA and Japan) by mapping the distributed word representations in one space with the ones in the other space. We first introduce an effective technique for automatically constructing seed pairs of terms to be used for finding the optimal mapping function. Then we propose general and topic-based transformations of terms from one space to another. We test the performance of the proposed approaches on datasets derived from Wikipedia which are related to two quite diverse countries: Japan and USA.",1.1,0.7860829830169678,True,0.401312339887548,0.5936976614522579,True
"How to Impute Missing Ratings?: Claims, Solution, and Its Application to Collaborative Filtering","Data sparsity is one of the biggest problems faced by collaborative filtering used in recommender systems. Data imputation alleviates the data sparsity problem by inferring missing ratings and imputing them to the original rating matrix. In this paper, we identify the limitations of existing data imputation approaches and suggest three new claims that all data imputation approaches should follow to achieve high recommendation accuracy. Furthermore, we propose a deep-learning based approach to compute imputed values that satisfies all three claims. Based on our hypothesis that most pre-use preferences (e.g., impressions) on items lead to their post-use preferences (e.g., ratings), our approach tries to understand via deep learning how pre-use preferences lead to post-use preferences differently depending on the characteristics of users and items. Through extensive experiments on real-world datasets, we verify our three claims and hypothesis, and also demonstrate that our approach significantly outperforms existing state-of-the-art approaches.",1.1,0.701310396194458,True,0.401312339887548,0.551311368041003,True
Have you been misinformed?: Computational tools and analysis of our interactions with false and corrective information,"Misinformation has always been part of humankind’s information ecosystem. The development of tools and methods for automatically detecting the reliability of information has received a great deal of attention in recent years, such as calculating the authenticity of images, calculating the likelihood of claims, and assessing the credibility of sources. Unfortunately, there is little evidence that the presence of these advanced technologies or the constant effort of fact-checkers worldwide can help stop the spread of misinformation. I will try to convince you that you also hold various false beliefs, and argue for the need for technologies and processes to assess the information shared by ourselves or by others, over a longer period of time, in order to improve our knowledge of our information credibility and vulnerability, as well as those of the people we listen to. Also, I will describe the benefits, challenges, and risks of automated information corrective actions, both for the target recipients and their wider audience.",1.1,0.7785897850990295,True,0.401312339887548,0.5899510624932888,True
SCStory: Self-supervised and Continual Online Story Discovery,"We present a framework SCStory for online story discovery, that helps people digest rapidly published news article streams in real-time without human annotations. To organize news article streams into stories, existing approaches directly encode the articles and cluster them based on representation similarity. However, these methods yield noisy and inaccurate story discovery results because the generic article embeddings do not effectively reflect the story-indicative semantics in an article and cannot adapt to the rapidly evolving news article streams. SCStory employs self-supervised and continual learning with a novel idea of story-indicative adaptive modeling of news article streams. With a lightweight hierarchical embedding module that first learns sentence representations and then article representations, SCStory identifies story-relevant information of news articles and uses them to discover stories. The embedding module is continuously updated to adapt to evolving news streams with a contrastive learning objective, backed up by two unique techniques, confidence-aware memory replay and prioritized-augmentation, employed for label absence and data scarcity problems. Thorough experiments on real and the latest news data sets demonstrate that SCStory outperforms existing state-of-the-art algorithms for unsupervised online story discovery.",1.0,0.7888504862785339,True,0.3775406687981454,0.5831955775383397,True
SHACL and ShEx in the Wild: A Community Survey on Validating Shapes Generation and Adoption,"Knowledge Graphs (KGs) are widely used to represent heterogeneous domain knowledge on the Web and within organizations. Various methods exist to manage KGs and ensure the quality of their data. Among these, the Shapes Constraint Language (SHACL) and the Shapes Expression Language (ShEx) are the two state-of-the-art languages to define validating shapes for KGs. Since the usage of these constraint languages has recently increased, new needs arose. One such need is to enable the efficient generation of these shapes. Yet, since these languages are relatively new, we witness a lack of understanding of how they are effectively employed for existing KGs. Therefore, in this work, we answer How validating shapes are being generated and adopted? Our contribution is threefold. First, we conducted a community survey to analyze the needs of users (both from industry and academia) generating validating shapes. Then, we cross-referenced our results with an extensive survey of the existing tools and their features. Finally, we investigated how existing automatic shape extraction approaches work in practice on real, large KGs. Our analysis shows the need for developing semi-automatic methods that can help users generate shapes from large KGs.",1.0,0.9338966012001038,True,0.3775406687981454,0.6557186349991246,True
"Extreme Classification: Tagging on Wikipedia, Recommendation on Amazon & Advertising on Bing","I will introduce extreme classi cation which is a new area of machine learning research focusing on multi-class & multi-label problems involving millions of categories. Extreme classification has opened up a new paradigm for thinking about key applications such as tagging, ranking and recommendation. I will discuss algorithms for some of these applications and present results on tagging on Wikipedia, product recommendation on Amazon and search and advertising on the Bing search engine. More details can be found on The Extreme Classification Repository webpage at http://manikvarma.org/downloads/XC/XMLRepository.html",0.8,0.8275136947631836,True,0.3318122278318339,0.5796629612975087,True
The few-get-richer: a surprising consequence of popularity-based rankings?,"Ranking algorithms play a crucial role in online platforms ranging from search engines to recommender systems. In this paper, we identify a surprising consequence of popularity-based rankings: the fewer the items reporting a given signal, the higher the share of the overall traffic they collectively attract. This few-get-richer effect emerges in settings where there are few distinct classes of items (e.g., left-leaning news sources versus right-leaning news sources), and items are ranked based on their popularity. We demonstrate analytically that the few-get-richer effect emerges when people tend to click on top-ranked items and have heterogeneous preferences for the classes of items. Using simulations, we analyze how the strength of the effect changes with assumptions about the setting and human behavior. We also test our predictions experimentally in an online experiment with human participants. Our findings have important implications to understand the spread of misinformation.",1.3,0.9530736207962036,True,0.45016600268752216,0.7016198117418628,True
Knowledge or Gaming?: Cognitive Modelling Based on Multiple-Attempt Response,"Recent decades have witnessed the rapid growth of intelligent tutoring systems (ITS), in which personalized adaptive techniques are successfully employed to improve the learning of each individual student. However, the problem of using cognitive analysis to distill the knowledge and gaming factor from students learning history is still underexplored. To this end, we propose a Knowledge Plus Gaming Response Model (KPGRM) based on multiple-attempt responses. Specifically, we first measure the explicit gaming factor in each multiple-attempt response. Next, we utilise collaborative filtering methods to infer the implicit gaming factor of one-attempt responses. Then we model student learning cognitively by considering both gaming and knowledge factors simultaneously based on a signal detection model. Extensive experiments on two real-world datasets prove that KPGRM can model student learning more effectively as well as obtain a more reasonable analysis.",1.1,0.9252469539642334,True,0.401312339887548,0.6632796469258907,True
Workshop on Web APIs and Service Architecture (WS-REST) Chairs' Welcome & Organization,"Welcome to the 9th International Workshop on Web APIs and Service Architecture (WS-REST). First held in 2010 at WWW in Raleigh, North Carolina, USA, this 2018 edition of the WS-REST Workshop Series is proud to be a part of the renowned WWW conference series in Lyon, France. WS-REST 2018 brings together a community of researcher and practitioners interested in Web APIs and service architecture. Bringing Research and Industry Together In keeping with the history of WS-REST events, the 2018 edition strives to bring together vital content from both the Web Services and REST communities. This year we are hosting two individual tracks (Research and Industry) as a way to continue and strengthen this collaboration between academic and applied experience. The research track submissions received careful peer-review and will be published in the Web Conference proceedings. Industry track submissions focus on field-tested examples and use-cases in the form of extended abstracts or position papers and were selected by the organizers with advice from select program committee members. APIs, Services, and REST APIs have become the connective fabric of the Web and any application area that uses Internet or Web technologies. The goal of WS-REST 2018 is to provide a forum for researchers and practitioners where they can openly and freely exchange ideas about how they are using Web technologies in their APIs, what works and what does not work for them, and what challenges they see in the current landscape of standards and technologies. Our goal is to capture both the state of the art when it comes to Web APIs and service architecture, but to also provide a forum that identifies some of the most pressing issues in that space, and can help solving them.",1.6,0.673216700553894,True,0.52497918747894,0.599097944016417,True
Is Saki #delicious?: The Food Perception Gap on Instagram and Its Relation to Health,"Food is an integral part of our life and what and how much we eat crucially affects our health. Our food choices largely depend on how we perceive certain characteristics of food, such as whether it is healthy, delicious or if it qualifies as a salad. But these perceptions differ from person to person and one person's ""single lettuce leaf"" might be another person's ""side salad"". Studying how food is perceived in relation to what it actually is typically involves a laboratory setup. Here we propose to use recent advances in image recognition to tackle this problem. Concretely, we use data for 1.9 million images from Instagram from the US to look at systematic differences in how a machine would objectively label an image compared to how a human subjectively does. We show that this difference, which we call the ""perception gap"", relates to a number of health outcomes observed at the county level. To the best of our knowledge, this is the first time that image recognition is being used to study the ""misalignment"" of how people describe food images vs. what they actually depict.",1.1,0.8690763115882874,True,0.401312339887548,0.6351943257379177,True
Can You Give Me a Reason?: Argument-inducing Online Forum by Argument Mining,"This demonstration paper presents an argument-inducing online forum that stimulates participants with lack of premises for their claim in online discussions. The proposed forum provides its participants the following two subsystems: (1) Argument estimator for online discussions automatically generates a visualization of the argument structures in posts based on argument mining. The forum indicates structures such as claim-premise relations in real time by exploiting a state-of-the-art deep learning model. (2) Argument-inducing agent for online discussion (AIAD) automatically generates a reply post based on the argument estimator requesting further reasons to improve the argumentation of participants. Our experimental discussion demonstrates that the argument estimator can detect the argument structures from online discussions, and AIAD can induce premises from the participants. To the best of our knowledge, our argument-inducing online forum is the first approach to either visualize or request a real-time argument for online discussions. Our forum can be used to collect and induce claim-reasons pairs rather than only opinions to understand various lines of reasoning in online arguments such as civic discussions, online debates, and education objectives. The argument estimator code is available at https://github.com/EdoFrank/EMNLP2018-ArgMining-Morio and the demonstration video is available at https://youtu.be/T9fNJfneQV8.",1.1,0.9477895498275757,True,0.401312339887548,0.6745509448575618,True
Loops of Humans and Bots in Wikidata,"Wikidata is one of most successful knowledge graphs ever created. It expresses knowledge in the form of subject-property-value statements accompanied by provenance information. A project of the Wikimedia Foundation, Wikidata is supported by a community of currently 19 thousand active users and 234 bots, who together are responsible for editing more than 45 million entities since the start of the project in 2012. This makes Wikidata a prime example for what human-in-the-loop technology can achieve. In this talk, we are going to present several studies that aim to understand the links between its socio-technical fabric and its success.",1.0,0.9199422597885132,True,0.3775406687981454,0.6487414642933294,True
