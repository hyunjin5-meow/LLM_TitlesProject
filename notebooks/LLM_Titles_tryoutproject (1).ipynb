{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5791,
     "status": "ok",
     "timestamp": 1757020203442,
     "user": {
      "displayName": "Jane Oh",
      "userId": "14949100660211267305"
     },
     "user_tz": 240
    },
    "id": "0TeyMWLfdtwS",
    "outputId": "87eb8cf0-ce49-4470-e616-6b4d1757b43b"
   },
   "outputs": [],
   "source": [
    "!pip install gdown pandas\n",
    "import os\n",
    "os.makedirs(\"data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11309,
     "status": "ok",
     "timestamp": 1757020214755,
     "user": {
      "displayName": "Jane Oh",
      "userId": "14949100660211267305"
     },
     "user_tz": 240
    },
    "id": "BCHpcQUGd6d4",
    "outputId": "a25d49bc-2f48-436f-b9ef-85f6f86b3cbb"
   },
   "outputs": [],
   "source": [
    "!gdown --id 1ExuBzkObUNmqgmeaVMF-OqnAuo9yuozK -O data/All_capped_keywords.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34878,
     "status": "ok",
     "timestamp": 1757020249636,
     "user": {
      "displayName": "Jane Oh",
      "userId": "14949100660211267305"
     },
     "user_tz": 240
    },
    "id": "p22kjTsGg7Ue",
    "outputId": "e2793ea0-ec83-48ed-918d-9b87391dcfc4"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"data/All_capped_keywords.zip\", \"r\") as z:\n",
    "    z.extractall(\"data/cspapersum\")\n",
    "    print(\"Extracted files:\", len(z.namelist()))\n",
    "    print(\"Sample files:\", z.namelist()[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1757020249637,
     "user": {
      "displayName": "Jane Oh",
      "userId": "14949100660211267305"
     },
     "user_tz": 240
    },
    "id": "sUdNmZw_g7w0",
    "outputId": "1cfa5563-c65a-49ab-8dd6-ffa3e86d83bf"
   },
   "outputs": [],
   "source": [
    "import glob, pandas as pd\n",
    "\n",
    "csvs = glob.glob(\"data/cspapersum/**/*.csv\", recursive=True)\n",
    "print(\"Found CSVs:\", csvs[:5])\n",
    "\n",
    "for path in csvs:\n",
    "    try:\n",
    "        df = pd.read_csv(path, nrows=3)\n",
    "        print(path, \"→\", df.columns.tolist())\n",
    "    except Exception as e:\n",
    "        print(\"Could not load\", path, e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "executionInfo": {
     "elapsed": 38527,
     "status": "ok",
     "timestamp": 1757020288160,
     "user": {
      "displayName": "Jane Oh",
      "userId": "14949100660211267305"
     },
     "user_tz": 240
    },
    "id": "JdhQOvPaiRkh",
    "outputId": "4a292f41-397d-4ec2-b7a0-60cd7967a460"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/cspapersum/All_capped_keywords.csv\")\n",
    "df = df[['title', 'abstract']]\n",
    "\n",
    "df.to_csv(\"data/titles_abstracts.csv\", index=False)\n",
    "\n",
    "print(\"Saved clean dataset.\")\n",
    "print(\"Number of rows: \", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5358,
     "status": "ok",
     "timestamp": 1757028323314,
     "user": {
      "displayName": "Jane Oh",
      "userId": "14949100660211267305"
     },
     "user_tz": 240
    },
    "id": "lsuo5RwJDGZM",
    "outputId": "48dbee97-1585-40ca-944c-5633b3e26c46"
   },
   "outputs": [],
   "source": [
    "import pandas as pd, os\n",
    "df = pd.read_csv(\"data/titles_abstracts.csv\")\n",
    "print(\"Full size (rows):\", len(df))\n",
    "sample = df.head(1000)                     # adjust if you want\n",
    "sample_path = \"data/titles_abstracts_sample.csv\"\n",
    "sample.to_csv(sample_path, index=False)\n",
    "print(\"Wrote:\", sample_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "executionInfo": {
     "elapsed": 3535,
     "status": "ok",
     "timestamp": 1757022144562,
     "user": {
      "displayName": "Jane Oh",
      "userId": "14949100660211267305"
     },
     "user_tz": 240
    },
    "id": "PR_1sCHbnPYw",
    "outputId": "1f09ee59-ca7e-47c6-bd88-1d762f936666"
   },
   "outputs": [],
   "source": [
    "!pip -q install pandas numpy transformers\n",
    "import re, pandas as pd, numpy as np\n",
    "df = pd.read_csv(\"data/titles_abstracts.csv\")\n",
    "print(len(df), \"rows\"); df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 6000,
     "status": "ok",
     "timestamp": 1757022150570,
     "user": {
      "displayName": "Jane Oh",
      "userId": "14949100660211267305"
     },
     "user_tz": 240
    },
    "id": "FfPSk30UpB6I",
    "outputId": "1e67a95f-aa36-472e-8e95-08c8576f082e"
   },
   "outputs": [],
   "source": [
    "#Heuristic\n",
    "\n",
    "PLAYFUL_WORDS = {\n",
    "    #humor/slang\n",
    "    \"haha\", \"lol\", \"lmao\", \"rofl\", \"silly\", \"goofy\", \"whimsical\", \"jest\", \"chuckle\", \"giggle\", \"smirk\", \"banter\", \"slapstick\", \"sarcasm\", \"wit\", \"irony\", \"satire\", \"parody\", \"observational\", \"cringe\", \"deadpan\", \"absurd\", \"exaggeration\", \"understatement\",\n",
    "    #vibe\n",
    "    \"ridiculously\", \"insanely\", \"super\", \"hella\", \"wicked\", \"terribly\", \"unbelievably\", \"totally\", \"absolutely\", \"so\", \"dead\", \"mad\", \"lowkey\", \"legit\", \"literally\", \"actually\", \"for real\", \"for sure\", \"dude\", \"bro\", \"sick\", \"fire\", \"epic\", \"wild\",\n",
    "    #metaphors / tropes\n",
    "    \"hack\",\"trick\",\"cookbook\",\"recipe\",\"alchemy\",\"wizard\",\"beast\",\"frankenstein\",\n",
    "    \"zoo\",\"odyssey\",\"tales\",\"story\",\"magic\",\"myth\",\"saga\",\"adventures\",\n",
    "    \"to rule them all\", \"the good, the bad\"\n",
    "}\n",
    "\n",
    "PATTERNS = [\n",
    "    re.compile(r\".+:\\s+(?:a|the)\\s+(?:tale|story|odyssey|cookbook)\", re.I),\n",
    "    re.compile(r\"the good, the bad(?:, and the ugly)?\", re.I),\n",
    "    re.compile(r\"to rule (?:them|it) all\", re.I),\n",
    "    re.compile(r\"[;:?!]{2,}\"),                  # multiple ? or !\n",
    "    re.compile(r\"[A-Za-z]+\\s*&\\s*[A-Za-z]+\"),   # “X & Y”\n",
    "    re.compile(r\"\\([^)]{0,30}\\)\"),              # brief parenthetical\n",
    "    re.compile(r\":\\s*\\)\", re.I),                # smiley-ish \": )\"\n",
    "]\n",
    "FORMAL_STARTS = tuple([\"on the\",\"towards\",\"an analysis of\",\"a study of\",\"investigating\",\"notes on\"])\n",
    "\n",
    "def rule_playful_score(title: str) -> float:\n",
    "    t = str(title).strip()\n",
    "    tl = t.lower()\n",
    "    score = 0.0\n",
    "    for w in PLAYFUL_WORDS:\n",
    "        if w in tl: score += 1.0\n",
    "    for p in PATTERNS:\n",
    "        if p.search(t): score += 0.8\n",
    "    if \"!\" in t: score += 0.5\n",
    "    if \"?\" in t: score += 0.3\n",
    "    if tl.startswith(FORMAL_STARTS): score -= 0.8\n",
    "    return round(score, 3)\n",
    "\n",
    "df[\"rule_score\"] = df[\"title\"].astype(str).apply(rule_playful_score)\n",
    "\n",
    "# quick output check\n",
    "df.sort_values(\"rule_score\", ascending=False).head(8)[[\"title\",\"rule_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 79504,
     "status": "ok",
     "timestamp": 1757023756693,
     "user": {
      "displayName": "Jane Oh",
      "userId": "14949100660211267305"
     },
     "user_tz": 240
    },
    "id": "Epnrja0osjun",
    "outputId": "1981931e-4a9f-41e4-80fe-6f2789838626"
   },
   "outputs": [],
   "source": [
    "!pip -q install transformers\n",
    "from transformers import pipeline\n",
    "import torch, numpy as np\n",
    "\n",
    "# Config\n",
    "HAS_GPU    = torch.cuda.is_available()\n",
    "MODEL_NAME = \"facebook/bart-large-mnli\" if HAS_GPU else \"typeform/distilbert-base-uncased-mnli\"\n",
    "DEVICE     = 0 if HAS_GPU else -1\n",
    "BATCH_SIZE = 48 if HAS_GPU else 12\n",
    "\n",
    "LABELS  = [\"playful\", \"neutral\"]\n",
    "HYP     = \"This paper title is {}.\"\n",
    "ZS_THRESH = 0.60\n",
    "USE_CASCADE = True\n",
    "LOW, HIGH   = 0.8, 2.5   # \"maybe\" band for rule_score\n",
    "\n",
    "zs = pipeline(\"zero-shot-classification\", model=MODEL_NAME, device=DEVICE)\n",
    "\n",
    "# Select which titles to score\n",
    "if USE_CASCADE and \"rule_score\" in df.columns:\n",
    "    mask = df[\"rule_score\"].between(LOW, HIGH)\n",
    "    idx = df.index[mask]\n",
    "else:\n",
    "    idx = df.index\n",
    "\n",
    "titles = df.loc[idx, \"title\"].fillna(\"\").astype(str).tolist()\n",
    "if len(titles) == 0:\n",
    "    # Nothing to score (maybe band empty)\n",
    "    if \"zs_playful_prob\" not in df.columns:\n",
    "        df[\"zs_playful_prob\"] = 0.0\n",
    "else:\n",
    "    outs = zs(\n",
    "        titles,\n",
    "        candidate_labels=LABELS,\n",
    "        hypothesis_template=HYP,\n",
    "        multi_label=False,\n",
    "        truncation=True,\n",
    "        batch_size=BATCH_SIZE  # <-- key for speed\n",
    "    )\n",
    "    p_idx = outs[0][\"labels\"].index(\"playful\")\n",
    "    probs = np.array([float(o[\"scores\"][p_idx]) for o in outs], dtype=float)\n",
    "\n",
    "    if len(idx) != len(df):\n",
    "        # cascade: fill only scored rows; others = 0.0\n",
    "        if \"zs_playful_prob\" not in df.columns:\n",
    "            df[\"zs_playful_prob\"] = 0.0\n",
    "        df.loc[idx, \"zs_playful_prob\"] = probs\n",
    "    else:\n",
    "        df[\"zs_playful_prob\"] = probs\n",
    "\n",
    "df[\"playful_zs_flag\"] = df[\"zs_playful_prob\"] >= ZS_THRESH\n",
    "df.sort_values(\"zs_playful_prob\", ascending=False).head(10)[[\"title\",\"zs_playful_prob\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1757024305766,
     "user": {
      "displayName": "Jane Oh",
      "userId": "14949100660211267305"
     },
     "user_tz": 240
    },
    "id": "Wkzd2BOPzU3e",
    "outputId": "60e5b7f8-98a4-4069-9c15-2a695c7d0640"
   },
   "outputs": [],
   "source": [
    "import math, os\n",
    "if \"rule_score\" not in df.columns:\n",
    "    df[\"rule_score\"] = 0.0\n",
    "\n",
    "def squash(x, center=1.5):\n",
    "    return 1 / (1 + math.exp(-(x - center)))  # map rule_score ~ to [0,1]\n",
    "\n",
    "df[\"rule_norm\"] = df[\"rule_score\"].apply(squash)\n",
    "\n",
    "df[\"ensemble_score\"] = 0.5*df[\"rule_norm\"] + 0.5*df[\"zs_playful_prob\"]\n",
    "\n",
    "ENSEMBLE_THRESH = 0.55   # ↑ for precision, ↓ for recall\n",
    "df[\"playful_flag\"] = df[\"ensemble_score\"] >= ENSEMBLE_THRESH\n",
    "\n",
    "# quick stats\n",
    "print(f\"Flagged (ensemble): {df['playful_flag'].mean():.2%} of {len(df)} titles\")\n",
    "\n",
    "# save outputs\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "df[df[\"playful_flag\"]].to_csv(\"results/playful_titles.csv\", index=False)\n",
    "df[~df[\"playful_flag\"]].sample(min(30, (~df[\"playful_flag\"]).sum()), random_state=7)\\\n",
    "  .to_csv(\"results/neutral_title_examples.csv\", index=False)\n",
    "\n",
    "print(\"Saved: results/playful_titles.csv and results/neutral_title_examples.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7442,
     "status": "ok",
     "timestamp": 1757025783890,
     "user": {
      "displayName": "Jane Oh",
      "userId": "14949100660211267305"
     },
     "user_tz": 240
    },
    "id": "u9sM4qsD5Qnm",
    "outputId": "49823b3f-39ac-45e1-c164-df62906ce6e5"
   },
   "outputs": [],
   "source": [
    "!pip -q install -U \"transformers>=4.41,<5\" datasets accelerate rouge-score nltk unidecode\n",
    "\n",
    "import os, re, numpy as np, pandas as pd, torch, nltk\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    ")\n",
    "from rouge_score import rouge_scorer\n",
    "from unidecode import unidecode\n",
    "\n",
    "nltk.download(\"punkt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137,
     "referenced_widgets": [
      "03bf7503e4f847a3b34f152dc55726e4",
      "3fe62f5471e44ebc9d9e524fd7547de0",
      "f4f79f1e98da4adf81084372dc930600",
      "1bd3c60b6b74455fa262fd42e762cf11",
      "57361b3b1d394393847e63738952de61",
      "7ec51ad872af4efbab3a63f9cd67e4af",
      "ef6104d5e479406aae66592088ed14dd",
      "ddd05c69e68e42d597f48f2e493c5156",
      "743e9d9b1edb4db38388b25b7a76c287",
      "ae04d0bc8f034fbfa5644e11e2106a56",
      "6b2875432f724ac3b57adad61ce92424",
      "b5827caeed43456e9bf6ee7270fba512",
      "074439caf1544fd483288c0cd534455a",
      "adb840b2eaaa40658aec70409125b3c8",
      "8bdbb3e11ba240c892155be1adc75979",
      "9edccef30863473e982b6b6cd63b8fae",
      "e2a19db7e429463fa6e8641e8ec6b5b5",
      "48f3a2b7eefb4fcd8a0fc201f42d4d3b",
      "5cc2d8b03c3f42e4b2fd1fa15461b400",
      "c5a059a3fe6a4c4d8c2f884a67b86519",
      "5eae25e90fd343cc8d1b9dc5e92baecf",
      "21cf38b0b07044ce9d3db47e0caa6205"
     ]
    },
    "executionInfo": {
     "elapsed": 56116,
     "status": "ok",
     "timestamp": 1757025840009,
     "user": {
      "displayName": "Jane Oh",
      "userId": "14949100660211267305"
     },
     "user_tz": 240
    },
    "id": "u1nxW4tI5TmS",
    "outputId": "cb7c202c-9bf0-400c-fca8-9f537e5ea010"
   },
   "outputs": [],
   "source": [
    "# Load your clean data\n",
    "df = pd.read_csv(\"data/titles_abstracts.csv\").dropna(subset=[\"abstract\",\"title\"]).copy()\n",
    "\n",
    "def clean(s):\n",
    "    s = unidecode(str(s))\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "df[\"abstract\"] = df[\"abstract\"].apply(clean)\n",
    "df[\"title\"]    = df[\"title\"].apply(clean)\n",
    "\n",
    "# (Optional) keep a manageable subset for the first run\n",
    "MAX_EXAMPLES = min(len(df), 4000)\n",
    "df = df.sample(MAX_EXAMPLES, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split\n",
    "split = int(0.9 * len(df))\n",
    "train_df, valid_df = df.iloc[:split], df.iloc[split:]\n",
    "\n",
    "ds = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df[[\"abstract\",\"title\"]]),\n",
    "    \"validation\": Dataset.from_pandas(valid_df[[\"abstract\",\"title\"]]),\n",
    "})\n",
    "\n",
    "# Tokenization\n",
    "MODEL_NAME = \"google/flan-t5-small\"  # bump to flan-t5-base if you have more VRAM\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "MAX_IN, MAX_OUT = 512, 32\n",
    "PROMPT_PREFIX = \"Write a concise, specific academic paper title for the abstract.\\nAbstract: \"\n",
    "\n",
    "def preprocess(batch):\n",
    "    inputs  = [PROMPT_PREFIX + a for a in batch[\"abstract\"]]\n",
    "    targets = batch[\"title\"]\n",
    "    model_inputs = tok(inputs, max_length=MAX_IN, truncation=True)\n",
    "    with tok.as_target_tokenizer():\n",
    "        labels = tok(targets, max_length=MAX_OUT, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized = ds.map(preprocess, batched=True, remove_columns=[\"abstract\",\"title\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 254268,
     "status": "ok",
     "timestamp": 1757026094280,
     "user": {
      "displayName": "Jane Oh",
      "userId": "14949100660211267305"
     },
     "user_tz": 240
    },
    "id": "NfkK9JTw5VBc",
    "outputId": "4924aa29-e5d7-4160-8727-c626ffb1d132"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "data_collator = DataCollatorForSeq2Seq(tok, model=model)\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"checkpoints/flan_t5_sft\",\n",
    "    per_device_train_batch_size=8,       # lower to 4 if OOM\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=2,\n",
    "    warmup_ratio=0.05,\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2,\n",
    "    fp16=torch.cuda.is_available(),      # mixed precision on GPU\n",
    "    report_to=[],                        # no wandb\n",
    "    # NOTE: we skip evaluation_strategy/eval_steps to avoid version issues.\n",
    "    # We'll evaluate manually right after training.\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],   # present but no auto-eval during training\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tok,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 128899,
     "status": "ok",
     "timestamp": 1757026223192,
     "user": {
      "displayName": "Jane Oh",
      "userId": "14949100660211267305"
     },
     "user_tz": 240
    },
    "id": "Z2ib2Flz5W4d",
    "outputId": "0c3da4b0-3fb1-499b-e468-4629b9aad4b0"
   },
   "outputs": [],
   "source": [
    "# Helper: generate one title\n",
    "def gen_title(abstract, max_new_tokens=32, num_beams=4):\n",
    "    inp = tok(PROMPT_PREFIX + abstract, return_tensors=\"pt\", truncation=True, max_length=MAX_IN).to(model.device)\n",
    "    out = model.generate(**inp, max_new_tokens=32, num_beams=num_beams)\n",
    "    return tok.decode(out[0], skip_special_tokens=True).strip()\n",
    "\n",
    "# Sample N examples from validation\n",
    "N = min(200, len(valid_df))\n",
    "sample = valid_df.head(N).copy()\n",
    "sample[\"gen_title\"] = sample[\"abstract\"].apply(gen_title)\n",
    "\n",
    "# ROUGE-L (rough overlap signal)\n",
    "scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "sample[\"rougeL\"] = sample.apply(lambda r: scorer.score(r[\"title\"], r[\"gen_title\"])[\"rougeL\"].fmeasure, axis=1)\n",
    "\n",
    "print(\"Mean ROUGE-L on sample:\", round(sample[\"rougeL\"].mean(), 3))\n",
    "sample.head(5)[[\"title\",\"gen_title\",\"rougeL\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5923,
     "status": "ok",
     "timestamp": 1757026229108,
     "user": {
      "displayName": "Jane Oh",
      "userId": "14949100660211267305"
     },
     "user_tz": 240
    },
    "id": "tB8Gp0H55Yeo",
    "outputId": "7818b938-3997-4597-cae4-0a9850eb36e0"
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"results\", exist_ok=True)\n",
    "sample.to_csv(\"results/sft_titles_validation_sample.csv\", index=False)\n",
    "trainer.save_model(\"checkpoints/flan_t5_sft/best\")\n",
    "print(\"Saved:\")\n",
    "print(\"- results/sft_titles_validation_sample.csv\")\n",
    "print(\"- checkpoints/flan_t5_sft/best (model + tokenizer)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COVUxlTvJn5M"
   },
   "outputs": [],
   "source": [
    "This cell strips widget metadata and outputs to create a *clean* copy of the notebook\n",
    "so GitHub can render it. It **does not affect any results**. You can ignore it when\n",
    "reading the notebook.\n",
    "\n",
    "To publish: run this cell → it writes a cleaned `.ipynb` which I upload/replace in the repo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpWVJEliJqEy"
   },
   "outputs": [],
   "source": [
    "# Clean a Colab notebook so GitHub can render it (removes metadata.widgets + outputs)\n",
    "!pip -q install nbformat\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import nbformat, glob, os, time, shutil\n",
    "from google.colab import files\n",
    "\n",
    "# 1) Find candidate .ipynb files in Drive (most recent first)\n",
    "cands = sorted(\n",
    "    glob.glob('/content/drive/MyDrive/**/*.ipynb', recursive=True),\n",
    "    key=os.path.getmtime, reverse=True\n",
    ")\n",
    "\n",
    "if not cands:\n",
    "    raise SystemExit(\"No .ipynb found in Drive. Save your notebook to Drive first: File → Save a copy in Drive.\")\n",
    "\n",
    "print(\"Top candidates:\")\n",
    "for i, p in enumerate(cands[:10]):\n",
    "    print(f\"[{i}] {time.ctime(os.path.getmtime(p))}  {p}\")\n",
    "\n",
    "# 2) Pick the most recent (change idx if you want a different one)\n",
    "idx = 0\n",
    "SRC = cands[idx]\n",
    "print(\"\\nUsing:\", SRC)\n",
    "\n",
    "nb = nbformat.read(SRC, as_version=4)\n",
    "\n",
    "# remove notebook-level widgets metadata\n",
    "nb.metadata.pop(\"widgets\", None)\n",
    "\n",
    "# remove cell-level widgets metadata and outputs\n",
    "for cell in nb.cells:\n",
    "    if isinstance(cell.get(\"metadata\"), dict):\n",
    "        cell.metadata.pop(\"widgets\", None)\n",
    "    if cell.get(\"cell_type\") == \"code\":\n",
    "        cell[\"outputs\"] = []\n",
    "        cell[\"execution_count\"] = None\n",
    "\n",
    "clean_name = \"cleaned_\" + os.path.basename(SRC)\n",
    "DST = f\"/content/{clean_name}\"\n",
    "nbformat.write(nb, DST)\n",
    "print(\"Wrote cleaned notebook:\", DST)\n",
    "\n",
    "# 4) Offer download so you can upload to GitHub\n",
    "files.download(DST)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPTkxE/0BU4Pch8UNCybKkl",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
